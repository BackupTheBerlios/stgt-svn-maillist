<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Stgt-svn] r396 - in branches/use-scsi-ml/patchset: . broken-out
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/stgt-svn/2006-April/index.html" >
   <LINK REL="made" HREF="mailto:stgt-svn%40lists.berlios.de?Subject=Re%3A%20%5BStgt-svn%5D%20r396%20-%20in%20branches/use-scsi-ml/patchset%3A%20.%20broken-out&In-Reply-To=%3C200604070134.k371YZkG031752%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000382.html">
   <LINK REL="Next"  HREF="000384.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Stgt-svn] r396 - in branches/use-scsi-ml/patchset: . broken-out</H1>
    <B>tomo at BerliOS</B> 
    <A HREF="mailto:stgt-svn%40lists.berlios.de?Subject=Re%3A%20%5BStgt-svn%5D%20r396%20-%20in%20branches/use-scsi-ml/patchset%3A%20.%20broken-out&In-Reply-To=%3C200604070134.k371YZkG031752%40sheep.berlios.de%3E"
       TITLE="[Stgt-svn] r396 - in branches/use-scsi-ml/patchset: . broken-out">tomo at berlios.de
       </A><BR>
    <I>Fri Apr  7 03:34:35 CEST 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="000382.html">[Stgt-svn] r395 - branches/use-scsi-ml/kernel
</A></li>
        <LI>Next message: <A HREF="000384.html">[Stgt-svn] r397 - branches/use-scsi-ml
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#383">[ date ]</a>
              <a href="thread.html#383">[ thread ]</a>
              <a href="subject.html#383">[ subject ]</a>
              <a href="author.html#383">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tomo
Date: 2006-04-07 03:34:11 +0200 (Fri, 07 Apr 2006)
New Revision: 396

Added:
   branches/use-scsi-ml/patchset/broken-out/
   branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
   branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
   branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
   branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
   branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
   branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
   branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
   branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
   branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
Removed:
   branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt
   branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt
   branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt
   branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt
   branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt
   branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff
   branches/use-scsi-ml/patchset/tmf.diff
Log:
Clean up the patchset directory.


Deleted: branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt
===================================================================
--- branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,347 +0,0 @@
-Subject: [PATCH] scsi-ml: export scsi-ml functions needed by tgt_scsi_lib and its LLDs
-
-This patch contains the needed changes to the scsi-ml to support targets.
-
-Note, per the last review we moved almost all the fields we added
-to the scsi_cmnd to our internal data structure which we are going
-to try and kill off when we can replace it with support from other
-parts of the kernel.
-
-The one field we left on was the offset variable. This is needed to handle
-the case where the target gets request that is so large that it cannot
-execute it in one dma operation. So max_secotors or a segment limit may
-limit the size of the transfer. In this case our tgt core code will
-break up the command into managable transfers and send them to the
-LLD one at a time. The offset is then used to tell the LLD where in
-the command we are at. Is there another field on the scsi_cmd for
-that?
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- drivers/scsi/hosts.c     |    5 +++
- drivers/scsi/scsi.c      |   91 ++++++++++++++++++++++++++++++++++++++++++++++
- drivers/scsi/scsi_lib.c  |   33 ++++++++++++-----
- include/scsi/scsi_cmnd.h |    8 ++++
- include/scsi/scsi_host.h |   40 ++++++++++++++++++++
- 5 files changed, 168 insertions(+), 9 deletions(-)
-
-b7a992fe8af27b25c30fc5e7c36abfe6ebb6fe84
-diff --git a/drivers/scsi/hosts.c b/drivers/scsi/hosts.c
-index 5881079..64e687a 100644
---- a/drivers/scsi/hosts.c
-+++ b/drivers/scsi/hosts.c
-@@ -264,6 +264,11 @@ static void scsi_host_dev_release(struct
- 	if (shost-&gt;work_q)
- 		destroy_workqueue(shost-&gt;work_q);
- 
-+	if (shost-&gt;uspace_req_q) {
-+		kfree(shost-&gt;uspace_req_q-&gt;queuedata);
-+		scsi_free_queue(shost-&gt;uspace_req_q);
-+	}
-+
- 	scsi_destroy_command_freelist(shost);
- 	kfree(shost-&gt;shost_data);
- 
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index 245ca99..a2295ed 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -236,6 +236,58 @@ static struct scsi_cmnd *__scsi_get_comm
- }
- 
- /*
-+ * Function:	scsi_host_get_command()
-+ *
-+ * Purpose:	Allocate and setup a scsi command block and blk request
-+ *
-+ * Arguments:	shost	- scsi host
-+ *		data_dir - dma data dir
-+ *		gfp_mask- allocator flags
-+ *
-+ * Returns:	The allocated scsi command structure.
-+ *
-+ * This should be called by target LLDs to get a command.
-+ */
-+struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *shost,
-+					enum dma_data_direction data_dir,
-+					gfp_t gfp_mask)
-+{
-+	int write = (data_dir == DMA_TO_DEVICE);
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+
-+	/* Bail if we can't get a reference to the device */
-+	if (!get_device(&amp;shost-&gt;shost_gendev))
-+		return NULL;
-+
-+	rq = blk_get_request(shost-&gt;uspace_req_q, write, gfp_mask);
-+	if (!rq)
-+		goto put_dev;
-+
-+	cmd = __scsi_get_command(shost, gfp_mask);
-+	if (!cmd)
-+		goto release_rq;
-+
-+	memset(cmd, 0, sizeof(*cmd));
-+	cmd-&gt;sc_data_direction = data_dir;
-+	cmd-&gt;jiffies_at_alloc = jiffies;
-+	cmd-&gt;request = rq;
-+
-+	rq-&gt;special = cmd;
-+	rq-&gt;flags |= REQ_SPECIAL | REQ_BLOCK_PC;
-+
-+	return cmd;
-+
-+release_rq:
-+	blk_put_request(rq);
-+put_dev:
-+	put_device(&amp;shost-&gt;shost_gendev);
-+	return NULL;
-+
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_get_command);
-+
-+/*
-  * Function:	scsi_get_command()
-  *
-  * Purpose:	Allocate and setup a scsi command block
-@@ -274,6 +326,45 @@ struct scsi_cmnd *scsi_get_command(struc
- EXPORT_SYMBOL(scsi_get_command);
- 
- /*
-+ * Function:	scsi_host_put_command()
-+ *
-+ * Purpose:	Free a scsi command block
-+ *
-+ * Arguments:	shost	- scsi host
-+ * 		cmd	- command block to free
-+ *
-+ * Returns:	Nothing.
-+ *
-+ * Notes:	The command must not belong to any lists.
-+ */
-+void scsi_host_put_command(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
-+{
-+	struct request_queue *q = shost-&gt;uspace_req_q;
-+	struct request *rq = cmd-&gt;request;
-+	unsigned long flags;
-+
-+	/* changing locks here, don't need to restore the irq state */
-+	spin_lock_irqsave(&amp;shost-&gt;free_list_lock, flags);
-+	if (unlikely(list_empty(&amp;shost-&gt;free_list))) {
-+		list_add(&amp;cmd-&gt;list, &amp;shost-&gt;free_list);
-+		cmd = NULL;
-+	}
-+	spin_unlock(&amp;shost-&gt;free_list_lock);
-+
-+	spin_lock(q-&gt;queue_lock);
-+	if (blk_rq_tagged(rq))
-+		blk_queue_end_tag(q, rq);
-+	__blk_put_request(q, rq);
-+	spin_unlock_irqrestore(q-&gt;queue_lock, flags);
-+
-+	if (likely(cmd != NULL))
-+		kmem_cache_free(shost-&gt;cmd_pool-&gt;slab, cmd);
-+
-+	put_device(&amp;shost-&gt;shost_gendev);
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_put_command);
-+
-+/*
-  * Function:	scsi_put_command()
-  *
-  * Purpose:	Free a scsi command block
-diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
-index 4362dcd..7307705 100644
---- a/drivers/scsi/scsi_lib.c
-+++ b/drivers/scsi/scsi_lib.c
-@@ -804,7 +804,7 @@ static struct scsi_cmnd *scsi_end_reques
- 	return NULL;
- }
- 
--static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
- {
- 	struct scsi_host_sg_pool *sgp;
- 	struct scatterlist *sgl;
-@@ -845,7 +845,9 @@ static struct scatterlist *scsi_alloc_sg
- 	return sgl;
- }
- 
--static void scsi_free_sgtable(struct scatterlist *sgl, int index)
-+EXPORT_SYMBOL(scsi_alloc_sgtable);
-+
-+void scsi_free_sgtable(struct scatterlist *sgl, int index)
- {
- 	struct scsi_host_sg_pool *sgp;
- 
-@@ -855,6 +857,8 @@ static void scsi_free_sgtable(struct sca
- 	mempool_free(sgl, sgp-&gt;pool);
- }
- 
-+EXPORT_SYMBOL(scsi_free_sgtable);
-+
- /*
-  * Function:    scsi_release_buffers()
-  *
-@@ -1687,29 +1691,40 @@ u64 scsi_calculate_bounce_limit(struct S
- }
- EXPORT_SYMBOL(scsi_calculate_bounce_limit);
- 
--struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					 request_fn_proc *request_fn)
- {
--	struct Scsi_Host *shost = sdev-&gt;host;
- 	struct request_queue *q;
- 
--	q = blk_init_queue(scsi_request_fn, NULL);
-+	q = blk_init_queue(request_fn, NULL);
- 	if (!q)
- 		return NULL;
- 
--	blk_queue_prep_rq(q, scsi_prep_fn);
--
- 	blk_queue_max_hw_segments(q, shost-&gt;sg_tablesize);
- 	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
- 	blk_queue_max_sectors(q, shost-&gt;max_sectors);
- 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
- 	blk_queue_segment_boundary(q, shost-&gt;dma_boundary);
--	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
--	blk_queue_softirq_done(q, scsi_softirq_done);
- 
- 	if (!shost-&gt;use_clustering)
- 		clear_bit(QUEUE_FLAG_CLUSTER, &amp;q-&gt;queue_flags);
- 	return q;
- }
-+EXPORT_SYMBOL(__scsi_alloc_queue);
-+
-+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+{
-+	struct request_queue *q;
-+
-+	q = __scsi_alloc_queue(sdev-&gt;host, scsi_request_fn);
-+	if (!q)
-+		return NULL;
-+
-+	blk_queue_prep_rq(q, scsi_prep_fn);
-+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
-+	blk_queue_softirq_done(q, scsi_softirq_done);
-+	return q;
-+}
- 
- void scsi_free_queue(struct request_queue *q)
- {
-diff --git a/include/scsi/scsi_cmnd.h b/include/scsi/scsi_cmnd.h
-index 7529f43..51156c7 100644
---- a/include/scsi/scsi_cmnd.h
-+++ b/include/scsi/scsi_cmnd.h
-@@ -8,6 +8,7 @@
- 
- struct request;
- struct scatterlist;
-+struct Scsi_Host;
- struct scsi_device;
- struct scsi_request;
- 
-@@ -84,6 +85,8 @@ struct scsi_cmnd {
- 	unsigned short sglist_len;	/* size of malloc'd scatter-gather list */
- 	unsigned bufflen;	/* Size of data buffer */
- 	void *buffer;		/* Data buffer */
-+	/* offset in cmd we are at (for multi-transfer tgt cmds) */
-+	unsigned offset;
- 
- 	unsigned underflow;	/* Return error if less than
- 				   this amount is transferred */
-@@ -147,9 +150,14 @@ struct scsi_cmnd {
- #define SCSI_STATE_MLQUEUE         0x100b
- 
- 
-+extern struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *,
-+					       enum dma_data_direction, gfp_t);
- extern struct scsi_cmnd *scsi_get_command(struct scsi_device *, gfp_t);
-+extern void scsi_host_put_command(struct Scsi_Host *, struct scsi_cmnd *);
- extern void scsi_put_command(struct scsi_cmnd *);
- extern void scsi_io_completion(struct scsi_cmnd *, unsigned int, unsigned int);
- extern void scsi_finish_command(struct scsi_cmnd *cmd);
-+extern struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *, gfp_t);
-+extern void scsi_free_sgtable(struct scatterlist *, int);
- 
- #endif /* _SCSI_SCSI_CMND_H */
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8279929..8b799db 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -7,6 +7,7 @@
- #include &lt;linux/workqueue.h&gt;
- #include &lt;linux/mutex.h&gt;
- 
-+struct request_queue;
- struct block_device;
- struct completion;
- struct module;
-@@ -123,6 +124,36 @@ struct scsi_host_template {
- 			     void (*done)(struct scsi_cmnd *));
- 
- 	/*
-+	 * The transfer functions are used to queue a scsi command to
-+	 * the LLD. When the driver is finished processing the command
-+	 * the done callback is invoked.
-+	 *
-+	 * return values: see queuecommand
-+	 *
-+	 * If the LLD accepts the cmd, it should set the result to an
-+	 * appropriate value when completed before calling the done function.
-+	 *
-+	 * STATUS: REQUIRED FOR TARGET DRIVERS
-+	 */
-+	/* TODO: rename */
-+	int (* transfer_response)(struct scsi_cmnd *,
-+				  void (*done)(struct scsi_cmnd *));
-+	/*
-+	 * This is called to inform the LLD to transfer cmd-&gt;request_bufflen
-+	 * bytes of the cmd at cmd-&gt;offset in the cmd. The cmd-&gt;use_sg
-+	 * speciefies the number of scatterlist entried in the command
-+	 * and cmd-&gt;request_buffer contains the scatterlist.
-+	 *
-+	 * If the command cannot be processed in one transfer_data call
-+	 * becuase a scatterlist within the LLD's limits cannot be
-+	 * created then transfer_data will be called multiple times.
-+	 * It is initially called from process context, and later
-+	 * calls are from the interrup context.
-+	 */
-+	int (* transfer_data)(struct scsi_cmnd *,
-+			      void (*done)(struct scsi_cmnd *));
-+
-+	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
- 	 * routine that is present that should work in most cases.  For those
-@@ -572,6 +603,12 @@ struct Scsi_Host {
- 	 */
- 	unsigned int max_host_blocked;
- 
-+	/*
-+	 * q used for scsi_tgt msgs, async events or any other requests that
-+	 * need to be processed in userspace
-+ 	 */
-+	struct request_queue *uspace_req_q;
-+
- 	/* legacy crap */
- 	unsigned long base;
- 	unsigned long io_port;
-@@ -674,6 +711,9 @@ extern void scsi_unblock_requests(struct
- extern void scsi_block_requests(struct Scsi_Host *);
- 
- struct class_container;
-+
-+extern struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					     void (*) (struct request_queue *));
- /*
-  * These two functions are used to allocate and free a pseudo device
-  * which will connect to the host adapter itself rather than any
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,45 +0,0 @@
-Subject: [PATCH] block layer: kill length alignment test in bin_map_user
-
-The tgt project is mapping in bios using bio_map_user. The current targets
-do not need their len to be aligned with a queue limit so this check is
-causing some problems.
-
-The major user, blk_bio_map_user checks for the len before mapping
-and is not affected by this patch.
-
-And the semi-newly added user blk_rq_map_user_iov has been failing
-out when the len is not aligned properly so maybe people have been
-good and not sending misaligned lens or that path is not used very
-often and this change will not be very dangerous. st and sg do not
-check the length and we have not seen any problem reports from those
-wider used paths so this patch should be fairly safe - for mm
-and wider testing at least.
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- fs/bio.c |    5 ++---
- 1 files changed, 2 insertions(+), 3 deletions(-)
-
-20ed0ebdd84e1a93550413f487dceaf1ab29a2cd
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..d8259d9 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -620,10 +620,9 @@ static struct bio *__bio_map_user_iov(re
- 
- 		nr_pages += end - start;
- 		/*
--		 * transfer and buffer must be aligned to at least hardsector
--		 * size for now, in the future we can relax this restriction
-+		 * buffer must be aligned to at least hardsector size for now
- 		 */
--		if ((uaddr &amp; queue_dma_alignment(q)) || (len &amp; queue_dma_alignment(q)))
-+		if (uaddr &amp; queue_dma_alignment(q))
- 			return ERR_PTR(-EINVAL);
- 	}
- 
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,148 +0,0 @@
-Subject: [PATCH] block layer: add partial mappings support to bio_map_user
-
-For target mode we could end up with the case where we get very large
-request from the initiator. The request could be so large that we
-cannot transfer all the data in one operation. For example the
-HBA's segment or max_sector limits might limit us to a 1 MB transfer.
-To send a 5 MB command then we need to transfer the command chunk by chunk.
-
-To do this, tgt core will map in as much data as possible into a bio,
-send this off, then when that transfer is completed we send off another
-request/bio. To be able to pack as much data into a bio as possible
-we need bio_map_user to support partially mapped bios.
-
-The attached patch allows bio_map_user to map bios partially. The two
-users (blk_rq_map_user and blk_rq_map_user_iov) will fail if the bio
-is partially mapped.
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- block/ll_rw_blk.c      |   29 ++++++++++++++++++-----------
- block/scsi_ioctl.c     |    3 ++-
- fs/bio.c               |   14 +-------------
- include/linux/blkdev.h |    3 ++-
- 4 files changed, 23 insertions(+), 26 deletions(-)
-
-95e0133e03f75a5edc7ca4eb7ce0c0347cf841bf
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 03d9c82..6849859 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq-&gt;bio = rq-&gt;biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq-&gt;buffer = rq-&gt;data = NULL;
--		rq-&gt;data_len = len;
--		return 0;
-+	if (bio-&gt;bi_size != len) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq-&gt;bio = rq-&gt;biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq-&gt;buffer = rq-&gt;data = NULL;
-+	rq-&gt;data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio-&gt;bi_size != len) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq-&gt;bio = rq-&gt;biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq-&gt;buffer = rq-&gt;data = NULL;
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count,
-+					  hdr-&gt;dxfer_len);
- 		kfree(iov);
- 	} else if (hdr-&gt;dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..f75c2f4 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -750,7 +750,6 @@ struct bio *bio_map_user_iov(request_que
- 			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -765,18 +764,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i &lt; iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio-&gt;bi_size == len)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio-&gt;bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt
===================================================================
--- branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,647 +0,0 @@
-Subject: [PATCH] The core scsi target lib functions.
-
-TODO:
-- mv md/dm-bio-list.h to linux/bio-list.h so md and us do not have to
-do that weird include.
-- convert scsi_tgt_cmd's work struct to James's execute code. And try
-to kill our scsi_tgt_cmd.
-- add host state checking. We do refcouting so hotplug is partially
-supported, but we need to add state checking to make it easier on
-the LLD.
-- make it so the request_queue can be used to pass around these target
-messages better (see todo in code), or maybe just remove request_queue
-usage all together and use our own linked_list or something else.
-We currently use the queue for tag numbers so if we remove the request_queue
-we will have to add some sort of host tag list like was suggested for iscsi.
-We also use the queue to store the HBA limits and build proper sized bios
-and reqeusts so we would need a shell queue like what dm uses.
-- eh handling (still in the process of working on proper state
-model in userspace).
-- must remove our request-&gt;flags hack
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- drivers/scsi/scsi_tgt_lib.c  |  556 ++++++++++++++++++++++++++++++++++++++++++
- drivers/scsi/scsi_tgt_priv.h |   25 ++
- include/scsi/scsi_tgt.h      |   11 +
- 3 files changed, 592 insertions(+), 0 deletions(-)
- create mode 100644 drivers/scsi/scsi_tgt_lib.c
- create mode 100644 drivers/scsi/scsi_tgt_priv.h
- create mode 100644 include/scsi/scsi_tgt.h
-
-ef599065dcacab6ed526d6156a369ed478d595a2
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-new file mode 100644
-index 0000000..4665ce4
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -0,0 +1,556 @@
-+/*
-+ * SCSI target lib functions
-+ *
-+ * Copyright (C) 2005 Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-+ * Copyright (C) 2005 FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">tomof at acm.org</A>&gt;
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#include &lt;linux/blkdev.h&gt;
-+#include &lt;linux/elevator.h&gt;
-+#include &lt;linux/module.h&gt;
-+#include &lt;linux/pagemap.h&gt;
-+#include &lt;scsi/scsi.h&gt;
-+#include &lt;scsi/scsi_cmnd.h&gt;
-+#include &lt;scsi/scsi_device.h&gt;
-+#include &lt;scsi/scsi_host.h&gt;
-+#include &lt;scsi/scsi_tgt.h&gt;
-+#include &lt;../drivers/md/dm-bio-list.h&gt;
-+
-+#include &quot;scsi_tgt_priv.h&quot;
-+
-+static struct workqueue_struct *scsi_tgtd;
-+static kmem_cache_t *scsi_tgt_cmd_cache;
-+
-+/*
-+ * TODO: this struct will be killed when the block layer supports large bios
-+ * and James's work struct code is in
-+ */
-+struct scsi_tgt_cmd {
-+	/* TODO replace work with James b's code */
-+	struct work_struct work;
-+	/* TODO replace the lists with a large bio */
-+	struct bio_list xfer_done_list;
-+	struct bio_list xfer_list;
-+	struct scsi_lun *lun;
-+};
-+
-+static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
-+{
-+	struct bio *bio;
-+
-+	/* must call bio_endio in case bio was bounced */
-+	while ((bio = bio_list_pop(&amp;tcmd-&gt;xfer_done_list))) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+	}
-+
-+	while ((bio = bio_list_pop(&amp;tcmd-&gt;xfer_list))) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+	}
-+}
-+
-+static void scsi_tgt_cmd_destroy(void *data)
-+{
-+	struct scsi_cmnd *cmd = data;
-+	struct scsi_tgt_cmd *tcmd = cmd-&gt;request-&gt;end_io_data;
-+	struct request_queue *q = cmd-&gt;request-&gt;q;
-+
-+	dprintk(&quot;cmd %p %d %lu\n&quot;, cmd, cmd-&gt;sc_data_direction,
-+		rq_data_dir(cmd-&gt;request));
-+	/*
-+	 * We must set rq-&gt;flags here because bio_map_user and
-+	 * blk_rq_bio_prep ruined ti.
-+	 */
-+	if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE)
-+		cmd-&gt;request-&gt;flags |= 1;
-+	else
-+		cmd-&gt;request-&gt;flags &amp;= ~1UL;
-+
-+	scsi_unmap_user_pages(tcmd);
-+	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
-+	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
-+	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
-+	blk_run_queue(q);
-+}
-+
-+static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
-+{
-+	tcmd-&gt;lun = rq-&gt;end_io_data;
-+	bio_list_init(&amp;tcmd-&gt;xfer_list);
-+	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
-+}
-+
-+static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
-+{
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd)
-+		return BLKPREP_DEFER;
-+
-+	init_scsi_tgt_cmd(rq, tcmd);
-+	rq-&gt;end_io_data = tcmd;
-+	rq-&gt;flags |= REQ_DONTPREP;
-+	return BLKPREP_OK;
-+}
-+
-+static void scsi_uspace_request_fn(struct request_queue *q)
-+{
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	/*
-+	 * TODO: just send everthing in the queue to userspace in
-+	 * one vector instead of multiple calls
-+	 */
-+	while ((rq = elv_next_request(q)) != NULL) {
-+		cmd = rq-&gt;special;
-+		tcmd = rq-&gt;end_io_data;
-+
-+		/* the completion code kicks us in case we hit this */
-+		if (blk_queue_start_tag(q, rq)) {
-+			eprintk(&quot;failed to tag: %p\n&quot;, cmd);
-+			break;
-+		}
-+
-+		spin_unlock_irq(q-&gt;queue_lock);
-+		if (scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, GFP_ATOMIC) &lt; 0) {
-+			eprintk(&quot;failed to send: %p\n&quot;, cmd);
-+			goto requeue;
-+		}
-+		spin_lock_irq(q-&gt;queue_lock);
-+	}
-+
-+	return;
-+requeue:
-+	spin_lock_irq(q-&gt;queue_lock);
-+	/* need to track cnts and plug */
-+	blk_requeue_request(q, rq);
-+	spin_unlock_irq(q-&gt;queue_lock);
-+}
-+
-+/**
-+ * scsi_tgt_alloc_queue - setup queue used for message passing
-+ * shost: scsi host
-+ *
-+ * This should be called by the LLD after host allocation.
-+ * And will be released when the host is released.
-+ **/
-+int scsi_tgt_alloc_queue(struct Scsi_Host *shost)
-+{
-+	struct scsi_tgt_queuedata *queuedata;
-+	struct request_queue *q;
-+	int err;
-+
-+	/*
-+	 * Do we need to send a netlink event or should uspace
-+	 * just respond to the hotplug event?
-+	 */
-+	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
-+	if (!q)
-+		return -ENOMEM;
-+
-+	queuedata = kzalloc(sizeof(*queuedata), GFP_KERNEL);
-+	if (!queuedata) {
-+		err = -ENOMEM;
-+		goto cleanup_queue;
-+	}
-+	queuedata-&gt;shost = shost;
-+	q-&gt;queuedata = queuedata;
-+
-+	elevator_exit(q-&gt;elevator);
-+	err = elevator_init(q, &quot;noop&quot;);
-+	if (err)
-+		goto free_data;
-+
-+	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
-+	/*
-+	 * this is a silly hack. We should probably just queue as many
-+	 * command as is recvd to userspace. uspace can then make
-+	 * sure we do not overload the HBA
-+	 */
-+	q-&gt;nr_requests = shost-&gt;hostt-&gt;can_queue * 2;
-+	blk_queue_init_tags(q, q-&gt;nr_requests, NULL);
-+	/*
-+	 * We currently only support software LLDs so this does
-+	 * not matter for now. Do we need this for the cards we support?
-+	 * If so we should make it a host template value.
-+	 */
-+	blk_queue_dma_alignment(q, 0);
-+	shost-&gt;uspace_req_q = q;
-+
-+	return 0;
-+
-+free_data:
-+	kfree(queuedata);
-+cleanup_queue:
-+	blk_cleanup_queue(q);
-+	return err;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_alloc_queue);
-+
-+struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_queuedata *queue = cmd-&gt;request-&gt;q-&gt;queuedata;
-+	return queue-&gt;shost;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
-+
-+/**
-+ * scsi_tgt_queue_command - queue command for userspace processing
-+ * @cmd:	scsi command
-+ * @scsilun:	scsi lun
-+ * @noblock:	set to nonzero if the command should be queued
-+ **/
-+void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-+			    int noblock)
-+{
-+	/*
-+	 * For now this just calls the request_fn from this context.
-+	 * For HW llds though we do not want to execute from here so
-+	 * the elevator code needs something like a REQ_TGT_CMD or
-+	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
-+	 */
-+	cmd-&gt;request-&gt;end_io_data = scsilun;
-+	elv_add_request(cmd-&gt;request-&gt;q, cmd-&gt;request, ELEVATOR_INSERT_BACK, 1);
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
-+
-+/*
-+ * This is run from a interrpt handler normally and the unmap
-+ * needs process context so we must queue
-+ */
-+static void scsi_tgt_cmd_done(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_cmd *tcmd = cmd-&gt;request-&gt;end_io_data;
-+
-+	dprintk(&quot;cmd %p %lu\n&quot;, cmd, rq_data_dir(cmd-&gt;request));
-+
-+	/* don't we have to call this if result is set or not */
-+	if (cmd-&gt;result) {
-+		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
-+		return;
-+	}
-+
-+	INIT_WORK(&amp;tcmd-&gt;work, scsi_tgt_cmd_destroy, cmd);
-+	queue_work(scsi_tgtd, &amp;tcmd-&gt;work);
-+}
-+
-+static int __scsi_tgt_transfer_response(struct scsi_cmnd *cmd)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	int err;
-+
-+	dprintk(&quot;cmd %p %lu\n&quot;, cmd, rq_data_dir(cmd-&gt;request));
-+
-+	err = shost-&gt;hostt-&gt;transfer_response(cmd, scsi_tgt_cmd_done);
-+	switch (err) {
-+	case SCSI_MLQUEUE_HOST_BUSY:
-+	case SCSI_MLQUEUE_DEVICE_BUSY:
-+		return -EAGAIN;
-+	}
-+
-+	return 0;
-+}
-+
-+static void scsi_tgt_transfer_response(struct scsi_cmnd *cmd)
-+{
-+	int err;
-+
-+	err = __scsi_tgt_transfer_response(cmd);
-+	if (!err)
-+		return;
-+
-+	cmd-&gt;result = DID_BUS_BUSY &lt;&lt; 16;
-+	if (scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC) &lt;= 0)
-+		/* the eh will have to pick this up */
-+		printk(KERN_ERR &quot;Could not send cmd %p status\n&quot;, cmd);
-+}
-+
-+static int scsi_tgt_init_cmd(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+{
-+	struct request *rq = cmd-&gt;request;
-+	int count;
-+
-+	cmd-&gt;use_sg = rq-&gt;nr_phys_segments;
-+	cmd-&gt;request_buffer = scsi_alloc_sgtable(cmd, gfp_mask);
-+	if (!cmd-&gt;request_buffer)
-+		return -ENOMEM;
-+
-+	cmd-&gt;request_bufflen = rq-&gt;data_len;
-+
-+	dprintk(&quot;cmd %p addr %p cnt %d %lu\n&quot;, cmd, cmd-&gt;buffer, cmd-&gt;use_sg,
-+		rq_data_dir(rq));
-+	count = blk_rq_map_sg(rq-&gt;q, rq, cmd-&gt;request_buffer);
-+	if (likely(count &lt;= cmd-&gt;use_sg)) {
-+		cmd-&gt;use_sg = count;
-+		return 0;
-+	}
-+
-+	eprintk(&quot;cmd %p addr %p cnt %d\n&quot;, cmd, cmd-&gt;buffer, cmd-&gt;use_sg);
-+	scsi_free_sgtable(cmd-&gt;request_buffer, cmd-&gt;sglist_len);
-+	return -EINVAL;
-+}
-+
-+/* TODO: test this crap and replace bio_map_user with new interface maybe */
-+static int scsi_map_user_pages(struct scsi_tgt_cmd *tcmd, struct scsi_cmnd *cmd,
-+			       int rw)
-+{
-+	struct request_queue *q = cmd-&gt;request-&gt;q;
-+	struct request *rq = cmd-&gt;request;
-+	void *uaddr = cmd-&gt;buffer;
-+	unsigned int len = cmd-&gt;bufflen;
-+	struct bio *bio;
-+	int err;
-+
-+	while (len &gt; 0) {
-+		dprintk(&quot;%lx %u\n&quot;, (unsigned long) uaddr, len);
-+		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
-+		if (IS_ERR(bio)) {
-+			err = PTR_ERR(bio);
-+			dprintk(&quot;fail to map %lx %u %d %x\n&quot;,
-+				(unsigned long) uaddr, len, err, cmd-&gt;cmnd[0]);
-+			goto unmap_bios;
-+		}
-+
-+		uaddr += bio-&gt;bi_size;
-+		len -= bio-&gt;bi_size;
-+
-+		/*
-+		 * The first bio is added and merged. We could probably
-+		 * try to add others using scsi_merge_bio() but for now
-+		 * we keep it simple. The first bio should be pretty large
-+		 * (either hitting the 1 MB bio pages limit or a queue limit)
-+		 * already but for really large IO we may want to try and
-+		 * merge these.
-+		 */
-+		if (!rq-&gt;bio) {
-+			blk_rq_bio_prep(q, rq, bio);
-+			rq-&gt;data_len = bio-&gt;bi_size;
-+		} else
-+			/* put list of bios to transfer in next go around */
-+			bio_list_add(&amp;tcmd-&gt;xfer_list, bio);
-+	}
-+
-+	cmd-&gt;offset = 0;
-+	err = scsi_tgt_init_cmd(cmd, GFP_KERNEL);
-+	if (err)
-+		goto unmap_bios;
-+
-+	return 0;
-+
-+unmap_bios:
-+	if (rq-&gt;bio) {
-+		bio_unmap_user(rq-&gt;bio);
-+		while ((bio = bio_list_pop(&amp;tcmd-&gt;xfer_list)))
-+			bio_unmap_user(bio);
-+	}
-+
-+	return err;
-+}
-+
-+static int scsi_tgt_transfer_data(struct scsi_cmnd *);
-+
-+static void scsi_tgt_data_transfer_done(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_cmd *tcmd = cmd-&gt;request-&gt;end_io_data;
-+	struct bio *bio;
-+	int err;
-+
-+	/* should we free resources here on error ? */
-+	if (cmd-&gt;result) {
-+send_uspace_err:
-+		if (scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC) &lt;= 0)
-+			/* the tgt uspace eh will have to pick this up */
-+			printk(KERN_ERR &quot;Could not send cmd %p status\n&quot;, cmd);
-+		return;
-+	}
-+
-+	dprintk(&quot;cmd %p request_bufflen %u bufflen %u\n&quot;,
-+		cmd, cmd-&gt;request_bufflen, cmd-&gt;bufflen);
-+
-+	scsi_free_sgtable(cmd-&gt;request_buffer, cmd-&gt;sglist_len);
-+	bio_list_add(&amp;tcmd-&gt;xfer_done_list, cmd-&gt;request-&gt;bio);
-+
-+	cmd-&gt;buffer += cmd-&gt;request_bufflen;
-+	cmd-&gt;offset += cmd-&gt;request_bufflen;
-+
-+	if (!tcmd-&gt;xfer_list.head) {
-+		scsi_tgt_transfer_response(cmd);
-+		return;
-+	}
-+
-+	dprintk(&quot;cmd2 %p request_bufflen %u bufflen %u\n&quot;,
-+		cmd, cmd-&gt;request_bufflen, cmd-&gt;bufflen);
-+
-+	bio = bio_list_pop(&amp;tcmd-&gt;xfer_list);
-+	BUG_ON(!bio);
-+
-+	blk_rq_bio_prep(cmd-&gt;request-&gt;q, cmd-&gt;request, bio);
-+	cmd-&gt;request-&gt;data_len = bio-&gt;bi_size;
-+	err = scsi_tgt_init_cmd(cmd, GFP_ATOMIC);
-+	if (err) {
-+		cmd-&gt;result = DID_ERROR &lt;&lt; 16;
-+		goto send_uspace_err;
-+	}
-+
-+	if (scsi_tgt_transfer_data(cmd)) {
-+		cmd-&gt;result = DID_NO_CONNECT &lt;&lt; 16;
-+		goto send_uspace_err;
-+	}
-+}
-+
-+static int scsi_tgt_transfer_data(struct scsi_cmnd *cmd)
-+{
-+	int err;
-+	struct Scsi_Host *host = scsi_tgt_cmd_to_host(cmd);
-+
-+	err = host-&gt;hostt-&gt;transfer_data(cmd, scsi_tgt_data_transfer_done);
-+	switch (err) {
-+		case SCSI_MLQUEUE_HOST_BUSY:
-+		case SCSI_MLQUEUE_DEVICE_BUSY:
-+			return -EAGAIN;
-+	default:
-+		return 0;
-+	}
-+}
-+
-+static int scsi_tgt_copy_sense(struct scsi_cmnd *cmd, unsigned long uaddr,
-+				unsigned len)
-+{
-+	char __user *p = (char __user *) uaddr;
-+
-+	if (copy_from_user(cmd-&gt;sense_buffer, p,
-+			   min_t(unsigned, SCSI_SENSE_BUFFERSIZE, len))) {
-+		printk(KERN_ERR &quot;Could not copy the sense buffer\n&quot;);
-+		return -EIO;
-+	}
-+	return 0;
-+}
-+
-+int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+			 unsigned long uaddr, u8 rw)
-+{
-+	struct Scsi_Host *shost;
-+	struct scsi_cmnd *cmd;
-+	struct request *rq;
-+	int err = 0;
-+
-+	dprintk(&quot;%d %u %d %u %lx %u\n&quot;, host_no, cid, result,
-+		len, uaddr, rw);
-+
-+	/* TODO: replace with a O(1) alg */
-+	shost = scsi_host_lookup(host_no);
-+	if (IS_ERR(shost)) {
-+		printk(KERN_ERR &quot;Could not find host no %d\n&quot;, host_no);
-+		return -EINVAL;
-+	}
-+
-+	rq = blk_queue_find_tag(shost-&gt;uspace_req_q, cid);
-+	if (!rq) {
-+		printk(KERN_ERR &quot;Could not find cid %u\n&quot;, cid);
-+		err = -EINVAL;
-+		goto done;
-+	}
-+	cmd = rq-&gt;special;
-+
-+	dprintk(&quot;cmd %p result %d len %d bufflen %u %lu %x\n&quot;, cmd,
-+		result, len, cmd-&gt;request_bufflen, rq_data_dir(rq), cmd-&gt;cmnd[0]);
-+
-+	/*
-+	 * store the userspace values here, the working values are
-+	 * in the request_* values
-+	 */
-+	cmd-&gt;buffer = (void *)uaddr;
-+	if (len)
-+		cmd-&gt;bufflen = len;
-+	cmd-&gt;result = result;
-+
-+	if (!cmd-&gt;bufflen) {
-+		err = __scsi_tgt_transfer_response(cmd);
-+		goto done;
-+	}
-+
-+	/*
-+	 * TODO: Do we need to handle case where request does not
-+	 * align with LLD.
-+	 */
-+	err = scsi_map_user_pages(rq-&gt;end_io_data, cmd, rw);
-+	if (err) {
-+		eprintk(&quot;%p %d\n&quot;, cmd, err);
-+		err = -EAGAIN;
-+		goto done;
-+	}
-+
-+	/* userspace failure */
-+	if (cmd-&gt;result) {
-+		if (status_byte(cmd-&gt;result) == CHECK_CONDITION)
-+			scsi_tgt_copy_sense(cmd, uaddr, len);
-+		err = __scsi_tgt_transfer_response(cmd);
-+		goto done;
-+	}
-+	/* ask the target LLD to transfer the data to the buffer */
-+	err = scsi_tgt_transfer_data(cmd);
-+
-+done:
-+	scsi_host_put(shost);
-+	return err;
-+}
-+
-+static int __init scsi_tgt_init(void)
-+{
-+	int err;
-+
-+	scsi_tgt_cmd_cache = kmem_cache_create(&quot;scsi_tgt_cmd&quot;,
-+					       sizeof(struct scsi_tgt_cmd),
-+					       0, 0, NULL, NULL);
-+	if (!scsi_tgt_cmd_cache)
-+		return -ENOMEM;
-+
-+	scsi_tgtd = create_workqueue(&quot;scsi_tgtd&quot;);
-+	if (!scsi_tgtd) {
-+		err = -ENOMEM;
-+		goto free_kmemcache;
-+	}
-+
-+	err = scsi_tgt_if_init();
-+	if (err)
-+		goto destroy_wq;
-+
-+	return 0;
-+
-+destroy_wq:
-+	destroy_workqueue(scsi_tgtd);
-+free_kmemcache:
-+	kmem_cache_destroy(scsi_tgt_cmd_cache);
-+	return err;
-+}
-+
-+static void __exit scsi_tgt_exit(void)
-+{
-+	destroy_workqueue(scsi_tgtd);
-+	scsi_tgt_if_exit();
-+	kmem_cache_destroy(scsi_tgt_cmd_cache);
-+}
-+
-+module_init(scsi_tgt_init);
-+module_exit(scsi_tgt_exit);
-+
-+MODULE_DESCRIPTION(&quot;SCSI target core&quot;);
-+MODULE_LICENSE(&quot;GPL&quot;);
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-new file mode 100644
-index 0000000..fcf2ec6
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -0,0 +1,25 @@
-+struct scsi_cmnd;
-+struct scsi_lun;
-+struct Scsi_Host;
-+struct task_struct;
-+
-+/* tmp - will replace with SCSI logging stuff */
-+#define dprintk(fmt, args...)					\
-+do {								\
-+	printk(&quot;%s(%d) &quot; fmt, __FUNCTION__, __LINE__, ##args);	\
-+} while (0)
-+
-+#define eprintk dprintk
-+
-+struct scsi_tgt_queuedata {
-+	struct Scsi_Host *shost;
-+};
-+
-+extern void scsi_tgt_if_exit(void);
-+extern int scsi_tgt_if_init(void);
-+
-+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
-+extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
-+extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+				unsigned long uaddr, u8 rw);
-+
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-new file mode 100644
-index 0000000..91ad6bc
---- /dev/null
-+++ b/include/scsi/scsi_tgt.h
-@@ -0,0 +1,11 @@
-+/*
-+ * SCSI target definitions
-+ */
-+
-+struct Scsi_Host;
-+struct scsi_cmnd;
-+struct scsi_lun;
-+
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt
===================================================================
--- branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,351 +0,0 @@
-Subject: [PATCH] Netlink interface for the scsi tgt framework.
-
-I did not think the netdev people wanted to see the scsi and
-block layer code, so I am just send the netlink interface part
-of this patchset to netdev. I can resend the other parts if
-needed.
-
-The scsi tgt framework, adds support for scsi target mode
-cards. So instead of using the scsi card in your box as a initiator
-you can use it as a target/server.
-
-The reason of the netlink use is becuase the target normally
-recieve a interrupt indicating that command or event is
-ready to be processed. The scsi card's driver will then call
-a scsi lib function which eventually calls scsi_tgt_uspace_send to
-tell userspace to begin to process the request (userspace contains
-the state model). Later userspace will call back into the kernel
-be sending a netlink msg, and instruct the scsi driver what to do next.
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- drivers/scsi/scsi_tgt_if.c |  205 ++++++++++++++++++++++++++++++++++++++++++++
- include/linux/netlink.h    |    1 
- include/scsi/scsi_tgt_if.h |   88 +++++++++++++++++++
- 3 files changed, 294 insertions(+), 0 deletions(-)
- create mode 100644 drivers/scsi/scsi_tgt_if.c
- create mode 100644 include/scsi/scsi_tgt_if.h
-
-5e0ec5395f282e9dd5802940046eb0f3cdfdbec5
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-new file mode 100644
-index 0000000..0780e3c
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -0,0 +1,205 @@
-+/*
-+ * SCSI target kernel/user interface functions
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">tomof at acm.org</A>&gt;
-+ * Copyright (C) 2005 Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#include &lt;linux/blkdev.h&gt;
-+#include &lt;linux/file.h&gt;
-+#include &lt;linux/netlink.h&gt;
-+#include &lt;net/tcp.h&gt;
-+#include &lt;scsi/scsi.h&gt;
-+#include &lt;scsi/scsi_cmnd.h&gt;
-+#include &lt;scsi/scsi_device.h&gt;
-+#include &lt;scsi/scsi_host.h&gt;
-+#include &lt;scsi/scsi_tgt.h&gt;
-+#include &lt;scsi/scsi_tgt_if.h&gt;
-+
-+#include &quot;scsi_tgt_priv.h&quot;
-+
-+static int tgtd_pid;
-+static struct sock *nl_sk;
-+
-+static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
-+			  pid_t pid)
-+{
-+	struct tgt_event *ev;
-+	struct nlmsghdr *nlh;
-+	struct sk_buff *skb;
-+	uint32_t len;
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
-+	skb = alloc_skb(len, flags);
-+	if (!skb)
-+		return -ENOMEM;
-+
-+	nlh = __nlmsg_put(skb, pid, 0, type, len - sizeof(*nlh), 0);
-+
-+	ev = NLMSG_DATA(nlh);
-+	memcpy(ev, p, sizeof(*ev));
-+
-+	return netlink_unicast(nl_sk, skb, pid, 0);
-+}
-+
-+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	struct sk_buff *skb;
-+	struct nlmsghdr *nlh;
-+	struct tgt_event *ev;
-+	int err, len;
-+
-+	/* FIXME: we need scsi core to do that. */
-+	memcpy(cmd-&gt;cmnd, cmd-&gt;data_cmnd, MAX_COMMAND_SIZE);
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
-+	/*
-+	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
-+	 */
-+	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
-+	if (!skb)
-+		return -ENOMEM;
-+
-+	nlh = __nlmsg_put(skb, tgtd_pid, 0, TGT_KEVENT_CMD_REQ,
-+			  len - sizeof(*nlh), 0);
-+
-+	ev = NLMSG_DATA(nlh);
-+	ev-&gt;k.cmd_req.host_no = shost-&gt;host_no;
-+	ev-&gt;k.cmd_req.cid = cmd-&gt;request-&gt;tag;
-+	ev-&gt;k.cmd_req.data_len = cmd-&gt;request_bufflen;
-+	memcpy(ev-&gt;k.cmd_req.scb, cmd-&gt;cmnd, sizeof(ev-&gt;k.cmd_req.scb));
-+	memcpy(ev-&gt;k.cmd_req.lun, lun, sizeof(ev-&gt;k.cmd_req.lun));
-+	ev-&gt;k.cmd_req.attribute = cmd-&gt;tag;
-+
-+	dprintk(&quot;%p %d %u %u %x\n&quot;, cmd, shost-&gt;host_no, ev-&gt;k.cmd_req.cid,
-+		ev-&gt;k.cmd_req.data_len, cmd-&gt;tag);
-+
-+	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
-+	if (err &lt; 0)
-+		eprintk(KERN_ERR &quot;could not send skb %d\n&quot;, err);
-+	return err;
-+}
-+
-+int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	struct tgt_event ev;
-+
-+	memset(&amp;ev, 0, sizeof(ev));
-+	ev.k.cmd_done.host_no = shost-&gt;host_no;
-+	ev.k.cmd_done.cid = cmd-&gt;request-&gt;tag;
-+	ev.k.cmd_done.result = cmd-&gt;result;
-+
-+	return send_event_rsp(TGT_KEVENT_CMD_DONE, &amp;ev, gfp_mask, tgtd_pid);
-+}
-+
-+static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
-+{
-+	struct tgt_event *ev = NLMSG_DATA(nlh);
-+	int err = 0;
-+
-+	dprintk(&quot;%d %d %d\n&quot;, nlh-&gt;nlmsg_type,
-+		nlh-&gt;nlmsg_pid, current-&gt;pid);
-+
-+	switch (nlh-&gt;nlmsg_type) {
-+	case TGT_UEVENT_REQ:
-+		tgtd_pid = NETLINK_CREDS(skb)-&gt;pid;
-+		break;
-+	case TGT_UEVENT_CMD_RSP:
-+		/* TODO: handle multiple cmds in one event */
-+		err = scsi_tgt_kspace_exec(ev-&gt;u.cmd_rsp.host_no,
-+					   ev-&gt;u.cmd_rsp.cid,
-+					   ev-&gt;u.cmd_rsp.result,
-+					   ev-&gt;u.cmd_rsp.len,
-+					   ev-&gt;u.cmd_rsp.uaddr,
-+					   ev-&gt;u.cmd_rsp.rw);
-+		break;
-+	default:
-+		eprintk(&quot;unknown type %d\n&quot;, nlh-&gt;nlmsg_type);
-+		err = -EINVAL;
-+	}
-+
-+	return err;
-+}
-+
-+static int event_recv_skb(struct sk_buff *skb)
-+{
-+	int err;
-+	uint32_t rlen;
-+	struct nlmsghdr	*nlh;
-+
-+	while (skb-&gt;len &gt;= NLMSG_SPACE(0)) {
-+		nlh = (struct nlmsghdr *) skb-&gt;data;
-+		if (nlh-&gt;nlmsg_len &lt; sizeof(*nlh) || skb-&gt;len &lt; nlh-&gt;nlmsg_len)
-+			return 0;
-+		rlen = NLMSG_ALIGN(nlh-&gt;nlmsg_len);
-+		if (rlen &gt; skb-&gt;len)
-+			rlen = skb-&gt;len;
-+		err = event_recv_msg(skb, nlh);
-+
-+		dprintk(&quot;%d %d\n&quot;, nlh-&gt;nlmsg_type, err);
-+		/*
-+		 * TODO for passthru commands the lower level should
-+		 * probably handle the result or we should modify this
-+		 */
-+		if (nlh-&gt;nlmsg_type != TGT_UEVENT_CMD_RSP) {
-+			struct tgt_event ev;
-+
-+			memset(&amp;ev, 0, sizeof(ev));
-+			ev.k.event_rsp.err = err;
-+			send_event_rsp(TGT_KEVENT_RSP, &amp;ev,
-+				       GFP_KERNEL | __GFP_NOFAIL,
-+					nlh-&gt;nlmsg_pid);
-+		}
-+		skb_pull(skb, rlen);
-+	}
-+	return 0;
-+}
-+
-+static void event_recv(struct sock *sk, int length)
-+{
-+	struct sk_buff *skb;
-+
-+	while ((skb = skb_dequeue(&amp;sk-&gt;sk_receive_queue))) {
-+		if (NETLINK_CREDS(skb)-&gt;uid) {
-+			skb_pull(skb, skb-&gt;len);
-+			kfree_skb(skb);
-+			continue;
-+		}
-+
-+		if (event_recv_skb(skb) &amp;&amp; skb-&gt;len)
-+			skb_queue_head(&amp;sk-&gt;sk_receive_queue, skb);
-+		else
-+			kfree_skb(skb);
-+	}
-+}
-+
-+void __exit scsi_tgt_if_exit(void)
-+{
-+	sock_release(nl_sk-&gt;sk_socket);
-+}
-+
-+int __init scsi_tgt_if_init(void)
-+{
-+	nl_sk = netlink_kernel_create(NETLINK_TGT, 1, event_recv,
-+				    THIS_MODULE);
-+	if (!nl_sk)
-+		return -ENOMEM;
-+
-+	return 0;
-+}
-diff --git a/include/linux/netlink.h b/include/linux/netlink.h
-index c256ebe..9422ae5 100644
---- a/include/linux/netlink.h
-+++ b/include/linux/netlink.h
-@@ -21,6 +21,7 @@
- #define NETLINK_DNRTMSG		14	/* DECnet routing messages */
- #define NETLINK_KOBJECT_UEVENT	15	/* Kernel messages to userspace */
- #define NETLINK_GENERIC		16
-+#define NETLINK_TGT		17	/* SCSI target */
- 
- #define MAX_LINKS 32		
- 
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-new file mode 100644
-index 0000000..ebca452
---- /dev/null
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -0,0 +1,88 @@
-+/*
-+ * SCSI target kernel/user interface
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">tomof at acm.org</A>&gt;
-+ * Copyright (C) 2005 Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#ifndef __SCSI_TARGET_IF_H
-+#define __SCSI_TARGET_IF_H
-+
-+enum tgt_event_type {
-+	/* user -&gt; kernel */
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
-+
-+	/* kernel -&gt; user */
-+	TGT_KEVENT_RSP,
-+	TGT_KEVENT_CMD_REQ,
-+	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
-+};
-+
-+struct tgt_event {
-+	/* user-&gt; kernel */
-+	union {
-+		struct {
-+			int type;
-+			int host_no;
-+		} event_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t len;
-+			int result;
-+			uint64_t uaddr;
-+			uint8_t rw;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			int mid;
-+			int result;
-+		} tsk_mgmt_rsp;
-+	} u;
-+
-+	/* kernel -&gt; user */
-+	union {
-+		struct {
-+			int err;
-+		} event_rsp;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t data_len;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
-+		} cmd_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			int result;
-+		} cmd_done;
-+		struct {
-+			int host_no;
-+			int mid;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			int function;
-+		} tsk_mgmt_req;
-+	} k;
-+
-+} __attribute__ ((aligned (sizeof(uint64_t))));
-+#endif
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt
===================================================================
--- branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,55 +0,0 @@
-Subject: [PATCH] scsi-ml: Makefile and Kconfig changes for stgt
-
-Makefile and Kconfig stuff.
-
-Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
-
----
-
- drivers/scsi/Kconfig  |    7 +++++++
- drivers/scsi/Makefile |    3 +++
- 2 files changed, 10 insertions(+), 0 deletions(-)
-
-f7a32ccf6c93402cf70e29c3ea45aeee15ea64cb
-diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
-index 3c606cf..d09c792 100644
---- a/drivers/scsi/Kconfig
-+++ b/drivers/scsi/Kconfig
-@@ -27,6 +27,13 @@ config SCSI
- 	  However, do not compile this as a module if your root file system
- 	  (the one containing the directory /) is located on a SCSI device.
- 
-+config SCSI_TGT
-+	tristate &quot;SCSI target support&quot;
-+	depends on SCSI &amp;&amp; EXPERIMENTAL
-+	---help---
-+	  If you want to use SCSI target mode drivers enable this option.
-+	  If you choose M, the module will be called scsi_tgt.
-+
- config SCSI_PROC_FS
- 	bool &quot;legacy /proc/scsi/ support&quot;
- 	depends on SCSI &amp;&amp; PROC_FS
-diff --git a/drivers/scsi/Makefile b/drivers/scsi/Makefile
-index 320e765..3d81b8d 100644
---- a/drivers/scsi/Makefile
-+++ b/drivers/scsi/Makefile
-@@ -21,6 +21,7 @@ CFLAGS_seagate.o =   -DARBITRATE -DPARIT
- subdir-$(CONFIG_PCMCIA)		+= pcmcia
- 
- obj-$(CONFIG_SCSI)		+= scsi_mod.o
-+obj-$(CONFIG_SCSI_TGT)		+= scsi_tgt.o
- 
- obj-$(CONFIG_RAID_ATTRS)	+= raid_class.o
- 
-@@ -155,6 +156,8 @@ scsi_mod-y			+= scsi.o hosts.o scsi_ioct
- scsi_mod-$(CONFIG_SYSCTL)	+= scsi_sysctl.o
- scsi_mod-$(CONFIG_SCSI_PROC_FS)	+= scsi_proc.o
- 
-+scsi_tgt-y			+= scsi_tgt_lib.o scsi_tgt_if.o
-+
- sd_mod-objs	:= sd.o
- sr_mod-objs	:= sr.o sr_ioctl.o sr_vendor.o
- ncr53c8xx-flags-$(CONFIG_SCSI_ZALON) \
--- 
-1.1.5

Added: branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,130 @@
+Subject: [PATCH] block layer: revoke the original patch to add partial mappings support
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409079 +0900
+
+For target mode we could end up with the case where we get very large
+request from the initiator. The request could be so large that we
+cannot transfer all the data in one operation. For example the
+HBA's segment or max_sector limits might limit us to a 1 MB transfer.
+To send a 5 MB command then we need to transfer the command chunk by chunk.
+
+To do this, tgt core will map in as much data as possible into a bio,
+send this off, then when that transfer is completed we send off another
+request/bio. To be able to pack as much data into a bio as possible
+we need bio_map_user to support partially mapped bios.
+
+Following the comments from Jens Axboe on the original patch:
+
+<A HREF="http://marc.theaimsgroup.com/?l=linux-scsi&amp;m=114012008928530&amp;w=2">http://marc.theaimsgroup.com/?l=linux-scsi&amp;m=114012008928530&amp;w=2</A>
+
+This patch will revoke changes by the original patch.
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ block/ll_rw_blk.c   |    5 ++---
+ fs/bio.c            |   11 ++++-------
+ include/linux/bio.h |    5 ++---
+ 3 files changed, 8 insertions(+), 13 deletions(-)
+
+4d84a7a7218de12ef1e3f58a0a5514a730994848
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..03d9c82 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2287,7 +2287,7 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	 */
+ 	uaddr = (unsigned long) ubuf;
+ 	if (!(uaddr &amp; queue_dma_alignment(q)) &amp;&amp; !(len &amp; queue_dma_alignment(q)))
+-		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
++		bio = bio_map_user(q, NULL, uaddr, len, reading);
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+@@ -2339,8 +2339,7 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	/* we don't allow misaligned data like bio_map_user() does.  If the
+ 	 * user is using sg, they're expected to know the alignment constraints
+ 	 * and respect them accordingly */
+-	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
+-				0);
++	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
+diff --git a/fs/bio.c b/fs/bio.c
+index 3e940c9..d8259d9 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
+  *	@uaddr: start of user address
+  *	@len: length in bytes
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
+-			 unsigned long uaddr, unsigned int len, int write_to_vm,
+-			 int support_partial)
++			 unsigned long uaddr, unsigned int len, int write_to_vm)
+ {
+ 	struct sg_iovec iov;
+ 
+ 	iov.iov_base = (void __user *)uaddr;
+ 	iov.iov_len = len;
+ 
+-	return bio_map_user_iov(q, bdev, &amp;iov, 1, write_to_vm, support_partial);
++	return bio_map_user_iov(q, bdev, &amp;iov, 1, write_to_vm);
+ }
+ 
+ /**
+@@ -742,14 +740,13 @@ struct bio *bio_map_user(request_queue_t
+  *	@iov:	the iovec.
+  *	@iov_count: number of elements in the iovec
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
+ 			     struct sg_iovec *iov, int iov_count,
+-			     int write_to_vm, int support_partial)
++			     int write_to_vm)
+ {
+ 	struct bio *bio;
+ 	int len = 0, i;
+@@ -770,7 +767,7 @@ struct bio *bio_map_user_iov(request_que
+ 	for (i = 0; i &lt; iov_count; i++)
+ 		len += iov[i].iov_len;
+ 
+-	if (bio-&gt;bi_size == len || support_partial)
++	if (bio-&gt;bi_size == len)
+ 		return bio;
+ 
+ 	/*
+diff --git a/include/linux/bio.h b/include/linux/bio.h
+index fc0906c..b60ffe3 100644
+--- a/include/linux/bio.h
++++ b/include/linux/bio.h
+@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
+ extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
+ 			   unsigned int, unsigned int);
+ extern int bio_get_nr_vecs(struct block_device *);
+-extern int __bio_get_nr_vecs(struct request_queue *);
+ extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
+-				unsigned long, unsigned int, int, int);
++				unsigned long, unsigned int, int);
+ struct sg_iovec;
+ extern struct bio *bio_map_user_iov(struct request_queue *,
+ 				    struct block_device *,
+-				    struct sg_iovec *, int, int, int);
++				    struct sg_iovec *, int, int);
+ extern void bio_unmap_user(struct bio *);
+ extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
+ 				gfp_t);
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,149 @@
+Subject: [PATCH] block layer: add partial mappings support to bio_map_user
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409163 +0900
+
+This is the updated patch for partial mappings support.
+
+- bio_map_user_iov always allows partial mappings.
+
+- The two users (blk_rq_map_user and blk_rq_map_user_iov) will fails
+if the bio is partially mapped.
+
+- Added a length argument to blk_rq_map_user_iov in order to avoid
+including sg.h in ll_rw_blk.c for struct sg_iovec.
+
+This is a resend:
+
+<A HREF="http://marc.theaimsgroup.com/?l=linux-scsi&amp;m=114086655400806&amp;w=2">http://marc.theaimsgroup.com/?l=linux-scsi&amp;m=114086655400806&amp;w=2</A>
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ block/ll_rw_blk.c      |   29 ++++++++++++++++++-----------
+ block/scsi_ioctl.c     |    3 ++-
+ fs/bio.c               |   14 +-------------
+ include/linux/blkdev.h |    3 ++-
+ 4 files changed, 23 insertions(+), 26 deletions(-)
+
+d43dcc5c747b5896c795e1fe1f8a6d5df525daa6
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 03d9c82..6849859 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+-	if (!IS_ERR(bio)) {
+-		rq-&gt;bio = rq-&gt;biotail = bio;
+-		blk_rq_bio_prep(q, rq, bio);
++	if (IS_ERR(bio))
++		return PTR_ERR(bio);
+ 
+-		rq-&gt;buffer = rq-&gt;data = NULL;
+-		rq-&gt;data_len = len;
+-		return 0;
++	if (bio-&gt;bi_size != len) {
++		bio_endio(bio, bio-&gt;bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
+ 	}
+ 
+-	/*
+-	 * bio is the err-ptr
+-	 */
+-	return PTR_ERR(bio);
++	rq-&gt;bio = rq-&gt;biotail = bio;
++	blk_rq_bio_prep(q, rq, bio);
++	rq-&gt;buffer = rq-&gt;data = NULL;
++	rq-&gt;data_len = len;
++	return 0;
+ }
+ 
+ EXPORT_SYMBOL(blk_rq_map_user);
+@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
+  *    unmapping.
+  */
+ int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
+-			struct sg_iovec *iov, int iov_count)
++			struct sg_iovec *iov, int iov_count, unsigned int len)
+ {
+ 	struct bio *bio;
+ 
+@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
++	if (bio-&gt;bi_size != len) {
++		bio_endio(bio, bio-&gt;bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
++	}
++
+ 	rq-&gt;bio = rq-&gt;biotail = bio;
+ 	blk_rq_bio_prep(q, rq, bio);
+ 	rq-&gt;buffer = rq-&gt;data = NULL;
+diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
+index 24f7af9..ef9900d 100644
+--- a/block/scsi_ioctl.c
++++ b/block/scsi_ioctl.c
+@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
+ 			goto out;
+ 		}
+ 
+-		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count);
++		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count,
++					  hdr-&gt;dxfer_len);
+ 		kfree(iov);
+ 	} else if (hdr-&gt;dxfer_len)
+ 		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
+diff --git a/fs/bio.c b/fs/bio.c
+index d8259d9..f51a873 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -749,7 +749,6 @@ struct bio *bio_map_user_iov(request_que
+ 			     int write_to_vm)
+ {
+ 	struct bio *bio;
+-	int len = 0, i;
+ 
+ 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
+ 
+@@ -764,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
+ 	 */
+ 	bio_get(bio);
+ 
+-	for (i = 0; i &lt; iov_count; i++)
+-		len += iov[i].iov_len;
+-
+-	if (bio-&gt;bi_size == len)
+-		return bio;
+-
+-	/*
+-	 * don't support partial mappings
+-	 */
+-	bio_endio(bio, bio-&gt;bi_size, 0);
+-	bio_unmap_user(bio);
+-	return ERR_PTR(-EINVAL);
++	return bio;
+ }
+ 
+ static void __bio_unmap_user(struct bio *bio)
+diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
+index 860e7a4..619ef1d 100644
+--- a/include/linux/blkdev.h
++++ b/include/linux/blkdev.h
+@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
+ extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
+ extern int blk_rq_unmap_user(struct bio *, unsigned int);
+ extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
+-extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
++extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
++			       struct sg_iovec *, int, unsigned int);
+ extern int blk_execute_rq(request_queue_t *, struct gendisk *,
+ 			  struct request *, int);
+ extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: use the original bio_map_user interface
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409283 +0900
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c |    2 +-
+ 1 files changed, 1 insertions(+), 1 deletions(-)
+
+2c78c6353dc183a16ef3e12b9c5618dd5b89679c
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..941dd64 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len &gt; 0) {
+ 		dprintk(&quot;%lx %u\n&quot;, (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk(&quot;fail to map %lx %u %d %x\n&quot;,
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,54 @@
+Subject: [PATCH] block layer: use blk_rq_bio_prep in init_request_from_bio
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409371 +0900
+
+Patch to use blk_rq_bio_prep in init_request_from_bio. And remove
+blk_rq_bio_prep's flags copying. The first three bits have not been
+the same for some time so that has been broken. The user of
+blk_rq_bio_prep will setup the request flags so if it wanted failfast
+or to be a barrier it will set the correct flag itself.
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ block/ll_rw_blk.c |   11 ++---------
+ 1 files changed, 2 insertions(+), 9 deletions(-)
+
+4b387c65f0645e86794c06eb3e734b0ec6e5733c
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..da2c57d 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2765,16 +2765,12 @@ static void init_request_from_bio(struct
+ 
+ 	req-&gt;errors = 0;
+ 	req-&gt;hard_sector = req-&gt;sector = bio-&gt;bi_sector;
+-	req-&gt;hard_nr_sectors = req-&gt;nr_sectors = bio_sectors(bio);
+-	req-&gt;current_nr_sectors = req-&gt;hard_cur_sectors = bio_cur_sectors(bio);
+-	req-&gt;nr_phys_segments = bio_phys_segments(req-&gt;q, bio);
+-	req-&gt;nr_hw_segments = bio_hw_segments(req-&gt;q, bio);
+-	req-&gt;buffer = bio_data(bio);	/* see -&gt;buffer comment above */
+ 	req-&gt;waiting = NULL;
+-	req-&gt;bio = req-&gt;biotail = bio;
+ 	req-&gt;ioprio = bio_prio(bio);
+ 	req-&gt;rq_disk = bio-&gt;bi_bdev-&gt;bd_disk;
+ 	req-&gt;start_time = jiffies;
++
++	blk_rq_bio_prep(req-&gt;q, req, bio);
+ }
+ 
+ static int __make_request(request_queue_t *q, struct bio *bio)
+@@ -3403,9 +3399,6 @@ EXPORT_SYMBOL(end_request);
+ 
+ void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
+ {
+-	/* first three bits are identical in rq-&gt;flags and bio-&gt;bi_rw */
+-	rq-&gt;flags |= (bio-&gt;bi_rw &amp; 7);
+-
+ 	rq-&gt;nr_phys_segments = bio_phys_segments(q, bio);
+ 	rq-&gt;nr_hw_segments = bio_hw_segments(q, bio);
+ 	rq-&gt;current_nr_sectors = bio_cur_sectors(bio);
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,293 @@
+Subject: [PATCH] scsi tgt: kernel/user interface changes
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409611 +0900
+
+- merge the tgt command structure with the the event structure for simplicity.
+- add a new event type for task management.
+- remove some of unused event types.
+- send task attributes to user-space daemon.
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ drivers/scsi/scsi_tgt_if.c   |   52 ++++++++++++++++++------------------------
+ drivers/scsi/scsi_tgt_lib.c  |   10 ++++----
+ drivers/scsi/scsi_tgt_priv.h |    4 ++-
+ include/scsi/scsi_tgt_if.h   |   50 ++++++++++++++++++++--------------------
+ 4 files changed, 54 insertions(+), 62 deletions(-)
+
+5804be31dad9a5ca05bef0ff2674cde90299ac3d
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index 38b35da..a31c8d5 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -35,15 +35,15 @@
+ static int tgtd_pid;
+ static struct sock *nl_sk;
+ 
+-static int send_event_res(uint16_t type, struct tgt_event *p,
+-			  void *data, int dlen, gfp_t flags, pid_t pid)
++static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
++			  pid_t pid)
+ {
+ 	struct tgt_event *ev;
+ 	struct nlmsghdr *nlh;
+ 	struct sk_buff *skb;
+ 	uint32_t len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + dlen);
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	skb = alloc_skb(len, flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+@@ -52,8 +52,6 @@ static int send_event_res(uint16_t type,
+ 
+ 	ev = NLMSG_DATA(nlh);
+ 	memcpy(ev, p, sizeof(*ev));
+-	if (dlen)
+-		memcpy(ev-&gt;data, data, dlen);
+ 
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+@@ -64,10 +62,12 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	struct sk_buff *skb;
+ 	struct nlmsghdr *nlh;
+ 	struct tgt_event *ev;
+-	struct tgt_cmd *tcmd;
+ 	int err, len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
++	/* FIXME: we need scsi core to do that. */
++	memcpy(cmd-&gt;cmnd, cmd-&gt;data_cmnd, MAX_COMMAND_SIZE);
++
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+@@ -82,17 +82,13 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	ev-&gt;k.cmd_req.host_no = shost-&gt;host_no;
+ 	ev-&gt;k.cmd_req.cid = cmd-&gt;request-&gt;tag;
+ 	ev-&gt;k.cmd_req.data_len = cmd-&gt;request_bufflen;
++	memcpy(ev-&gt;k.cmd_req.scb, cmd-&gt;cmnd, sizeof(ev-&gt;k.cmd_req.scb));
++	memcpy(ev-&gt;k.cmd_req.lun, lun, sizeof(ev-&gt;k.cmd_req.lun));
++	ev-&gt;k.cmd_req.attribute = cmd-&gt;tag;
+ 
+ 	dprintk(&quot;%d %u %u\n&quot;, ev-&gt;k.cmd_req.host_no, ev-&gt;k.cmd_req.cid,
+ 		ev-&gt;k.cmd_req.data_len);
+ 
+-	/* FIXME: we need scsi core to do that. */
+-	memcpy(cmd-&gt;cmnd, cmd-&gt;data_cmnd, MAX_COMMAND_SIZE);
+-
+-	tcmd = (struct tgt_cmd *) ev-&gt;data;
+-	memcpy(tcmd-&gt;scb, cmd-&gt;cmnd, sizeof(tcmd-&gt;scb));
+-	memcpy(tcmd-&gt;lun, lun, sizeof(struct scsi_lun));
+-
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err &lt; 0)
+ 		printk(KERN_ERR &quot;scsi_tgt_uspace_send: could not send skb %d\n&quot;,
+@@ -104,15 +100,13 @@ int scsi_tgt_uspace_send_status(struct s
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct tgt_event ev;
+-	char dummy[sizeof(struct tgt_cmd)];
+ 
+ 	memset(&amp;ev, 0, sizeof(ev));
+ 	ev.k.cmd_done.host_no = shost-&gt;host_no;
+ 	ev.k.cmd_done.cid = cmd-&gt;request-&gt;tag;
+ 	ev.k.cmd_done.result = cmd-&gt;result;
+ 
+-	return send_event_res(TGT_KEVENT_CMD_DONE, &amp;ev, dummy, sizeof(dummy),
+-			      gfp_mask, tgtd_pid);
++	return send_event_rsp(TGT_KEVENT_CMD_DONE, &amp;ev, gfp_mask, tgtd_pid);
+ }
+ 
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+@@ -124,19 +118,17 @@ static int event_recv_msg(struct sk_buff
+ 		nlh-&gt;nlmsg_pid, current-&gt;pid);
+ 
+ 	switch (nlh-&gt;nlmsg_type) {
+-	case TGT_UEVENT_TGTD_BIND:
++	case TGT_UEVENT_REQ:
+ 		tgtd_pid = NETLINK_CREDS(skb)-&gt;pid;
+ 		break;
+-	case TGT_UEVENT_CMD_RES:
++	case TGT_UEVENT_CMD_RSP:
+ 		/* TODO: handle multiple cmds in one event */
+-		err = scsi_tgt_kspace_exec(ev-&gt;u.cmd_res.host_no,
+-					   ev-&gt;u.cmd_res.cid,
+-					   ev-&gt;u.cmd_res.result,
+-					   ev-&gt;u.cmd_res.len,
+-					   ev-&gt;u.cmd_res.offset,
+-					   ev-&gt;u.cmd_res.uaddr,
+-					   ev-&gt;u.cmd_res.rw,
+-					   ev-&gt;u.cmd_res.try_map);
++		err = scsi_tgt_kspace_exec(ev-&gt;u.cmd_rsp.host_no,
++					   ev-&gt;u.cmd_rsp.cid,
++					   ev-&gt;u.cmd_rsp.result,
++					   ev-&gt;u.cmd_rsp.len,
++					   ev-&gt;u.cmd_rsp.uaddr,
++					   ev-&gt;u.cmd_rsp.rw);
+ 		break;
+ 	default:
+ 		eprintk(&quot;unknown type %d\n&quot;, nlh-&gt;nlmsg_type);
+@@ -166,12 +158,12 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh-&gt;nlmsg_type != TGT_UEVENT_CMD_RES) {
++		if (nlh-&gt;nlmsg_type != TGT_UEVENT_CMD_RSP) {
+ 			struct tgt_event ev;
+ 
+ 			memset(&amp;ev, 0, sizeof(ev));
+-			ev.k.event_res.err = err;
+-			send_event_res(TGT_KEVENT_RESPONSE, &amp;ev, NULL, 0,
++			ev.k.event_rsp.err = err;
++			send_event_rsp(TGT_KEVENT_RSP, &amp;ev,
+ 				       GFP_KERNEL | __GFP_NOFAIL,
+ 					nlh-&gt;nlmsg_pid);
+ 		}
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..3549e7c 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len &gt; 0) {
+ 		dprintk(&quot;%lx %u\n&quot;, (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk(&quot;fail to map %lx %u %d %x\n&quot;,
+@@ -438,16 +438,16 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
+-int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
+-			 unsigned long uaddr, u8 rw, u8 try_map)
++int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
++			 unsigned long uaddr, u8 rw)
+ {
+ 	struct Scsi_Host *shost;
+ 	struct scsi_cmnd *cmd;
+ 	struct request *rq;
+ 	int err = 0;
+ 
+-	dprintk(&quot;%d %u %d %u %llu %lx %u %u\n&quot;, host_no, cid, result,
+-		len, (unsigned long long) offset, uaddr, rw, try_map);
++	dprintk(&quot;%d %u %d %u %lx %u\n&quot;, host_no, cid, result,
++		len, uaddr, rw);
+ 
+ 	/* TODO: replace with a O(1) alg */
+ 	shost = scsi_host_lookup(host_no);
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 4236e50..fcf2ec6 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -21,5 +21,5 @@ extern int scsi_tgt_if_init(void);
+ extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+-				u64 offset, unsigned long uaddr, u8 rw,
+-				u8 try_map);
++				unsigned long uaddr, u8 rw);
++
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index da3a808..ebca452 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -24,65 +24,65 @@
+ 
+ enum tgt_event_type {
+ 	/* user -&gt; kernel */
+-	TGT_UEVENT_TGTD_BIND,
+-	TGT_UEVENT_TARGET_SETUP,
+-	TGT_UEVENT_CMD_RES,
++	TGT_UEVENT_REQ,
++	TGT_UEVENT_CMD_RSP,
++	TGT_UEVENT_TSK_MGMT_RSP,
+ 
+ 	/* kernel -&gt; user */
+-	TGT_KEVENT_RESPONSE,
++	TGT_KEVENT_RSP,
+ 	TGT_KEVENT_CMD_REQ,
+ 	TGT_KEVENT_CMD_DONE,
++	TGT_KEVENT_TSK_MGMT_REQ,
+ };
+ 
+ struct tgt_event {
+ 	/* user-&gt; kernel */
+ 	union {
+ 		struct {
+-			int pk_fd;
+-		} tgtd_bind;
++			int type;
++			int host_no;
++		} event_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t len;
+ 			int result;
+ 			uint64_t uaddr;
+-			uint64_t offset;
+ 			uint8_t rw;
+-			uint8_t try_map;
+-		} cmd_res;
++		} cmd_rsp;
++		struct {
++			int host_no;
++			int mid;
++			int result;
++		} tsk_mgmt_rsp;
+ 	} u;
+ 
+ 	/* kernel -&gt; user */
+ 	union {
+ 		struct {
+ 			int err;
+-		} event_res;
++		} event_rsp;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t data_len;
+-			uint64_t dev_id;
++			uint8_t scb[16];
++			uint8_t lun[8];
++			int attribute;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			int result;
+ 		} cmd_done;
++		struct {
++			int host_no;
++			int mid;
++			uint64_t tag;
++			uint8_t lun[8];
++			int function;
++		} tsk_mgmt_req;
+ 	} k;
+ 
+-	/*
+-	 * I think a pointer is a unsigned long but this struct
+-	 * gets passed around from the kernel to userspace and
+-	 * back again so to handle some ppc64 setups where userspace is
+-	 * 32 bits but the kernel is 64 we do this odd thing
+-	 */
+-	uint64_t data[0];
+-} __attribute__ ((aligned (sizeof(uint64_t))));
+-
+-struct tgt_cmd {
+-	uint8_t scb[16];
+-	uint8_t lun[8];
+-	int tags;
+ } __attribute__ ((aligned (sizeof(uint64_t))));
+-
+ #endif
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: fix double lock in scsi_uspace_request_fn
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142409678 +0900
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c |    2 +-
+ 1 files changed, 1 insertions(+), 1 deletions(-)
+
+1ddfd113a764450e7998cc16dd07dcc37077b05b
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..5d76078 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -136,7 +136,7 @@ requeue:
+ 	spin_lock_irq(q-&gt;queue_lock);
+ 	/* need to track cnts and plug */
+ 	blk_requeue_request(q, rq);
+-	spin_lock_irq(q-&gt;queue_lock);
++	spin_unlock_irq(q-&gt;queue_lock);
+ }
+ 
+ /**
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: remove blk_queue_end_tag
+From: fujita &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita at albi.localdomain</A>&gt;
+Date: 1142422083 +0900
+
+Remove blk_queue_end_tag() in scsi_host_put_command() because tgt
+doesn't use the elevator code.
+
+---
+
+ drivers/scsi/scsi.c |    2 --
+ 1 files changed, 0 insertions(+), 2 deletions(-)
+
+fd45c05acbc00cd21fa7c82f6aed5a5ef3e5b98a
+diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
+index 3cf02b1..9c22465 100644
+--- a/drivers/scsi/scsi.c
++++ b/drivers/scsi/scsi.c
+@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
+ 	spin_unlock(&amp;shost-&gt;free_list_lock);
+ 
+ 	spin_lock(q-&gt;queue_lock);
+-	if (blk_rq_tagged(rq))
+-		blk_queue_end_tag(q, rq);
+ 	__blk_put_request(q, rq);
+ 	spin_unlock_irqrestore(q-&gt;queue_lock, flags);
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,338 @@
+Subject: [PATCH] scsi tgt: replace the elevator code
+
+tgt uses the elevator code to send SCSI commands to the user-space
+daemon (q-&gt;request_fn sends netlink packets including commands).
+
+This patch replaces the elevator code with a simple list.
+
+This is mainly because tgt also needs to send TMF requests to the
+user-space daemon (the daemon does all the SCSI state machine
+stuff). tgt must send SCSI commands and TMF requests in an exact order
+so that it would be preferable to use a single queue (per host) for
+both. To uses the elevator code for TMF requests, tgt needs to
+allocate request structures for them. That's wasteful because request
+structures is useless for TMF requests, which don't perform any I/Os.
+
+We basically have a netdev queue of events to send to userspace so by
+using the request_queue and netdev queue we are basically double
+queueing and wasting resources and it is affecting performance
+
+We like to use shared memory stuff between kernel and user spaces
+instead of netlink in the future. These queues would go away.
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c  |  180 ++++++++++++++++++++++++++++++------------
+ drivers/scsi/scsi_tgt_priv.h |    4 -
+ 2 files changed, 129 insertions(+), 55 deletions(-)
+
+c4bb05742e1834d664a7d8e721ecea71d42fd7f7
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 274d929..2cbc749 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -20,7 +20,7 @@
+  * 02110-1301 USA
+  */
+ #include &lt;linux/blkdev.h&gt;
+-#include &lt;linux/elevator.h&gt;
++#include &lt;linux/hash.h&gt;
+ #include &lt;linux/module.h&gt;
+ #include &lt;linux/pagemap.h&gt;
+ #include &lt;scsi/scsi.h&gt;
+@@ -46,6 +46,24 @@ struct scsi_tgt_cmd {
+ 	struct bio_list xfer_done_list;
+ 	struct bio_list xfer_list;
+ 	struct scsi_lun *lun;
++
++	struct list_head hash_list;
++	struct request *rq;
++};
++
++#define TGT_HASH_ORDER	4
++#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
++
++struct scsi_tgt_queuedata {
++	struct Scsi_Host *shost;
++	struct list_head cmd_hash[1 &lt;&lt; TGT_HASH_ORDER];
++	spinlock_t cmd_hash_lock;
++
++	struct work_struct uspace_send_work;
++
++	spinlock_t cmd_req_lock;
++	struct mutex cmd_req_mutex;
++	struct list_head cmd_req;
+ };
+ 
+ static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
+@@ -68,9 +86,16 @@ static void scsi_tgt_cmd_destroy(void *d
+ {
+ 	struct scsi_cmnd *cmd = data;
+ 	struct scsi_tgt_cmd *tcmd = cmd-&gt;request-&gt;end_io_data;
++	struct scsi_tgt_queuedata *qdata = cmd-&gt;request-&gt;q-&gt;queuedata;
++	unsigned long flags;
+ 
+ 	dprintk(&quot;cmd %p %d %lu\n&quot;, cmd, cmd-&gt;sc_data_direction,
+ 		rq_data_dir(cmd-&gt;request));
++
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	list_del(&amp;tcmd-&gt;hash_list);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
++
+ 	/*
+ 	 * We must set rq-&gt;flags here because bio_map_user and
+ 	 * blk_rq_bio_prep ruined ti.
+@@ -88,55 +113,84 @@ static void scsi_tgt_cmd_destroy(void *d
+ 
+ static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
+ {
++	struct scsi_tgt_queuedata *qdata = rq-&gt;q-&gt;queuedata;
++	unsigned long flags;
++	struct list_head *head;
++	static u32 tag = 0;
++
+ 	tcmd-&gt;lun = rq-&gt;end_io_data;
+ 	bio_list_init(&amp;tcmd-&gt;xfer_list);
+ 	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
+-}
+-
+-static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
+-{
+-	struct scsi_tgt_cmd *tcmd;
+ 
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd)
+-		return BLKPREP_DEFER;
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	rq-&gt;tag = tag++;
++	head = &amp;qdata-&gt;cmd_hash[cmd_hashfn(rq-&gt;tag)];
++	list_add(&amp;tcmd-&gt;hash_list, head);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
+ 
+-	init_scsi_tgt_cmd(rq, tcmd);
++	tcmd-&gt;rq = rq;
+ 	rq-&gt;end_io_data = tcmd;
+ 	rq-&gt;flags |= REQ_DONTPREP;
+-	return BLKPREP_OK;
+ }
+ 
+-static void scsi_uspace_request_fn(struct request_queue *q)
++static void scsi_tgt_uspace_send_fn(void *data)
+ {
++	struct request_queue *q = data;
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
+ 	struct request *rq;
+ 	struct scsi_cmnd *cmd;
+ 	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++	int err;
+ 
+-	/*
+-	 * TODO: just send everthing in the queue to userspace in
+-	 * one vector instead of multiple calls
+-	 */
+-	while ((rq = elv_next_request(q)) != NULL) {
+-		cmd = rq-&gt;special;
+-		tcmd = rq-&gt;end_io_data;
++retry:
++	err = 0;
++	if (list_empty(&amp;qdata-&gt;cmd_req))
++		return;
+ 
+-		/* the completion code kicks us in case we hit this */
+-		if (blk_queue_start_tag(q, rq))
+-			break;
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd) {
++		err = -ENOMEM;
++		goto out;
++	}
++
++	mutex_lock(&amp;qdata-&gt;cmd_req_mutex);
+ 
+-		spin_unlock_irq(q-&gt;queue_lock);
+-		if (scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, GFP_ATOMIC) &lt; 0)
+-			goto requeue;
+-		spin_lock_irq(q-&gt;queue_lock);
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++	if (list_empty(&amp;qdata-&gt;cmd_req)) {
++		spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++		mutex_unlock(&amp;qdata-&gt;cmd_req_mutex);
++		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
++		goto out;
+ 	}
++	rq = list_entry_rq(qdata-&gt;cmd_req.next);
++	list_del_init(&amp;rq-&gt;queuelist);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
+ 
+-	return;
+-requeue:
+-	spin_lock_irq(q-&gt;queue_lock);
+-	/* need to track cnts and plug */
+-	blk_requeue_request(q, rq);
+-	spin_unlock_irq(q-&gt;queue_lock);
++	if ((rq-&gt;flags &amp; REQ_DONTPREP)) {
++		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
++		tcmd = rq-&gt;end_io_data;
++	} else
++		init_scsi_tgt_cmd(rq, tcmd);
++
++	cmd = rq-&gt;special;
++	err = scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, GFP_ATOMIC);
++	if (err &lt; 0) {
++		eprintk(&quot;failed to send: %p %d\n&quot;, cmd, err);
++
++		spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++		list_add(&amp;rq-&gt;queuelist, &amp;qdata-&gt;cmd_req);
++		spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++	}
++
++	mutex_unlock(&amp;qdata-&gt;cmd_req_mutex);
++out:
++	/* TODO: proper error handling */
++	if (err &lt; 0)
++		queue_delayed_work(scsi_tgtd, &amp;qdata-&gt;uspace_send_work,
++				   HZ / 10);
++	else
++		goto retry;
+ }
+ 
+ /**
+@@ -150,13 +204,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ {
+ 	struct scsi_tgt_queuedata *queuedata;
+ 	struct request_queue *q;
+-	int err;
++	int err, i;
+ 
+ 	/*
+ 	 * Do we need to send a netlink event or should uspace
+ 	 * just respond to the hotplug event?
+ 	 */
+-	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
++	q = __scsi_alloc_queue(shost, NULL);
+ 	if (!q)
+ 		return -ENOMEM;
+ 
+@@ -168,19 +222,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	queuedata-&gt;shost = shost;
+ 	q-&gt;queuedata = queuedata;
+ 
+-	elevator_exit(q-&gt;elevator);
+-	err = elevator_init(q, &quot;noop&quot;);
+-	if (err)
+-		goto free_data;
+-
+-	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
+ 	/*
+ 	 * this is a silly hack. We should probably just queue as many
+ 	 * command as is recvd to userspace. uspace can then make
+ 	 * sure we do not overload the HBA
+ 	 */
+ 	q-&gt;nr_requests = shost-&gt;hostt-&gt;can_queue;
+-	blk_queue_init_tags(q, shost-&gt;hostt-&gt;can_queue, NULL);
+ 	/*
+ 	 * We currently only support software LLDs so this does
+ 	 * not matter for now. Do we need this for the cards we support?
+@@ -189,10 +236,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	blk_queue_dma_alignment(q, 0);
+ 	shost-&gt;uspace_req_q = q;
+ 
++	for (i = 0; i &lt; ARRAY_SIZE(queuedata-&gt;cmd_hash); i++)
++		INIT_LIST_HEAD(&amp;queuedata-&gt;cmd_hash[i]);
++	spin_lock_init(&amp;queuedata-&gt;cmd_hash_lock);
++
++	INIT_LIST_HEAD(&amp;queuedata-&gt;cmd_req);
++	spin_lock_init(&amp;queuedata-&gt;cmd_req_lock);
++	INIT_WORK(&amp;queuedata-&gt;uspace_send_work, scsi_tgt_uspace_send_fn, q);
++	mutex_init(&amp;queuedata-&gt;cmd_req_mutex);
++
+ 	return 0;
+ 
+-free_data:
+-	kfree(queuedata);
+ cleanup_queue:
+ 	blk_cleanup_queue(q);
+ 	return err;
+@@ -215,14 +269,17 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+ void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+ 			    int noblock)
+ {
+-	/*
+-	 * For now this just calls the request_fn from this context.
+-	 * For HW llds though we do not want to execute from here so
+-	 * the elevator code needs something like a REQ_TGT_CMD or
+-	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
+-	 */
++	struct request_queue *q = cmd-&gt;request-&gt;q;
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
++	unsigned long flags;
++
+ 	cmd-&gt;request-&gt;end_io_data = scsilun;
+-	elv_add_request(cmd-&gt;request-&gt;q, cmd-&gt;request, ELEVATOR_INSERT_BACK, 1);
++
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++	list_add_tail(&amp;cmd-&gt;request-&gt;queuelist, &amp;qdata-&gt;cmd_req);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++
++	queue_work(scsi_tgtd, &amp;qdata-&gt;uspace_send_work);
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -438,6 +495,27 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
++static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
++{
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
++	struct request *rq = NULL;
++	struct list_head *head;
++	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++
++	head = &amp;qdata-&gt;cmd_hash[cmd_hashfn(cid)];
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	list_for_each_entry(tcmd, head, hash_list) {
++		if (tcmd-&gt;rq-&gt;tag == cid) {
++			rq = tcmd-&gt;rq;
++			break;
++		}
++	}
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
++
++	return rq;
++}
++
+ int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+ 			 unsigned long uaddr, u8 rw)
+ {
+@@ -456,7 +534,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 		return -EINVAL;
+ 	}
+ 
+-	rq = blk_queue_find_tag(shost-&gt;uspace_req_q, cid);
++	rq = tgt_cmd_hash_lookup(shost-&gt;uspace_req_q, cid);
+ 	if (!rq) {
+ 		printk(KERN_ERR &quot;Could not find cid %u\n&quot;, cid);
+ 		err = -EINVAL;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index fcf2ec6..6fedcec 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -11,10 +11,6 @@ do {								\
+ 
+ #define eprintk dprintk
+ 
+-struct scsi_tgt_queuedata {
+-	struct Scsi_Host *shost;
+-};
+-
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,583 @@
+Subject: [PATCH] ibmvscsi: convert the ibmvscsi driver to use include/scsi/srp.h
+From: FUJITA &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Date: 1143376921 +0900
+
+---
+
+ drivers/scsi/ibmvscsi/ibmvscsi.c  |  247 +++++++++++++++++++------------------
+ drivers/scsi/ibmvscsi/ibmvscsi.h  |    2 
+ drivers/scsi/ibmvscsi/rpa_vscsi.c |    1 
+ drivers/scsi/ibmvscsi/viosrp.h    |   17 ++-
+ 4 files changed, 142 insertions(+), 125 deletions(-)
+
+74aa6fe8367e04be9cc7d0e7d16cc790754a73f3
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
+index eaefedd..e7bd028 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.c
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
+@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
+ 			++in_use;
+ 		if (pool-&gt;events[i].ext_list) {
+ 			dma_free_coherent(hostdata-&gt;dev,
+-				  SG_ALL * sizeof(struct memory_descriptor),
++				  SG_ALL * sizeof(struct srp_direct_buf),
+ 				  pool-&gt;events[i].ext_list,
+ 				  pool-&gt;events[i].ext_list_token);
+ 		}
+@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
+ 			      struct srp_cmd *srp_cmd, 
+ 			      int numbuf)
+ {
++	u8 fmt;
++
+ 	if (numbuf == 0)
+ 		return;
+ 	
+-	if (numbuf == 1) {
++	if (numbuf == 1)
++		fmt = SRP_DATA_DESC_DIRECT;
++	else {
++		fmt = SRP_DATA_DESC_INDIRECT;
++		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
++
+ 		if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE)
+-			srp_cmd-&gt;data_out_format = SRP_DIRECT_BUFFER;
+-		else 
+-			srp_cmd-&gt;data_in_format = SRP_DIRECT_BUFFER;
+-	} else {
+-		if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE) {
+-			srp_cmd-&gt;data_out_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd-&gt;data_out_count =
+-				numbuf &lt; MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		} else {
+-			srp_cmd-&gt;data_in_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd-&gt;data_in_count =
+-				numbuf &lt; MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		}
++			srp_cmd-&gt;data_out_desc_cnt = numbuf;
++		else
++			srp_cmd-&gt;data_in_desc_cnt = numbuf;
+ 	}
++
++	if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE)
++		srp_cmd-&gt;buf_fmt = fmt &lt;&lt; 4;
++	else
++		srp_cmd-&gt;buf_fmt = fmt;
+ }
+ 
+-static void unmap_sg_list(int num_entries, 
++static void unmap_sg_list(int num_entries,
+ 		struct device *dev,
+-		struct memory_descriptor *md)
+-{ 
++		struct srp_direct_buf *md)
++{
+ 	int i;
+ 
+-	for (i = 0; i &lt; num_entries; ++i) {
+-		dma_unmap_single(dev,
+-			md[i].virtual_address,
+-			md[i].length, DMA_BIDIRECTIONAL);
+-	}
++	for (i = 0; i &lt; num_entries; ++i)
++		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
+ }
+ 
+ /**
+@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
+ 			   struct srp_event_struct *evt_struct,
+ 			   struct device *dev)
+ {
+-	if ((cmd-&gt;data_out_format == SRP_NO_BUFFER) &amp;&amp;
+-	    (cmd-&gt;data_in_format == SRP_NO_BUFFER))
++	u8 out_fmt, in_fmt;
++
++	out_fmt = cmd-&gt;buf_fmt &gt;&gt; 4;
++	in_fmt = cmd-&gt;buf_fmt &amp; ((1U &lt;&lt; 4) - 1);
++
++	if (out_fmt == SRP_NO_DATA_DESC &amp;&amp; in_fmt == SRP_NO_DATA_DESC)
+ 		return;
+-	else if ((cmd-&gt;data_out_format == SRP_DIRECT_BUFFER) ||
+-		 (cmd-&gt;data_in_format == SRP_DIRECT_BUFFER)) {
+-		struct memory_descriptor *data =
+-			(struct memory_descriptor *)cmd-&gt;additional_data;
+-		dma_unmap_single(dev, data-&gt;virtual_address, data-&gt;length,
+-				 DMA_BIDIRECTIONAL);
++	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
++		 in_fmt == SRP_DATA_DESC_DIRECT) {
++		struct srp_direct_buf *data =
++			(struct srp_direct_buf *) cmd-&gt;add_data;
++		dma_unmap_single(dev, data-&gt;va, data-&gt;len, DMA_BIDIRECTIONAL);
+ 	} else {
+-		struct indirect_descriptor *indirect =
+-			(struct indirect_descriptor *)cmd-&gt;additional_data;
+-		int num_mapped = indirect-&gt;head.length / 
+-			sizeof(indirect-&gt;list[0]);
++		struct srp_indirect_buf *indirect =
++			(struct srp_indirect_buf *) cmd-&gt;add_data;
++		int num_mapped = indirect-&gt;table_desc.len /
++			sizeof(struct srp_direct_buf);
+ 
+ 		if (num_mapped &lt;= MAX_INDIRECT_BUFS) {
+-			unmap_sg_list(num_mapped, dev, &amp;indirect-&gt;list[0]);
++			unmap_sg_list(num_mapped, dev, &amp;indirect-&gt;desc_list[0]);
+ 			return;
+ 		}
+ 
+@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
+ 
+ static int map_sg_list(int num_entries, 
+ 		       struct scatterlist *sg,
+-		       struct memory_descriptor *md)
++		       struct srp_direct_buf *md)
+ {
+ 	int i;
+ 	u64 total_length = 0;
+ 
+ 	for (i = 0; i &lt; num_entries; ++i) {
+-		struct memory_descriptor *descr = md + i;
++		struct srp_direct_buf *descr = md + i;
+ 		struct scatterlist *sg_entry = &amp;sg[i];
+-		descr-&gt;virtual_address = sg_dma_address(sg_entry);
+-		descr-&gt;length = sg_dma_len(sg_entry);
+-		descr-&gt;memory_handle = 0;
++		descr-&gt;va = sg_dma_address(sg_entry);
++		descr-&gt;len = sg_dma_len(sg_entry);
++		descr-&gt;key = 0;
+ 		total_length += sg_dma_len(sg_entry);
+  	}
+ 	return total_length;
+@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
+ 	int sg_mapped;
+ 	u64 total_length = 0;
+ 	struct scatterlist *sg = cmd-&gt;request_buffer;
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd-&gt;additional_data;
+-	struct indirect_descriptor *indirect =
+-	    (struct indirect_descriptor *)data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd-&gt;add_data;
++	struct srp_indirect_buf *indirect =
++		(struct srp_indirect_buf *) data;
+ 
+ 	sg_mapped = dma_map_sg(dev, sg, cmd-&gt;use_sg, DMA_BIDIRECTIONAL);
+ 
+@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	/* special case; we can use a single direct descriptor */
+ 	if (sg_mapped == 1) {
+-		data-&gt;virtual_address = sg_dma_address(&amp;sg[0]);
+-		data-&gt;length = sg_dma_len(&amp;sg[0]);
+-		data-&gt;memory_handle = 0;
++		data-&gt;va = sg_dma_address(&amp;sg[0]);
++		data-&gt;len = sg_dma_len(&amp;sg[0]);
++		data-&gt;key = 0;
+ 		return 1;
+ 	}
+ 
+@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
+ 		return 0;
+ 	}
+ 
+-	indirect-&gt;head.virtual_address = 0;
+-	indirect-&gt;head.length = sg_mapped * sizeof(indirect-&gt;list[0]);
+-	indirect-&gt;head.memory_handle = 0;
++	indirect-&gt;table_desc.va = 0;
++	indirect-&gt;table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
++	indirect-&gt;table_desc.key = 0;
+ 
+ 	if (sg_mapped &lt;= MAX_INDIRECT_BUFS) {
+-		total_length = map_sg_list(sg_mapped, sg, &amp;indirect-&gt;list[0]);
+-		indirect-&gt;total_length = total_length;
++		total_length = map_sg_list(sg_mapped, sg,
++					   &amp;indirect-&gt;desc_list[0]);
++		indirect-&gt;len = total_length;
+ 		return 1;
+ 	}
+ 
+ 	/* get indirect table */
+ 	if (!evt_struct-&gt;ext_list) {
+-		evt_struct-&gt;ext_list =(struct memory_descriptor*)
++		evt_struct-&gt;ext_list = (struct srp_direct_buf *)
+ 			dma_alloc_coherent(dev, 
+-				SG_ALL * sizeof(struct memory_descriptor),
+-				&amp;evt_struct-&gt;ext_list_token, 0);
++					   SG_ALL * sizeof(struct srp_direct_buf),
++					   &amp;evt_struct-&gt;ext_list_token, 0);
+ 		if (!evt_struct-&gt;ext_list) {
+-		    printk(KERN_ERR
+-		   	&quot;ibmvscsi: Can't allocate memory for indirect table\n&quot;);
++			printk(KERN_ERR
++			       &quot;ibmvscsi: Can't allocate memory for indirect table\n&quot;);
+ 			return 0;
+ 			
+ 		}
+@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	total_length = map_sg_list(sg_mapped, sg, evt_struct-&gt;ext_list);	
+ 
+-	indirect-&gt;total_length = total_length;
+-	indirect-&gt;head.virtual_address = evt_struct-&gt;ext_list_token;
+-	indirect-&gt;head.length = sg_mapped * sizeof(indirect-&gt;list[0]);
+-	memcpy(indirect-&gt;list, evt_struct-&gt;ext_list,
+-		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
++	indirect-&gt;len = total_length;
++	indirect-&gt;table_desc.va = evt_struct-&gt;ext_list_token;
++	indirect-&gt;table_desc.len = sg_mapped * sizeof(indirect-&gt;desc_list[0]);
++	memcpy(indirect-&gt;desc_list, evt_struct-&gt;ext_list,
++	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
+ 	
+  	return 1;
+ }
+@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
+ static int map_single_data(struct scsi_cmnd *cmd,
+ 			   struct srp_cmd *srp_cmd, struct device *dev)
+ {
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd-&gt;additional_data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd-&gt;add_data;
+ 
+-	data-&gt;virtual_address =
++	data-&gt;va =
+ 		dma_map_single(dev, cmd-&gt;request_buffer,
+ 			       cmd-&gt;request_bufflen,
+ 			       DMA_BIDIRECTIONAL);
+-	if (dma_mapping_error(data-&gt;virtual_address)) {
++	if (dma_mapping_error(data-&gt;va)) {
+ 		printk(KERN_ERR
+ 		       &quot;ibmvscsi: Unable to map request_buffer for command!\n&quot;);
+ 		return 0;
+ 	}
+-	data-&gt;length = cmd-&gt;request_bufflen;
+-	data-&gt;memory_handle = 0;
++	data-&gt;len = cmd-&gt;request_bufflen;
++	data-&gt;key = 0;
+ 
+ 	set_srp_direction(cmd, srp_cmd, 1);
+ 
+@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
+ 
+ 	/* Copy the IU into the transfer area */
+ 	*evt_struct-&gt;xfer_iu = evt_struct-&gt;iu;
+-	evt_struct-&gt;xfer_iu-&gt;srp.generic.tag = (u64)evt_struct;
++	evt_struct-&gt;xfer_iu-&gt;srp.rsp.tag = (u64)evt_struct;
+ 
+ 	/* Add this to the sent list.  We need to do this 
+ 	 * before we actually send 
+@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
+ 	struct srp_rsp *rsp = &amp;evt_struct-&gt;xfer_iu-&gt;srp.rsp;
+ 	struct scsi_cmnd *cmnd = evt_struct-&gt;cmnd;
+ 
+-	if (unlikely(rsp-&gt;type != SRP_RSP_TYPE)) {
++	if (unlikely(rsp-&gt;opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: bad SRP RSP type %d\n&quot;,
+-			       rsp-&gt;type);
++			       rsp-&gt;opcode);
+ 	}
+ 	
+ 	if (cmnd) {
+ 		cmnd-&gt;result = rsp-&gt;status;
+ 		if (((cmnd-&gt;result &gt;&gt; 1) &amp; 0x1f) == CHECK_CONDITION)
+ 			memcpy(cmnd-&gt;sense_buffer,
+-			       rsp-&gt;sense_and_response_data,
+-			       rsp-&gt;sense_data_list_length);
++			       rsp-&gt;data,
++			       rsp-&gt;sense_data_len);
+ 		unmap_cmd_data(&amp;evt_struct-&gt;iu.srp.cmd, 
+ 			       evt_struct, 
+ 			       evt_struct-&gt;hostdata-&gt;dev);
+ 
+-		if (rsp-&gt;doover)
+-			cmnd-&gt;resid = rsp-&gt;data_out_residual_count;
+-		else if (rsp-&gt;diover)
+-			cmnd-&gt;resid = rsp-&gt;data_in_residual_count;
++		if (rsp-&gt;flags &amp; SRP_RSP_FLAG_DOOVER)
++			cmnd-&gt;resid = rsp-&gt;data_out_res_cnt;
++		else if (rsp-&gt;flags &amp; SRP_RSP_FLAG_DIOVER)
++			cmnd-&gt;resid = rsp-&gt;data_in_res_cnt;
+ 	}
+ 
+ 	if (evt_struct-&gt;cmnd_done)
+@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
+ {
+ 	struct srp_cmd *srp_cmd;
+ 	struct srp_event_struct *evt_struct;
+-	struct indirect_descriptor *indirect;
++	struct srp_indirect_buf *indirect;
+ 	struct ibmvscsi_host_data *hostdata =
+ 		(struct ibmvscsi_host_data *)&amp;cmnd-&gt;device-&gt;host-&gt;hostdata;
+ 	u16 lun = lun_from_dev(cmnd-&gt;device);
++	u8 out_fmt, in_fmt;
+ 
+ 	evt_struct = get_event_struct(&amp;hostdata-&gt;pool);
+ 	if (!evt_struct)
+@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
+ 
+ 	/* Set up the actual SRP IU */
+ 	srp_cmd = &amp;evt_struct-&gt;iu.srp.cmd;
+-	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
+-	srp_cmd-&gt;type = SRP_CMD_TYPE;
++	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
++	srp_cmd-&gt;opcode = SRP_CMD;
+ 	memcpy(srp_cmd-&gt;cdb, cmnd-&gt;cmnd, sizeof(cmnd-&gt;cmnd));
+ 	srp_cmd-&gt;lun = ((u64) lun) &lt;&lt; 48;
+ 
+@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
+ 	evt_struct-&gt;cmnd_done = done;
+ 
+ 	/* Fix up dma address of the buffer itself */
+-	indirect = (struct indirect_descriptor *)srp_cmd-&gt;additional_data;
+-	if (((srp_cmd-&gt;data_out_format == SRP_INDIRECT_BUFFER) ||
+-	    (srp_cmd-&gt;data_in_format == SRP_INDIRECT_BUFFER)) &amp;&amp;
+-	    (indirect-&gt;head.virtual_address == 0)) {
+-		indirect-&gt;head.virtual_address = evt_struct-&gt;crq.IU_data_ptr +
+-		    offsetof(struct srp_cmd, additional_data) +
+-		    offsetof(struct indirect_descriptor, list);
++	indirect = (struct srp_indirect_buf *) srp_cmd-&gt;add_data;
++	out_fmt = srp_cmd-&gt;buf_fmt &gt;&gt; 4;
++	in_fmt = srp_cmd-&gt;buf_fmt &amp; ((1U &lt;&lt; 4) - 1);
++	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
++	     out_fmt == SRP_DATA_DESC_INDIRECT) &amp;&amp;
++	    indirect-&gt;table_desc.va == 0) {
++		indirect-&gt;table_desc.va = evt_struct-&gt;crq.IU_data_ptr +
++			offsetof(struct srp_cmd, add_data) +
++			offsetof(struct srp_indirect_buf, desc_list);
+ 	}
+ 
+ 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
+@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
+ static void login_rsp(struct srp_event_struct *evt_struct)
+ {
+ 	struct ibmvscsi_host_data *hostdata = evt_struct-&gt;hostdata;
+-	switch (evt_struct-&gt;xfer_iu-&gt;srp.generic.type) {
+-	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
++	switch (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.opcode) {
++	case SRP_LOGIN_RSP:	/* it worked! */
+ 		break;
+-	case SRP_LOGIN_REJ_TYPE:	/* refused! */
++	case SRP_LOGIN_REJ:	/* refused! */
+ 		printk(KERN_INFO &quot;ibmvscsi: SRP_LOGIN_REJ reason %u\n&quot;,
+ 		       evt_struct-&gt;xfer_iu-&gt;srp.login_rej.reason);
+ 		/* Login failed.  */
+@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
+ 	default:
+ 		printk(KERN_ERR
+ 		       &quot;ibmvscsi: Invalid login response typecode 0x%02x!\n&quot;,
+-		       evt_struct-&gt;xfer_iu-&gt;srp.generic.type);
++		       evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.opcode);
+ 		/* Login failed.  */
+ 		atomic_set(&amp;hostdata-&gt;request_limit, -1);
+ 		return;
+@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: SRP_LOGIN succeeded\n&quot;);
+ 
+-	if (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta &gt;
++	if (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta &gt;
+ 	    (max_requests - 2))
+-		evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta =
++		evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta =
+ 		    max_requests - 2;
+ 
+ 	/* Now we know what the real request-limit is */
+ 	atomic_set(&amp;hostdata-&gt;request_limit,
+-		   evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta);
++		   evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta);
+ 
+ 	hostdata-&gt;host-&gt;can_queue =
+-	    evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta - 2;
++	    evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta - 2;
+ 
+ 	if (hostdata-&gt;host-&gt;can_queue &lt; 1) {
+ 		printk(KERN_ERR &quot;ibmvscsi: Invalid request_limit_delta\n&quot;);
+@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
+ 
+ 	login = &amp;evt_struct-&gt;iu.srp.login_req;
+ 	memset(login, 0x00, sizeof(struct srp_login_req));
+-	login-&gt;type = SRP_LOGIN_REQ_TYPE;
+-	login-&gt;max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
+-	login-&gt;required_buffer_formats = 0x0006;
++	login-&gt;opcode = SRP_LOGIN_REQ;
++	login-&gt;req_it_iu_len = sizeof(union srp_iu);
++	login-&gt;req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
+ 	
+ 	/* Start out with a request limit of 1, since this is negotiated in
+ 	 * the login request we are just sending
+@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 	
+ 	/* Set up an abort SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt-&gt;type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt-&gt;opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt-&gt;lun = ((u64) lun) &lt;&lt; 48;
+-	tsk_mgmt-&gt;task_mgmt_flags = 0x01;	/* ABORT TASK */
+-	tsk_mgmt-&gt;managed_task_tag = (u64) found_evt;
++	tsk_mgmt-&gt;tsk_mgmt_func = SRP_TSK_ABORT_TASK;
++	tsk_mgmt-&gt;task_tag = (u64) found_evt;
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n&quot;,
+-	       tsk_mgmt-&gt;lun, tsk_mgmt-&gt;managed_task_tag);
++	       tsk_mgmt-&gt;lun, tsk_mgmt-&gt;task_tag);
+ 
+ 	evt-&gt;sync_srp = &amp;srp_rsp;
+ 	init_completion(&amp;evt-&gt;comp);
+@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
+ 	wait_for_completion(&amp;evt-&gt;comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: abort bad SRP RSP type %d\n&quot;,
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags &amp; SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+ 	if (rsp_rc) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+-		       &quot;ibmvscsi: abort code %d for task tag 0x%lx\n&quot;,
++			       &quot;ibmvscsi: abort code %d for task tag 0x%lx\n&quot;,
+ 			       rsp_rc,
+-			       tsk_mgmt-&gt;managed_task_tag);
++			       tsk_mgmt-&gt;task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 		spin_unlock_irqrestore(hostdata-&gt;host-&gt;host_lock, flags);
+ 		printk(KERN_INFO
+ 		       &quot;ibmvscsi: aborted task tag 0x%lx completed\n&quot;,
+-		       tsk_mgmt-&gt;managed_task_tag);
++		       tsk_mgmt-&gt;task_tag);
+ 		return SUCCESS;
+ 	}
+ 
+ 	printk(KERN_INFO
+ 	       &quot;ibmvscsi: successfully aborted task tag 0x%lx\n&quot;,
+-	       tsk_mgmt-&gt;managed_task_tag);
++	       tsk_mgmt-&gt;task_tag);
+ 
+ 	cmd-&gt;result = (DID_ABORT &lt;&lt; 16);
+ 	list_del(&amp;found_evt-&gt;list);
+@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
+ 
+ 	/* Set up a lun reset SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt-&gt;type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt-&gt;opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt-&gt;lun = ((u64) lun) &lt;&lt; 48;
+-	tsk_mgmt-&gt;task_mgmt_flags = 0x08;	/* LUN RESET */
++	tsk_mgmt-&gt;tsk_mgmt_func = SRP_TSK_LUN_RESET;
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: resetting device. lun 0x%lx\n&quot;,
+ 	       tsk_mgmt-&gt;lun);
+@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
+ 	wait_for_completion(&amp;evt-&gt;comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: reset bad SRP RSP type %d\n&quot;,
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags &amp; SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: reset code %d for task tag 0x%lx\n&quot;,
+-		       rsp_rc,
+-			       tsk_mgmt-&gt;managed_task_tag);
++			       rsp_rc, tsk_mgmt-&gt;task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
+ 	}
+ 
+ 	if (crq-&gt;format == VIOSRP_SRP_FORMAT)
+-		atomic_add(evt_struct-&gt;xfer_iu-&gt;srp.rsp.request_limit_delta,
++		atomic_add(evt_struct-&gt;xfer_iu-&gt;srp.rsp.req_lim_delta,
+ 			   &amp;hostdata-&gt;request_limit);
+ 
+ 	if (evt_struct-&gt;done)
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
+index 4550d71..5c6d935 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.h
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
+@@ -68,7 +68,7 @@ struct srp_event_struct {
+ 	void (*cmnd_done) (struct scsi_cmnd *);
+ 	struct completion comp;
+ 	union viosrp_iu *sync_srp;
+-	struct memory_descriptor *ext_list;
++	struct srp_direct_buf *ext_list;
+ 	dma_addr_t ext_list_token;
+ };
+ 
+diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+index f47dd87..58aa530 100644
+--- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
++++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+@@ -34,7 +34,6 @@
+ #include &lt;linux/dma-mapping.h&gt;
+ #include &lt;linux/interrupt.h&gt;
+ #include &quot;ibmvscsi.h&quot;
+-#include &quot;srp.h&quot;
+ 
+ static char partition_name[97] = &quot;UNKNOWN&quot;;
+ static unsigned int partition_number = -1;
+diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
+index 6a6bba8..90f1a61 100644
+--- a/drivers/scsi/ibmvscsi/viosrp.h
++++ b/drivers/scsi/ibmvscsi/viosrp.h
+@@ -33,7 +33,22 @@
+ /*****************************************************************************/
+ #ifndef VIOSRP_H
+ #define VIOSRP_H
+-#include &quot;srp.h&quot;
++#include &lt;scsi/srp.h&gt;
++
++#define SRP_VERSION &quot;16.a&quot;
++#define SRP_MAX_IU_LEN	256
++
++union srp_iu {
++	struct srp_login_req login_req;
++	struct srp_login_rsp login_rsp;
++	struct srp_login_rej login_rej;
++	struct srp_i_logout i_logout;
++	struct srp_t_logout t_logout;
++	struct srp_tsk_mgmt tsk_mgmt;
++	struct srp_cmd cmd;
++	struct srp_rsp rsp;
++	u8 reserved[SRP_MAX_IU_LEN];
++};
+ 
+ enum viosrp_crq_formats {
+ 	VIOSRP_SRP_FORMAT = 0x01,
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,246 @@
+Subject: [PATCH] ibmvscsi: remove drivers/scsi/ibmvscsi/srp.h
+From: FUJITA &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Date: 1143377151 +0900
+
+---
+
+ drivers/scsi/ibmvscsi/srp.h |  227 -------------------------------------------
+ 1 files changed, 0 insertions(+), 227 deletions(-)
+ delete mode 100644 drivers/scsi/ibmvscsi/srp.h
+
+acbd74e89dc7bcf4e2596800e46a19378db44641
+diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
+deleted file mode 100644
+index 7d8e4c4..0000000
+--- a/drivers/scsi/ibmvscsi/srp.h
++++ /dev/null
+@@ -1,227 +0,0 @@
+-/*****************************************************************************/
+-/* srp.h -- SCSI RDMA Protocol definitions                                   */
+-/*                                                                           */
+-/* Written By: Colin Devilbis, IBM Corporation                               */
+-/*                                                                           */
+-/* Copyright (C) 2003 IBM Corporation                                        */
+-/*                                                                           */
+-/* This program is free software; you can redistribute it and/or modify      */
+-/* it under the terms of the GNU General Public License as published by      */
+-/* the Free Software Foundation; either version 2 of the License, or         */
+-/* (at your option) any later version.                                       */
+-/*                                                                           */
+-/* This program is distributed in the hope that it will be useful,           */
+-/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+-/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+-/* GNU General Public License for more details.                              */
+-/*                                                                           */
+-/* You should have received a copy of the GNU General Public License         */
+-/* along with this program; if not, write to the Free Software               */
+-/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+-/*                                                                           */
+-/*                                                                           */
+-/* This file contains structures and definitions for the SCSI RDMA Protocol  */
+-/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
+-/* file was based on the 16a version of the standard                         */
+-/*                                                                           */
+-/*****************************************************************************/
+-#ifndef SRP_H
+-#define SRP_H
+-
+-#define SRP_VERSION &quot;16.a&quot;
+-
+-#define PACKED __attribute__((packed))
+-
+-enum srp_types {
+-	SRP_LOGIN_REQ_TYPE = 0x00,
+-	SRP_LOGIN_RSP_TYPE = 0xC0,
+-	SRP_LOGIN_REJ_TYPE = 0xC2,
+-	SRP_I_LOGOUT_TYPE = 0x03,
+-	SRP_T_LOGOUT_TYPE = 0x80,
+-	SRP_TSK_MGMT_TYPE = 0x01,
+-	SRP_CMD_TYPE = 0x02,
+-	SRP_RSP_TYPE = 0xC1,
+-	SRP_CRED_REQ_TYPE = 0x81,
+-	SRP_CRED_RSP_TYPE = 0x41,
+-	SRP_AER_REQ_TYPE = 0x82,
+-	SRP_AER_RSP_TYPE = 0x42
+-};
+-
+-enum srp_descriptor_formats {
+-	SRP_NO_BUFFER = 0x00,
+-	SRP_DIRECT_BUFFER = 0x01,
+-	SRP_INDIRECT_BUFFER = 0x02
+-};
+-
+-struct memory_descriptor {
+-	u64 virtual_address;
+-	u32 memory_handle;
+-	u32 length;
+-};
+-
+-struct indirect_descriptor {
+-	struct memory_descriptor head;
+-	u32 total_length;
+-	struct memory_descriptor list[1] PACKED;
+-};
+-
+-struct srp_generic {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_login_req {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 max_requested_initiator_to_target_iulen;
+-	u32 reserved2;
+-	u16 required_buffer_formats;
+-	u8 reserved3:6;
+-	u8 multi_channel_action:2;
+-	u8 reserved4;
+-	u32 reserved5;
+-	u8 initiator_port_identifier[16];
+-	u8 target_port_identifier[16];
+-};
+-
+-struct srp_login_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 max_initiator_to_target_iulen;
+-	u32 max_target_to_initiator_iulen;
+-	u16 supported_buffer_formats;
+-	u8 reserved2:6;
+-	u8 multi_channel_result:2;
+-	u8 reserved3;
+-	u8 reserved4[24];
+-};
+-
+-struct srp_login_rej {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-	u64 reserved2;
+-	u16 supported_buffer_formats;
+-	u8 reserved3[6];
+-};
+-
+-struct srp_i_logout {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_t_logout {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-};
+-
+-struct srp_tsk_mgmt {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4;
+-	u8 task_mgmt_flags;
+-	u8 reserved5;
+-	u64 managed_task_tag;
+-	u64 reserved6;
+-};
+-
+-struct srp_cmd {
+-	u8 type;
+-	u32 reserved1 PACKED;
+-	u8 data_out_format:4;
+-	u8 data_in_format:4;
+-	u8 data_out_count;
+-	u8 data_in_count;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4:5;
+-	u8 task_attribute:3;
+-	u8 reserved5;
+-	u8 additional_cdb_len;
+-	u8 cdb[16];
+-	u8 additional_data[0x100 - 0x30];
+-};
+-
+-struct srp_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u16 reserved2;
+-	u8 reserved3:2;
+-	u8 diunder:1;
+-	u8 diover:1;
+-	u8 dounder:1;
+-	u8 doover:1;
+-	u8 snsvalid:1;
+-	u8 rspvalid:1;
+-	u8 status;
+-	u32 data_in_residual_count;
+-	u32 data_out_residual_count;
+-	u32 sense_data_list_length;
+-	u32 response_data_list_length;
+-	u8 sense_and_response_data[18];
+-};
+-
+-struct srp_cred_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-};
+-
+-struct srp_cred_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_aer_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun;
+-	u32 sense_data_list_length;
+-	u32 reserved3;
+-	u8 sense_data[20];
+-};
+-
+-struct srp_aer_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-union srp_iu {
+-	struct srp_generic generic;
+-	struct srp_login_req login_req;
+-	struct srp_login_rsp login_rsp;
+-	struct srp_login_rej login_rej;
+-	struct srp_i_logout i_logout;
+-	struct srp_t_logout t_logout;
+-	struct srp_tsk_mgmt tsk_mgmt;
+-	struct srp_cmd cmd;
+-	struct srp_rsp rsp;
+-	struct srp_cred_req cred_req;
+-	struct srp_cred_rsp cred_rsp;
+-	struct srp_aer_req aer_req;
+-	struct srp_aer_rsp aer_rsp;
+-};
+-
+-#endif
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,461 @@
+Subject: [PATCH] scsi tgt: add task management function support
+
+This patch addes task management function support to tgt. This
+assumes that all the previous patchsets are applied.
+
+- add callback to task management function to scsi_host_template
+structure. It is used notify LLDs of the completion of a TMF request.
+
+- this patch doesn't use a single queue for TMF requests and SCSI
+commands yet. We'll work on it later on.
+
+- when LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command for ABORT_TASK.
+
+- when tgt aborts a command, it calls eh_abort_handler in
+scsi_host_template structure. Would be better to add
+tgt_eh_abort_handler for LLDs support target and initiator modes at
+the same time?
+
+tgt TMF works in the followings:
+
+- When LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command.
+
+- LLDs call 'int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *host, int,
+u64 tag, struct scsi_lun *lun, void *data)'.
+
+- int (* tsk_mgmt_response)(u64 data, int result) is added to
+scsi_host_template.
+
+When an initiator sends a task management request, the LLD calls
+scsi_tgt_tsk_mgmt_request. the LLD can use whatever it wants for the
+data arg. The data arg is used later as the arg in the
+tsk_mgmt_response callback.
+
+tgt core just sends the task management request to user space
+(by using TGT_KEVENT_TSK_MGMT_REQ).
+
+In the case of ABORT_TASK, tgtd finds a single command to abort and
+sends TGT_UEVENT_CMD_RSP and TGT_UEVENT_TSK_MGMT_RSP events.
+
+tgt core calls eh_abort_handler for TGT_UEVENT_CMD_RSP and then
+tsk_mgmt_response for TGT_UEVENT_TSK_MGMT_RSP.
+
+If tgtd fails to find a command to abort, it sends only
+TGT_UEVENT_TSK_MGMT_RSP event (no TGT_UEVENT_CMD_RSP event).
+
+In the case of the rests task management function (like
+ABORT_TASK_SET), tgt needs to abort multiple commands. Thus, tgtd
+finds multiple commands to abort and sends multiple TGT_UEVENT_CMD_RSP
+events and a single TGT_UEVENT_TSK_MGMT_RSP event. tgt core calls
+eh_abort_handler multiple times and tsk_mgmt_response once.
+
+eh_abort_handler enables LLDs to safely free resource related with a
+command to abort.
+
+Signed-off-by: FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">fujita.tomonori at lab.ntt.co.jp</A>&gt;
+Signed-off-by: Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
+
+---
+
+ drivers/scsi/scsi_tgt_if.c   |   43 +++++++++++++++---
+ drivers/scsi/scsi_tgt_lib.c  |  103 +++++++++++++++++++++++++++++-------------
+ drivers/scsi/scsi_tgt_priv.h |   11 +++-
+ include/scsi/scsi_host.h     |    3 +
+ include/scsi/scsi_tgt.h      |    6 ++
+ include/scsi/scsi_tgt_if.h   |    7 ++-
+ 6 files changed, 125 insertions(+), 48 deletions(-)
+
+b9579b62f8d6309815a60da2e6f9a7638df074aa
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index a31c8d5..ba1b75b 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -56,7 +56,8 @@ static int send_event_rsp(uint16_t type,
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+ 
+-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
++int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
++			 gfp_t flags)
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct sk_buff *skb;
+@@ -71,7 +72,7 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
++	skb = alloc_skb(NLMSG_SPACE(len), flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+ 
+@@ -85,9 +86,11 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	memcpy(ev-&gt;k.cmd_req.scb, cmd-&gt;cmnd, sizeof(ev-&gt;k.cmd_req.scb));
+ 	memcpy(ev-&gt;k.cmd_req.lun, lun, sizeof(ev-&gt;k.cmd_req.lun));
+ 	ev-&gt;k.cmd_req.attribute = cmd-&gt;tag;
++	ev-&gt;k.cmd_req.tag = tag;
+ 
+-	dprintk(&quot;%d %u %u\n&quot;, ev-&gt;k.cmd_req.host_no, ev-&gt;k.cmd_req.cid,
+-		ev-&gt;k.cmd_req.data_len);
++	dprintk(&quot;%p %d %u %u %x %llx\n&quot;, cmd, shost-&gt;host_no, ev-&gt;k.cmd_req.cid,
++		ev-&gt;k.cmd_req.data_len, cmd-&gt;tag,
++		(unsigned long long) ev-&gt;k.cmd_req.tag);
+ 
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err &lt; 0)
+@@ -109,6 +112,24 @@ int scsi_tgt_uspace_send_status(struct s
+ 	return send_event_rsp(TGT_KEVENT_CMD_DONE, &amp;ev, gfp_mask, tgtd_pid);
+ }
+ 
++int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++				  struct scsi_lun *scsilun, void *data)
++{
++	struct tgt_event ev;
++
++	memset(&amp;ev, 0, sizeof(ev));
++	ev.k.tsk_mgmt_req.host_no = host_no;
++	ev.k.tsk_mgmt_req.function = function;
++	ev.k.tsk_mgmt_req.tag = tag;
++	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
++	ev.k.tsk_mgmt_req.mid = (u64) data;
++
++	dprintk(&quot;%d %x %llx %llx\n&quot;, host_no, function, (unsigned long long) tag,
++		(unsigned long long) ev.k.tsk_mgmt_req.mid);
++
++	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &amp;ev, GFP_KERNEL, tgtd_pid);
++}
++
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+ {
+ 	struct tgt_event *ev = NLMSG_DATA(nlh);
+@@ -130,6 +151,11 @@ static int event_recv_msg(struct sk_buff
+ 					   ev-&gt;u.cmd_rsp.uaddr,
+ 					   ev-&gt;u.cmd_rsp.rw);
+ 		break;
++	case TGT_UEVENT_TSK_MGMT_RSP:
++		err = scsi_tgt_kspace_tsk_mgmt(ev-&gt;u.tsk_mgmt_rsp.host_no,
++					       ev-&gt;u.tsk_mgmt_rsp.mid,
++					       ev-&gt;u.tsk_mgmt_rsp.result);
++		break;
+ 	default:
+ 		eprintk(&quot;unknown type %d\n&quot;, nlh-&gt;nlmsg_type);
+ 		err = -EINVAL;
+@@ -143,6 +169,7 @@ static int event_recv_skb(struct sk_buff
+ 	int err;
+ 	uint32_t rlen;
+ 	struct nlmsghdr	*nlh;
++	struct tgt_event ev;
+ 
+ 	while (skb-&gt;len &gt;= NLMSG_SPACE(0)) {
+ 		nlh = (struct nlmsghdr *) skb-&gt;data;
+@@ -158,9 +185,11 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh-&gt;nlmsg_type != TGT_UEVENT_CMD_RSP) {
+-			struct tgt_event ev;
+-
++		switch (nlh-&gt;nlmsg_type) {
++		case TGT_UEVENT_CMD_RSP:
++		case TGT_UEVENT_TSK_MGMT_RSP:
++			break;
++		default:
+ 			memset(&amp;ev, 0, sizeof(ev));
+ 			ev.k.event_rsp.err = err;
+ 			send_event_rsp(TGT_KEVENT_RSP, &amp;ev,
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 2cbc749..5a98fc4 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -49,6 +49,7 @@ struct scsi_tgt_cmd {
+ 
+ 	struct list_head hash_list;
+ 	struct request *rq;
++	u64 tag;
+ };
+ 
+ #define TGT_HASH_ORDER	4
+@@ -106,7 +107,6 @@ static void scsi_tgt_cmd_destroy(void *d
+ 		cmd-&gt;request-&gt;flags &amp;= ~1UL;
+ 
+ 	scsi_unmap_user_pages(tcmd);
+-	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
+ 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
+ }
+@@ -118,19 +118,11 @@ static void init_scsi_tgt_cmd(struct req
+ 	struct list_head *head;
+ 	static u32 tag = 0;
+ 
+-	tcmd-&gt;lun = rq-&gt;end_io_data;
+-	bio_list_init(&amp;tcmd-&gt;xfer_list);
+-	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
+-
+ 	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
+ 	rq-&gt;tag = tag++;
+ 	head = &amp;qdata-&gt;cmd_hash[cmd_hashfn(rq-&gt;tag)];
+ 	list_add(&amp;tcmd-&gt;hash_list, head);
+ 	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
+-
+-	tcmd-&gt;rq = rq;
+-	rq-&gt;end_io_data = tcmd;
+-	rq-&gt;flags |= REQ_DONTPREP;
+ }
+ 
+ static void scsi_tgt_uspace_send_fn(void *data)
+@@ -148,33 +140,22 @@ retry:
+ 	if (list_empty(&amp;qdata-&gt;cmd_req))
+ 		return;
+ 
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd) {
+-		err = -ENOMEM;
+-		goto out;
+-	}
+-
+ 	mutex_lock(&amp;qdata-&gt;cmd_req_mutex);
+ 
+ 	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
+ 	if (list_empty(&amp;qdata-&gt;cmd_req)) {
+ 		spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
+ 		mutex_unlock(&amp;qdata-&gt;cmd_req_mutex);
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 		goto out;
+ 	}
+ 	rq = list_entry_rq(qdata-&gt;cmd_req.next);
+ 	list_del_init(&amp;rq-&gt;queuelist);
+ 	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
+ 
+-	if ((rq-&gt;flags &amp; REQ_DONTPREP)) {
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+-		tcmd = rq-&gt;end_io_data;
+-	} else
+-		init_scsi_tgt_cmd(rq, tcmd);
+-
++	tcmd = rq-&gt;end_io_data;
++	init_scsi_tgt_cmd(rq, tcmd);
+ 	cmd = rq-&gt;special;
+-	err = scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, GFP_ATOMIC);
++	err = scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, tcmd-&gt;tag, GFP_ATOMIC);
+ 	if (err &lt; 0) {
+ 		eprintk(&quot;failed to send: %p %d\n&quot;, cmd, err);
+ 
+@@ -266,20 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+  * @scsilun:	scsi lun
+  * @noblock:	set to nonzero if the command should be queued
+  **/
+-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+-			    int noblock)
++int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
++			   u64 tag)
+ {
+ 	struct request_queue *q = cmd-&gt;request-&gt;q;
+ 	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
+ 	unsigned long flags;
++	struct scsi_tgt_cmd *tcmd;
++
++	/*
++	 * It would be better to allocate scsi_tgt_cmd structure in
++	 * scsi_host_get_command and not to fail due to OOM.
++	 */
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd)
++		return -ENOMEM;
++	cmd-&gt;request-&gt;end_io_data = tcmd;
+ 
+-	cmd-&gt;request-&gt;end_io_data = scsilun;
++	bio_list_init(&amp;tcmd-&gt;xfer_list);
++	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
++	tcmd-&gt;lun = scsilun;
++	tcmd-&gt;tag = tag;
++	tcmd-&gt;rq = cmd-&gt;request;
+ 
+ 	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
+ 	list_add_tail(&amp;cmd-&gt;request-&gt;queuelist, &amp;qdata-&gt;cmd_req);
+ 	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
+ 
+ 	queue_work(scsi_tgtd, &amp;qdata-&gt;uspace_send_work);
++	return 0;
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -293,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
+ 
+ 	dprintk(&quot;cmd %p %lu\n&quot;, cmd, rq_data_dir(cmd-&gt;request));
+ 
+-	/* don't we have to call this if result is set or not */
+-	if (cmd-&gt;result) {
+-		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+-		return;
+-	}
+-
++	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+ 	INIT_WORK(&amp;tcmd-&gt;work, scsi_tgt_cmd_destroy, cmd);
+ 	queue_work(scsi_tgtd, &amp;tcmd-&gt;work);
+ }
+@@ -495,6 +486,18 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
++static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
++{
++	int err;
++
++	err = host-&gt;hostt-&gt;eh_abort_handler(cmd);
++	if (err)
++		eprintk(&quot;fail to abort %p\n&quot;, cmd);
++
++	scsi_tgt_cmd_destroy(cmd);
++	return err;
++}
++
+ static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
+ {
+ 	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
+@@ -545,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 	dprintk(&quot;cmd %p result %d len %d bufflen %u %lu %x\n&quot;, cmd,
+ 		result, len, cmd-&gt;request_bufflen, rq_data_dir(rq), cmd-&gt;cmnd[0]);
+ 
++	if (result == TASK_ABORTED) {
++		scsi_tgt_abort_cmd(shost, cmd);
++		goto done;
++	}
+ 	/*
+ 	 * store the userspace values here, the working values are
+ 	 * in the request_* values
+@@ -585,6 +592,38 @@ done:
+ 	return err;
+ }
+ 
++int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
++			      struct scsi_lun *scsilun, void *data)
++{
++	int err;
++
++	/* TODO: need to retry if this fails. */
++	err = scsi_tgt_uspace_send_tsk_mgmt(shost-&gt;host_no, function,
++					    tag, scsilun, data);
++	if (err &lt; 0)
++		eprintk(&quot;The task management request lost!\n&quot;);
++	return err;
++}
++EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
++
++int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
++{
++	struct Scsi_Host *shost;
++	int err;
++
++	dprintk(&quot;%d %d %llx\n&quot;, host_no, result, (unsigned long long) mid);
++
++	shost = scsi_host_lookup(host_no);
++	if (IS_ERR(shost)) {
++		printk(KERN_ERR &quot;Could not find host no %d\n&quot;, host_no);
++		return -EINVAL;
++	}
++	err = shost-&gt;hostt-&gt;tsk_mgmt_response(mid, result);
++	scsi_host_put(shost);
++
++	return err;
++}
++
+ static int __init scsi_tgt_init(void)
+ {
+ 	int err;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 6fedcec..77a1d06 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -4,18 +4,21 @@ struct Scsi_Host;
+ struct task_struct;
+ 
+ /* tmp - will replace with SCSI logging stuff */
+-#define dprintk(fmt, args...)					\
++#define eprintk(fmt, args...)					\
+ do {								\
+ 	printk(&quot;%s(%d) &quot; fmt, __FUNCTION__, __LINE__, ##args);	\
+ } while (0)
+ 
+-#define eprintk dprintk
++#define dprintk eprintk
+ 
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
++extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
++				u64 tag, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+ 				unsigned long uaddr, u8 rw);
+-
++extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++					 struct scsi_lun *scsilun, void *data);
++extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
+diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
+index 8b799db..eca5721 100644
+--- a/include/scsi/scsi_host.h
++++ b/include/scsi/scsi_host.h
+@@ -153,6 +153,9 @@ struct scsi_host_template {
+ 	int (* transfer_data)(struct scsi_cmnd *,
+ 			      void (*done)(struct scsi_cmnd *));
+ 
++	/* Used as callback for the completion of task management request. */
++	int (* tsk_mgmt_response)(u64 mid, int result);
++
+ 	/*
+ 	 * This is an error handling strategy routine.  You don't need to
+ 	 * define one of these if you don't want to - there is a default
+diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
+index 91ad6bc..2d65be7 100644
+--- a/include/scsi/scsi_tgt.h
++++ b/include/scsi/scsi_tgt.h
+@@ -6,6 +6,8 @@ struct Scsi_Host;
+ struct scsi_cmnd;
+ struct scsi_lun;
+ 
+-extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
++extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
+ extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
+-extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
++extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
++extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
++				     void *);
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index ebca452..63b2e3a 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -52,7 +52,7 @@ struct tgt_event {
+ 		} cmd_rsp;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			uint64_t mid;
+ 			int result;
+ 		} tsk_mgmt_rsp;
+ 	} u;
+@@ -69,6 +69,7 @@ struct tgt_event {
+ 			uint8_t scb[16];
+ 			uint8_t lun[8];
+ 			int attribute;
++			uint64_t tag;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+@@ -77,10 +78,10 @@ struct tgt_event {
+ 		} cmd_done;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			int function;
+ 			uint64_t tag;
+ 			uint8_t lun[8];
+-			int function;
++			uint64_t mid;
+ 		} tsk_mgmt_req;
+ 	} k;
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
===================================================================
--- branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,1767 @@
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..e9d3388 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2287,23 +2287,24 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	 */
+ 	uaddr = (unsigned long) ubuf;
+ 	if (!(uaddr &amp; queue_dma_alignment(q)) &amp;&amp; !(len &amp; queue_dma_alignment(q)))
+-		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
++		bio = bio_map_user(q, NULL, uaddr, len, reading);
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+-	if (!IS_ERR(bio)) {
+-		rq-&gt;bio = rq-&gt;biotail = bio;
+-		blk_rq_bio_prep(q, rq, bio);
++	if (IS_ERR(bio))
++		return PTR_ERR(bio);
+ 
+-		rq-&gt;buffer = rq-&gt;data = NULL;
+-		rq-&gt;data_len = len;
+-		return 0;
++	if (bio-&gt;bi_size != len) {
++		bio_endio(bio, bio-&gt;bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
+ 	}
+ 
+-	/*
+-	 * bio is the err-ptr
+-	 */
+-	return PTR_ERR(bio);
++	rq-&gt;bio = rq-&gt;biotail = bio;
++	blk_rq_bio_prep(q, rq, bio);
++	rq-&gt;buffer = rq-&gt;data = NULL;
++	rq-&gt;data_len = len;
++	return 0;
+ }
+ 
+ EXPORT_SYMBOL(blk_rq_map_user);
+@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
+  *    unmapping.
+  */
+ int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
+-			struct sg_iovec *iov, int iov_count)
++			struct sg_iovec *iov, int iov_count, unsigned int len)
+ {
+ 	struct bio *bio;
+ 
+@@ -2339,11 +2340,16 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	/* we don't allow misaligned data like bio_map_user() does.  If the
+ 	 * user is using sg, they're expected to know the alignment constraints
+ 	 * and respect them accordingly */
+-	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
+-				0);
++	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
++	if (bio-&gt;bi_size != len) {
++		bio_endio(bio, bio-&gt;bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
++	}
++
+ 	rq-&gt;bio = rq-&gt;biotail = bio;
+ 	blk_rq_bio_prep(q, rq, bio);
+ 	rq-&gt;buffer = rq-&gt;data = NULL;
+@@ -2765,16 +2771,12 @@ static void init_request_from_bio(struct
+ 
+ 	req-&gt;errors = 0;
+ 	req-&gt;hard_sector = req-&gt;sector = bio-&gt;bi_sector;
+-	req-&gt;hard_nr_sectors = req-&gt;nr_sectors = bio_sectors(bio);
+-	req-&gt;current_nr_sectors = req-&gt;hard_cur_sectors = bio_cur_sectors(bio);
+-	req-&gt;nr_phys_segments = bio_phys_segments(req-&gt;q, bio);
+-	req-&gt;nr_hw_segments = bio_hw_segments(req-&gt;q, bio);
+-	req-&gt;buffer = bio_data(bio);	/* see -&gt;buffer comment above */
+ 	req-&gt;waiting = NULL;
+-	req-&gt;bio = req-&gt;biotail = bio;
+ 	req-&gt;ioprio = bio_prio(bio);
+ 	req-&gt;rq_disk = bio-&gt;bi_bdev-&gt;bd_disk;
+ 	req-&gt;start_time = jiffies;
++
++	blk_rq_bio_prep(req-&gt;q, req, bio);
+ }
+ 
+ static int __make_request(request_queue_t *q, struct bio *bio)
+@@ -3403,9 +3405,6 @@ EXPORT_SYMBOL(end_request);
+ 
+ void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
+ {
+-	/* first three bits are identical in rq-&gt;flags and bio-&gt;bi_rw */
+-	rq-&gt;flags |= (bio-&gt;bi_rw &amp; 7);
+-
+ 	rq-&gt;nr_phys_segments = bio_phys_segments(q, bio);
+ 	rq-&gt;nr_hw_segments = bio_hw_segments(q, bio);
+ 	rq-&gt;current_nr_sectors = bio_cur_sectors(bio);
+diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
+index 24f7af9..ef9900d 100644
+--- a/block/scsi_ioctl.c
++++ b/block/scsi_ioctl.c
+@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
+ 			goto out;
+ 		}
+ 
+-		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count);
++		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count,
++					  hdr-&gt;dxfer_len);
+ 		kfree(iov);
+ 	} else if (hdr-&gt;dxfer_len)
+ 		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
+index eaefedd..e7bd028 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.c
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
+@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
+ 			++in_use;
+ 		if (pool-&gt;events[i].ext_list) {
+ 			dma_free_coherent(hostdata-&gt;dev,
+-				  SG_ALL * sizeof(struct memory_descriptor),
++				  SG_ALL * sizeof(struct srp_direct_buf),
+ 				  pool-&gt;events[i].ext_list,
+ 				  pool-&gt;events[i].ext_list_token);
+ 		}
+@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
+ 			      struct srp_cmd *srp_cmd, 
+ 			      int numbuf)
+ {
++	u8 fmt;
++
+ 	if (numbuf == 0)
+ 		return;
+ 	
+-	if (numbuf == 1) {
++	if (numbuf == 1)
++		fmt = SRP_DATA_DESC_DIRECT;
++	else {
++		fmt = SRP_DATA_DESC_INDIRECT;
++		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
++
+ 		if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE)
+-			srp_cmd-&gt;data_out_format = SRP_DIRECT_BUFFER;
+-		else 
+-			srp_cmd-&gt;data_in_format = SRP_DIRECT_BUFFER;
+-	} else {
+-		if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE) {
+-			srp_cmd-&gt;data_out_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd-&gt;data_out_count =
+-				numbuf &lt; MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		} else {
+-			srp_cmd-&gt;data_in_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd-&gt;data_in_count =
+-				numbuf &lt; MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		}
++			srp_cmd-&gt;data_out_desc_cnt = numbuf;
++		else
++			srp_cmd-&gt;data_in_desc_cnt = numbuf;
+ 	}
++
++	if (cmd-&gt;sc_data_direction == DMA_TO_DEVICE)
++		srp_cmd-&gt;buf_fmt = fmt &lt;&lt; 4;
++	else
++		srp_cmd-&gt;buf_fmt = fmt;
+ }
+ 
+-static void unmap_sg_list(int num_entries, 
++static void unmap_sg_list(int num_entries,
+ 		struct device *dev,
+-		struct memory_descriptor *md)
+-{ 
++		struct srp_direct_buf *md)
++{
+ 	int i;
+ 
+-	for (i = 0; i &lt; num_entries; ++i) {
+-		dma_unmap_single(dev,
+-			md[i].virtual_address,
+-			md[i].length, DMA_BIDIRECTIONAL);
+-	}
++	for (i = 0; i &lt; num_entries; ++i)
++		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
+ }
+ 
+ /**
+@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
+ 			   struct srp_event_struct *evt_struct,
+ 			   struct device *dev)
+ {
+-	if ((cmd-&gt;data_out_format == SRP_NO_BUFFER) &amp;&amp;
+-	    (cmd-&gt;data_in_format == SRP_NO_BUFFER))
++	u8 out_fmt, in_fmt;
++
++	out_fmt = cmd-&gt;buf_fmt &gt;&gt; 4;
++	in_fmt = cmd-&gt;buf_fmt &amp; ((1U &lt;&lt; 4) - 1);
++
++	if (out_fmt == SRP_NO_DATA_DESC &amp;&amp; in_fmt == SRP_NO_DATA_DESC)
+ 		return;
+-	else if ((cmd-&gt;data_out_format == SRP_DIRECT_BUFFER) ||
+-		 (cmd-&gt;data_in_format == SRP_DIRECT_BUFFER)) {
+-		struct memory_descriptor *data =
+-			(struct memory_descriptor *)cmd-&gt;additional_data;
+-		dma_unmap_single(dev, data-&gt;virtual_address, data-&gt;length,
+-				 DMA_BIDIRECTIONAL);
++	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
++		 in_fmt == SRP_DATA_DESC_DIRECT) {
++		struct srp_direct_buf *data =
++			(struct srp_direct_buf *) cmd-&gt;add_data;
++		dma_unmap_single(dev, data-&gt;va, data-&gt;len, DMA_BIDIRECTIONAL);
+ 	} else {
+-		struct indirect_descriptor *indirect =
+-			(struct indirect_descriptor *)cmd-&gt;additional_data;
+-		int num_mapped = indirect-&gt;head.length / 
+-			sizeof(indirect-&gt;list[0]);
++		struct srp_indirect_buf *indirect =
++			(struct srp_indirect_buf *) cmd-&gt;add_data;
++		int num_mapped = indirect-&gt;table_desc.len /
++			sizeof(struct srp_direct_buf);
+ 
+ 		if (num_mapped &lt;= MAX_INDIRECT_BUFS) {
+-			unmap_sg_list(num_mapped, dev, &amp;indirect-&gt;list[0]);
++			unmap_sg_list(num_mapped, dev, &amp;indirect-&gt;desc_list[0]);
+ 			return;
+ 		}
+ 
+@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
+ 
+ static int map_sg_list(int num_entries, 
+ 		       struct scatterlist *sg,
+-		       struct memory_descriptor *md)
++		       struct srp_direct_buf *md)
+ {
+ 	int i;
+ 	u64 total_length = 0;
+ 
+ 	for (i = 0; i &lt; num_entries; ++i) {
+-		struct memory_descriptor *descr = md + i;
++		struct srp_direct_buf *descr = md + i;
+ 		struct scatterlist *sg_entry = &amp;sg[i];
+-		descr-&gt;virtual_address = sg_dma_address(sg_entry);
+-		descr-&gt;length = sg_dma_len(sg_entry);
+-		descr-&gt;memory_handle = 0;
++		descr-&gt;va = sg_dma_address(sg_entry);
++		descr-&gt;len = sg_dma_len(sg_entry);
++		descr-&gt;key = 0;
+ 		total_length += sg_dma_len(sg_entry);
+  	}
+ 	return total_length;
+@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
+ 	int sg_mapped;
+ 	u64 total_length = 0;
+ 	struct scatterlist *sg = cmd-&gt;request_buffer;
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd-&gt;additional_data;
+-	struct indirect_descriptor *indirect =
+-	    (struct indirect_descriptor *)data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd-&gt;add_data;
++	struct srp_indirect_buf *indirect =
++		(struct srp_indirect_buf *) data;
+ 
+ 	sg_mapped = dma_map_sg(dev, sg, cmd-&gt;use_sg, DMA_BIDIRECTIONAL);
+ 
+@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	/* special case; we can use a single direct descriptor */
+ 	if (sg_mapped == 1) {
+-		data-&gt;virtual_address = sg_dma_address(&amp;sg[0]);
+-		data-&gt;length = sg_dma_len(&amp;sg[0]);
+-		data-&gt;memory_handle = 0;
++		data-&gt;va = sg_dma_address(&amp;sg[0]);
++		data-&gt;len = sg_dma_len(&amp;sg[0]);
++		data-&gt;key = 0;
+ 		return 1;
+ 	}
+ 
+@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
+ 		return 0;
+ 	}
+ 
+-	indirect-&gt;head.virtual_address = 0;
+-	indirect-&gt;head.length = sg_mapped * sizeof(indirect-&gt;list[0]);
+-	indirect-&gt;head.memory_handle = 0;
++	indirect-&gt;table_desc.va = 0;
++	indirect-&gt;table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
++	indirect-&gt;table_desc.key = 0;
+ 
+ 	if (sg_mapped &lt;= MAX_INDIRECT_BUFS) {
+-		total_length = map_sg_list(sg_mapped, sg, &amp;indirect-&gt;list[0]);
+-		indirect-&gt;total_length = total_length;
++		total_length = map_sg_list(sg_mapped, sg,
++					   &amp;indirect-&gt;desc_list[0]);
++		indirect-&gt;len = total_length;
+ 		return 1;
+ 	}
+ 
+ 	/* get indirect table */
+ 	if (!evt_struct-&gt;ext_list) {
+-		evt_struct-&gt;ext_list =(struct memory_descriptor*)
++		evt_struct-&gt;ext_list = (struct srp_direct_buf *)
+ 			dma_alloc_coherent(dev, 
+-				SG_ALL * sizeof(struct memory_descriptor),
+-				&amp;evt_struct-&gt;ext_list_token, 0);
++					   SG_ALL * sizeof(struct srp_direct_buf),
++					   &amp;evt_struct-&gt;ext_list_token, 0);
+ 		if (!evt_struct-&gt;ext_list) {
+-		    printk(KERN_ERR
+-		   	&quot;ibmvscsi: Can't allocate memory for indirect table\n&quot;);
++			printk(KERN_ERR
++			       &quot;ibmvscsi: Can't allocate memory for indirect table\n&quot;);
+ 			return 0;
+ 			
+ 		}
+@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	total_length = map_sg_list(sg_mapped, sg, evt_struct-&gt;ext_list);	
+ 
+-	indirect-&gt;total_length = total_length;
+-	indirect-&gt;head.virtual_address = evt_struct-&gt;ext_list_token;
+-	indirect-&gt;head.length = sg_mapped * sizeof(indirect-&gt;list[0]);
+-	memcpy(indirect-&gt;list, evt_struct-&gt;ext_list,
+-		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
++	indirect-&gt;len = total_length;
++	indirect-&gt;table_desc.va = evt_struct-&gt;ext_list_token;
++	indirect-&gt;table_desc.len = sg_mapped * sizeof(indirect-&gt;desc_list[0]);
++	memcpy(indirect-&gt;desc_list, evt_struct-&gt;ext_list,
++	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
+ 	
+  	return 1;
+ }
+@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
+ static int map_single_data(struct scsi_cmnd *cmd,
+ 			   struct srp_cmd *srp_cmd, struct device *dev)
+ {
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd-&gt;additional_data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd-&gt;add_data;
+ 
+-	data-&gt;virtual_address =
++	data-&gt;va =
+ 		dma_map_single(dev, cmd-&gt;request_buffer,
+ 			       cmd-&gt;request_bufflen,
+ 			       DMA_BIDIRECTIONAL);
+-	if (dma_mapping_error(data-&gt;virtual_address)) {
++	if (dma_mapping_error(data-&gt;va)) {
+ 		printk(KERN_ERR
+ 		       &quot;ibmvscsi: Unable to map request_buffer for command!\n&quot;);
+ 		return 0;
+ 	}
+-	data-&gt;length = cmd-&gt;request_bufflen;
+-	data-&gt;memory_handle = 0;
++	data-&gt;len = cmd-&gt;request_bufflen;
++	data-&gt;key = 0;
+ 
+ 	set_srp_direction(cmd, srp_cmd, 1);
+ 
+@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
+ 
+ 	/* Copy the IU into the transfer area */
+ 	*evt_struct-&gt;xfer_iu = evt_struct-&gt;iu;
+-	evt_struct-&gt;xfer_iu-&gt;srp.generic.tag = (u64)evt_struct;
++	evt_struct-&gt;xfer_iu-&gt;srp.rsp.tag = (u64)evt_struct;
+ 
+ 	/* Add this to the sent list.  We need to do this 
+ 	 * before we actually send 
+@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
+ 	struct srp_rsp *rsp = &amp;evt_struct-&gt;xfer_iu-&gt;srp.rsp;
+ 	struct scsi_cmnd *cmnd = evt_struct-&gt;cmnd;
+ 
+-	if (unlikely(rsp-&gt;type != SRP_RSP_TYPE)) {
++	if (unlikely(rsp-&gt;opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: bad SRP RSP type %d\n&quot;,
+-			       rsp-&gt;type);
++			       rsp-&gt;opcode);
+ 	}
+ 	
+ 	if (cmnd) {
+ 		cmnd-&gt;result = rsp-&gt;status;
+ 		if (((cmnd-&gt;result &gt;&gt; 1) &amp; 0x1f) == CHECK_CONDITION)
+ 			memcpy(cmnd-&gt;sense_buffer,
+-			       rsp-&gt;sense_and_response_data,
+-			       rsp-&gt;sense_data_list_length);
++			       rsp-&gt;data,
++			       rsp-&gt;sense_data_len);
+ 		unmap_cmd_data(&amp;evt_struct-&gt;iu.srp.cmd, 
+ 			       evt_struct, 
+ 			       evt_struct-&gt;hostdata-&gt;dev);
+ 
+-		if (rsp-&gt;doover)
+-			cmnd-&gt;resid = rsp-&gt;data_out_residual_count;
+-		else if (rsp-&gt;diover)
+-			cmnd-&gt;resid = rsp-&gt;data_in_residual_count;
++		if (rsp-&gt;flags &amp; SRP_RSP_FLAG_DOOVER)
++			cmnd-&gt;resid = rsp-&gt;data_out_res_cnt;
++		else if (rsp-&gt;flags &amp; SRP_RSP_FLAG_DIOVER)
++			cmnd-&gt;resid = rsp-&gt;data_in_res_cnt;
+ 	}
+ 
+ 	if (evt_struct-&gt;cmnd_done)
+@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
+ {
+ 	struct srp_cmd *srp_cmd;
+ 	struct srp_event_struct *evt_struct;
+-	struct indirect_descriptor *indirect;
++	struct srp_indirect_buf *indirect;
+ 	struct ibmvscsi_host_data *hostdata =
+ 		(struct ibmvscsi_host_data *)&amp;cmnd-&gt;device-&gt;host-&gt;hostdata;
+ 	u16 lun = lun_from_dev(cmnd-&gt;device);
++	u8 out_fmt, in_fmt;
+ 
+ 	evt_struct = get_event_struct(&amp;hostdata-&gt;pool);
+ 	if (!evt_struct)
+@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
+ 
+ 	/* Set up the actual SRP IU */
+ 	srp_cmd = &amp;evt_struct-&gt;iu.srp.cmd;
+-	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
+-	srp_cmd-&gt;type = SRP_CMD_TYPE;
++	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
++	srp_cmd-&gt;opcode = SRP_CMD;
+ 	memcpy(srp_cmd-&gt;cdb, cmnd-&gt;cmnd, sizeof(cmnd-&gt;cmnd));
+ 	srp_cmd-&gt;lun = ((u64) lun) &lt;&lt; 48;
+ 
+@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
+ 	evt_struct-&gt;cmnd_done = done;
+ 
+ 	/* Fix up dma address of the buffer itself */
+-	indirect = (struct indirect_descriptor *)srp_cmd-&gt;additional_data;
+-	if (((srp_cmd-&gt;data_out_format == SRP_INDIRECT_BUFFER) ||
+-	    (srp_cmd-&gt;data_in_format == SRP_INDIRECT_BUFFER)) &amp;&amp;
+-	    (indirect-&gt;head.virtual_address == 0)) {
+-		indirect-&gt;head.virtual_address = evt_struct-&gt;crq.IU_data_ptr +
+-		    offsetof(struct srp_cmd, additional_data) +
+-		    offsetof(struct indirect_descriptor, list);
++	indirect = (struct srp_indirect_buf *) srp_cmd-&gt;add_data;
++	out_fmt = srp_cmd-&gt;buf_fmt &gt;&gt; 4;
++	in_fmt = srp_cmd-&gt;buf_fmt &amp; ((1U &lt;&lt; 4) - 1);
++	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
++	     out_fmt == SRP_DATA_DESC_INDIRECT) &amp;&amp;
++	    indirect-&gt;table_desc.va == 0) {
++		indirect-&gt;table_desc.va = evt_struct-&gt;crq.IU_data_ptr +
++			offsetof(struct srp_cmd, add_data) +
++			offsetof(struct srp_indirect_buf, desc_list);
+ 	}
+ 
+ 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
+@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
+ static void login_rsp(struct srp_event_struct *evt_struct)
+ {
+ 	struct ibmvscsi_host_data *hostdata = evt_struct-&gt;hostdata;
+-	switch (evt_struct-&gt;xfer_iu-&gt;srp.generic.type) {
+-	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
++	switch (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.opcode) {
++	case SRP_LOGIN_RSP:	/* it worked! */
+ 		break;
+-	case SRP_LOGIN_REJ_TYPE:	/* refused! */
++	case SRP_LOGIN_REJ:	/* refused! */
+ 		printk(KERN_INFO &quot;ibmvscsi: SRP_LOGIN_REJ reason %u\n&quot;,
+ 		       evt_struct-&gt;xfer_iu-&gt;srp.login_rej.reason);
+ 		/* Login failed.  */
+@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
+ 	default:
+ 		printk(KERN_ERR
+ 		       &quot;ibmvscsi: Invalid login response typecode 0x%02x!\n&quot;,
+-		       evt_struct-&gt;xfer_iu-&gt;srp.generic.type);
++		       evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.opcode);
+ 		/* Login failed.  */
+ 		atomic_set(&amp;hostdata-&gt;request_limit, -1);
+ 		return;
+@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: SRP_LOGIN succeeded\n&quot;);
+ 
+-	if (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta &gt;
++	if (evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta &gt;
+ 	    (max_requests - 2))
+-		evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta =
++		evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta =
+ 		    max_requests - 2;
+ 
+ 	/* Now we know what the real request-limit is */
+ 	atomic_set(&amp;hostdata-&gt;request_limit,
+-		   evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta);
++		   evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta);
+ 
+ 	hostdata-&gt;host-&gt;can_queue =
+-	    evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.request_limit_delta - 2;
++	    evt_struct-&gt;xfer_iu-&gt;srp.login_rsp.req_lim_delta - 2;
+ 
+ 	if (hostdata-&gt;host-&gt;can_queue &lt; 1) {
+ 		printk(KERN_ERR &quot;ibmvscsi: Invalid request_limit_delta\n&quot;);
+@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
+ 
+ 	login = &amp;evt_struct-&gt;iu.srp.login_req;
+ 	memset(login, 0x00, sizeof(struct srp_login_req));
+-	login-&gt;type = SRP_LOGIN_REQ_TYPE;
+-	login-&gt;max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
+-	login-&gt;required_buffer_formats = 0x0006;
++	login-&gt;opcode = SRP_LOGIN_REQ;
++	login-&gt;req_it_iu_len = sizeof(union srp_iu);
++	login-&gt;req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
+ 	
+ 	/* Start out with a request limit of 1, since this is negotiated in
+ 	 * the login request we are just sending
+@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 	
+ 	/* Set up an abort SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt-&gt;type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt-&gt;opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt-&gt;lun = ((u64) lun) &lt;&lt; 48;
+-	tsk_mgmt-&gt;task_mgmt_flags = 0x01;	/* ABORT TASK */
+-	tsk_mgmt-&gt;managed_task_tag = (u64) found_evt;
++	tsk_mgmt-&gt;tsk_mgmt_func = SRP_TSK_ABORT_TASK;
++	tsk_mgmt-&gt;task_tag = (u64) found_evt;
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n&quot;,
+-	       tsk_mgmt-&gt;lun, tsk_mgmt-&gt;managed_task_tag);
++	       tsk_mgmt-&gt;lun, tsk_mgmt-&gt;task_tag);
+ 
+ 	evt-&gt;sync_srp = &amp;srp_rsp;
+ 	init_completion(&amp;evt-&gt;comp);
+@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
+ 	wait_for_completion(&amp;evt-&gt;comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: abort bad SRP RSP type %d\n&quot;,
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags &amp; SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+ 	if (rsp_rc) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+-		       &quot;ibmvscsi: abort code %d for task tag 0x%lx\n&quot;,
++			       &quot;ibmvscsi: abort code %d for task tag 0x%lx\n&quot;,
+ 			       rsp_rc,
+-			       tsk_mgmt-&gt;managed_task_tag);
++			       tsk_mgmt-&gt;task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 		spin_unlock_irqrestore(hostdata-&gt;host-&gt;host_lock, flags);
+ 		printk(KERN_INFO
+ 		       &quot;ibmvscsi: aborted task tag 0x%lx completed\n&quot;,
+-		       tsk_mgmt-&gt;managed_task_tag);
++		       tsk_mgmt-&gt;task_tag);
+ 		return SUCCESS;
+ 	}
+ 
+ 	printk(KERN_INFO
+ 	       &quot;ibmvscsi: successfully aborted task tag 0x%lx\n&quot;,
+-	       tsk_mgmt-&gt;managed_task_tag);
++	       tsk_mgmt-&gt;task_tag);
+ 
+ 	cmd-&gt;result = (DID_ABORT &lt;&lt; 16);
+ 	list_del(&amp;found_evt-&gt;list);
+@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
+ 
+ 	/* Set up a lun reset SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt-&gt;type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt-&gt;opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt-&gt;lun = ((u64) lun) &lt;&lt; 48;
+-	tsk_mgmt-&gt;task_mgmt_flags = 0x08;	/* LUN RESET */
++	tsk_mgmt-&gt;tsk_mgmt_func = SRP_TSK_LUN_RESET;
+ 
+ 	printk(KERN_INFO &quot;ibmvscsi: resetting device. lun 0x%lx\n&quot;,
+ 	       tsk_mgmt-&gt;lun);
+@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
+ 	wait_for_completion(&amp;evt-&gt;comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: reset bad SRP RSP type %d\n&quot;,
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags &amp; SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       &quot;ibmvscsi: reset code %d for task tag 0x%lx\n&quot;,
+-		       rsp_rc,
+-			       tsk_mgmt-&gt;managed_task_tag);
++			       rsp_rc, tsk_mgmt-&gt;task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
+ 	}
+ 
+ 	if (crq-&gt;format == VIOSRP_SRP_FORMAT)
+-		atomic_add(evt_struct-&gt;xfer_iu-&gt;srp.rsp.request_limit_delta,
++		atomic_add(evt_struct-&gt;xfer_iu-&gt;srp.rsp.req_lim_delta,
+ 			   &amp;hostdata-&gt;request_limit);
+ 
+ 	if (evt_struct-&gt;done)
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
+index 4550d71..5c6d935 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.h
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
+@@ -68,7 +68,7 @@ struct srp_event_struct {
+ 	void (*cmnd_done) (struct scsi_cmnd *);
+ 	struct completion comp;
+ 	union viosrp_iu *sync_srp;
+-	struct memory_descriptor *ext_list;
++	struct srp_direct_buf *ext_list;
+ 	dma_addr_t ext_list_token;
+ };
+ 
+diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+index f47dd87..58aa530 100644
+--- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
++++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+@@ -34,7 +34,6 @@
+ #include &lt;linux/dma-mapping.h&gt;
+ #include &lt;linux/interrupt.h&gt;
+ #include &quot;ibmvscsi.h&quot;
+-#include &quot;srp.h&quot;
+ 
+ static char partition_name[97] = &quot;UNKNOWN&quot;;
+ static unsigned int partition_number = -1;
+diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
+deleted file mode 100644
+index 7d8e4c4..0000000
+--- a/drivers/scsi/ibmvscsi/srp.h
++++ /dev/null
+@@ -1,227 +0,0 @@
+-/*****************************************************************************/
+-/* srp.h -- SCSI RDMA Protocol definitions                                   */
+-/*                                                                           */
+-/* Written By: Colin Devilbis, IBM Corporation                               */
+-/*                                                                           */
+-/* Copyright (C) 2003 IBM Corporation                                        */
+-/*                                                                           */
+-/* This program is free software; you can redistribute it and/or modify      */
+-/* it under the terms of the GNU General Public License as published by      */
+-/* the Free Software Foundation; either version 2 of the License, or         */
+-/* (at your option) any later version.                                       */
+-/*                                                                           */
+-/* This program is distributed in the hope that it will be useful,           */
+-/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+-/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+-/* GNU General Public License for more details.                              */
+-/*                                                                           */
+-/* You should have received a copy of the GNU General Public License         */
+-/* along with this program; if not, write to the Free Software               */
+-/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+-/*                                                                           */
+-/*                                                                           */
+-/* This file contains structures and definitions for the SCSI RDMA Protocol  */
+-/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
+-/* file was based on the 16a version of the standard                         */
+-/*                                                                           */
+-/*****************************************************************************/
+-#ifndef SRP_H
+-#define SRP_H
+-
+-#define SRP_VERSION &quot;16.a&quot;
+-
+-#define PACKED __attribute__((packed))
+-
+-enum srp_types {
+-	SRP_LOGIN_REQ_TYPE = 0x00,
+-	SRP_LOGIN_RSP_TYPE = 0xC0,
+-	SRP_LOGIN_REJ_TYPE = 0xC2,
+-	SRP_I_LOGOUT_TYPE = 0x03,
+-	SRP_T_LOGOUT_TYPE = 0x80,
+-	SRP_TSK_MGMT_TYPE = 0x01,
+-	SRP_CMD_TYPE = 0x02,
+-	SRP_RSP_TYPE = 0xC1,
+-	SRP_CRED_REQ_TYPE = 0x81,
+-	SRP_CRED_RSP_TYPE = 0x41,
+-	SRP_AER_REQ_TYPE = 0x82,
+-	SRP_AER_RSP_TYPE = 0x42
+-};
+-
+-enum srp_descriptor_formats {
+-	SRP_NO_BUFFER = 0x00,
+-	SRP_DIRECT_BUFFER = 0x01,
+-	SRP_INDIRECT_BUFFER = 0x02
+-};
+-
+-struct memory_descriptor {
+-	u64 virtual_address;
+-	u32 memory_handle;
+-	u32 length;
+-};
+-
+-struct indirect_descriptor {
+-	struct memory_descriptor head;
+-	u32 total_length;
+-	struct memory_descriptor list[1] PACKED;
+-};
+-
+-struct srp_generic {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_login_req {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 max_requested_initiator_to_target_iulen;
+-	u32 reserved2;
+-	u16 required_buffer_formats;
+-	u8 reserved3:6;
+-	u8 multi_channel_action:2;
+-	u8 reserved4;
+-	u32 reserved5;
+-	u8 initiator_port_identifier[16];
+-	u8 target_port_identifier[16];
+-};
+-
+-struct srp_login_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 max_initiator_to_target_iulen;
+-	u32 max_target_to_initiator_iulen;
+-	u16 supported_buffer_formats;
+-	u8 reserved2:6;
+-	u8 multi_channel_result:2;
+-	u8 reserved3;
+-	u8 reserved4[24];
+-};
+-
+-struct srp_login_rej {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-	u64 reserved2;
+-	u16 supported_buffer_formats;
+-	u8 reserved3[6];
+-};
+-
+-struct srp_i_logout {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_t_logout {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-};
+-
+-struct srp_tsk_mgmt {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4;
+-	u8 task_mgmt_flags;
+-	u8 reserved5;
+-	u64 managed_task_tag;
+-	u64 reserved6;
+-};
+-
+-struct srp_cmd {
+-	u8 type;
+-	u32 reserved1 PACKED;
+-	u8 data_out_format:4;
+-	u8 data_in_format:4;
+-	u8 data_out_count;
+-	u8 data_in_count;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4:5;
+-	u8 task_attribute:3;
+-	u8 reserved5;
+-	u8 additional_cdb_len;
+-	u8 cdb[16];
+-	u8 additional_data[0x100 - 0x30];
+-};
+-
+-struct srp_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u16 reserved2;
+-	u8 reserved3:2;
+-	u8 diunder:1;
+-	u8 diover:1;
+-	u8 dounder:1;
+-	u8 doover:1;
+-	u8 snsvalid:1;
+-	u8 rspvalid:1;
+-	u8 status;
+-	u32 data_in_residual_count;
+-	u32 data_out_residual_count;
+-	u32 sense_data_list_length;
+-	u32 response_data_list_length;
+-	u8 sense_and_response_data[18];
+-};
+-
+-struct srp_cred_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-};
+-
+-struct srp_cred_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_aer_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun;
+-	u32 sense_data_list_length;
+-	u32 reserved3;
+-	u8 sense_data[20];
+-};
+-
+-struct srp_aer_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-union srp_iu {
+-	struct srp_generic generic;
+-	struct srp_login_req login_req;
+-	struct srp_login_rsp login_rsp;
+-	struct srp_login_rej login_rej;
+-	struct srp_i_logout i_logout;
+-	struct srp_t_logout t_logout;
+-	struct srp_tsk_mgmt tsk_mgmt;
+-	struct srp_cmd cmd;
+-	struct srp_rsp rsp;
+-	struct srp_cred_req cred_req;
+-	struct srp_cred_rsp cred_rsp;
+-	struct srp_aer_req aer_req;
+-	struct srp_aer_rsp aer_rsp;
+-};
+-
+-#endif
+diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
+index 6a6bba8..90f1a61 100644
+--- a/drivers/scsi/ibmvscsi/viosrp.h
++++ b/drivers/scsi/ibmvscsi/viosrp.h
+@@ -33,7 +33,22 @@
+ /*****************************************************************************/
+ #ifndef VIOSRP_H
+ #define VIOSRP_H
+-#include &quot;srp.h&quot;
++#include &lt;scsi/srp.h&gt;
++
++#define SRP_VERSION &quot;16.a&quot;
++#define SRP_MAX_IU_LEN	256
++
++union srp_iu {
++	struct srp_login_req login_req;
++	struct srp_login_rsp login_rsp;
++	struct srp_login_rej login_rej;
++	struct srp_i_logout i_logout;
++	struct srp_t_logout t_logout;
++	struct srp_tsk_mgmt tsk_mgmt;
++	struct srp_cmd cmd;
++	struct srp_rsp rsp;
++	u8 reserved[SRP_MAX_IU_LEN];
++};
+ 
+ enum viosrp_crq_formats {
+ 	VIOSRP_SRP_FORMAT = 0x01,
+diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
+index 3cf02b1..9c22465 100644
+--- a/drivers/scsi/scsi.c
++++ b/drivers/scsi/scsi.c
+@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
+ 	spin_unlock(&amp;shost-&gt;free_list_lock);
+ 
+ 	spin_lock(q-&gt;queue_lock);
+-	if (blk_rq_tagged(rq))
+-		blk_queue_end_tag(q, rq);
+ 	__blk_put_request(q, rq);
+ 	spin_unlock_irqrestore(q-&gt;queue_lock, flags);
+ 
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index 38b35da..ba1b75b 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -35,15 +35,15 @@
+ static int tgtd_pid;
+ static struct sock *nl_sk;
+ 
+-static int send_event_res(uint16_t type, struct tgt_event *p,
+-			  void *data, int dlen, gfp_t flags, pid_t pid)
++static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
++			  pid_t pid)
+ {
+ 	struct tgt_event *ev;
+ 	struct nlmsghdr *nlh;
+ 	struct sk_buff *skb;
+ 	uint32_t len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + dlen);
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	skb = alloc_skb(len, flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+@@ -52,26 +52,27 @@ static int send_event_res(uint16_t type,
+ 
+ 	ev = NLMSG_DATA(nlh);
+ 	memcpy(ev, p, sizeof(*ev));
+-	if (dlen)
+-		memcpy(ev-&gt;data, data, dlen);
+ 
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+ 
+-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
++int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
++			 gfp_t flags)
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct sk_buff *skb;
+ 	struct nlmsghdr *nlh;
+ 	struct tgt_event *ev;
+-	struct tgt_cmd *tcmd;
+ 	int err, len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
++	/* FIXME: we need scsi core to do that. */
++	memcpy(cmd-&gt;cmnd, cmd-&gt;data_cmnd, MAX_COMMAND_SIZE);
++
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
++	skb = alloc_skb(NLMSG_SPACE(len), flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+ 
+@@ -82,16 +83,14 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	ev-&gt;k.cmd_req.host_no = shost-&gt;host_no;
+ 	ev-&gt;k.cmd_req.cid = cmd-&gt;request-&gt;tag;
+ 	ev-&gt;k.cmd_req.data_len = cmd-&gt;request_bufflen;
+-
+-	dprintk(&quot;%d %u %u\n&quot;, ev-&gt;k.cmd_req.host_no, ev-&gt;k.cmd_req.cid,
+-		ev-&gt;k.cmd_req.data_len);
+-
+-	/* FIXME: we need scsi core to do that. */
+-	memcpy(cmd-&gt;cmnd, cmd-&gt;data_cmnd, MAX_COMMAND_SIZE);
+-
+-	tcmd = (struct tgt_cmd *) ev-&gt;data;
+-	memcpy(tcmd-&gt;scb, cmd-&gt;cmnd, sizeof(tcmd-&gt;scb));
+-	memcpy(tcmd-&gt;lun, lun, sizeof(struct scsi_lun));
++	memcpy(ev-&gt;k.cmd_req.scb, cmd-&gt;cmnd, sizeof(ev-&gt;k.cmd_req.scb));
++	memcpy(ev-&gt;k.cmd_req.lun, lun, sizeof(ev-&gt;k.cmd_req.lun));
++	ev-&gt;k.cmd_req.attribute = cmd-&gt;tag;
++	ev-&gt;k.cmd_req.tag = tag;
++
++	dprintk(&quot;%p %d %u %u %x %llx\n&quot;, cmd, shost-&gt;host_no, ev-&gt;k.cmd_req.cid,
++		ev-&gt;k.cmd_req.data_len, cmd-&gt;tag,
++		(unsigned long long) ev-&gt;k.cmd_req.tag);
+ 
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err &lt; 0)
+@@ -104,15 +103,31 @@ int scsi_tgt_uspace_send_status(struct s
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct tgt_event ev;
+-	char dummy[sizeof(struct tgt_cmd)];
+ 
+ 	memset(&amp;ev, 0, sizeof(ev));
+ 	ev.k.cmd_done.host_no = shost-&gt;host_no;
+ 	ev.k.cmd_done.cid = cmd-&gt;request-&gt;tag;
+ 	ev.k.cmd_done.result = cmd-&gt;result;
+ 
+-	return send_event_res(TGT_KEVENT_CMD_DONE, &amp;ev, dummy, sizeof(dummy),
+-			      gfp_mask, tgtd_pid);
++	return send_event_rsp(TGT_KEVENT_CMD_DONE, &amp;ev, gfp_mask, tgtd_pid);
++}
++
++int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++				  struct scsi_lun *scsilun, void *data)
++{
++	struct tgt_event ev;
++
++	memset(&amp;ev, 0, sizeof(ev));
++	ev.k.tsk_mgmt_req.host_no = host_no;
++	ev.k.tsk_mgmt_req.function = function;
++	ev.k.tsk_mgmt_req.tag = tag;
++	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
++	ev.k.tsk_mgmt_req.mid = (u64) data;
++
++	dprintk(&quot;%d %x %llx %llx\n&quot;, host_no, function, (unsigned long long) tag,
++		(unsigned long long) ev.k.tsk_mgmt_req.mid);
++
++	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &amp;ev, GFP_KERNEL, tgtd_pid);
+ }
+ 
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+@@ -124,19 +139,22 @@ static int event_recv_msg(struct sk_buff
+ 		nlh-&gt;nlmsg_pid, current-&gt;pid);
+ 
+ 	switch (nlh-&gt;nlmsg_type) {
+-	case TGT_UEVENT_TGTD_BIND:
++	case TGT_UEVENT_REQ:
+ 		tgtd_pid = NETLINK_CREDS(skb)-&gt;pid;
+ 		break;
+-	case TGT_UEVENT_CMD_RES:
++	case TGT_UEVENT_CMD_RSP:
+ 		/* TODO: handle multiple cmds in one event */
+-		err = scsi_tgt_kspace_exec(ev-&gt;u.cmd_res.host_no,
+-					   ev-&gt;u.cmd_res.cid,
+-					   ev-&gt;u.cmd_res.result,
+-					   ev-&gt;u.cmd_res.len,
+-					   ev-&gt;u.cmd_res.offset,
+-					   ev-&gt;u.cmd_res.uaddr,
+-					   ev-&gt;u.cmd_res.rw,
+-					   ev-&gt;u.cmd_res.try_map);
++		err = scsi_tgt_kspace_exec(ev-&gt;u.cmd_rsp.host_no,
++					   ev-&gt;u.cmd_rsp.cid,
++					   ev-&gt;u.cmd_rsp.result,
++					   ev-&gt;u.cmd_rsp.len,
++					   ev-&gt;u.cmd_rsp.uaddr,
++					   ev-&gt;u.cmd_rsp.rw);
++		break;
++	case TGT_UEVENT_TSK_MGMT_RSP:
++		err = scsi_tgt_kspace_tsk_mgmt(ev-&gt;u.tsk_mgmt_rsp.host_no,
++					       ev-&gt;u.tsk_mgmt_rsp.mid,
++					       ev-&gt;u.tsk_mgmt_rsp.result);
+ 		break;
+ 	default:
+ 		eprintk(&quot;unknown type %d\n&quot;, nlh-&gt;nlmsg_type);
+@@ -151,6 +169,7 @@ static int event_recv_skb(struct sk_buff
+ 	int err;
+ 	uint32_t rlen;
+ 	struct nlmsghdr	*nlh;
++	struct tgt_event ev;
+ 
+ 	while (skb-&gt;len &gt;= NLMSG_SPACE(0)) {
+ 		nlh = (struct nlmsghdr *) skb-&gt;data;
+@@ -166,12 +185,14 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh-&gt;nlmsg_type != TGT_UEVENT_CMD_RES) {
+-			struct tgt_event ev;
+-
++		switch (nlh-&gt;nlmsg_type) {
++		case TGT_UEVENT_CMD_RSP:
++		case TGT_UEVENT_TSK_MGMT_RSP:
++			break;
++		default:
+ 			memset(&amp;ev, 0, sizeof(ev));
+-			ev.k.event_res.err = err;
+-			send_event_res(TGT_KEVENT_RESPONSE, &amp;ev, NULL, 0,
++			ev.k.event_rsp.err = err;
++			send_event_rsp(TGT_KEVENT_RSP, &amp;ev,
+ 				       GFP_KERNEL | __GFP_NOFAIL,
+ 					nlh-&gt;nlmsg_pid);
+ 		}
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..5a98fc4 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -20,7 +20,7 @@
+  * 02110-1301 USA
+  */
+ #include &lt;linux/blkdev.h&gt;
+-#include &lt;linux/elevator.h&gt;
++#include &lt;linux/hash.h&gt;
+ #include &lt;linux/module.h&gt;
+ #include &lt;linux/pagemap.h&gt;
+ #include &lt;scsi/scsi.h&gt;
+@@ -46,6 +46,25 @@ struct scsi_tgt_cmd {
+ 	struct bio_list xfer_done_list;
+ 	struct bio_list xfer_list;
+ 	struct scsi_lun *lun;
++
++	struct list_head hash_list;
++	struct request *rq;
++	u64 tag;
++};
++
++#define TGT_HASH_ORDER	4
++#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
++
++struct scsi_tgt_queuedata {
++	struct Scsi_Host *shost;
++	struct list_head cmd_hash[1 &lt;&lt; TGT_HASH_ORDER];
++	spinlock_t cmd_hash_lock;
++
++	struct work_struct uspace_send_work;
++
++	spinlock_t cmd_req_lock;
++	struct mutex cmd_req_mutex;
++	struct list_head cmd_req;
+ };
+ 
+ static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
+@@ -68,9 +87,16 @@ static void scsi_tgt_cmd_destroy(void *d
+ {
+ 	struct scsi_cmnd *cmd = data;
+ 	struct scsi_tgt_cmd *tcmd = cmd-&gt;request-&gt;end_io_data;
++	struct scsi_tgt_queuedata *qdata = cmd-&gt;request-&gt;q-&gt;queuedata;
++	unsigned long flags;
+ 
+ 	dprintk(&quot;cmd %p %d %lu\n&quot;, cmd, cmd-&gt;sc_data_direction,
+ 		rq_data_dir(cmd-&gt;request));
++
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	list_del(&amp;tcmd-&gt;hash_list);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
++
+ 	/*
+ 	 * We must set rq-&gt;flags here because bio_map_user and
+ 	 * blk_rq_bio_prep ruined ti.
+@@ -81,62 +107,71 @@ static void scsi_tgt_cmd_destroy(void *d
+ 		cmd-&gt;request-&gt;flags &amp;= ~1UL;
+ 
+ 	scsi_unmap_user_pages(tcmd);
+-	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
+ 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
+ }
+ 
+ static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
+ {
+-	tcmd-&gt;lun = rq-&gt;end_io_data;
+-	bio_list_init(&amp;tcmd-&gt;xfer_list);
+-	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
++	struct scsi_tgt_queuedata *qdata = rq-&gt;q-&gt;queuedata;
++	unsigned long flags;
++	struct list_head *head;
++	static u32 tag = 0;
++
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	rq-&gt;tag = tag++;
++	head = &amp;qdata-&gt;cmd_hash[cmd_hashfn(rq-&gt;tag)];
++	list_add(&amp;tcmd-&gt;hash_list, head);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
+ }
+ 
+-static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
+-{
+-	struct scsi_tgt_cmd *tcmd;
+-
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd)
+-		return BLKPREP_DEFER;
+-
+-	init_scsi_tgt_cmd(rq, tcmd);
+-	rq-&gt;end_io_data = tcmd;
+-	rq-&gt;flags |= REQ_DONTPREP;
+-	return BLKPREP_OK;
+-}
+-
+-static void scsi_uspace_request_fn(struct request_queue *q)
++static void scsi_tgt_uspace_send_fn(void *data)
+ {
++	struct request_queue *q = data;
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
+ 	struct request *rq;
+ 	struct scsi_cmnd *cmd;
+ 	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++	int err;
+ 
+-	/*
+-	 * TODO: just send everthing in the queue to userspace in
+-	 * one vector instead of multiple calls
+-	 */
+-	while ((rq = elv_next_request(q)) != NULL) {
+-		cmd = rq-&gt;special;
+-		tcmd = rq-&gt;end_io_data;
++retry:
++	err = 0;
++	if (list_empty(&amp;qdata-&gt;cmd_req))
++		return;
+ 
+-		/* the completion code kicks us in case we hit this */
+-		if (blk_queue_start_tag(q, rq))
+-			break;
++	mutex_lock(&amp;qdata-&gt;cmd_req_mutex);
+ 
+-		spin_unlock_irq(q-&gt;queue_lock);
+-		if (scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, GFP_ATOMIC) &lt; 0)
+-			goto requeue;
+-		spin_lock_irq(q-&gt;queue_lock);
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++	if (list_empty(&amp;qdata-&gt;cmd_req)) {
++		spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++		mutex_unlock(&amp;qdata-&gt;cmd_req_mutex);
++		goto out;
++	}
++	rq = list_entry_rq(qdata-&gt;cmd_req.next);
++	list_del_init(&amp;rq-&gt;queuelist);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++
++	tcmd = rq-&gt;end_io_data;
++	init_scsi_tgt_cmd(rq, tcmd);
++	cmd = rq-&gt;special;
++	err = scsi_tgt_uspace_send(cmd, tcmd-&gt;lun, tcmd-&gt;tag, GFP_ATOMIC);
++	if (err &lt; 0) {
++		eprintk(&quot;failed to send: %p %d\n&quot;, cmd, err);
++
++		spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++		list_add(&amp;rq-&gt;queuelist, &amp;qdata-&gt;cmd_req);
++		spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
+ 	}
+ 
+-	return;
+-requeue:
+-	spin_lock_irq(q-&gt;queue_lock);
+-	/* need to track cnts and plug */
+-	blk_requeue_request(q, rq);
+-	spin_lock_irq(q-&gt;queue_lock);
++	mutex_unlock(&amp;qdata-&gt;cmd_req_mutex);
++out:
++	/* TODO: proper error handling */
++	if (err &lt; 0)
++		queue_delayed_work(scsi_tgtd, &amp;qdata-&gt;uspace_send_work,
++				   HZ / 10);
++	else
++		goto retry;
+ }
+ 
+ /**
+@@ -150,13 +185,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ {
+ 	struct scsi_tgt_queuedata *queuedata;
+ 	struct request_queue *q;
+-	int err;
++	int err, i;
+ 
+ 	/*
+ 	 * Do we need to send a netlink event or should uspace
+ 	 * just respond to the hotplug event?
+ 	 */
+-	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
++	q = __scsi_alloc_queue(shost, NULL);
+ 	if (!q)
+ 		return -ENOMEM;
+ 
+@@ -168,19 +203,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	queuedata-&gt;shost = shost;
+ 	q-&gt;queuedata = queuedata;
+ 
+-	elevator_exit(q-&gt;elevator);
+-	err = elevator_init(q, &quot;noop&quot;);
+-	if (err)
+-		goto free_data;
+-
+-	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
+ 	/*
+ 	 * this is a silly hack. We should probably just queue as many
+ 	 * command as is recvd to userspace. uspace can then make
+ 	 * sure we do not overload the HBA
+ 	 */
+ 	q-&gt;nr_requests = shost-&gt;hostt-&gt;can_queue;
+-	blk_queue_init_tags(q, shost-&gt;hostt-&gt;can_queue, NULL);
+ 	/*
+ 	 * We currently only support software LLDs so this does
+ 	 * not matter for now. Do we need this for the cards we support?
+@@ -189,10 +217,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	blk_queue_dma_alignment(q, 0);
+ 	shost-&gt;uspace_req_q = q;
+ 
++	for (i = 0; i &lt; ARRAY_SIZE(queuedata-&gt;cmd_hash); i++)
++		INIT_LIST_HEAD(&amp;queuedata-&gt;cmd_hash[i]);
++	spin_lock_init(&amp;queuedata-&gt;cmd_hash_lock);
++
++	INIT_LIST_HEAD(&amp;queuedata-&gt;cmd_req);
++	spin_lock_init(&amp;queuedata-&gt;cmd_req_lock);
++	INIT_WORK(&amp;queuedata-&gt;uspace_send_work, scsi_tgt_uspace_send_fn, q);
++	mutex_init(&amp;queuedata-&gt;cmd_req_mutex);
++
+ 	return 0;
+ 
+-free_data:
+-	kfree(queuedata);
+ cleanup_queue:
+ 	blk_cleanup_queue(q);
+ 	return err;
+@@ -212,17 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+  * @scsilun:	scsi lun
+  * @noblock:	set to nonzero if the command should be queued
+  **/
+-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+-			    int noblock)
++int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
++			   u64 tag)
+ {
++	struct request_queue *q = cmd-&gt;request-&gt;q;
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
++	unsigned long flags;
++	struct scsi_tgt_cmd *tcmd;
++
+ 	/*
+-	 * For now this just calls the request_fn from this context.
+-	 * For HW llds though we do not want to execute from here so
+-	 * the elevator code needs something like a REQ_TGT_CMD or
+-	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
++	 * It would be better to allocate scsi_tgt_cmd structure in
++	 * scsi_host_get_command and not to fail due to OOM.
+ 	 */
+-	cmd-&gt;request-&gt;end_io_data = scsilun;
+-	elv_add_request(cmd-&gt;request-&gt;q, cmd-&gt;request, ELEVATOR_INSERT_BACK, 1);
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd)
++		return -ENOMEM;
++	cmd-&gt;request-&gt;end_io_data = tcmd;
++
++	bio_list_init(&amp;tcmd-&gt;xfer_list);
++	bio_list_init(&amp;tcmd-&gt;xfer_done_list);
++	tcmd-&gt;lun = scsilun;
++	tcmd-&gt;tag = tag;
++	tcmd-&gt;rq = cmd-&gt;request;
++
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_req_lock, flags);
++	list_add_tail(&amp;cmd-&gt;request-&gt;queuelist, &amp;qdata-&gt;cmd_req);
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_req_lock, flags);
++
++	queue_work(scsi_tgtd, &amp;qdata-&gt;uspace_send_work);
++	return 0;
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -236,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
+ 
+ 	dprintk(&quot;cmd %p %lu\n&quot;, cmd, rq_data_dir(cmd-&gt;request));
+ 
+-	/* don't we have to call this if result is set or not */
+-	if (cmd-&gt;result) {
+-		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+-		return;
+-	}
+-
++	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+ 	INIT_WORK(&amp;tcmd-&gt;work, scsi_tgt_cmd_destroy, cmd);
+ 	queue_work(scsi_tgtd, &amp;tcmd-&gt;work);
+ }
+@@ -315,7 +363,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len &gt; 0) {
+ 		dprintk(&quot;%lx %u\n&quot;, (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk(&quot;fail to map %lx %u %d %x\n&quot;,
+@@ -438,16 +486,49 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
+-int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
+-			 unsigned long uaddr, u8 rw, u8 try_map)
++static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
++{
++	int err;
++
++	err = host-&gt;hostt-&gt;eh_abort_handler(cmd);
++	if (err)
++		eprintk(&quot;fail to abort %p\n&quot;, cmd);
++
++	scsi_tgt_cmd_destroy(cmd);
++	return err;
++}
++
++static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
++{
++	struct scsi_tgt_queuedata *qdata = q-&gt;queuedata;
++	struct request *rq = NULL;
++	struct list_head *head;
++	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++
++	head = &amp;qdata-&gt;cmd_hash[cmd_hashfn(cid)];
++	spin_lock_irqsave(&amp;qdata-&gt;cmd_hash_lock, flags);
++	list_for_each_entry(tcmd, head, hash_list) {
++		if (tcmd-&gt;rq-&gt;tag == cid) {
++			rq = tcmd-&gt;rq;
++			break;
++		}
++	}
++	spin_unlock_irqrestore(&amp;qdata-&gt;cmd_hash_lock, flags);
++
++	return rq;
++}
++
++int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
++			 unsigned long uaddr, u8 rw)
+ {
+ 	struct Scsi_Host *shost;
+ 	struct scsi_cmnd *cmd;
+ 	struct request *rq;
+ 	int err = 0;
+ 
+-	dprintk(&quot;%d %u %d %u %llu %lx %u %u\n&quot;, host_no, cid, result,
+-		len, (unsigned long long) offset, uaddr, rw, try_map);
++	dprintk(&quot;%d %u %d %u %lx %u\n&quot;, host_no, cid, result,
++		len, uaddr, rw);
+ 
+ 	/* TODO: replace with a O(1) alg */
+ 	shost = scsi_host_lookup(host_no);
+@@ -456,7 +537,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 		return -EINVAL;
+ 	}
+ 
+-	rq = blk_queue_find_tag(shost-&gt;uspace_req_q, cid);
++	rq = tgt_cmd_hash_lookup(shost-&gt;uspace_req_q, cid);
+ 	if (!rq) {
+ 		printk(KERN_ERR &quot;Could not find cid %u\n&quot;, cid);
+ 		err = -EINVAL;
+@@ -467,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 	dprintk(&quot;cmd %p result %d len %d bufflen %u %lu %x\n&quot;, cmd,
+ 		result, len, cmd-&gt;request_bufflen, rq_data_dir(rq), cmd-&gt;cmnd[0]);
+ 
++	if (result == TASK_ABORTED) {
++		scsi_tgt_abort_cmd(shost, cmd);
++		goto done;
++	}
+ 	/*
+ 	 * store the userspace values here, the working values are
+ 	 * in the request_* values
+@@ -507,6 +592,38 @@ done:
+ 	return err;
+ }
+ 
++int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
++			      struct scsi_lun *scsilun, void *data)
++{
++	int err;
++
++	/* TODO: need to retry if this fails. */
++	err = scsi_tgt_uspace_send_tsk_mgmt(shost-&gt;host_no, function,
++					    tag, scsilun, data);
++	if (err &lt; 0)
++		eprintk(&quot;The task management request lost!\n&quot;);
++	return err;
++}
++EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
++
++int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
++{
++	struct Scsi_Host *shost;
++	int err;
++
++	dprintk(&quot;%d %d %llx\n&quot;, host_no, result, (unsigned long long) mid);
++
++	shost = scsi_host_lookup(host_no);
++	if (IS_ERR(shost)) {
++		printk(KERN_ERR &quot;Could not find host no %d\n&quot;, host_no);
++		return -EINVAL;
++	}
++	err = shost-&gt;hostt-&gt;tsk_mgmt_response(mid, result);
++	scsi_host_put(shost);
++
++	return err;
++}
++
+ static int __init scsi_tgt_init(void)
+ {
+ 	int err;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 4236e50..77a1d06 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -4,22 +4,21 @@ struct Scsi_Host;
+ struct task_struct;
+ 
+ /* tmp - will replace with SCSI logging stuff */
+-#define dprintk(fmt, args...)					\
++#define eprintk(fmt, args...)					\
+ do {								\
+ 	printk(&quot;%s(%d) &quot; fmt, __FUNCTION__, __LINE__, ##args);	\
+ } while (0)
+ 
+-#define eprintk dprintk
+-
+-struct scsi_tgt_queuedata {
+-	struct Scsi_Host *shost;
+-};
++#define dprintk eprintk
+ 
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
++extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
++				u64 tag, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+-				u64 offset, unsigned long uaddr, u8 rw,
+-				u8 try_map);
++				unsigned long uaddr, u8 rw);
++extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++					 struct scsi_lun *scsilun, void *data);
++extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
+diff --git a/fs/bio.c b/fs/bio.c
+index 3e940c9..f51a873 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
+  *	@uaddr: start of user address
+  *	@len: length in bytes
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
+-			 unsigned long uaddr, unsigned int len, int write_to_vm,
+-			 int support_partial)
++			 unsigned long uaddr, unsigned int len, int write_to_vm)
+ {
+ 	struct sg_iovec iov;
+ 
+ 	iov.iov_base = (void __user *)uaddr;
+ 	iov.iov_len = len;
+ 
+-	return bio_map_user_iov(q, bdev, &amp;iov, 1, write_to_vm, support_partial);
++	return bio_map_user_iov(q, bdev, &amp;iov, 1, write_to_vm);
+ }
+ 
+ /**
+@@ -742,17 +740,15 @@ struct bio *bio_map_user(request_queue_t
+  *	@iov:	the iovec.
+  *	@iov_count: number of elements in the iovec
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
+ 			     struct sg_iovec *iov, int iov_count,
+-			     int write_to_vm, int support_partial)
++			     int write_to_vm)
+ {
+ 	struct bio *bio;
+-	int len = 0, i;
+ 
+ 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
+ 
+@@ -767,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
+ 	 */
+ 	bio_get(bio);
+ 
+-	for (i = 0; i &lt; iov_count; i++)
+-		len += iov[i].iov_len;
+-
+-	if (bio-&gt;bi_size == len || support_partial)
+-		return bio;
+-
+-	/*
+-	 * don't support partial mappings
+-	 */
+-	bio_endio(bio, bio-&gt;bi_size, 0);
+-	bio_unmap_user(bio);
+-	return ERR_PTR(-EINVAL);
++	return bio;
+ }
+ 
+ static void __bio_unmap_user(struct bio *bio)
+diff --git a/include/linux/bio.h b/include/linux/bio.h
+index fc0906c..b60ffe3 100644
+--- a/include/linux/bio.h
++++ b/include/linux/bio.h
+@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
+ extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
+ 			   unsigned int, unsigned int);
+ extern int bio_get_nr_vecs(struct block_device *);
+-extern int __bio_get_nr_vecs(struct request_queue *);
+ extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
+-				unsigned long, unsigned int, int, int);
++				unsigned long, unsigned int, int);
+ struct sg_iovec;
+ extern struct bio *bio_map_user_iov(struct request_queue *,
+ 				    struct block_device *,
+-				    struct sg_iovec *, int, int, int);
++				    struct sg_iovec *, int, int);
+ extern void bio_unmap_user(struct bio *);
+ extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
+ 				gfp_t);
+diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
+index 860e7a4..619ef1d 100644
+--- a/include/linux/blkdev.h
++++ b/include/linux/blkdev.h
+@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
+ extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
+ extern int blk_rq_unmap_user(struct bio *, unsigned int);
+ extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
+-extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
++extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
++			       struct sg_iovec *, int, unsigned int);
+ extern int blk_execute_rq(request_queue_t *, struct gendisk *,
+ 			  struct request *, int);
+ extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
+diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
+index 8b799db..eca5721 100644
+--- a/include/scsi/scsi_host.h
++++ b/include/scsi/scsi_host.h
+@@ -153,6 +153,9 @@ struct scsi_host_template {
+ 	int (* transfer_data)(struct scsi_cmnd *,
+ 			      void (*done)(struct scsi_cmnd *));
+ 
++	/* Used as callback for the completion of task management request. */
++	int (* tsk_mgmt_response)(u64 mid, int result);
++
+ 	/*
+ 	 * This is an error handling strategy routine.  You don't need to
+ 	 * define one of these if you don't want to - there is a default
+diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
+index 91ad6bc..2d65be7 100644
+--- a/include/scsi/scsi_tgt.h
++++ b/include/scsi/scsi_tgt.h
+@@ -6,6 +6,8 @@ struct Scsi_Host;
+ struct scsi_cmnd;
+ struct scsi_lun;
+ 
+-extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
++extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
+ extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
+-extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
++extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
++extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
++				     void *);
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index da3a808..63b2e3a 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -24,65 +24,66 @@
+ 
+ enum tgt_event_type {
+ 	/* user -&gt; kernel */
+-	TGT_UEVENT_TGTD_BIND,
+-	TGT_UEVENT_TARGET_SETUP,
+-	TGT_UEVENT_CMD_RES,
++	TGT_UEVENT_REQ,
++	TGT_UEVENT_CMD_RSP,
++	TGT_UEVENT_TSK_MGMT_RSP,
+ 
+ 	/* kernel -&gt; user */
+-	TGT_KEVENT_RESPONSE,
++	TGT_KEVENT_RSP,
+ 	TGT_KEVENT_CMD_REQ,
+ 	TGT_KEVENT_CMD_DONE,
++	TGT_KEVENT_TSK_MGMT_REQ,
+ };
+ 
+ struct tgt_event {
+ 	/* user-&gt; kernel */
+ 	union {
+ 		struct {
+-			int pk_fd;
+-		} tgtd_bind;
++			int type;
++			int host_no;
++		} event_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t len;
+ 			int result;
+ 			uint64_t uaddr;
+-			uint64_t offset;
+ 			uint8_t rw;
+-			uint8_t try_map;
+-		} cmd_res;
++		} cmd_rsp;
++		struct {
++			int host_no;
++			uint64_t mid;
++			int result;
++		} tsk_mgmt_rsp;
+ 	} u;
+ 
+ 	/* kernel -&gt; user */
+ 	union {
+ 		struct {
+ 			int err;
+-		} event_res;
++		} event_rsp;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t data_len;
+-			uint64_t dev_id;
++			uint8_t scb[16];
++			uint8_t lun[8];
++			int attribute;
++			uint64_t tag;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			int result;
+ 		} cmd_done;
++		struct {
++			int host_no;
++			int function;
++			uint64_t tag;
++			uint8_t lun[8];
++			uint64_t mid;
++		} tsk_mgmt_req;
+ 	} k;
+ 
+-	/*
+-	 * I think a pointer is a unsigned long but this struct
+-	 * gets passed around from the kernel to userspace and
+-	 * back again so to handle some ppc64 setups where userspace is
+-	 * 32 bits but the kernel is 64 we do this odd thing
+-	 */
+-	uint64_t data[0];
+-} __attribute__ ((aligned (sizeof(uint64_t))));
+-
+-struct tgt_cmd {
+-	uint8_t scb[16];
+-	uint8_t lun[8];
+-	int tags;
+ } __attribute__ ((aligned (sizeof(uint64_t))));
+-
+ #endif

Deleted: branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff
===================================================================
--- branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,573 +0,0 @@
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 03d9c82..6849859 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq-&gt;bio = rq-&gt;biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq-&gt;buffer = rq-&gt;data = NULL;
--		rq-&gt;data_len = len;
--		return 0;
-+	if (bio-&gt;bi_size != len) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq-&gt;bio = rq-&gt;biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq-&gt;buffer = rq-&gt;data = NULL;
-+	rq-&gt;data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio-&gt;bi_size != len) {
-+		bio_endio(bio, bio-&gt;bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq-&gt;bio = rq-&gt;biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq-&gt;buffer = rq-&gt;data = NULL;
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr-&gt;iovec_count,
-+					  hdr-&gt;dxfer_len);
- 		kfree(iov);
- 	} else if (hdr-&gt;dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr-&gt;dxferp, hdr-&gt;dxfer_len);
-diff --git a/drivers/scsi/hosts.c b/drivers/scsi/hosts.c
-index 5881079..64e687a 100644
---- a/drivers/scsi/hosts.c
-+++ b/drivers/scsi/hosts.c
-@@ -264,6 +264,11 @@ static void scsi_host_dev_release(struct
- 	if (shost-&gt;work_q)
- 		destroy_workqueue(shost-&gt;work_q);
- 
-+	if (shost-&gt;uspace_req_q) {
-+		kfree(shost-&gt;uspace_req_q-&gt;queuedata);
-+		scsi_free_queue(shost-&gt;uspace_req_q);
-+	}
-+
- 	scsi_destroy_command_freelist(shost);
- 	kfree(shost-&gt;shost_data);
- 
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index c551bb8..3cf02b1 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -236,6 +236,58 @@ static struct scsi_cmnd *__scsi_get_comm
- }
- 
- /*
-+ * Function:	scsi_host_get_command()
-+ *
-+ * Purpose:	Allocate and setup a scsi command block and blk request
-+ *
-+ * Arguments:	shost	- scsi host
-+ *		data_dir - dma data dir
-+ *		gfp_mask- allocator flags
-+ *
-+ * Returns:	The allocated scsi command structure.
-+ *
-+ * This should be called by target LLDs to get a command.
-+ */
-+struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *shost,
-+					enum dma_data_direction data_dir,
-+					gfp_t gfp_mask)
-+{
-+	int write = (data_dir == DMA_TO_DEVICE);
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+
-+	/* Bail if we can't get a reference to the device */
-+	if (!get_device(&amp;shost-&gt;shost_gendev))
-+		return NULL;
-+
-+	rq = blk_get_request(shost-&gt;uspace_req_q, write, gfp_mask);
-+	if (!rq)
-+		goto put_dev;
-+
-+	cmd = __scsi_get_command(shost, gfp_mask);
-+	if (!cmd)
-+		goto release_rq;
-+
-+	memset(cmd, 0, sizeof(*cmd));
-+	cmd-&gt;sc_data_direction = data_dir;
-+	cmd-&gt;jiffies_at_alloc = jiffies;
-+	cmd-&gt;request = rq;
-+
-+	rq-&gt;special = cmd;
-+	rq-&gt;flags |= REQ_SPECIAL | REQ_BLOCK_PC;
-+
-+	return cmd;
-+
-+release_rq:
-+	blk_put_request(rq);
-+put_dev:
-+	put_device(&amp;shost-&gt;shost_gendev);
-+	return NULL;
-+
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_get_command);
-+
-+/*
-  * Function:	scsi_get_command()
-  *
-  * Purpose:	Allocate and setup a scsi command block
-@@ -274,6 +326,45 @@ struct scsi_cmnd *scsi_get_command(struc
- EXPORT_SYMBOL(scsi_get_command);
- 
- /*
-+ * Function:	scsi_host_put_command()
-+ *
-+ * Purpose:	Free a scsi command block
-+ *
-+ * Arguments:	shost	- scsi host
-+ * 		cmd	- command block to free
-+ *
-+ * Returns:	Nothing.
-+ *
-+ * Notes:	The command must not belong to any lists.
-+ */
-+void scsi_host_put_command(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
-+{
-+	struct request_queue *q = shost-&gt;uspace_req_q;
-+	struct request *rq = cmd-&gt;request;
-+	unsigned long flags;
-+
-+	/* changing locks here, don't need to restore the irq state */
-+	spin_lock_irqsave(&amp;shost-&gt;free_list_lock, flags);
-+	if (unlikely(list_empty(&amp;shost-&gt;free_list))) {
-+		list_add(&amp;cmd-&gt;list, &amp;shost-&gt;free_list);
-+		cmd = NULL;
-+	}
-+	spin_unlock(&amp;shost-&gt;free_list_lock);
-+
-+	spin_lock(q-&gt;queue_lock);
-+	if (blk_rq_tagged(rq))
-+		blk_queue_end_tag(q, rq);
-+	__blk_put_request(q, rq);
-+	spin_unlock_irqrestore(q-&gt;queue_lock, flags);
-+
-+	if (likely(cmd != NULL))
-+		kmem_cache_free(shost-&gt;cmd_pool-&gt;slab, cmd);
-+
-+	put_device(&amp;shost-&gt;shost_gendev);
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_put_command);
-+
-+/*
-  * Function:	scsi_put_command()
-  *
-  * Purpose:	Free a scsi command block
-diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
-index 4362dcd..7307705 100644
---- a/drivers/scsi/scsi_lib.c
-+++ b/drivers/scsi/scsi_lib.c
-@@ -804,7 +804,7 @@ static struct scsi_cmnd *scsi_end_reques
- 	return NULL;
- }
- 
--static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
- {
- 	struct scsi_host_sg_pool *sgp;
- 	struct scatterlist *sgl;
-@@ -845,7 +845,9 @@ static struct scatterlist *scsi_alloc_sg
- 	return sgl;
- }
- 
--static void scsi_free_sgtable(struct scatterlist *sgl, int index)
-+EXPORT_SYMBOL(scsi_alloc_sgtable);
-+
-+void scsi_free_sgtable(struct scatterlist *sgl, int index)
- {
- 	struct scsi_host_sg_pool *sgp;
- 
-@@ -855,6 +857,8 @@ static void scsi_free_sgtable(struct sca
- 	mempool_free(sgl, sgp-&gt;pool);
- }
- 
-+EXPORT_SYMBOL(scsi_free_sgtable);
-+
- /*
-  * Function:    scsi_release_buffers()
-  *
-@@ -1687,29 +1691,40 @@ u64 scsi_calculate_bounce_limit(struct S
- }
- EXPORT_SYMBOL(scsi_calculate_bounce_limit);
- 
--struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					 request_fn_proc *request_fn)
- {
--	struct Scsi_Host *shost = sdev-&gt;host;
- 	struct request_queue *q;
- 
--	q = blk_init_queue(scsi_request_fn, NULL);
-+	q = blk_init_queue(request_fn, NULL);
- 	if (!q)
- 		return NULL;
- 
--	blk_queue_prep_rq(q, scsi_prep_fn);
--
- 	blk_queue_max_hw_segments(q, shost-&gt;sg_tablesize);
- 	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
- 	blk_queue_max_sectors(q, shost-&gt;max_sectors);
- 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
- 	blk_queue_segment_boundary(q, shost-&gt;dma_boundary);
--	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
--	blk_queue_softirq_done(q, scsi_softirq_done);
- 
- 	if (!shost-&gt;use_clustering)
- 		clear_bit(QUEUE_FLAG_CLUSTER, &amp;q-&gt;queue_flags);
- 	return q;
- }
-+EXPORT_SYMBOL(__scsi_alloc_queue);
-+
-+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+{
-+	struct request_queue *q;
-+
-+	q = __scsi_alloc_queue(sdev-&gt;host, scsi_request_fn);
-+	if (!q)
-+		return NULL;
-+
-+	blk_queue_prep_rq(q, scsi_prep_fn);
-+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
-+	blk_queue_softirq_done(q, scsi_softirq_done);
-+	return q;
-+}
- 
- void scsi_free_queue(struct request_queue *q)
- {
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..f51a873 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -620,10 +620,9 @@ static struct bio *__bio_map_user_iov(re
- 
- 		nr_pages += end - start;
- 		/*
--		 * transfer and buffer must be aligned to at least hardsector
--		 * size for now, in the future we can relax this restriction
-+		 * buffer must be aligned to at least hardsector size for now
- 		 */
--		if ((uaddr &amp; queue_dma_alignment(q)) || (len &amp; queue_dma_alignment(q)))
-+		if (uaddr &amp; queue_dma_alignment(q))
- 			return ERR_PTR(-EINVAL);
- 	}
- 
-@@ -750,7 +749,6 @@ struct bio *bio_map_user_iov(request_que
- 			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -765,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i &lt; iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio-&gt;bi_size == len)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio-&gt;bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
-diff --git a/include/linux/netlink.h b/include/linux/netlink.h
-index c256ebe..9422ae5 100644
---- a/include/linux/netlink.h
-+++ b/include/linux/netlink.h
-@@ -21,6 +21,7 @@
- #define NETLINK_DNRTMSG		14	/* DECnet routing messages */
- #define NETLINK_KOBJECT_UEVENT	15	/* Kernel messages to userspace */
- #define NETLINK_GENERIC		16
-+#define NETLINK_TGT		17	/* SCSI target */
- 
- #define MAX_LINKS 32		
- 
-diff --git a/include/scsi/scsi_cmnd.h b/include/scsi/scsi_cmnd.h
-index 7529f43..51156c7 100644
---- a/include/scsi/scsi_cmnd.h
-+++ b/include/scsi/scsi_cmnd.h
-@@ -8,6 +8,7 @@
- 
- struct request;
- struct scatterlist;
-+struct Scsi_Host;
- struct scsi_device;
- struct scsi_request;
- 
-@@ -84,6 +85,8 @@ struct scsi_cmnd {
- 	unsigned short sglist_len;	/* size of malloc'd scatter-gather list */
- 	unsigned bufflen;	/* Size of data buffer */
- 	void *buffer;		/* Data buffer */
-+	/* offset in cmd we are at (for multi-transfer tgt cmds) */
-+	unsigned offset;
- 
- 	unsigned underflow;	/* Return error if less than
- 				   this amount is transferred */
-@@ -147,9 +150,14 @@ struct scsi_cmnd {
- #define SCSI_STATE_MLQUEUE         0x100b
- 
- 
-+extern struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *,
-+					       enum dma_data_direction, gfp_t);
- extern struct scsi_cmnd *scsi_get_command(struct scsi_device *, gfp_t);
-+extern void scsi_host_put_command(struct Scsi_Host *, struct scsi_cmnd *);
- extern void scsi_put_command(struct scsi_cmnd *);
- extern void scsi_io_completion(struct scsi_cmnd *, unsigned int, unsigned int);
- extern void scsi_finish_command(struct scsi_cmnd *cmd);
-+extern struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *, gfp_t);
-+extern void scsi_free_sgtable(struct scatterlist *, int);
- 
- #endif /* _SCSI_SCSI_CMND_H */
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8279929..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -7,6 +7,7 @@
- #include &lt;linux/workqueue.h&gt;
- #include &lt;linux/mutex.h&gt;
- 
-+struct request_queue;
- struct block_device;
- struct completion;
- struct module;
-@@ -123,6 +124,39 @@ struct scsi_host_template {
- 			     void (*done)(struct scsi_cmnd *));
- 
- 	/*
-+	 * The transfer functions are used to queue a scsi command to
-+	 * the LLD. When the driver is finished processing the command
-+	 * the done callback is invoked.
-+	 *
-+	 * return values: see queuecommand
-+	 *
-+	 * If the LLD accepts the cmd, it should set the result to an
-+	 * appropriate value when completed before calling the done function.
-+	 *
-+	 * STATUS: REQUIRED FOR TARGET DRIVERS
-+	 */
-+	/* TODO: rename */
-+	int (* transfer_response)(struct scsi_cmnd *,
-+				  void (*done)(struct scsi_cmnd *));
-+	/*
-+	 * This is called to inform the LLD to transfer cmd-&gt;request_bufflen
-+	 * bytes of the cmd at cmd-&gt;offset in the cmd. The cmd-&gt;use_sg
-+	 * speciefies the number of scatterlist entried in the command
-+	 * and cmd-&gt;request_buffer contains the scatterlist.
-+	 *
-+	 * If the command cannot be processed in one transfer_data call
-+	 * becuase a scatterlist within the LLD's limits cannot be
-+	 * created then transfer_data will be called multiple times.
-+	 * It is initially called from process context, and later
-+	 * calls are from the interrup context.
-+	 */
-+	int (* transfer_data)(struct scsi_cmnd *,
-+			      void (*done)(struct scsi_cmnd *));
-+
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
-+	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
- 	 * routine that is present that should work in most cases.  For those
-@@ -572,6 +606,12 @@ struct Scsi_Host {
- 	 */
- 	unsigned int max_host_blocked;
- 
-+	/*
-+	 * q used for scsi_tgt msgs, async events or any other requests that
-+	 * need to be processed in userspace
-+ 	 */
-+	struct request_queue *uspace_req_q;
-+
- 	/* legacy crap */
- 	unsigned long base;
- 	unsigned long io_port;
-@@ -674,6 +714,9 @@ extern void scsi_unblock_requests(struct
- extern void scsi_block_requests(struct Scsi_Host *);
- 
- struct class_container;
-+
-+extern struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					     void (*) (struct request_queue *));
- /*
-  * These two functions are used to allocate and free a pseudo device
-  * which will connect to the host adapter itself rather than any
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-new file mode 100644
-index 0000000..3d09a1a
---- /dev/null
-+++ b/include/scsi/scsi_tgt.h
-@@ -0,0 +1,13 @@
-+/*
-+ * SCSI target definitions
-+ */
-+
-+struct Scsi_Host;
-+struct scsi_cmnd;
-+struct scsi_lun;
-+
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-new file mode 100644
-index 0000000..63b2e3a
---- /dev/null
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -0,0 +1,89 @@
-+/*
-+ * SCSI target kernel/user interface
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">tomof at acm.org</A>&gt;
-+ * Copyright (C) 2005 Mike Christie &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/stgt-svn">michaelc at cs.wisc.edu</A>&gt;
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#ifndef __SCSI_TARGET_IF_H
-+#define __SCSI_TARGET_IF_H
-+
-+enum tgt_event_type {
-+	/* user -&gt; kernel */
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
-+
-+	/* kernel -&gt; user */
-+	TGT_KEVENT_RSP,
-+	TGT_KEVENT_CMD_REQ,
-+	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
-+};
-+
-+struct tgt_event {
-+	/* user-&gt; kernel */
-+	union {
-+		struct {
-+			int type;
-+			int host_no;
-+		} event_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t len;
-+			int result;
-+			uint64_t uaddr;
-+			uint8_t rw;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			uint64_t mid;
-+			int result;
-+		} tsk_mgmt_rsp;
-+	} u;
-+
-+	/* kernel -&gt; user */
-+	union {
-+		struct {
-+			int err;
-+		} event_rsp;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t data_len;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
-+			uint64_t tag;
-+		} cmd_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			int result;
-+		} cmd_done;
-+		struct {
-+			int host_no;
-+			int function;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			uint64_t mid;
-+		} tsk_mgmt_req;
-+	} k;
-+
-+} __attribute__ ((aligned (sizeof(uint64_t))));
-+#endif

Deleted: branches/use-scsi-ml/patchset/tmf.diff
===================================================================
--- branches/use-scsi-ml/patchset/tmf.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/tmf.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,60 +0,0 @@
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8b799db..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -153,6 +153,9 @@ struct scsi_host_template {
- 	int (* transfer_data)(struct scsi_cmnd *,
- 			      void (*done)(struct scsi_cmnd *));
- 
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
- 	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-index 91ad6bc..3d09a1a 100644
---- a/include/scsi/scsi_tgt.h
-+++ b/include/scsi/scsi_tgt.h
-@@ -8,4 +8,6 @@ struct scsi_lun;
- 
- extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
- extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
--extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index ebca452..63b2e3a 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -52,7 +52,7 @@ struct tgt_event {
- 		} cmd_rsp;
- 		struct {
- 			int host_no;
--			int mid;
-+			uint64_t mid;
- 			int result;
- 		} tsk_mgmt_rsp;
- 	} u;
-@@ -69,6 +69,7 @@ struct tgt_event {
- 			uint8_t scb[16];
- 			uint8_t lun[8];
- 			int attribute;
-+			uint64_t tag;
- 		} cmd_req;
- 		struct {
- 			int host_no;
-@@ -77,10 +78,10 @@ struct tgt_event {
- 		} cmd_done;
- 		struct {
- 			int host_no;
--			int mid;
-+			int function;
- 			uint64_t tag;
- 			uint8_t lun[8];
--			int function;
-+			uint64_t mid;
- 		} tsk_mgmt_req;
- 	} k;
- 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000382.html">[Stgt-svn] r395 - branches/use-scsi-ml/kernel
</A></li>
	<LI>Next message: <A HREF="000384.html">[Stgt-svn] r397 - branches/use-scsi-ml
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#383">[ date ]</a>
              <a href="thread.html#383">[ thread ]</a>
              <a href="subject.html#383">[ subject ]</a>
              <a href="author.html#383">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/stgt-svn">More information about the Stgt-svn
mailing list</a><br>
</body></html>
