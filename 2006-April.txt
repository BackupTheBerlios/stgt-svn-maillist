From tomo at berlios.de  Fri Apr  7 01:09:49 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 7 Apr 2006 01:09:49 +0200
Subject: [Stgt-svn] r393 - branches/use-scsi-ml/kernel
Message-ID: <200604062309.k36N9nW3027381@sheep.berlios.de>

Author: tomo
Date: 2006-04-07 01:09:45 +0200 (Fri, 07 Apr 2006)
New Revision: 393

Modified:
   branches/use-scsi-ml/kernel/scsi_tgt_if.c
   branches/use-scsi-ml/kernel/scsi_tgt_lib.c
Log:
Sync with the git tree with the submitted patches.


Modified: branches/use-scsi-ml/kernel/scsi_tgt_if.c
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_if.c	2006-03-27 04:36:17 UTC (rev 392)
+++ branches/use-scsi-ml/kernel/scsi_tgt_if.c	2006-04-06 23:09:45 UTC (rev 393)
@@ -35,7 +35,7 @@
 static int tgtd_pid;
 static struct sock *nl_sk;
 
-static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t gfp_mask,
+static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
 			  pid_t pid)
 {
 	struct tgt_event *ev;
@@ -44,7 +44,7 @@
 	uint32_t len;
 
 	len = NLMSG_SPACE(sizeof(*ev));
-	skb = alloc_skb(len, gfp_mask);
+	skb = alloc_skb(len, flags);
 	if (!skb)
 		return -ENOMEM;
 
@@ -53,11 +53,10 @@
 	ev = NLMSG_DATA(nlh);
 	memcpy(ev, p, sizeof(*ev));
 
-	return netlink_unicast(nl_sk, skb, pid, gfp_mask & GFP_ATOMIC);
+	return netlink_unicast(nl_sk, skb, pid, 0);
 }
 
-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
-			 gfp_t gfp_mask)
+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
 {
 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
 	struct sk_buff *skb;
@@ -92,9 +91,10 @@
 		ev->k.cmd_req.data_len, cmd->tag,
 		(unsigned long long) ev->k.cmd_req.tag);
 
-	err = netlink_unicast(nl_sk, skb, tgtd_pid, gfp_mask & GFP_ATOMIC);
+	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
 	if (err < 0)
-		eprintk("fail to send skb %d\n", err);
+		printk(KERN_ERR "scsi_tgt_uspace_send: could not send skb %d\n",
+		       err);
 	return err;
 }
 

Modified: branches/use-scsi-ml/kernel/scsi_tgt_lib.c
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-03-27 04:36:17 UTC (rev 392)
+++ branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-04-06 23:09:45 UTC (rev 393)
@@ -20,7 +20,6 @@
  * 02110-1301 USA
  */
 #include <linux/blkdev.h>
-#include <linux/elevator.h>
 #include <linux/hash.h>
 #include <linux/module.h>
 #include <linux/pagemap.h>
@@ -52,8 +51,8 @@
 	struct request *rq;
 };
 
-#define	TGT_HASH_ORDER	4
-#define	cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
+#define TGT_HASH_ORDER	4
+#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
 
 struct scsi_tgt_queuedata {
 	struct Scsi_Host *shost;
@@ -114,8 +113,8 @@
 static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
 {
 	struct scsi_tgt_queuedata *qdata = rq->q->queuedata;
-	struct list_head *head;
 	unsigned long flags;
+	struct list_head *head;
 	static u32 tag = 0;
 
 	tcmd->lun = rq->end_io_data;
@@ -174,7 +173,6 @@
 		init_scsi_tgt_cmd(rq, tcmd);
 
 	cmd = rq->special;
-
 	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
 	if (err < 0) {
 		eprintk("failed to send: %p %d\n", cmd, err);
@@ -185,7 +183,6 @@
 	}
 
 	mutex_unlock(&qdata->cmd_req_mutex);
-
 out:
 	/* TODO: proper error handling */
 	if (err < 0)
@@ -544,7 +541,6 @@
 		printk(KERN_ERR "Could not find host no %d\n", host_no);
 		return -EINVAL;
 	}
-	scsi_host_put(shost);
 
 	rq = tgt_cmd_hash_lookup(shost->uspace_req_q, cid);
 	if (!rq) {
@@ -597,6 +593,7 @@
 	err = scsi_tgt_transfer_data(cmd);
 
 done:
+	scsi_host_put(shost);
 	return err;
 }
 



From tomo at berlios.de  Fri Apr  7 02:16:25 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 7 Apr 2006 02:16:25 +0200
Subject: [Stgt-svn] r394 - branches/use-scsi-ml/kernel
Message-ID: <200604070016.k370GPfO015086@sheep.berlios.de>

Author: tomo
Date: 2006-04-07 02:16:10 +0200 (Fri, 07 Apr 2006)
New Revision: 394

Modified:
   branches/use-scsi-ml/kernel/scsi_tgt_lib.c
Log:
Allocate scsi_tgt_cmd structure in scsi_tgt_queue_command(), though I think that it would be better to allocate scsi_tgt_cmd structure in scsi_host_get_command() to make scsi_tgt_queue_command() not fail due to OOM.


Modified: branches/use-scsi-ml/kernel/scsi_tgt_lib.c
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-04-06 23:09:45 UTC (rev 393)
+++ branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-04-07 00:16:10 UTC (rev 394)
@@ -49,6 +49,7 @@
 
 	struct list_head hash_list;
 	struct request *rq;
+	u64 tag;
 };
 
 #define TGT_HASH_ORDER	4
@@ -117,19 +118,11 @@
 	struct list_head *head;
 	static u32 tag = 0;
 
-	tcmd->lun = rq->end_io_data;
-	bio_list_init(&tcmd->xfer_list);
-	bio_list_init(&tcmd->xfer_done_list);
-
 	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
 	rq->tag = tag++;
 	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
 	list_add(&tcmd->hash_list, head);
 	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
-
-	tcmd->rq = rq;
-	rq->end_io_data = tcmd;
-	rq->flags |= REQ_DONTPREP;
 }
 
 static void scsi_tgt_uspace_send_fn(void *data)
@@ -147,31 +140,20 @@
 	if (list_empty(&qdata->cmd_req))
 		return;
 
-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-	if (!tcmd) {
-		err = -ENOMEM;
-		goto out;
-	}
-
 	mutex_lock(&qdata->cmd_req_mutex);
 
 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
 	if (list_empty(&qdata->cmd_req)) {
 		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
 		mutex_unlock(&qdata->cmd_req_mutex);
-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
 		goto out;
 	}
 	rq = list_entry_rq(qdata->cmd_req.next);
 	list_del_init(&rq->queuelist);
 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
 
-	if ((rq->flags & REQ_DONTPREP)) {
-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
-		tcmd = rq->end_io_data;
-	} else
-		init_scsi_tgt_cmd(rq, tcmd);
-
+	tcmd = rq->end_io_data;
+	init_scsi_tgt_cmd(rq, tcmd);
 	cmd = rq->special;
 	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
 	if (err < 0) {
@@ -265,22 +247,35 @@
  * @scsilun:	scsi lun
  * @noblock:	set to nonzero if the command should be queued
  **/
-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-			    u64 tag)
+int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+			   u64 tag)
 {
 	struct request_queue *q = cmd->request->q;
 	struct scsi_tgt_queuedata *qdata = q->queuedata;
 	unsigned long flags;
+	struct scsi_tgt_cmd *tcmd;
 
-	cmd->request->end_io_data = scsilun;
-	/* FIXME */
-	*((u64 *) (cmd->sense_buffer)) = tag;
+	/*
+	 * It would be better to allocate scsi_tgt_cmd structure in
+	 * scsi_host_get_command and not to fail due to OOM.
+	 */
+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+	if (!tcmd)
+		return -ENOMEM;
+	cmd->request->end_io_data = tcmd;
 
+	bio_list_init(&tcmd->xfer_list);
+	bio_list_init(&tcmd->xfer_done_list);
+	tcmd->lun = scsilun;
+	tcmd->tag = tag;
+	tcmd->rq = cmd->request;
+
 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
 	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
 
 	queue_work(scsi_tgtd, &qdata->uspace_send_work);
+	return 0;
 }
 EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
 



From tomo at berlios.de  Fri Apr  7 02:44:40 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 7 Apr 2006 02:44:40 +0200
Subject: [Stgt-svn] r395 - branches/use-scsi-ml/kernel
Message-ID: <200604070044.k370ieoD020927@sheep.berlios.de>

Author: tomo
Date: 2006-04-07 02:44:26 +0200 (Fri, 07 Apr 2006)
New Revision: 395

Modified:
   branches/use-scsi-ml/kernel/scsi_tgt_if.c
   branches/use-scsi-ml/kernel/scsi_tgt_lib.c
   branches/use-scsi-ml/kernel/scsi_tgt_priv.h
Log:
Finish the previous commit.

Modified: branches/use-scsi-ml/kernel/scsi_tgt_if.c
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_if.c	2006-04-07 00:16:10 UTC (rev 394)
+++ branches/use-scsi-ml/kernel/scsi_tgt_if.c	2006-04-07 00:44:26 UTC (rev 395)
@@ -56,7 +56,8 @@
 	return netlink_unicast(nl_sk, skb, pid, 0);
 }
 
-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
+			 gfp_t flags)
 {
 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
 	struct sk_buff *skb;
@@ -71,7 +72,7 @@
 	/*
 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
 	 */
-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
+	skb = alloc_skb(NLMSG_SPACE(len), flags);
 	if (!skb)
 		return -ENOMEM;
 
@@ -85,7 +86,7 @@
 	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
 	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
 	ev->k.cmd_req.attribute = cmd->tag;
-	ev->k.cmd_req.tag = *((u64 *) (cmd->sense_buffer));
+	ev->k.cmd_req.tag = tag;
 
 	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
 		ev->k.cmd_req.data_len, cmd->tag,

Modified: branches/use-scsi-ml/kernel/scsi_tgt_lib.c
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-04-07 00:16:10 UTC (rev 394)
+++ branches/use-scsi-ml/kernel/scsi_tgt_lib.c	2006-04-07 00:44:26 UTC (rev 395)
@@ -155,7 +155,7 @@
 	tcmd = rq->end_io_data;
 	init_scsi_tgt_cmd(rq, tcmd);
 	cmd = rq->special;
-	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
+	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
 	if (err < 0) {
 		eprintk("failed to send: %p %d\n", cmd, err);
 

Modified: branches/use-scsi-ml/kernel/scsi_tgt_priv.h
===================================================================
--- branches/use-scsi-ml/kernel/scsi_tgt_priv.h	2006-04-07 00:16:10 UTC (rev 394)
+++ branches/use-scsi-ml/kernel/scsi_tgt_priv.h	2006-04-07 00:44:26 UTC (rev 395)
@@ -15,7 +15,8 @@
 extern void scsi_tgt_if_exit(void);
 extern int scsi_tgt_if_init(void);
 
-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
+				u64 tag, gfp_t flags);
 extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
 extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
 				unsigned long uaddr, u8 rw);



From tomo at berlios.de  Fri Apr  7 03:34:35 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 7 Apr 2006 03:34:35 +0200
Subject: [Stgt-svn] r396 - in branches/use-scsi-ml/patchset: . broken-out
Message-ID: <200604070134.k371YZkG031752@sheep.berlios.de>

Author: tomo
Date: 2006-04-07 03:34:11 +0200 (Fri, 07 Apr 2006)
New Revision: 396

Added:
   branches/use-scsi-ml/patchset/broken-out/
   branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
   branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
   branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
   branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
   branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
   branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
   branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
   branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
   branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
Removed:
   branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt
   branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt
   branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt
   branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt
   branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt
   branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff
   branches/use-scsi-ml/patchset/tmf.diff
Log:
Clean up the patchset directory.


Deleted: branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt
===================================================================
--- branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0001-scsi-ml-export-scsi-ml-functions-needed-by-tgt_scsi_lib-and-its-LLDs.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,347 +0,0 @@
-Subject: [PATCH] scsi-ml: export scsi-ml functions needed by tgt_scsi_lib and its LLDs
-
-This patch contains the needed changes to the scsi-ml to support targets.
-
-Note, per the last review we moved almost all the fields we added
-to the scsi_cmnd to our internal data structure which we are going
-to try and kill off when we can replace it with support from other
-parts of the kernel.
-
-The one field we left on was the offset variable. This is needed to handle
-the case where the target gets request that is so large that it cannot
-execute it in one dma operation. So max_secotors or a segment limit may
-limit the size of the transfer. In this case our tgt core code will
-break up the command into managable transfers and send them to the
-LLD one at a time. The offset is then used to tell the LLD where in
-the command we are at. Is there another field on the scsi_cmd for
-that?
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- drivers/scsi/hosts.c     |    5 +++
- drivers/scsi/scsi.c      |   91 ++++++++++++++++++++++++++++++++++++++++++++++
- drivers/scsi/scsi_lib.c  |   33 ++++++++++++-----
- include/scsi/scsi_cmnd.h |    8 ++++
- include/scsi/scsi_host.h |   40 ++++++++++++++++++++
- 5 files changed, 168 insertions(+), 9 deletions(-)
-
-b7a992fe8af27b25c30fc5e7c36abfe6ebb6fe84
-diff --git a/drivers/scsi/hosts.c b/drivers/scsi/hosts.c
-index 5881079..64e687a 100644
---- a/drivers/scsi/hosts.c
-+++ b/drivers/scsi/hosts.c
-@@ -264,6 +264,11 @@ static void scsi_host_dev_release(struct
- 	if (shost->work_q)
- 		destroy_workqueue(shost->work_q);
- 
-+	if (shost->uspace_req_q) {
-+		kfree(shost->uspace_req_q->queuedata);
-+		scsi_free_queue(shost->uspace_req_q);
-+	}
-+
- 	scsi_destroy_command_freelist(shost);
- 	kfree(shost->shost_data);
- 
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index 245ca99..a2295ed 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -236,6 +236,58 @@ static struct scsi_cmnd *__scsi_get_comm
- }
- 
- /*
-+ * Function:	scsi_host_get_command()
-+ *
-+ * Purpose:	Allocate and setup a scsi command block and blk request
-+ *
-+ * Arguments:	shost	- scsi host
-+ *		data_dir - dma data dir
-+ *		gfp_mask- allocator flags
-+ *
-+ * Returns:	The allocated scsi command structure.
-+ *
-+ * This should be called by target LLDs to get a command.
-+ */
-+struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *shost,
-+					enum dma_data_direction data_dir,
-+					gfp_t gfp_mask)
-+{
-+	int write = (data_dir == DMA_TO_DEVICE);
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+
-+	/* Bail if we can't get a reference to the device */
-+	if (!get_device(&shost->shost_gendev))
-+		return NULL;
-+
-+	rq = blk_get_request(shost->uspace_req_q, write, gfp_mask);
-+	if (!rq)
-+		goto put_dev;
-+
-+	cmd = __scsi_get_command(shost, gfp_mask);
-+	if (!cmd)
-+		goto release_rq;
-+
-+	memset(cmd, 0, sizeof(*cmd));
-+	cmd->sc_data_direction = data_dir;
-+	cmd->jiffies_at_alloc = jiffies;
-+	cmd->request = rq;
-+
-+	rq->special = cmd;
-+	rq->flags |= REQ_SPECIAL | REQ_BLOCK_PC;
-+
-+	return cmd;
-+
-+release_rq:
-+	blk_put_request(rq);
-+put_dev:
-+	put_device(&shost->shost_gendev);
-+	return NULL;
-+
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_get_command);
-+
-+/*
-  * Function:	scsi_get_command()
-  *
-  * Purpose:	Allocate and setup a scsi command block
-@@ -274,6 +326,45 @@ struct scsi_cmnd *scsi_get_command(struc
- EXPORT_SYMBOL(scsi_get_command);
- 
- /*
-+ * Function:	scsi_host_put_command()
-+ *
-+ * Purpose:	Free a scsi command block
-+ *
-+ * Arguments:	shost	- scsi host
-+ * 		cmd	- command block to free
-+ *
-+ * Returns:	Nothing.
-+ *
-+ * Notes:	The command must not belong to any lists.
-+ */
-+void scsi_host_put_command(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
-+{
-+	struct request_queue *q = shost->uspace_req_q;
-+	struct request *rq = cmd->request;
-+	unsigned long flags;
-+
-+	/* changing locks here, don't need to restore the irq state */
-+	spin_lock_irqsave(&shost->free_list_lock, flags);
-+	if (unlikely(list_empty(&shost->free_list))) {
-+		list_add(&cmd->list, &shost->free_list);
-+		cmd = NULL;
-+	}
-+	spin_unlock(&shost->free_list_lock);
-+
-+	spin_lock(q->queue_lock);
-+	if (blk_rq_tagged(rq))
-+		blk_queue_end_tag(q, rq);
-+	__blk_put_request(q, rq);
-+	spin_unlock_irqrestore(q->queue_lock, flags);
-+
-+	if (likely(cmd != NULL))
-+		kmem_cache_free(shost->cmd_pool->slab, cmd);
-+
-+	put_device(&shost->shost_gendev);
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_put_command);
-+
-+/*
-  * Function:	scsi_put_command()
-  *
-  * Purpose:	Free a scsi command block
-diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
-index 4362dcd..7307705 100644
---- a/drivers/scsi/scsi_lib.c
-+++ b/drivers/scsi/scsi_lib.c
-@@ -804,7 +804,7 @@ static struct scsi_cmnd *scsi_end_reques
- 	return NULL;
- }
- 
--static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
- {
- 	struct scsi_host_sg_pool *sgp;
- 	struct scatterlist *sgl;
-@@ -845,7 +845,9 @@ static struct scatterlist *scsi_alloc_sg
- 	return sgl;
- }
- 
--static void scsi_free_sgtable(struct scatterlist *sgl, int index)
-+EXPORT_SYMBOL(scsi_alloc_sgtable);
-+
-+void scsi_free_sgtable(struct scatterlist *sgl, int index)
- {
- 	struct scsi_host_sg_pool *sgp;
- 
-@@ -855,6 +857,8 @@ static void scsi_free_sgtable(struct sca
- 	mempool_free(sgl, sgp->pool);
- }
- 
-+EXPORT_SYMBOL(scsi_free_sgtable);
-+
- /*
-  * Function:    scsi_release_buffers()
-  *
-@@ -1687,29 +1691,40 @@ u64 scsi_calculate_bounce_limit(struct S
- }
- EXPORT_SYMBOL(scsi_calculate_bounce_limit);
- 
--struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					 request_fn_proc *request_fn)
- {
--	struct Scsi_Host *shost = sdev->host;
- 	struct request_queue *q;
- 
--	q = blk_init_queue(scsi_request_fn, NULL);
-+	q = blk_init_queue(request_fn, NULL);
- 	if (!q)
- 		return NULL;
- 
--	blk_queue_prep_rq(q, scsi_prep_fn);
--
- 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
- 	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
- 	blk_queue_max_sectors(q, shost->max_sectors);
- 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
- 	blk_queue_segment_boundary(q, shost->dma_boundary);
--	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
--	blk_queue_softirq_done(q, scsi_softirq_done);
- 
- 	if (!shost->use_clustering)
- 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
- 	return q;
- }
-+EXPORT_SYMBOL(__scsi_alloc_queue);
-+
-+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+{
-+	struct request_queue *q;
-+
-+	q = __scsi_alloc_queue(sdev->host, scsi_request_fn);
-+	if (!q)
-+		return NULL;
-+
-+	blk_queue_prep_rq(q, scsi_prep_fn);
-+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
-+	blk_queue_softirq_done(q, scsi_softirq_done);
-+	return q;
-+}
- 
- void scsi_free_queue(struct request_queue *q)
- {
-diff --git a/include/scsi/scsi_cmnd.h b/include/scsi/scsi_cmnd.h
-index 7529f43..51156c7 100644
---- a/include/scsi/scsi_cmnd.h
-+++ b/include/scsi/scsi_cmnd.h
-@@ -8,6 +8,7 @@
- 
- struct request;
- struct scatterlist;
-+struct Scsi_Host;
- struct scsi_device;
- struct scsi_request;
- 
-@@ -84,6 +85,8 @@ struct scsi_cmnd {
- 	unsigned short sglist_len;	/* size of malloc'd scatter-gather list */
- 	unsigned bufflen;	/* Size of data buffer */
- 	void *buffer;		/* Data buffer */
-+	/* offset in cmd we are at (for multi-transfer tgt cmds) */
-+	unsigned offset;
- 
- 	unsigned underflow;	/* Return error if less than
- 				   this amount is transferred */
-@@ -147,9 +150,14 @@ struct scsi_cmnd {
- #define SCSI_STATE_MLQUEUE         0x100b
- 
- 
-+extern struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *,
-+					       enum dma_data_direction, gfp_t);
- extern struct scsi_cmnd *scsi_get_command(struct scsi_device *, gfp_t);
-+extern void scsi_host_put_command(struct Scsi_Host *, struct scsi_cmnd *);
- extern void scsi_put_command(struct scsi_cmnd *);
- extern void scsi_io_completion(struct scsi_cmnd *, unsigned int, unsigned int);
- extern void scsi_finish_command(struct scsi_cmnd *cmd);
-+extern struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *, gfp_t);
-+extern void scsi_free_sgtable(struct scatterlist *, int);
- 
- #endif /* _SCSI_SCSI_CMND_H */
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8279929..8b799db 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -7,6 +7,7 @@
- #include <linux/workqueue.h>
- #include <linux/mutex.h>
- 
-+struct request_queue;
- struct block_device;
- struct completion;
- struct module;
-@@ -123,6 +124,36 @@ struct scsi_host_template {
- 			     void (*done)(struct scsi_cmnd *));
- 
- 	/*
-+	 * The transfer functions are used to queue a scsi command to
-+	 * the LLD. When the driver is finished processing the command
-+	 * the done callback is invoked.
-+	 *
-+	 * return values: see queuecommand
-+	 *
-+	 * If the LLD accepts the cmd, it should set the result to an
-+	 * appropriate value when completed before calling the done function.
-+	 *
-+	 * STATUS: REQUIRED FOR TARGET DRIVERS
-+	 */
-+	/* TODO: rename */
-+	int (* transfer_response)(struct scsi_cmnd *,
-+				  void (*done)(struct scsi_cmnd *));
-+	/*
-+	 * This is called to inform the LLD to transfer cmd->request_bufflen
-+	 * bytes of the cmd at cmd->offset in the cmd. The cmd->use_sg
-+	 * speciefies the number of scatterlist entried in the command
-+	 * and cmd->request_buffer contains the scatterlist.
-+	 *
-+	 * If the command cannot be processed in one transfer_data call
-+	 * becuase a scatterlist within the LLD's limits cannot be
-+	 * created then transfer_data will be called multiple times.
-+	 * It is initially called from process context, and later
-+	 * calls are from the interrup context.
-+	 */
-+	int (* transfer_data)(struct scsi_cmnd *,
-+			      void (*done)(struct scsi_cmnd *));
-+
-+	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
- 	 * routine that is present that should work in most cases.  For those
-@@ -572,6 +603,12 @@ struct Scsi_Host {
- 	 */
- 	unsigned int max_host_blocked;
- 
-+	/*
-+	 * q used for scsi_tgt msgs, async events or any other requests that
-+	 * need to be processed in userspace
-+ 	 */
-+	struct request_queue *uspace_req_q;
-+
- 	/* legacy crap */
- 	unsigned long base;
- 	unsigned long io_port;
-@@ -674,6 +711,9 @@ extern void scsi_unblock_requests(struct
- extern void scsi_block_requests(struct Scsi_Host *);
- 
- struct class_container;
-+
-+extern struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					     void (*) (struct request_queue *));
- /*
-  * These two functions are used to allocate and free a pseudo device
-  * which will connect to the host adapter itself rather than any
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0002-block-layer-kill-length-alignment-test-in-bin_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,45 +0,0 @@
-Subject: [PATCH] block layer: kill length alignment test in bin_map_user
-
-The tgt project is mapping in bios using bio_map_user. The current targets
-do not need their len to be aligned with a queue limit so this check is
-causing some problems.
-
-The major user, blk_bio_map_user checks for the len before mapping
-and is not affected by this patch.
-
-And the semi-newly added user blk_rq_map_user_iov has been failing
-out when the len is not aligned properly so maybe people have been
-good and not sending misaligned lens or that path is not used very
-often and this change will not be very dangerous. st and sg do not
-check the length and we have not seen any problem reports from those
-wider used paths so this patch should be fairly safe - for mm
-and wider testing at least.
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- fs/bio.c |    5 ++---
- 1 files changed, 2 insertions(+), 3 deletions(-)
-
-20ed0ebdd84e1a93550413f487dceaf1ab29a2cd
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..d8259d9 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -620,10 +620,9 @@ static struct bio *__bio_map_user_iov(re
- 
- 		nr_pages += end - start;
- 		/*
--		 * transfer and buffer must be aligned to at least hardsector
--		 * size for now, in the future we can relax this restriction
-+		 * buffer must be aligned to at least hardsector size for now
- 		 */
--		if ((uaddr & queue_dma_alignment(q)) || (len & queue_dma_alignment(q)))
-+		if (uaddr & queue_dma_alignment(q))
- 			return ERR_PTR(-EINVAL);
- 	}
- 
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0003-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,148 +0,0 @@
-Subject: [PATCH] block layer: add partial mappings support to bio_map_user
-
-For target mode we could end up with the case where we get very large
-request from the initiator. The request could be so large that we
-cannot transfer all the data in one operation. For example the
-HBA's segment or max_sector limits might limit us to a 1 MB transfer.
-To send a 5 MB command then we need to transfer the command chunk by chunk.
-
-To do this, tgt core will map in as much data as possible into a bio,
-send this off, then when that transfer is completed we send off another
-request/bio. To be able to pack as much data into a bio as possible
-we need bio_map_user to support partially mapped bios.
-
-The attached patch allows bio_map_user to map bios partially. The two
-users (blk_rq_map_user and blk_rq_map_user_iov) will fail if the bio
-is partially mapped.
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- block/ll_rw_blk.c      |   29 ++++++++++++++++++-----------
- block/scsi_ioctl.c     |    3 ++-
- fs/bio.c               |   14 +-------------
- include/linux/blkdev.h |    3 ++-
- 4 files changed, 23 insertions(+), 26 deletions(-)
-
-95e0133e03f75a5edc7ca4eb7ce0c0347cf841bf
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 03d9c82..6849859 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq->bio = rq->biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq->buffer = rq->data = NULL;
--		rq->data_len = len;
--		return 0;
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq->bio = rq->biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq->buffer = rq->data = NULL;
-+	rq->data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq->bio = rq->biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq->buffer = rq->data = NULL;
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
-+					  hdr->dxfer_len);
- 		kfree(iov);
- 	} else if (hdr->dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..f75c2f4 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -750,7 +750,6 @@ struct bio *bio_map_user_iov(request_que
- 			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -765,18 +764,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i < iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio->bi_size == len)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio->bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt
===================================================================
--- branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0004-core-scsi-target-fns.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,647 +0,0 @@
-Subject: [PATCH] The core scsi target lib functions.
-
-TODO:
-- mv md/dm-bio-list.h to linux/bio-list.h so md and us do not have to
-do that weird include.
-- convert scsi_tgt_cmd's work struct to James's execute code. And try
-to kill our scsi_tgt_cmd.
-- add host state checking. We do refcouting so hotplug is partially
-supported, but we need to add state checking to make it easier on
-the LLD.
-- make it so the request_queue can be used to pass around these target
-messages better (see todo in code), or maybe just remove request_queue
-usage all together and use our own linked_list or something else.
-We currently use the queue for tag numbers so if we remove the request_queue
-we will have to add some sort of host tag list like was suggested for iscsi.
-We also use the queue to store the HBA limits and build proper sized bios
-and reqeusts so we would need a shell queue like what dm uses.
-- eh handling (still in the process of working on proper state
-model in userspace).
-- must remove our request->flags hack
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- drivers/scsi/scsi_tgt_lib.c  |  556 ++++++++++++++++++++++++++++++++++++++++++
- drivers/scsi/scsi_tgt_priv.h |   25 ++
- include/scsi/scsi_tgt.h      |   11 +
- 3 files changed, 592 insertions(+), 0 deletions(-)
- create mode 100644 drivers/scsi/scsi_tgt_lib.c
- create mode 100644 drivers/scsi/scsi_tgt_priv.h
- create mode 100644 include/scsi/scsi_tgt.h
-
-ef599065dcacab6ed526d6156a369ed478d595a2
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-new file mode 100644
-index 0000000..4665ce4
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -0,0 +1,556 @@
-+/*
-+ * SCSI target lib functions
-+ *
-+ * Copyright (C) 2005 Mike Christie <michaelc at cs.wisc.edu>
-+ * Copyright (C) 2005 FUJITA Tomonori <tomof at acm.org>
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#include <linux/blkdev.h>
-+#include <linux/elevator.h>
-+#include <linux/module.h>
-+#include <linux/pagemap.h>
-+#include <scsi/scsi.h>
-+#include <scsi/scsi_cmnd.h>
-+#include <scsi/scsi_device.h>
-+#include <scsi/scsi_host.h>
-+#include <scsi/scsi_tgt.h>
-+#include <../drivers/md/dm-bio-list.h>
-+
-+#include "scsi_tgt_priv.h"
-+
-+static struct workqueue_struct *scsi_tgtd;
-+static kmem_cache_t *scsi_tgt_cmd_cache;
-+
-+/*
-+ * TODO: this struct will be killed when the block layer supports large bios
-+ * and James's work struct code is in
-+ */
-+struct scsi_tgt_cmd {
-+	/* TODO replace work with James b's code */
-+	struct work_struct work;
-+	/* TODO replace the lists with a large bio */
-+	struct bio_list xfer_done_list;
-+	struct bio_list xfer_list;
-+	struct scsi_lun *lun;
-+};
-+
-+static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
-+{
-+	struct bio *bio;
-+
-+	/* must call bio_endio in case bio was bounced */
-+	while ((bio = bio_list_pop(&tcmd->xfer_done_list))) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+	}
-+
-+	while ((bio = bio_list_pop(&tcmd->xfer_list))) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+	}
-+}
-+
-+static void scsi_tgt_cmd_destroy(void *data)
-+{
-+	struct scsi_cmnd *cmd = data;
-+	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
-+	struct request_queue *q = cmd->request->q;
-+
-+	dprintk("cmd %p %d %lu\n", cmd, cmd->sc_data_direction,
-+		rq_data_dir(cmd->request));
-+	/*
-+	 * We must set rq->flags here because bio_map_user and
-+	 * blk_rq_bio_prep ruined ti.
-+	 */
-+	if (cmd->sc_data_direction == DMA_TO_DEVICE)
-+		cmd->request->flags |= 1;
-+	else
-+		cmd->request->flags &= ~1UL;
-+
-+	scsi_unmap_user_pages(tcmd);
-+	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
-+	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
-+	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
-+	blk_run_queue(q);
-+}
-+
-+static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
-+{
-+	tcmd->lun = rq->end_io_data;
-+	bio_list_init(&tcmd->xfer_list);
-+	bio_list_init(&tcmd->xfer_done_list);
-+}
-+
-+static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
-+{
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd)
-+		return BLKPREP_DEFER;
-+
-+	init_scsi_tgt_cmd(rq, tcmd);
-+	rq->end_io_data = tcmd;
-+	rq->flags |= REQ_DONTPREP;
-+	return BLKPREP_OK;
-+}
-+
-+static void scsi_uspace_request_fn(struct request_queue *q)
-+{
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	/*
-+	 * TODO: just send everthing in the queue to userspace in
-+	 * one vector instead of multiple calls
-+	 */
-+	while ((rq = elv_next_request(q)) != NULL) {
-+		cmd = rq->special;
-+		tcmd = rq->end_io_data;
-+
-+		/* the completion code kicks us in case we hit this */
-+		if (blk_queue_start_tag(q, rq)) {
-+			eprintk("failed to tag: %p\n", cmd);
-+			break;
-+		}
-+
-+		spin_unlock_irq(q->queue_lock);
-+		if (scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC) < 0) {
-+			eprintk("failed to send: %p\n", cmd);
-+			goto requeue;
-+		}
-+		spin_lock_irq(q->queue_lock);
-+	}
-+
-+	return;
-+requeue:
-+	spin_lock_irq(q->queue_lock);
-+	/* need to track cnts and plug */
-+	blk_requeue_request(q, rq);
-+	spin_unlock_irq(q->queue_lock);
-+}
-+
-+/**
-+ * scsi_tgt_alloc_queue - setup queue used for message passing
-+ * shost: scsi host
-+ *
-+ * This should be called by the LLD after host allocation.
-+ * And will be released when the host is released.
-+ **/
-+int scsi_tgt_alloc_queue(struct Scsi_Host *shost)
-+{
-+	struct scsi_tgt_queuedata *queuedata;
-+	struct request_queue *q;
-+	int err;
-+
-+	/*
-+	 * Do we need to send a netlink event or should uspace
-+	 * just respond to the hotplug event?
-+	 */
-+	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
-+	if (!q)
-+		return -ENOMEM;
-+
-+	queuedata = kzalloc(sizeof(*queuedata), GFP_KERNEL);
-+	if (!queuedata) {
-+		err = -ENOMEM;
-+		goto cleanup_queue;
-+	}
-+	queuedata->shost = shost;
-+	q->queuedata = queuedata;
-+
-+	elevator_exit(q->elevator);
-+	err = elevator_init(q, "noop");
-+	if (err)
-+		goto free_data;
-+
-+	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
-+	/*
-+	 * this is a silly hack. We should probably just queue as many
-+	 * command as is recvd to userspace. uspace can then make
-+	 * sure we do not overload the HBA
-+	 */
-+	q->nr_requests = shost->hostt->can_queue * 2;
-+	blk_queue_init_tags(q, q->nr_requests, NULL);
-+	/*
-+	 * We currently only support software LLDs so this does
-+	 * not matter for now. Do we need this for the cards we support?
-+	 * If so we should make it a host template value.
-+	 */
-+	blk_queue_dma_alignment(q, 0);
-+	shost->uspace_req_q = q;
-+
-+	return 0;
-+
-+free_data:
-+	kfree(queuedata);
-+cleanup_queue:
-+	blk_cleanup_queue(q);
-+	return err;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_alloc_queue);
-+
-+struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_queuedata *queue = cmd->request->q->queuedata;
-+	return queue->shost;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
-+
-+/**
-+ * scsi_tgt_queue_command - queue command for userspace processing
-+ * @cmd:	scsi command
-+ * @scsilun:	scsi lun
-+ * @noblock:	set to nonzero if the command should be queued
-+ **/
-+void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-+			    int noblock)
-+{
-+	/*
-+	 * For now this just calls the request_fn from this context.
-+	 * For HW llds though we do not want to execute from here so
-+	 * the elevator code needs something like a REQ_TGT_CMD or
-+	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
-+	 */
-+	cmd->request->end_io_data = scsilun;
-+	elv_add_request(cmd->request->q, cmd->request, ELEVATOR_INSERT_BACK, 1);
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
-+
-+/*
-+ * This is run from a interrpt handler normally and the unmap
-+ * needs process context so we must queue
-+ */
-+static void scsi_tgt_cmd_done(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
-+
-+	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
-+
-+	/* don't we have to call this if result is set or not */
-+	if (cmd->result) {
-+		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
-+		return;
-+	}
-+
-+	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
-+	queue_work(scsi_tgtd, &tcmd->work);
-+}
-+
-+static int __scsi_tgt_transfer_response(struct scsi_cmnd *cmd)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	int err;
-+
-+	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
-+
-+	err = shost->hostt->transfer_response(cmd, scsi_tgt_cmd_done);
-+	switch (err) {
-+	case SCSI_MLQUEUE_HOST_BUSY:
-+	case SCSI_MLQUEUE_DEVICE_BUSY:
-+		return -EAGAIN;
-+	}
-+
-+	return 0;
-+}
-+
-+static void scsi_tgt_transfer_response(struct scsi_cmnd *cmd)
-+{
-+	int err;
-+
-+	err = __scsi_tgt_transfer_response(cmd);
-+	if (!err)
-+		return;
-+
-+	cmd->result = DID_BUS_BUSY << 16;
-+	if (scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC) <= 0)
-+		/* the eh will have to pick this up */
-+		printk(KERN_ERR "Could not send cmd %p status\n", cmd);
-+}
-+
-+static int scsi_tgt_init_cmd(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+{
-+	struct request *rq = cmd->request;
-+	int count;
-+
-+	cmd->use_sg = rq->nr_phys_segments;
-+	cmd->request_buffer = scsi_alloc_sgtable(cmd, gfp_mask);
-+	if (!cmd->request_buffer)
-+		return -ENOMEM;
-+
-+	cmd->request_bufflen = rq->data_len;
-+
-+	dprintk("cmd %p addr %p cnt %d %lu\n", cmd, cmd->buffer, cmd->use_sg,
-+		rq_data_dir(rq));
-+	count = blk_rq_map_sg(rq->q, rq, cmd->request_buffer);
-+	if (likely(count <= cmd->use_sg)) {
-+		cmd->use_sg = count;
-+		return 0;
-+	}
-+
-+	eprintk("cmd %p addr %p cnt %d\n", cmd, cmd->buffer, cmd->use_sg);
-+	scsi_free_sgtable(cmd->request_buffer, cmd->sglist_len);
-+	return -EINVAL;
-+}
-+
-+/* TODO: test this crap and replace bio_map_user with new interface maybe */
-+static int scsi_map_user_pages(struct scsi_tgt_cmd *tcmd, struct scsi_cmnd *cmd,
-+			       int rw)
-+{
-+	struct request_queue *q = cmd->request->q;
-+	struct request *rq = cmd->request;
-+	void *uaddr = cmd->buffer;
-+	unsigned int len = cmd->bufflen;
-+	struct bio *bio;
-+	int err;
-+
-+	while (len > 0) {
-+		dprintk("%lx %u\n", (unsigned long) uaddr, len);
-+		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
-+		if (IS_ERR(bio)) {
-+			err = PTR_ERR(bio);
-+			dprintk("fail to map %lx %u %d %x\n",
-+				(unsigned long) uaddr, len, err, cmd->cmnd[0]);
-+			goto unmap_bios;
-+		}
-+
-+		uaddr += bio->bi_size;
-+		len -= bio->bi_size;
-+
-+		/*
-+		 * The first bio is added and merged. We could probably
-+		 * try to add others using scsi_merge_bio() but for now
-+		 * we keep it simple. The first bio should be pretty large
-+		 * (either hitting the 1 MB bio pages limit or a queue limit)
-+		 * already but for really large IO we may want to try and
-+		 * merge these.
-+		 */
-+		if (!rq->bio) {
-+			blk_rq_bio_prep(q, rq, bio);
-+			rq->data_len = bio->bi_size;
-+		} else
-+			/* put list of bios to transfer in next go around */
-+			bio_list_add(&tcmd->xfer_list, bio);
-+	}
-+
-+	cmd->offset = 0;
-+	err = scsi_tgt_init_cmd(cmd, GFP_KERNEL);
-+	if (err)
-+		goto unmap_bios;
-+
-+	return 0;
-+
-+unmap_bios:
-+	if (rq->bio) {
-+		bio_unmap_user(rq->bio);
-+		while ((bio = bio_list_pop(&tcmd->xfer_list)))
-+			bio_unmap_user(bio);
-+	}
-+
-+	return err;
-+}
-+
-+static int scsi_tgt_transfer_data(struct scsi_cmnd *);
-+
-+static void scsi_tgt_data_transfer_done(struct scsi_cmnd *cmd)
-+{
-+	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
-+	struct bio *bio;
-+	int err;
-+
-+	/* should we free resources here on error ? */
-+	if (cmd->result) {
-+send_uspace_err:
-+		if (scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC) <= 0)
-+			/* the tgt uspace eh will have to pick this up */
-+			printk(KERN_ERR "Could not send cmd %p status\n", cmd);
-+		return;
-+	}
-+
-+	dprintk("cmd %p request_bufflen %u bufflen %u\n",
-+		cmd, cmd->request_bufflen, cmd->bufflen);
-+
-+	scsi_free_sgtable(cmd->request_buffer, cmd->sglist_len);
-+	bio_list_add(&tcmd->xfer_done_list, cmd->request->bio);
-+
-+	cmd->buffer += cmd->request_bufflen;
-+	cmd->offset += cmd->request_bufflen;
-+
-+	if (!tcmd->xfer_list.head) {
-+		scsi_tgt_transfer_response(cmd);
-+		return;
-+	}
-+
-+	dprintk("cmd2 %p request_bufflen %u bufflen %u\n",
-+		cmd, cmd->request_bufflen, cmd->bufflen);
-+
-+	bio = bio_list_pop(&tcmd->xfer_list);
-+	BUG_ON(!bio);
-+
-+	blk_rq_bio_prep(cmd->request->q, cmd->request, bio);
-+	cmd->request->data_len = bio->bi_size;
-+	err = scsi_tgt_init_cmd(cmd, GFP_ATOMIC);
-+	if (err) {
-+		cmd->result = DID_ERROR << 16;
-+		goto send_uspace_err;
-+	}
-+
-+	if (scsi_tgt_transfer_data(cmd)) {
-+		cmd->result = DID_NO_CONNECT << 16;
-+		goto send_uspace_err;
-+	}
-+}
-+
-+static int scsi_tgt_transfer_data(struct scsi_cmnd *cmd)
-+{
-+	int err;
-+	struct Scsi_Host *host = scsi_tgt_cmd_to_host(cmd);
-+
-+	err = host->hostt->transfer_data(cmd, scsi_tgt_data_transfer_done);
-+	switch (err) {
-+		case SCSI_MLQUEUE_HOST_BUSY:
-+		case SCSI_MLQUEUE_DEVICE_BUSY:
-+			return -EAGAIN;
-+	default:
-+		return 0;
-+	}
-+}
-+
-+static int scsi_tgt_copy_sense(struct scsi_cmnd *cmd, unsigned long uaddr,
-+				unsigned len)
-+{
-+	char __user *p = (char __user *) uaddr;
-+
-+	if (copy_from_user(cmd->sense_buffer, p,
-+			   min_t(unsigned, SCSI_SENSE_BUFFERSIZE, len))) {
-+		printk(KERN_ERR "Could not copy the sense buffer\n");
-+		return -EIO;
-+	}
-+	return 0;
-+}
-+
-+int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+			 unsigned long uaddr, u8 rw)
-+{
-+	struct Scsi_Host *shost;
-+	struct scsi_cmnd *cmd;
-+	struct request *rq;
-+	int err = 0;
-+
-+	dprintk("%d %u %d %u %lx %u\n", host_no, cid, result,
-+		len, uaddr, rw);
-+
-+	/* TODO: replace with a O(1) alg */
-+	shost = scsi_host_lookup(host_no);
-+	if (IS_ERR(shost)) {
-+		printk(KERN_ERR "Could not find host no %d\n", host_no);
-+		return -EINVAL;
-+	}
-+
-+	rq = blk_queue_find_tag(shost->uspace_req_q, cid);
-+	if (!rq) {
-+		printk(KERN_ERR "Could not find cid %u\n", cid);
-+		err = -EINVAL;
-+		goto done;
-+	}
-+	cmd = rq->special;
-+
-+	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
-+		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
-+
-+	/*
-+	 * store the userspace values here, the working values are
-+	 * in the request_* values
-+	 */
-+	cmd->buffer = (void *)uaddr;
-+	if (len)
-+		cmd->bufflen = len;
-+	cmd->result = result;
-+
-+	if (!cmd->bufflen) {
-+		err = __scsi_tgt_transfer_response(cmd);
-+		goto done;
-+	}
-+
-+	/*
-+	 * TODO: Do we need to handle case where request does not
-+	 * align with LLD.
-+	 */
-+	err = scsi_map_user_pages(rq->end_io_data, cmd, rw);
-+	if (err) {
-+		eprintk("%p %d\n", cmd, err);
-+		err = -EAGAIN;
-+		goto done;
-+	}
-+
-+	/* userspace failure */
-+	if (cmd->result) {
-+		if (status_byte(cmd->result) == CHECK_CONDITION)
-+			scsi_tgt_copy_sense(cmd, uaddr, len);
-+		err = __scsi_tgt_transfer_response(cmd);
-+		goto done;
-+	}
-+	/* ask the target LLD to transfer the data to the buffer */
-+	err = scsi_tgt_transfer_data(cmd);
-+
-+done:
-+	scsi_host_put(shost);
-+	return err;
-+}
-+
-+static int __init scsi_tgt_init(void)
-+{
-+	int err;
-+
-+	scsi_tgt_cmd_cache = kmem_cache_create("scsi_tgt_cmd",
-+					       sizeof(struct scsi_tgt_cmd),
-+					       0, 0, NULL, NULL);
-+	if (!scsi_tgt_cmd_cache)
-+		return -ENOMEM;
-+
-+	scsi_tgtd = create_workqueue("scsi_tgtd");
-+	if (!scsi_tgtd) {
-+		err = -ENOMEM;
-+		goto free_kmemcache;
-+	}
-+
-+	err = scsi_tgt_if_init();
-+	if (err)
-+		goto destroy_wq;
-+
-+	return 0;
-+
-+destroy_wq:
-+	destroy_workqueue(scsi_tgtd);
-+free_kmemcache:
-+	kmem_cache_destroy(scsi_tgt_cmd_cache);
-+	return err;
-+}
-+
-+static void __exit scsi_tgt_exit(void)
-+{
-+	destroy_workqueue(scsi_tgtd);
-+	scsi_tgt_if_exit();
-+	kmem_cache_destroy(scsi_tgt_cmd_cache);
-+}
-+
-+module_init(scsi_tgt_init);
-+module_exit(scsi_tgt_exit);
-+
-+MODULE_DESCRIPTION("SCSI target core");
-+MODULE_LICENSE("GPL");
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-new file mode 100644
-index 0000000..fcf2ec6
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -0,0 +1,25 @@
-+struct scsi_cmnd;
-+struct scsi_lun;
-+struct Scsi_Host;
-+struct task_struct;
-+
-+/* tmp - will replace with SCSI logging stuff */
-+#define dprintk(fmt, args...)					\
-+do {								\
-+	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
-+} while (0)
-+
-+#define eprintk dprintk
-+
-+struct scsi_tgt_queuedata {
-+	struct Scsi_Host *shost;
-+};
-+
-+extern void scsi_tgt_if_exit(void);
-+extern int scsi_tgt_if_init(void);
-+
-+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
-+extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
-+extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+				unsigned long uaddr, u8 rw);
-+
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-new file mode 100644
-index 0000000..91ad6bc
---- /dev/null
-+++ b/include/scsi/scsi_tgt.h
-@@ -0,0 +1,11 @@
-+/*
-+ * SCSI target definitions
-+ */
-+
-+struct Scsi_Host;
-+struct scsi_cmnd;
-+struct scsi_lun;
-+
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt
===================================================================
--- branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0005-scsi-target-netlink-if.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,351 +0,0 @@
-Subject: [PATCH] Netlink interface for the scsi tgt framework.
-
-I did not think the netdev people wanted to see the scsi and
-block layer code, so I am just send the netlink interface part
-of this patchset to netdev. I can resend the other parts if
-needed.
-
-The scsi tgt framework, adds support for scsi target mode
-cards. So instead of using the scsi card in your box as a initiator
-you can use it as a target/server.
-
-The reason of the netlink use is becuase the target normally
-recieve a interrupt indicating that command or event is
-ready to be processed. The scsi card's driver will then call
-a scsi lib function which eventually calls scsi_tgt_uspace_send to
-tell userspace to begin to process the request (userspace contains
-the state model). Later userspace will call back into the kernel
-be sending a netlink msg, and instruct the scsi driver what to do next.
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- drivers/scsi/scsi_tgt_if.c |  205 ++++++++++++++++++++++++++++++++++++++++++++
- include/linux/netlink.h    |    1 
- include/scsi/scsi_tgt_if.h |   88 +++++++++++++++++++
- 3 files changed, 294 insertions(+), 0 deletions(-)
- create mode 100644 drivers/scsi/scsi_tgt_if.c
- create mode 100644 include/scsi/scsi_tgt_if.h
-
-5e0ec5395f282e9dd5802940046eb0f3cdfdbec5
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-new file mode 100644
-index 0000000..0780e3c
---- /dev/null
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -0,0 +1,205 @@
-+/*
-+ * SCSI target kernel/user interface functions
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori <tomof at acm.org>
-+ * Copyright (C) 2005 Mike Christie <michaelc at cs.wisc.edu>
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#include <linux/blkdev.h>
-+#include <linux/file.h>
-+#include <linux/netlink.h>
-+#include <net/tcp.h>
-+#include <scsi/scsi.h>
-+#include <scsi/scsi_cmnd.h>
-+#include <scsi/scsi_device.h>
-+#include <scsi/scsi_host.h>
-+#include <scsi/scsi_tgt.h>
-+#include <scsi/scsi_tgt_if.h>
-+
-+#include "scsi_tgt_priv.h"
-+
-+static int tgtd_pid;
-+static struct sock *nl_sk;
-+
-+static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
-+			  pid_t pid)
-+{
-+	struct tgt_event *ev;
-+	struct nlmsghdr *nlh;
-+	struct sk_buff *skb;
-+	uint32_t len;
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
-+	skb = alloc_skb(len, flags);
-+	if (!skb)
-+		return -ENOMEM;
-+
-+	nlh = __nlmsg_put(skb, pid, 0, type, len - sizeof(*nlh), 0);
-+
-+	ev = NLMSG_DATA(nlh);
-+	memcpy(ev, p, sizeof(*ev));
-+
-+	return netlink_unicast(nl_sk, skb, pid, 0);
-+}
-+
-+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	struct sk_buff *skb;
-+	struct nlmsghdr *nlh;
-+	struct tgt_event *ev;
-+	int err, len;
-+
-+	/* FIXME: we need scsi core to do that. */
-+	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
-+	/*
-+	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
-+	 */
-+	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
-+	if (!skb)
-+		return -ENOMEM;
-+
-+	nlh = __nlmsg_put(skb, tgtd_pid, 0, TGT_KEVENT_CMD_REQ,
-+			  len - sizeof(*nlh), 0);
-+
-+	ev = NLMSG_DATA(nlh);
-+	ev->k.cmd_req.host_no = shost->host_no;
-+	ev->k.cmd_req.cid = cmd->request->tag;
-+	ev->k.cmd_req.data_len = cmd->request_bufflen;
-+	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
-+	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
-+	ev->k.cmd_req.attribute = cmd->tag;
-+
-+	dprintk("%p %d %u %u %x\n", cmd, shost->host_no, ev->k.cmd_req.cid,
-+		ev->k.cmd_req.data_len, cmd->tag);
-+
-+	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
-+	if (err < 0)
-+		eprintk(KERN_ERR "could not send skb %d\n", err);
-+	return err;
-+}
-+
-+int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+{
-+	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
-+	struct tgt_event ev;
-+
-+	memset(&ev, 0, sizeof(ev));
-+	ev.k.cmd_done.host_no = shost->host_no;
-+	ev.k.cmd_done.cid = cmd->request->tag;
-+	ev.k.cmd_done.result = cmd->result;
-+
-+	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
-+}
-+
-+static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
-+{
-+	struct tgt_event *ev = NLMSG_DATA(nlh);
-+	int err = 0;
-+
-+	dprintk("%d %d %d\n", nlh->nlmsg_type,
-+		nlh->nlmsg_pid, current->pid);
-+
-+	switch (nlh->nlmsg_type) {
-+	case TGT_UEVENT_REQ:
-+		tgtd_pid = NETLINK_CREDS(skb)->pid;
-+		break;
-+	case TGT_UEVENT_CMD_RSP:
-+		/* TODO: handle multiple cmds in one event */
-+		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
-+					   ev->u.cmd_rsp.cid,
-+					   ev->u.cmd_rsp.result,
-+					   ev->u.cmd_rsp.len,
-+					   ev->u.cmd_rsp.uaddr,
-+					   ev->u.cmd_rsp.rw);
-+		break;
-+	default:
-+		eprintk("unknown type %d\n", nlh->nlmsg_type);
-+		err = -EINVAL;
-+	}
-+
-+	return err;
-+}
-+
-+static int event_recv_skb(struct sk_buff *skb)
-+{
-+	int err;
-+	uint32_t rlen;
-+	struct nlmsghdr	*nlh;
-+
-+	while (skb->len >= NLMSG_SPACE(0)) {
-+		nlh = (struct nlmsghdr *) skb->data;
-+		if (nlh->nlmsg_len < sizeof(*nlh) || skb->len < nlh->nlmsg_len)
-+			return 0;
-+		rlen = NLMSG_ALIGN(nlh->nlmsg_len);
-+		if (rlen > skb->len)
-+			rlen = skb->len;
-+		err = event_recv_msg(skb, nlh);
-+
-+		dprintk("%d %d\n", nlh->nlmsg_type, err);
-+		/*
-+		 * TODO for passthru commands the lower level should
-+		 * probably handle the result or we should modify this
-+		 */
-+		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
-+			struct tgt_event ev;
-+
-+			memset(&ev, 0, sizeof(ev));
-+			ev.k.event_rsp.err = err;
-+			send_event_rsp(TGT_KEVENT_RSP, &ev,
-+				       GFP_KERNEL | __GFP_NOFAIL,
-+					nlh->nlmsg_pid);
-+		}
-+		skb_pull(skb, rlen);
-+	}
-+	return 0;
-+}
-+
-+static void event_recv(struct sock *sk, int length)
-+{
-+	struct sk_buff *skb;
-+
-+	while ((skb = skb_dequeue(&sk->sk_receive_queue))) {
-+		if (NETLINK_CREDS(skb)->uid) {
-+			skb_pull(skb, skb->len);
-+			kfree_skb(skb);
-+			continue;
-+		}
-+
-+		if (event_recv_skb(skb) && skb->len)
-+			skb_queue_head(&sk->sk_receive_queue, skb);
-+		else
-+			kfree_skb(skb);
-+	}
-+}
-+
-+void __exit scsi_tgt_if_exit(void)
-+{
-+	sock_release(nl_sk->sk_socket);
-+}
-+
-+int __init scsi_tgt_if_init(void)
-+{
-+	nl_sk = netlink_kernel_create(NETLINK_TGT, 1, event_recv,
-+				    THIS_MODULE);
-+	if (!nl_sk)
-+		return -ENOMEM;
-+
-+	return 0;
-+}
-diff --git a/include/linux/netlink.h b/include/linux/netlink.h
-index c256ebe..9422ae5 100644
---- a/include/linux/netlink.h
-+++ b/include/linux/netlink.h
-@@ -21,6 +21,7 @@
- #define NETLINK_DNRTMSG		14	/* DECnet routing messages */
- #define NETLINK_KOBJECT_UEVENT	15	/* Kernel messages to userspace */
- #define NETLINK_GENERIC		16
-+#define NETLINK_TGT		17	/* SCSI target */
- 
- #define MAX_LINKS 32		
- 
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-new file mode 100644
-index 0000000..ebca452
---- /dev/null
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -0,0 +1,88 @@
-+/*
-+ * SCSI target kernel/user interface
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori <tomof at acm.org>
-+ * Copyright (C) 2005 Mike Christie <michaelc at cs.wisc.edu>
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#ifndef __SCSI_TARGET_IF_H
-+#define __SCSI_TARGET_IF_H
-+
-+enum tgt_event_type {
-+	/* user -> kernel */
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
-+
-+	/* kernel -> user */
-+	TGT_KEVENT_RSP,
-+	TGT_KEVENT_CMD_REQ,
-+	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
-+};
-+
-+struct tgt_event {
-+	/* user-> kernel */
-+	union {
-+		struct {
-+			int type;
-+			int host_no;
-+		} event_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t len;
-+			int result;
-+			uint64_t uaddr;
-+			uint8_t rw;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			int mid;
-+			int result;
-+		} tsk_mgmt_rsp;
-+	} u;
-+
-+	/* kernel -> user */
-+	union {
-+		struct {
-+			int err;
-+		} event_rsp;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t data_len;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
-+		} cmd_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			int result;
-+		} cmd_done;
-+		struct {
-+			int host_no;
-+			int mid;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			int function;
-+		} tsk_mgmt_req;
-+	} k;
-+
-+} __attribute__ ((aligned (sizeof(uint64_t))));
-+#endif
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt
===================================================================
--- branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/0006-scsi-ml-Makefile-and-Kconfig-changes-for-stgt.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,55 +0,0 @@
-Subject: [PATCH] scsi-ml: Makefile and Kconfig changes for stgt
-
-Makefile and Kconfig stuff.
-
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-
----
-
- drivers/scsi/Kconfig  |    7 +++++++
- drivers/scsi/Makefile |    3 +++
- 2 files changed, 10 insertions(+), 0 deletions(-)
-
-f7a32ccf6c93402cf70e29c3ea45aeee15ea64cb
-diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
-index 3c606cf..d09c792 100644
---- a/drivers/scsi/Kconfig
-+++ b/drivers/scsi/Kconfig
-@@ -27,6 +27,13 @@ config SCSI
- 	  However, do not compile this as a module if your root file system
- 	  (the one containing the directory /) is located on a SCSI device.
- 
-+config SCSI_TGT
-+	tristate "SCSI target support"
-+	depends on SCSI && EXPERIMENTAL
-+	---help---
-+	  If you want to use SCSI target mode drivers enable this option.
-+	  If you choose M, the module will be called scsi_tgt.
-+
- config SCSI_PROC_FS
- 	bool "legacy /proc/scsi/ support"
- 	depends on SCSI && PROC_FS
-diff --git a/drivers/scsi/Makefile b/drivers/scsi/Makefile
-index 320e765..3d81b8d 100644
---- a/drivers/scsi/Makefile
-+++ b/drivers/scsi/Makefile
-@@ -21,6 +21,7 @@ CFLAGS_seagate.o =   -DARBITRATE -DPARIT
- subdir-$(CONFIG_PCMCIA)		+= pcmcia
- 
- obj-$(CONFIG_SCSI)		+= scsi_mod.o
-+obj-$(CONFIG_SCSI_TGT)		+= scsi_tgt.o
- 
- obj-$(CONFIG_RAID_ATTRS)	+= raid_class.o
- 
-@@ -155,6 +156,8 @@ scsi_mod-y			+= scsi.o hosts.o scsi_ioct
- scsi_mod-$(CONFIG_SYSCTL)	+= scsi_sysctl.o
- scsi_mod-$(CONFIG_SCSI_PROC_FS)	+= scsi_proc.o
- 
-+scsi_tgt-y			+= scsi_tgt_lib.o scsi_tgt_if.o
-+
- sd_mod-objs	:= sd.o
- sr_mod-objs	:= sr.o sr_ioctl.o sr_vendor.o
- ncr53c8xx-flags-$(CONFIG_SCSI_ZALON) \
--- 
-1.1.5

Added: branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,130 @@
+Subject: [PATCH] block layer: revoke the original patch to add partial mappings support
+From: fujita <fujita at albi.localdomain>
+Date: 1142409079 +0900
+
+For target mode we could end up with the case where we get very large
+request from the initiator. The request could be so large that we
+cannot transfer all the data in one operation. For example the
+HBA's segment or max_sector limits might limit us to a 1 MB transfer.
+To send a 5 MB command then we need to transfer the command chunk by chunk.
+
+To do this, tgt core will map in as much data as possible into a bio,
+send this off, then when that transfer is completed we send off another
+request/bio. To be able to pack as much data into a bio as possible
+we need bio_map_user to support partially mapped bios.
+
+Following the comments from Jens Axboe on the original patch:
+
+http://marc.theaimsgroup.com/?l=linux-scsi&m=114012008928530&w=2
+
+This patch will revoke changes by the original patch.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ block/ll_rw_blk.c   |    5 ++---
+ fs/bio.c            |   11 ++++-------
+ include/linux/bio.h |    5 ++---
+ 3 files changed, 8 insertions(+), 13 deletions(-)
+
+4d84a7a7218de12ef1e3f58a0a5514a730994848
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..03d9c82 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2287,7 +2287,7 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	 */
+ 	uaddr = (unsigned long) ubuf;
+ 	if (!(uaddr & queue_dma_alignment(q)) && !(len & queue_dma_alignment(q)))
+-		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
++		bio = bio_map_user(q, NULL, uaddr, len, reading);
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+@@ -2339,8 +2339,7 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	/* we don't allow misaligned data like bio_map_user() does.  If the
+ 	 * user is using sg, they're expected to know the alignment constraints
+ 	 * and respect them accordingly */
+-	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
+-				0);
++	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
+diff --git a/fs/bio.c b/fs/bio.c
+index 3e940c9..d8259d9 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
+  *	@uaddr: start of user address
+  *	@len: length in bytes
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
+-			 unsigned long uaddr, unsigned int len, int write_to_vm,
+-			 int support_partial)
++			 unsigned long uaddr, unsigned int len, int write_to_vm)
+ {
+ 	struct sg_iovec iov;
+ 
+ 	iov.iov_base = (void __user *)uaddr;
+ 	iov.iov_len = len;
+ 
+-	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm, support_partial);
++	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm);
+ }
+ 
+ /**
+@@ -742,14 +740,13 @@ struct bio *bio_map_user(request_queue_t
+  *	@iov:	the iovec.
+  *	@iov_count: number of elements in the iovec
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
+ 			     struct sg_iovec *iov, int iov_count,
+-			     int write_to_vm, int support_partial)
++			     int write_to_vm)
+ {
+ 	struct bio *bio;
+ 	int len = 0, i;
+@@ -770,7 +767,7 @@ struct bio *bio_map_user_iov(request_que
+ 	for (i = 0; i < iov_count; i++)
+ 		len += iov[i].iov_len;
+ 
+-	if (bio->bi_size == len || support_partial)
++	if (bio->bi_size == len)
+ 		return bio;
+ 
+ 	/*
+diff --git a/include/linux/bio.h b/include/linux/bio.h
+index fc0906c..b60ffe3 100644
+--- a/include/linux/bio.h
++++ b/include/linux/bio.h
+@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
+ extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
+ 			   unsigned int, unsigned int);
+ extern int bio_get_nr_vecs(struct block_device *);
+-extern int __bio_get_nr_vecs(struct request_queue *);
+ extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
+-				unsigned long, unsigned int, int, int);
++				unsigned long, unsigned int, int);
+ struct sg_iovec;
+ extern struct bio *bio_map_user_iov(struct request_queue *,
+ 				    struct block_device *,
+-				    struct sg_iovec *, int, int, int);
++				    struct sg_iovec *, int, int);
+ extern void bio_unmap_user(struct bio *);
+ extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
+ 				gfp_t);
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,149 @@
+Subject: [PATCH] block layer: add partial mappings support to bio_map_user
+From: fujita <fujita at albi.localdomain>
+Date: 1142409163 +0900
+
+This is the updated patch for partial mappings support.
+
+- bio_map_user_iov always allows partial mappings.
+
+- The two users (blk_rq_map_user and blk_rq_map_user_iov) will fails
+if the bio is partially mapped.
+
+- Added a length argument to blk_rq_map_user_iov in order to avoid
+including sg.h in ll_rw_blk.c for struct sg_iovec.
+
+This is a resend:
+
+http://marc.theaimsgroup.com/?l=linux-scsi&m=114086655400806&w=2
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ block/ll_rw_blk.c      |   29 ++++++++++++++++++-----------
+ block/scsi_ioctl.c     |    3 ++-
+ fs/bio.c               |   14 +-------------
+ include/linux/blkdev.h |    3 ++-
+ 4 files changed, 23 insertions(+), 26 deletions(-)
+
+d43dcc5c747b5896c795e1fe1f8a6d5df525daa6
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 03d9c82..6849859 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+-	if (!IS_ERR(bio)) {
+-		rq->bio = rq->biotail = bio;
+-		blk_rq_bio_prep(q, rq, bio);
++	if (IS_ERR(bio))
++		return PTR_ERR(bio);
+ 
+-		rq->buffer = rq->data = NULL;
+-		rq->data_len = len;
+-		return 0;
++	if (bio->bi_size != len) {
++		bio_endio(bio, bio->bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
+ 	}
+ 
+-	/*
+-	 * bio is the err-ptr
+-	 */
+-	return PTR_ERR(bio);
++	rq->bio = rq->biotail = bio;
++	blk_rq_bio_prep(q, rq, bio);
++	rq->buffer = rq->data = NULL;
++	rq->data_len = len;
++	return 0;
+ }
+ 
+ EXPORT_SYMBOL(blk_rq_map_user);
+@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
+  *    unmapping.
+  */
+ int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
+-			struct sg_iovec *iov, int iov_count)
++			struct sg_iovec *iov, int iov_count, unsigned int len)
+ {
+ 	struct bio *bio;
+ 
+@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
++	if (bio->bi_size != len) {
++		bio_endio(bio, bio->bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
++	}
++
+ 	rq->bio = rq->biotail = bio;
+ 	blk_rq_bio_prep(q, rq, bio);
+ 	rq->buffer = rq->data = NULL;
+diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
+index 24f7af9..ef9900d 100644
+--- a/block/scsi_ioctl.c
++++ b/block/scsi_ioctl.c
+@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
+ 			goto out;
+ 		}
+ 
+-		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
++		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
++					  hdr->dxfer_len);
+ 		kfree(iov);
+ 	} else if (hdr->dxfer_len)
+ 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
+diff --git a/fs/bio.c b/fs/bio.c
+index d8259d9..f51a873 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -749,7 +749,6 @@ struct bio *bio_map_user_iov(request_que
+ 			     int write_to_vm)
+ {
+ 	struct bio *bio;
+-	int len = 0, i;
+ 
+ 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
+ 
+@@ -764,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
+ 	 */
+ 	bio_get(bio);
+ 
+-	for (i = 0; i < iov_count; i++)
+-		len += iov[i].iov_len;
+-
+-	if (bio->bi_size == len)
+-		return bio;
+-
+-	/*
+-	 * don't support partial mappings
+-	 */
+-	bio_endio(bio, bio->bi_size, 0);
+-	bio_unmap_user(bio);
+-	return ERR_PTR(-EINVAL);
++	return bio;
+ }
+ 
+ static void __bio_unmap_user(struct bio *bio)
+diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
+index 860e7a4..619ef1d 100644
+--- a/include/linux/blkdev.h
++++ b/include/linux/blkdev.h
+@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
+ extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
+ extern int blk_rq_unmap_user(struct bio *, unsigned int);
+ extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
+-extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
++extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
++			       struct sg_iovec *, int, unsigned int);
+ extern int blk_execute_rq(request_queue_t *, struct gendisk *,
+ 			  struct request *, int);
+ extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: use the original bio_map_user interface
+From: fujita <fujita at albi.localdomain>
+Date: 1142409283 +0900
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c |    2 +-
+ 1 files changed, 1 insertions(+), 1 deletions(-)
+
+2c78c6353dc183a16ef3e12b9c5618dd5b89679c
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..941dd64 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len > 0) {
+ 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk("fail to map %lx %u %d %x\n",
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,54 @@
+Subject: [PATCH] block layer: use blk_rq_bio_prep in init_request_from_bio
+From: fujita <fujita at albi.localdomain>
+Date: 1142409371 +0900
+
+Patch to use blk_rq_bio_prep in init_request_from_bio. And remove
+blk_rq_bio_prep's flags copying. The first three bits have not been
+the same for some time so that has been broken. The user of
+blk_rq_bio_prep will setup the request flags so if it wanted failfast
+or to be a barrier it will set the correct flag itself.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ block/ll_rw_blk.c |   11 ++---------
+ 1 files changed, 2 insertions(+), 9 deletions(-)
+
+4b387c65f0645e86794c06eb3e734b0ec6e5733c
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..da2c57d 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2765,16 +2765,12 @@ static void init_request_from_bio(struct
+ 
+ 	req->errors = 0;
+ 	req->hard_sector = req->sector = bio->bi_sector;
+-	req->hard_nr_sectors = req->nr_sectors = bio_sectors(bio);
+-	req->current_nr_sectors = req->hard_cur_sectors = bio_cur_sectors(bio);
+-	req->nr_phys_segments = bio_phys_segments(req->q, bio);
+-	req->nr_hw_segments = bio_hw_segments(req->q, bio);
+-	req->buffer = bio_data(bio);	/* see ->buffer comment above */
+ 	req->waiting = NULL;
+-	req->bio = req->biotail = bio;
+ 	req->ioprio = bio_prio(bio);
+ 	req->rq_disk = bio->bi_bdev->bd_disk;
+ 	req->start_time = jiffies;
++
++	blk_rq_bio_prep(req->q, req, bio);
+ }
+ 
+ static int __make_request(request_queue_t *q, struct bio *bio)
+@@ -3403,9 +3399,6 @@ EXPORT_SYMBOL(end_request);
+ 
+ void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
+ {
+-	/* first three bits are identical in rq->flags and bio->bi_rw */
+-	rq->flags |= (bio->bi_rw & 7);
+-
+ 	rq->nr_phys_segments = bio_phys_segments(q, bio);
+ 	rq->nr_hw_segments = bio_hw_segments(q, bio);
+ 	rq->current_nr_sectors = bio_cur_sectors(bio);
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,293 @@
+Subject: [PATCH] scsi tgt: kernel/user interface changes
+From: fujita <fujita at albi.localdomain>
+Date: 1142409611 +0900
+
+- merge the tgt command structure with the the event structure for simplicity.
+- add a new event type for task management.
+- remove some of unused event types.
+- send task attributes to user-space daemon.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_if.c   |   52 ++++++++++++++++++------------------------
+ drivers/scsi/scsi_tgt_lib.c  |   10 ++++----
+ drivers/scsi/scsi_tgt_priv.h |    4 ++-
+ include/scsi/scsi_tgt_if.h   |   50 ++++++++++++++++++++--------------------
+ 4 files changed, 54 insertions(+), 62 deletions(-)
+
+5804be31dad9a5ca05bef0ff2674cde90299ac3d
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index 38b35da..a31c8d5 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -35,15 +35,15 @@
+ static int tgtd_pid;
+ static struct sock *nl_sk;
+ 
+-static int send_event_res(uint16_t type, struct tgt_event *p,
+-			  void *data, int dlen, gfp_t flags, pid_t pid)
++static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
++			  pid_t pid)
+ {
+ 	struct tgt_event *ev;
+ 	struct nlmsghdr *nlh;
+ 	struct sk_buff *skb;
+ 	uint32_t len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + dlen);
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	skb = alloc_skb(len, flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+@@ -52,8 +52,6 @@ static int send_event_res(uint16_t type,
+ 
+ 	ev = NLMSG_DATA(nlh);
+ 	memcpy(ev, p, sizeof(*ev));
+-	if (dlen)
+-		memcpy(ev->data, data, dlen);
+ 
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+@@ -64,10 +62,12 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	struct sk_buff *skb;
+ 	struct nlmsghdr *nlh;
+ 	struct tgt_event *ev;
+-	struct tgt_cmd *tcmd;
+ 	int err, len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
++	/* FIXME: we need scsi core to do that. */
++	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
++
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+@@ -82,17 +82,13 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	ev->k.cmd_req.host_no = shost->host_no;
+ 	ev->k.cmd_req.cid = cmd->request->tag;
+ 	ev->k.cmd_req.data_len = cmd->request_bufflen;
++	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
++	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
++	ev->k.cmd_req.attribute = cmd->tag;
+ 
+ 	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
+ 		ev->k.cmd_req.data_len);
+ 
+-	/* FIXME: we need scsi core to do that. */
+-	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
+-
+-	tcmd = (struct tgt_cmd *) ev->data;
+-	memcpy(tcmd->scb, cmd->cmnd, sizeof(tcmd->scb));
+-	memcpy(tcmd->lun, lun, sizeof(struct scsi_lun));
+-
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err < 0)
+ 		printk(KERN_ERR "scsi_tgt_uspace_send: could not send skb %d\n",
+@@ -104,15 +100,13 @@ int scsi_tgt_uspace_send_status(struct s
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct tgt_event ev;
+-	char dummy[sizeof(struct tgt_cmd)];
+ 
+ 	memset(&ev, 0, sizeof(ev));
+ 	ev.k.cmd_done.host_no = shost->host_no;
+ 	ev.k.cmd_done.cid = cmd->request->tag;
+ 	ev.k.cmd_done.result = cmd->result;
+ 
+-	return send_event_res(TGT_KEVENT_CMD_DONE, &ev, dummy, sizeof(dummy),
+-			      gfp_mask, tgtd_pid);
++	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
+ }
+ 
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+@@ -124,19 +118,17 @@ static int event_recv_msg(struct sk_buff
+ 		nlh->nlmsg_pid, current->pid);
+ 
+ 	switch (nlh->nlmsg_type) {
+-	case TGT_UEVENT_TGTD_BIND:
++	case TGT_UEVENT_REQ:
+ 		tgtd_pid = NETLINK_CREDS(skb)->pid;
+ 		break;
+-	case TGT_UEVENT_CMD_RES:
++	case TGT_UEVENT_CMD_RSP:
+ 		/* TODO: handle multiple cmds in one event */
+-		err = scsi_tgt_kspace_exec(ev->u.cmd_res.host_no,
+-					   ev->u.cmd_res.cid,
+-					   ev->u.cmd_res.result,
+-					   ev->u.cmd_res.len,
+-					   ev->u.cmd_res.offset,
+-					   ev->u.cmd_res.uaddr,
+-					   ev->u.cmd_res.rw,
+-					   ev->u.cmd_res.try_map);
++		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
++					   ev->u.cmd_rsp.cid,
++					   ev->u.cmd_rsp.result,
++					   ev->u.cmd_rsp.len,
++					   ev->u.cmd_rsp.uaddr,
++					   ev->u.cmd_rsp.rw);
+ 		break;
+ 	default:
+ 		eprintk("unknown type %d\n", nlh->nlmsg_type);
+@@ -166,12 +158,12 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RES) {
++		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
+ 			struct tgt_event ev;
+ 
+ 			memset(&ev, 0, sizeof(ev));
+-			ev.k.event_res.err = err;
+-			send_event_res(TGT_KEVENT_RESPONSE, &ev, NULL, 0,
++			ev.k.event_rsp.err = err;
++			send_event_rsp(TGT_KEVENT_RSP, &ev,
+ 				       GFP_KERNEL | __GFP_NOFAIL,
+ 					nlh->nlmsg_pid);
+ 		}
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..3549e7c 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len > 0) {
+ 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk("fail to map %lx %u %d %x\n",
+@@ -438,16 +438,16 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
+-int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
+-			 unsigned long uaddr, u8 rw, u8 try_map)
++int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
++			 unsigned long uaddr, u8 rw)
+ {
+ 	struct Scsi_Host *shost;
+ 	struct scsi_cmnd *cmd;
+ 	struct request *rq;
+ 	int err = 0;
+ 
+-	dprintk("%d %u %d %u %llu %lx %u %u\n", host_no, cid, result,
+-		len, (unsigned long long) offset, uaddr, rw, try_map);
++	dprintk("%d %u %d %u %lx %u\n", host_no, cid, result,
++		len, uaddr, rw);
+ 
+ 	/* TODO: replace with a O(1) alg */
+ 	shost = scsi_host_lookup(host_no);
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 4236e50..fcf2ec6 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -21,5 +21,5 @@ extern int scsi_tgt_if_init(void);
+ extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+-				u64 offset, unsigned long uaddr, u8 rw,
+-				u8 try_map);
++				unsigned long uaddr, u8 rw);
++
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index da3a808..ebca452 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -24,65 +24,65 @@
+ 
+ enum tgt_event_type {
+ 	/* user -> kernel */
+-	TGT_UEVENT_TGTD_BIND,
+-	TGT_UEVENT_TARGET_SETUP,
+-	TGT_UEVENT_CMD_RES,
++	TGT_UEVENT_REQ,
++	TGT_UEVENT_CMD_RSP,
++	TGT_UEVENT_TSK_MGMT_RSP,
+ 
+ 	/* kernel -> user */
+-	TGT_KEVENT_RESPONSE,
++	TGT_KEVENT_RSP,
+ 	TGT_KEVENT_CMD_REQ,
+ 	TGT_KEVENT_CMD_DONE,
++	TGT_KEVENT_TSK_MGMT_REQ,
+ };
+ 
+ struct tgt_event {
+ 	/* user-> kernel */
+ 	union {
+ 		struct {
+-			int pk_fd;
+-		} tgtd_bind;
++			int type;
++			int host_no;
++		} event_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t len;
+ 			int result;
+ 			uint64_t uaddr;
+-			uint64_t offset;
+ 			uint8_t rw;
+-			uint8_t try_map;
+-		} cmd_res;
++		} cmd_rsp;
++		struct {
++			int host_no;
++			int mid;
++			int result;
++		} tsk_mgmt_rsp;
+ 	} u;
+ 
+ 	/* kernel -> user */
+ 	union {
+ 		struct {
+ 			int err;
+-		} event_res;
++		} event_rsp;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t data_len;
+-			uint64_t dev_id;
++			uint8_t scb[16];
++			uint8_t lun[8];
++			int attribute;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			int result;
+ 		} cmd_done;
++		struct {
++			int host_no;
++			int mid;
++			uint64_t tag;
++			uint8_t lun[8];
++			int function;
++		} tsk_mgmt_req;
+ 	} k;
+ 
+-	/*
+-	 * I think a pointer is a unsigned long but this struct
+-	 * gets passed around from the kernel to userspace and
+-	 * back again so to handle some ppc64 setups where userspace is
+-	 * 32 bits but the kernel is 64 we do this odd thing
+-	 */
+-	uint64_t data[0];
+-} __attribute__ ((aligned (sizeof(uint64_t))));
+-
+-struct tgt_cmd {
+-	uint8_t scb[16];
+-	uint8_t lun[8];
+-	int tags;
+ } __attribute__ ((aligned (sizeof(uint64_t))));
+-
+ #endif
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: fix double lock in scsi_uspace_request_fn
+From: fujita <fujita at albi.localdomain>
+Date: 1142409678 +0900
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c |    2 +-
+ 1 files changed, 1 insertions(+), 1 deletions(-)
+
+1ddfd113a764450e7998cc16dd07dcc37077b05b
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..5d76078 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -136,7 +136,7 @@ requeue:
+ 	spin_lock_irq(q->queue_lock);
+ 	/* need to track cnts and plug */
+ 	blk_requeue_request(q, rq);
+-	spin_lock_irq(q->queue_lock);
++	spin_unlock_irq(q->queue_lock);
+ }
+ 
+ /**
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,28 @@
+Subject: [PATCH] scsi tgt: remove blk_queue_end_tag
+From: fujita <fujita at albi.localdomain>
+Date: 1142422083 +0900
+
+Remove blk_queue_end_tag() in scsi_host_put_command() because tgt
+doesn't use the elevator code.
+
+---
+
+ drivers/scsi/scsi.c |    2 --
+ 1 files changed, 0 insertions(+), 2 deletions(-)
+
+fd45c05acbc00cd21fa7c82f6aed5a5ef3e5b98a
+diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
+index 3cf02b1..9c22465 100644
+--- a/drivers/scsi/scsi.c
++++ b/drivers/scsi/scsi.c
+@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
+ 	spin_unlock(&shost->free_list_lock);
+ 
+ 	spin_lock(q->queue_lock);
+-	if (blk_rq_tagged(rq))
+-		blk_queue_end_tag(q, rq);
+ 	__blk_put_request(q, rq);
+ 	spin_unlock_irqrestore(q->queue_lock, flags);
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,338 @@
+Subject: [PATCH] scsi tgt: replace the elevator code
+
+tgt uses the elevator code to send SCSI commands to the user-space
+daemon (q->request_fn sends netlink packets including commands).
+
+This patch replaces the elevator code with a simple list.
+
+This is mainly because tgt also needs to send TMF requests to the
+user-space daemon (the daemon does all the SCSI state machine
+stuff). tgt must send SCSI commands and TMF requests in an exact order
+so that it would be preferable to use a single queue (per host) for
+both. To uses the elevator code for TMF requests, tgt needs to
+allocate request structures for them. That's wasteful because request
+structures is useless for TMF requests, which don't perform any I/Os.
+
+We basically have a netdev queue of events to send to userspace so by
+using the request_queue and netdev queue we are basically double
+queueing and wasting resources and it is affecting performance
+
+We like to use shared memory stuff between kernel and user spaces
+instead of netlink in the future. These queues would go away.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_lib.c  |  180 ++++++++++++++++++++++++++++++------------
+ drivers/scsi/scsi_tgt_priv.h |    4 -
+ 2 files changed, 129 insertions(+), 55 deletions(-)
+
+c4bb05742e1834d664a7d8e721ecea71d42fd7f7
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 274d929..2cbc749 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -20,7 +20,7 @@
+  * 02110-1301 USA
+  */
+ #include <linux/blkdev.h>
+-#include <linux/elevator.h>
++#include <linux/hash.h>
+ #include <linux/module.h>
+ #include <linux/pagemap.h>
+ #include <scsi/scsi.h>
+@@ -46,6 +46,24 @@ struct scsi_tgt_cmd {
+ 	struct bio_list xfer_done_list;
+ 	struct bio_list xfer_list;
+ 	struct scsi_lun *lun;
++
++	struct list_head hash_list;
++	struct request *rq;
++};
++
++#define TGT_HASH_ORDER	4
++#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
++
++struct scsi_tgt_queuedata {
++	struct Scsi_Host *shost;
++	struct list_head cmd_hash[1 << TGT_HASH_ORDER];
++	spinlock_t cmd_hash_lock;
++
++	struct work_struct uspace_send_work;
++
++	spinlock_t cmd_req_lock;
++	struct mutex cmd_req_mutex;
++	struct list_head cmd_req;
+ };
+ 
+ static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
+@@ -68,9 +86,16 @@ static void scsi_tgt_cmd_destroy(void *d
+ {
+ 	struct scsi_cmnd *cmd = data;
+ 	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
++	struct scsi_tgt_queuedata *qdata = cmd->request->q->queuedata;
++	unsigned long flags;
+ 
+ 	dprintk("cmd %p %d %lu\n", cmd, cmd->sc_data_direction,
+ 		rq_data_dir(cmd->request));
++
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	list_del(&tcmd->hash_list);
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
++
+ 	/*
+ 	 * We must set rq->flags here because bio_map_user and
+ 	 * blk_rq_bio_prep ruined ti.
+@@ -88,55 +113,84 @@ static void scsi_tgt_cmd_destroy(void *d
+ 
+ static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
+ {
++	struct scsi_tgt_queuedata *qdata = rq->q->queuedata;
++	unsigned long flags;
++	struct list_head *head;
++	static u32 tag = 0;
++
+ 	tcmd->lun = rq->end_io_data;
+ 	bio_list_init(&tcmd->xfer_list);
+ 	bio_list_init(&tcmd->xfer_done_list);
+-}
+-
+-static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
+-{
+-	struct scsi_tgt_cmd *tcmd;
+ 
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd)
+-		return BLKPREP_DEFER;
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	rq->tag = tag++;
++	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
++	list_add(&tcmd->hash_list, head);
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
+ 
+-	init_scsi_tgt_cmd(rq, tcmd);
++	tcmd->rq = rq;
+ 	rq->end_io_data = tcmd;
+ 	rq->flags |= REQ_DONTPREP;
+-	return BLKPREP_OK;
+ }
+ 
+-static void scsi_uspace_request_fn(struct request_queue *q)
++static void scsi_tgt_uspace_send_fn(void *data)
+ {
++	struct request_queue *q = data;
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
+ 	struct request *rq;
+ 	struct scsi_cmnd *cmd;
+ 	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++	int err;
+ 
+-	/*
+-	 * TODO: just send everthing in the queue to userspace in
+-	 * one vector instead of multiple calls
+-	 */
+-	while ((rq = elv_next_request(q)) != NULL) {
+-		cmd = rq->special;
+-		tcmd = rq->end_io_data;
++retry:
++	err = 0;
++	if (list_empty(&qdata->cmd_req))
++		return;
+ 
+-		/* the completion code kicks us in case we hit this */
+-		if (blk_queue_start_tag(q, rq))
+-			break;
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd) {
++		err = -ENOMEM;
++		goto out;
++	}
++
++	mutex_lock(&qdata->cmd_req_mutex);
+ 
+-		spin_unlock_irq(q->queue_lock);
+-		if (scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC) < 0)
+-			goto requeue;
+-		spin_lock_irq(q->queue_lock);
++	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++	if (list_empty(&qdata->cmd_req)) {
++		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++		mutex_unlock(&qdata->cmd_req_mutex);
++		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
++		goto out;
+ 	}
++	rq = list_entry_rq(qdata->cmd_req.next);
++	list_del_init(&rq->queuelist);
++	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 
+-	return;
+-requeue:
+-	spin_lock_irq(q->queue_lock);
+-	/* need to track cnts and plug */
+-	blk_requeue_request(q, rq);
+-	spin_unlock_irq(q->queue_lock);
++	if ((rq->flags & REQ_DONTPREP)) {
++		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
++		tcmd = rq->end_io_data;
++	} else
++		init_scsi_tgt_cmd(rq, tcmd);
++
++	cmd = rq->special;
++	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
++	if (err < 0) {
++		eprintk("failed to send: %p %d\n", cmd, err);
++
++		spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++		list_add(&rq->queuelist, &qdata->cmd_req);
++		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++	}
++
++	mutex_unlock(&qdata->cmd_req_mutex);
++out:
++	/* TODO: proper error handling */
++	if (err < 0)
++		queue_delayed_work(scsi_tgtd, &qdata->uspace_send_work,
++				   HZ / 10);
++	else
++		goto retry;
+ }
+ 
+ /**
+@@ -150,13 +204,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ {
+ 	struct scsi_tgt_queuedata *queuedata;
+ 	struct request_queue *q;
+-	int err;
++	int err, i;
+ 
+ 	/*
+ 	 * Do we need to send a netlink event or should uspace
+ 	 * just respond to the hotplug event?
+ 	 */
+-	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
++	q = __scsi_alloc_queue(shost, NULL);
+ 	if (!q)
+ 		return -ENOMEM;
+ 
+@@ -168,19 +222,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	queuedata->shost = shost;
+ 	q->queuedata = queuedata;
+ 
+-	elevator_exit(q->elevator);
+-	err = elevator_init(q, "noop");
+-	if (err)
+-		goto free_data;
+-
+-	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
+ 	/*
+ 	 * this is a silly hack. We should probably just queue as many
+ 	 * command as is recvd to userspace. uspace can then make
+ 	 * sure we do not overload the HBA
+ 	 */
+ 	q->nr_requests = shost->hostt->can_queue;
+-	blk_queue_init_tags(q, shost->hostt->can_queue, NULL);
+ 	/*
+ 	 * We currently only support software LLDs so this does
+ 	 * not matter for now. Do we need this for the cards we support?
+@@ -189,10 +236,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	blk_queue_dma_alignment(q, 0);
+ 	shost->uspace_req_q = q;
+ 
++	for (i = 0; i < ARRAY_SIZE(queuedata->cmd_hash); i++)
++		INIT_LIST_HEAD(&queuedata->cmd_hash[i]);
++	spin_lock_init(&queuedata->cmd_hash_lock);
++
++	INIT_LIST_HEAD(&queuedata->cmd_req);
++	spin_lock_init(&queuedata->cmd_req_lock);
++	INIT_WORK(&queuedata->uspace_send_work, scsi_tgt_uspace_send_fn, q);
++	mutex_init(&queuedata->cmd_req_mutex);
++
+ 	return 0;
+ 
+-free_data:
+-	kfree(queuedata);
+ cleanup_queue:
+ 	blk_cleanup_queue(q);
+ 	return err;
+@@ -215,14 +269,17 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+ void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+ 			    int noblock)
+ {
+-	/*
+-	 * For now this just calls the request_fn from this context.
+-	 * For HW llds though we do not want to execute from here so
+-	 * the elevator code needs something like a REQ_TGT_CMD or
+-	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
+-	 */
++	struct request_queue *q = cmd->request->q;
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
++	unsigned long flags;
++
+ 	cmd->request->end_io_data = scsilun;
+-	elv_add_request(cmd->request->q, cmd->request, ELEVATOR_INSERT_BACK, 1);
++
++	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
++	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++
++	queue_work(scsi_tgtd, &qdata->uspace_send_work);
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -438,6 +495,27 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
++static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
++{
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
++	struct request *rq = NULL;
++	struct list_head *head;
++	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++
++	head = &qdata->cmd_hash[cmd_hashfn(cid)];
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	list_for_each_entry(tcmd, head, hash_list) {
++		if (tcmd->rq->tag == cid) {
++			rq = tcmd->rq;
++			break;
++		}
++	}
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
++
++	return rq;
++}
++
+ int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+ 			 unsigned long uaddr, u8 rw)
+ {
+@@ -456,7 +534,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 		return -EINVAL;
+ 	}
+ 
+-	rq = blk_queue_find_tag(shost->uspace_req_q, cid);
++	rq = tgt_cmd_hash_lookup(shost->uspace_req_q, cid);
+ 	if (!rq) {
+ 		printk(KERN_ERR "Could not find cid %u\n", cid);
+ 		err = -EINVAL;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index fcf2ec6..6fedcec 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -11,10 +11,6 @@ do {								\
+ 
+ #define eprintk dprintk
+ 
+-struct scsi_tgt_queuedata {
+-	struct Scsi_Host *shost;
+-};
+-
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,583 @@
+Subject: [PATCH] ibmvscsi: convert the ibmvscsi driver to use include/scsi/srp.h
+From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
+Date: 1143376921 +0900
+
+---
+
+ drivers/scsi/ibmvscsi/ibmvscsi.c  |  247 +++++++++++++++++++------------------
+ drivers/scsi/ibmvscsi/ibmvscsi.h  |    2 
+ drivers/scsi/ibmvscsi/rpa_vscsi.c |    1 
+ drivers/scsi/ibmvscsi/viosrp.h    |   17 ++-
+ 4 files changed, 142 insertions(+), 125 deletions(-)
+
+74aa6fe8367e04be9cc7d0e7d16cc790754a73f3
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
+index eaefedd..e7bd028 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.c
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
+@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
+ 			++in_use;
+ 		if (pool->events[i].ext_list) {
+ 			dma_free_coherent(hostdata->dev,
+-				  SG_ALL * sizeof(struct memory_descriptor),
++				  SG_ALL * sizeof(struct srp_direct_buf),
+ 				  pool->events[i].ext_list,
+ 				  pool->events[i].ext_list_token);
+ 		}
+@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
+ 			      struct srp_cmd *srp_cmd, 
+ 			      int numbuf)
+ {
++	u8 fmt;
++
+ 	if (numbuf == 0)
+ 		return;
+ 	
+-	if (numbuf == 1) {
++	if (numbuf == 1)
++		fmt = SRP_DATA_DESC_DIRECT;
++	else {
++		fmt = SRP_DATA_DESC_INDIRECT;
++		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
++
+ 		if (cmd->sc_data_direction == DMA_TO_DEVICE)
+-			srp_cmd->data_out_format = SRP_DIRECT_BUFFER;
+-		else 
+-			srp_cmd->data_in_format = SRP_DIRECT_BUFFER;
+-	} else {
+-		if (cmd->sc_data_direction == DMA_TO_DEVICE) {
+-			srp_cmd->data_out_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_out_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		} else {
+-			srp_cmd->data_in_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_in_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		}
++			srp_cmd->data_out_desc_cnt = numbuf;
++		else
++			srp_cmd->data_in_desc_cnt = numbuf;
+ 	}
++
++	if (cmd->sc_data_direction == DMA_TO_DEVICE)
++		srp_cmd->buf_fmt = fmt << 4;
++	else
++		srp_cmd->buf_fmt = fmt;
+ }
+ 
+-static void unmap_sg_list(int num_entries, 
++static void unmap_sg_list(int num_entries,
+ 		struct device *dev,
+-		struct memory_descriptor *md)
+-{ 
++		struct srp_direct_buf *md)
++{
+ 	int i;
+ 
+-	for (i = 0; i < num_entries; ++i) {
+-		dma_unmap_single(dev,
+-			md[i].virtual_address,
+-			md[i].length, DMA_BIDIRECTIONAL);
+-	}
++	for (i = 0; i < num_entries; ++i)
++		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
+ }
+ 
+ /**
+@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
+ 			   struct srp_event_struct *evt_struct,
+ 			   struct device *dev)
+ {
+-	if ((cmd->data_out_format == SRP_NO_BUFFER) &&
+-	    (cmd->data_in_format == SRP_NO_BUFFER))
++	u8 out_fmt, in_fmt;
++
++	out_fmt = cmd->buf_fmt >> 4;
++	in_fmt = cmd->buf_fmt & ((1U << 4) - 1);
++
++	if (out_fmt == SRP_NO_DATA_DESC && in_fmt == SRP_NO_DATA_DESC)
+ 		return;
+-	else if ((cmd->data_out_format == SRP_DIRECT_BUFFER) ||
+-		 (cmd->data_in_format == SRP_DIRECT_BUFFER)) {
+-		struct memory_descriptor *data =
+-			(struct memory_descriptor *)cmd->additional_data;
+-		dma_unmap_single(dev, data->virtual_address, data->length,
+-				 DMA_BIDIRECTIONAL);
++	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
++		 in_fmt == SRP_DATA_DESC_DIRECT) {
++		struct srp_direct_buf *data =
++			(struct srp_direct_buf *) cmd->add_data;
++		dma_unmap_single(dev, data->va, data->len, DMA_BIDIRECTIONAL);
+ 	} else {
+-		struct indirect_descriptor *indirect =
+-			(struct indirect_descriptor *)cmd->additional_data;
+-		int num_mapped = indirect->head.length / 
+-			sizeof(indirect->list[0]);
++		struct srp_indirect_buf *indirect =
++			(struct srp_indirect_buf *) cmd->add_data;
++		int num_mapped = indirect->table_desc.len /
++			sizeof(struct srp_direct_buf);
+ 
+ 		if (num_mapped <= MAX_INDIRECT_BUFS) {
+-			unmap_sg_list(num_mapped, dev, &indirect->list[0]);
++			unmap_sg_list(num_mapped, dev, &indirect->desc_list[0]);
+ 			return;
+ 		}
+ 
+@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
+ 
+ static int map_sg_list(int num_entries, 
+ 		       struct scatterlist *sg,
+-		       struct memory_descriptor *md)
++		       struct srp_direct_buf *md)
+ {
+ 	int i;
+ 	u64 total_length = 0;
+ 
+ 	for (i = 0; i < num_entries; ++i) {
+-		struct memory_descriptor *descr = md + i;
++		struct srp_direct_buf *descr = md + i;
+ 		struct scatterlist *sg_entry = &sg[i];
+-		descr->virtual_address = sg_dma_address(sg_entry);
+-		descr->length = sg_dma_len(sg_entry);
+-		descr->memory_handle = 0;
++		descr->va = sg_dma_address(sg_entry);
++		descr->len = sg_dma_len(sg_entry);
++		descr->key = 0;
+ 		total_length += sg_dma_len(sg_entry);
+  	}
+ 	return total_length;
+@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
+ 	int sg_mapped;
+ 	u64 total_length = 0;
+ 	struct scatterlist *sg = cmd->request_buffer;
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
+-	struct indirect_descriptor *indirect =
+-	    (struct indirect_descriptor *)data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
++	struct srp_indirect_buf *indirect =
++		(struct srp_indirect_buf *) data;
+ 
+ 	sg_mapped = dma_map_sg(dev, sg, cmd->use_sg, DMA_BIDIRECTIONAL);
+ 
+@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	/* special case; we can use a single direct descriptor */
+ 	if (sg_mapped == 1) {
+-		data->virtual_address = sg_dma_address(&sg[0]);
+-		data->length = sg_dma_len(&sg[0]);
+-		data->memory_handle = 0;
++		data->va = sg_dma_address(&sg[0]);
++		data->len = sg_dma_len(&sg[0]);
++		data->key = 0;
+ 		return 1;
+ 	}
+ 
+@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
+ 		return 0;
+ 	}
+ 
+-	indirect->head.virtual_address = 0;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	indirect->head.memory_handle = 0;
++	indirect->table_desc.va = 0;
++	indirect->table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
++	indirect->table_desc.key = 0;
+ 
+ 	if (sg_mapped <= MAX_INDIRECT_BUFS) {
+-		total_length = map_sg_list(sg_mapped, sg, &indirect->list[0]);
+-		indirect->total_length = total_length;
++		total_length = map_sg_list(sg_mapped, sg,
++					   &indirect->desc_list[0]);
++		indirect->len = total_length;
+ 		return 1;
+ 	}
+ 
+ 	/* get indirect table */
+ 	if (!evt_struct->ext_list) {
+-		evt_struct->ext_list =(struct memory_descriptor*)
++		evt_struct->ext_list = (struct srp_direct_buf *)
+ 			dma_alloc_coherent(dev, 
+-				SG_ALL * sizeof(struct memory_descriptor),
+-				&evt_struct->ext_list_token, 0);
++					   SG_ALL * sizeof(struct srp_direct_buf),
++					   &evt_struct->ext_list_token, 0);
+ 		if (!evt_struct->ext_list) {
+-		    printk(KERN_ERR
+-		   	"ibmvscsi: Can't allocate memory for indirect table\n");
++			printk(KERN_ERR
++			       "ibmvscsi: Can't allocate memory for indirect table\n");
+ 			return 0;
+ 			
+ 		}
+@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	total_length = map_sg_list(sg_mapped, sg, evt_struct->ext_list);	
+ 
+-	indirect->total_length = total_length;
+-	indirect->head.virtual_address = evt_struct->ext_list_token;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	memcpy(indirect->list, evt_struct->ext_list,
+-		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
++	indirect->len = total_length;
++	indirect->table_desc.va = evt_struct->ext_list_token;
++	indirect->table_desc.len = sg_mapped * sizeof(indirect->desc_list[0]);
++	memcpy(indirect->desc_list, evt_struct->ext_list,
++	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
+ 	
+  	return 1;
+ }
+@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
+ static int map_single_data(struct scsi_cmnd *cmd,
+ 			   struct srp_cmd *srp_cmd, struct device *dev)
+ {
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
+ 
+-	data->virtual_address =
++	data->va =
+ 		dma_map_single(dev, cmd->request_buffer,
+ 			       cmd->request_bufflen,
+ 			       DMA_BIDIRECTIONAL);
+-	if (dma_mapping_error(data->virtual_address)) {
++	if (dma_mapping_error(data->va)) {
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Unable to map request_buffer for command!\n");
+ 		return 0;
+ 	}
+-	data->length = cmd->request_bufflen;
+-	data->memory_handle = 0;
++	data->len = cmd->request_bufflen;
++	data->key = 0;
+ 
+ 	set_srp_direction(cmd, srp_cmd, 1);
+ 
+@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
+ 
+ 	/* Copy the IU into the transfer area */
+ 	*evt_struct->xfer_iu = evt_struct->iu;
+-	evt_struct->xfer_iu->srp.generic.tag = (u64)evt_struct;
++	evt_struct->xfer_iu->srp.rsp.tag = (u64)evt_struct;
+ 
+ 	/* Add this to the sent list.  We need to do this 
+ 	 * before we actually send 
+@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
+ 	struct srp_rsp *rsp = &evt_struct->xfer_iu->srp.rsp;
+ 	struct scsi_cmnd *cmnd = evt_struct->cmnd;
+ 
+-	if (unlikely(rsp->type != SRP_RSP_TYPE)) {
++	if (unlikely(rsp->opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: bad SRP RSP type %d\n",
+-			       rsp->type);
++			       rsp->opcode);
+ 	}
+ 	
+ 	if (cmnd) {
+ 		cmnd->result = rsp->status;
+ 		if (((cmnd->result >> 1) & 0x1f) == CHECK_CONDITION)
+ 			memcpy(cmnd->sense_buffer,
+-			       rsp->sense_and_response_data,
+-			       rsp->sense_data_list_length);
++			       rsp->data,
++			       rsp->sense_data_len);
+ 		unmap_cmd_data(&evt_struct->iu.srp.cmd, 
+ 			       evt_struct, 
+ 			       evt_struct->hostdata->dev);
+ 
+-		if (rsp->doover)
+-			cmnd->resid = rsp->data_out_residual_count;
+-		else if (rsp->diover)
+-			cmnd->resid = rsp->data_in_residual_count;
++		if (rsp->flags & SRP_RSP_FLAG_DOOVER)
++			cmnd->resid = rsp->data_out_res_cnt;
++		else if (rsp->flags & SRP_RSP_FLAG_DIOVER)
++			cmnd->resid = rsp->data_in_res_cnt;
+ 	}
+ 
+ 	if (evt_struct->cmnd_done)
+@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
+ {
+ 	struct srp_cmd *srp_cmd;
+ 	struct srp_event_struct *evt_struct;
+-	struct indirect_descriptor *indirect;
++	struct srp_indirect_buf *indirect;
+ 	struct ibmvscsi_host_data *hostdata =
+ 		(struct ibmvscsi_host_data *)&cmnd->device->host->hostdata;
+ 	u16 lun = lun_from_dev(cmnd->device);
++	u8 out_fmt, in_fmt;
+ 
+ 	evt_struct = get_event_struct(&hostdata->pool);
+ 	if (!evt_struct)
+@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
+ 
+ 	/* Set up the actual SRP IU */
+ 	srp_cmd = &evt_struct->iu.srp.cmd;
+-	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
+-	srp_cmd->type = SRP_CMD_TYPE;
++	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
++	srp_cmd->opcode = SRP_CMD;
+ 	memcpy(srp_cmd->cdb, cmnd->cmnd, sizeof(cmnd->cmnd));
+ 	srp_cmd->lun = ((u64) lun) << 48;
+ 
+@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
+ 	evt_struct->cmnd_done = done;
+ 
+ 	/* Fix up dma address of the buffer itself */
+-	indirect = (struct indirect_descriptor *)srp_cmd->additional_data;
+-	if (((srp_cmd->data_out_format == SRP_INDIRECT_BUFFER) ||
+-	    (srp_cmd->data_in_format == SRP_INDIRECT_BUFFER)) &&
+-	    (indirect->head.virtual_address == 0)) {
+-		indirect->head.virtual_address = evt_struct->crq.IU_data_ptr +
+-		    offsetof(struct srp_cmd, additional_data) +
+-		    offsetof(struct indirect_descriptor, list);
++	indirect = (struct srp_indirect_buf *) srp_cmd->add_data;
++	out_fmt = srp_cmd->buf_fmt >> 4;
++	in_fmt = srp_cmd->buf_fmt & ((1U << 4) - 1);
++	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
++	     out_fmt == SRP_DATA_DESC_INDIRECT) &&
++	    indirect->table_desc.va == 0) {
++		indirect->table_desc.va = evt_struct->crq.IU_data_ptr +
++			offsetof(struct srp_cmd, add_data) +
++			offsetof(struct srp_indirect_buf, desc_list);
+ 	}
+ 
+ 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
+@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
+ static void login_rsp(struct srp_event_struct *evt_struct)
+ {
+ 	struct ibmvscsi_host_data *hostdata = evt_struct->hostdata;
+-	switch (evt_struct->xfer_iu->srp.generic.type) {
+-	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
++	switch (evt_struct->xfer_iu->srp.login_rsp.opcode) {
++	case SRP_LOGIN_RSP:	/* it worked! */
+ 		break;
+-	case SRP_LOGIN_REJ_TYPE:	/* refused! */
++	case SRP_LOGIN_REJ:	/* refused! */
+ 		printk(KERN_INFO "ibmvscsi: SRP_LOGIN_REJ reason %u\n",
+ 		       evt_struct->xfer_iu->srp.login_rej.reason);
+ 		/* Login failed.  */
+@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
+ 	default:
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Invalid login response typecode 0x%02x!\n",
+-		       evt_struct->xfer_iu->srp.generic.type);
++		       evt_struct->xfer_iu->srp.login_rsp.opcode);
+ 		/* Login failed.  */
+ 		atomic_set(&hostdata->request_limit, -1);
+ 		return;
+@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
+ 
+ 	printk(KERN_INFO "ibmvscsi: SRP_LOGIN succeeded\n");
+ 
+-	if (evt_struct->xfer_iu->srp.login_rsp.request_limit_delta >
++	if (evt_struct->xfer_iu->srp.login_rsp.req_lim_delta >
+ 	    (max_requests - 2))
+-		evt_struct->xfer_iu->srp.login_rsp.request_limit_delta =
++		evt_struct->xfer_iu->srp.login_rsp.req_lim_delta =
+ 		    max_requests - 2;
+ 
+ 	/* Now we know what the real request-limit is */
+ 	atomic_set(&hostdata->request_limit,
+-		   evt_struct->xfer_iu->srp.login_rsp.request_limit_delta);
++		   evt_struct->xfer_iu->srp.login_rsp.req_lim_delta);
+ 
+ 	hostdata->host->can_queue =
+-	    evt_struct->xfer_iu->srp.login_rsp.request_limit_delta - 2;
++	    evt_struct->xfer_iu->srp.login_rsp.req_lim_delta - 2;
+ 
+ 	if (hostdata->host->can_queue < 1) {
+ 		printk(KERN_ERR "ibmvscsi: Invalid request_limit_delta\n");
+@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
+ 
+ 	login = &evt_struct->iu.srp.login_req;
+ 	memset(login, 0x00, sizeof(struct srp_login_req));
+-	login->type = SRP_LOGIN_REQ_TYPE;
+-	login->max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
+-	login->required_buffer_formats = 0x0006;
++	login->opcode = SRP_LOGIN_REQ;
++	login->req_it_iu_len = sizeof(union srp_iu);
++	login->req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
+ 	
+ 	/* Start out with a request limit of 1, since this is negotiated in
+ 	 * the login request we are just sending
+@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 	
+ 	/* Set up an abort SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x01;	/* ABORT TASK */
+-	tsk_mgmt->managed_task_tag = (u64) found_evt;
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_ABORT_TASK;
++	tsk_mgmt->task_tag = (u64) found_evt;
+ 
+ 	printk(KERN_INFO "ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n",
+-	       tsk_mgmt->lun, tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->lun, tsk_mgmt->task_tag);
+ 
+ 	evt->sync_srp = &srp_rsp;
+ 	init_completion(&evt->comp);
+@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: abort bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+ 	if (rsp_rc) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+-		       "ibmvscsi: abort code %d for task tag 0x%lx\n",
++			       "ibmvscsi: abort code %d for task tag 0x%lx\n",
+ 			       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 		spin_unlock_irqrestore(hostdata->host->host_lock, flags);
+ 		printk(KERN_INFO
+ 		       "ibmvscsi: aborted task tag 0x%lx completed\n",
+-		       tsk_mgmt->managed_task_tag);
++		       tsk_mgmt->task_tag);
+ 		return SUCCESS;
+ 	}
+ 
+ 	printk(KERN_INFO
+ 	       "ibmvscsi: successfully aborted task tag 0x%lx\n",
+-	       tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->task_tag);
+ 
+ 	cmd->result = (DID_ABORT << 16);
+ 	list_del(&found_evt->list);
+@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
+ 
+ 	/* Set up a lun reset SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x08;	/* LUN RESET */
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_LUN_RESET;
+ 
+ 	printk(KERN_INFO "ibmvscsi: resetting device. lun 0x%lx\n",
+ 	       tsk_mgmt->lun);
+@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset code %d for task tag 0x%lx\n",
+-		       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       rsp_rc, tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
+ 	}
+ 
+ 	if (crq->format == VIOSRP_SRP_FORMAT)
+-		atomic_add(evt_struct->xfer_iu->srp.rsp.request_limit_delta,
++		atomic_add(evt_struct->xfer_iu->srp.rsp.req_lim_delta,
+ 			   &hostdata->request_limit);
+ 
+ 	if (evt_struct->done)
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
+index 4550d71..5c6d935 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.h
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
+@@ -68,7 +68,7 @@ struct srp_event_struct {
+ 	void (*cmnd_done) (struct scsi_cmnd *);
+ 	struct completion comp;
+ 	union viosrp_iu *sync_srp;
+-	struct memory_descriptor *ext_list;
++	struct srp_direct_buf *ext_list;
+ 	dma_addr_t ext_list_token;
+ };
+ 
+diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+index f47dd87..58aa530 100644
+--- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
++++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+@@ -34,7 +34,6 @@
+ #include <linux/dma-mapping.h>
+ #include <linux/interrupt.h>
+ #include "ibmvscsi.h"
+-#include "srp.h"
+ 
+ static char partition_name[97] = "UNKNOWN";
+ static unsigned int partition_number = -1;
+diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
+index 6a6bba8..90f1a61 100644
+--- a/drivers/scsi/ibmvscsi/viosrp.h
++++ b/drivers/scsi/ibmvscsi/viosrp.h
+@@ -33,7 +33,22 @@
+ /*****************************************************************************/
+ #ifndef VIOSRP_H
+ #define VIOSRP_H
+-#include "srp.h"
++#include <scsi/srp.h>
++
++#define SRP_VERSION "16.a"
++#define SRP_MAX_IU_LEN	256
++
++union srp_iu {
++	struct srp_login_req login_req;
++	struct srp_login_rsp login_rsp;
++	struct srp_login_rej login_rej;
++	struct srp_i_logout i_logout;
++	struct srp_t_logout t_logout;
++	struct srp_tsk_mgmt tsk_mgmt;
++	struct srp_cmd cmd;
++	struct srp_rsp rsp;
++	u8 reserved[SRP_MAX_IU_LEN];
++};
+ 
+ enum viosrp_crq_formats {
+ 	VIOSRP_SRP_FORMAT = 0x01,
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,246 @@
+Subject: [PATCH] ibmvscsi: remove drivers/scsi/ibmvscsi/srp.h
+From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
+Date: 1143377151 +0900
+
+---
+
+ drivers/scsi/ibmvscsi/srp.h |  227 -------------------------------------------
+ 1 files changed, 0 insertions(+), 227 deletions(-)
+ delete mode 100644 drivers/scsi/ibmvscsi/srp.h
+
+acbd74e89dc7bcf4e2596800e46a19378db44641
+diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
+deleted file mode 100644
+index 7d8e4c4..0000000
+--- a/drivers/scsi/ibmvscsi/srp.h
++++ /dev/null
+@@ -1,227 +0,0 @@
+-/*****************************************************************************/
+-/* srp.h -- SCSI RDMA Protocol definitions                                   */
+-/*                                                                           */
+-/* Written By: Colin Devilbis, IBM Corporation                               */
+-/*                                                                           */
+-/* Copyright (C) 2003 IBM Corporation                                        */
+-/*                                                                           */
+-/* This program is free software; you can redistribute it and/or modify      */
+-/* it under the terms of the GNU General Public License as published by      */
+-/* the Free Software Foundation; either version 2 of the License, or         */
+-/* (at your option) any later version.                                       */
+-/*                                                                           */
+-/* This program is distributed in the hope that it will be useful,           */
+-/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+-/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+-/* GNU General Public License for more details.                              */
+-/*                                                                           */
+-/* You should have received a copy of the GNU General Public License         */
+-/* along with this program; if not, write to the Free Software               */
+-/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+-/*                                                                           */
+-/*                                                                           */
+-/* This file contains structures and definitions for the SCSI RDMA Protocol  */
+-/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
+-/* file was based on the 16a version of the standard                         */
+-/*                                                                           */
+-/*****************************************************************************/
+-#ifndef SRP_H
+-#define SRP_H
+-
+-#define SRP_VERSION "16.a"
+-
+-#define PACKED __attribute__((packed))
+-
+-enum srp_types {
+-	SRP_LOGIN_REQ_TYPE = 0x00,
+-	SRP_LOGIN_RSP_TYPE = 0xC0,
+-	SRP_LOGIN_REJ_TYPE = 0xC2,
+-	SRP_I_LOGOUT_TYPE = 0x03,
+-	SRP_T_LOGOUT_TYPE = 0x80,
+-	SRP_TSK_MGMT_TYPE = 0x01,
+-	SRP_CMD_TYPE = 0x02,
+-	SRP_RSP_TYPE = 0xC1,
+-	SRP_CRED_REQ_TYPE = 0x81,
+-	SRP_CRED_RSP_TYPE = 0x41,
+-	SRP_AER_REQ_TYPE = 0x82,
+-	SRP_AER_RSP_TYPE = 0x42
+-};
+-
+-enum srp_descriptor_formats {
+-	SRP_NO_BUFFER = 0x00,
+-	SRP_DIRECT_BUFFER = 0x01,
+-	SRP_INDIRECT_BUFFER = 0x02
+-};
+-
+-struct memory_descriptor {
+-	u64 virtual_address;
+-	u32 memory_handle;
+-	u32 length;
+-};
+-
+-struct indirect_descriptor {
+-	struct memory_descriptor head;
+-	u32 total_length;
+-	struct memory_descriptor list[1] PACKED;
+-};
+-
+-struct srp_generic {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_login_req {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 max_requested_initiator_to_target_iulen;
+-	u32 reserved2;
+-	u16 required_buffer_formats;
+-	u8 reserved3:6;
+-	u8 multi_channel_action:2;
+-	u8 reserved4;
+-	u32 reserved5;
+-	u8 initiator_port_identifier[16];
+-	u8 target_port_identifier[16];
+-};
+-
+-struct srp_login_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 max_initiator_to_target_iulen;
+-	u32 max_target_to_initiator_iulen;
+-	u16 supported_buffer_formats;
+-	u8 reserved2:6;
+-	u8 multi_channel_result:2;
+-	u8 reserved3;
+-	u8 reserved4[24];
+-};
+-
+-struct srp_login_rej {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-	u64 reserved2;
+-	u16 supported_buffer_formats;
+-	u8 reserved3[6];
+-};
+-
+-struct srp_i_logout {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_t_logout {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-};
+-
+-struct srp_tsk_mgmt {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4;
+-	u8 task_mgmt_flags;
+-	u8 reserved5;
+-	u64 managed_task_tag;
+-	u64 reserved6;
+-};
+-
+-struct srp_cmd {
+-	u8 type;
+-	u32 reserved1 PACKED;
+-	u8 data_out_format:4;
+-	u8 data_in_format:4;
+-	u8 data_out_count;
+-	u8 data_in_count;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4:5;
+-	u8 task_attribute:3;
+-	u8 reserved5;
+-	u8 additional_cdb_len;
+-	u8 cdb[16];
+-	u8 additional_data[0x100 - 0x30];
+-};
+-
+-struct srp_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u16 reserved2;
+-	u8 reserved3:2;
+-	u8 diunder:1;
+-	u8 diover:1;
+-	u8 dounder:1;
+-	u8 doover:1;
+-	u8 snsvalid:1;
+-	u8 rspvalid:1;
+-	u8 status;
+-	u32 data_in_residual_count;
+-	u32 data_out_residual_count;
+-	u32 sense_data_list_length;
+-	u32 response_data_list_length;
+-	u8 sense_and_response_data[18];
+-};
+-
+-struct srp_cred_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-};
+-
+-struct srp_cred_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_aer_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun;
+-	u32 sense_data_list_length;
+-	u32 reserved3;
+-	u8 sense_data[20];
+-};
+-
+-struct srp_aer_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-union srp_iu {
+-	struct srp_generic generic;
+-	struct srp_login_req login_req;
+-	struct srp_login_rsp login_rsp;
+-	struct srp_login_rej login_rej;
+-	struct srp_i_logout i_logout;
+-	struct srp_t_logout t_logout;
+-	struct srp_tsk_mgmt tsk_mgmt;
+-	struct srp_cmd cmd;
+-	struct srp_rsp rsp;
+-	struct srp_cred_req cred_req;
+-	struct srp_cred_rsp cred_rsp;
+-	struct srp_aer_req aer_req;
+-	struct srp_aer_rsp aer_rsp;
+-};
+-
+-#endif
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,461 @@
+Subject: [PATCH] scsi tgt: add task management function support
+
+This patch addes task management function support to tgt. This
+assumes that all the previous patchsets are applied.
+
+- add callback to task management function to scsi_host_template
+structure. It is used notify LLDs of the completion of a TMF request.
+
+- this patch doesn't use a single queue for TMF requests and SCSI
+commands yet. We'll work on it later on.
+
+- when LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command for ABORT_TASK.
+
+- when tgt aborts a command, it calls eh_abort_handler in
+scsi_host_template structure. Would be better to add
+tgt_eh_abort_handler for LLDs support target and initiator modes at
+the same time?
+
+tgt TMF works in the followings:
+
+- When LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command.
+
+- LLDs call 'int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *host, int,
+u64 tag, struct scsi_lun *lun, void *data)'.
+
+- int (* tsk_mgmt_response)(u64 data, int result) is added to
+scsi_host_template.
+
+When an initiator sends a task management request, the LLD calls
+scsi_tgt_tsk_mgmt_request. the LLD can use whatever it wants for the
+data arg. The data arg is used later as the arg in the
+tsk_mgmt_response callback.
+
+tgt core just sends the task management request to user space
+(by using TGT_KEVENT_TSK_MGMT_REQ).
+
+In the case of ABORT_TASK, tgtd finds a single command to abort and
+sends TGT_UEVENT_CMD_RSP and TGT_UEVENT_TSK_MGMT_RSP events.
+
+tgt core calls eh_abort_handler for TGT_UEVENT_CMD_RSP and then
+tsk_mgmt_response for TGT_UEVENT_TSK_MGMT_RSP.
+
+If tgtd fails to find a command to abort, it sends only
+TGT_UEVENT_TSK_MGMT_RSP event (no TGT_UEVENT_CMD_RSP event).
+
+In the case of the rests task management function (like
+ABORT_TASK_SET), tgt needs to abort multiple commands. Thus, tgtd
+finds multiple commands to abort and sends multiple TGT_UEVENT_CMD_RSP
+events and a single TGT_UEVENT_TSK_MGMT_RSP event. tgt core calls
+eh_abort_handler multiple times and tsk_mgmt_response once.
+
+eh_abort_handler enables LLDs to safely free resource related with a
+command to abort.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_if.c   |   43 +++++++++++++++---
+ drivers/scsi/scsi_tgt_lib.c  |  103 +++++++++++++++++++++++++++++-------------
+ drivers/scsi/scsi_tgt_priv.h |   11 +++-
+ include/scsi/scsi_host.h     |    3 +
+ include/scsi/scsi_tgt.h      |    6 ++
+ include/scsi/scsi_tgt_if.h   |    7 ++-
+ 6 files changed, 125 insertions(+), 48 deletions(-)
+
+b9579b62f8d6309815a60da2e6f9a7638df074aa
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index a31c8d5..ba1b75b 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -56,7 +56,8 @@ static int send_event_rsp(uint16_t type,
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+ 
+-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
++int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
++			 gfp_t flags)
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct sk_buff *skb;
+@@ -71,7 +72,7 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
++	skb = alloc_skb(NLMSG_SPACE(len), flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+ 
+@@ -85,9 +86,11 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
+ 	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
+ 	ev->k.cmd_req.attribute = cmd->tag;
++	ev->k.cmd_req.tag = tag;
+ 
+-	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
+-		ev->k.cmd_req.data_len);
++	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
++		ev->k.cmd_req.data_len, cmd->tag,
++		(unsigned long long) ev->k.cmd_req.tag);
+ 
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err < 0)
+@@ -109,6 +112,24 @@ int scsi_tgt_uspace_send_status(struct s
+ 	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
+ }
+ 
++int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++				  struct scsi_lun *scsilun, void *data)
++{
++	struct tgt_event ev;
++
++	memset(&ev, 0, sizeof(ev));
++	ev.k.tsk_mgmt_req.host_no = host_no;
++	ev.k.tsk_mgmt_req.function = function;
++	ev.k.tsk_mgmt_req.tag = tag;
++	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
++	ev.k.tsk_mgmt_req.mid = (u64) data;
++
++	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
++		(unsigned long long) ev.k.tsk_mgmt_req.mid);
++
++	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
++}
++
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+ {
+ 	struct tgt_event *ev = NLMSG_DATA(nlh);
+@@ -130,6 +151,11 @@ static int event_recv_msg(struct sk_buff
+ 					   ev->u.cmd_rsp.uaddr,
+ 					   ev->u.cmd_rsp.rw);
+ 		break;
++	case TGT_UEVENT_TSK_MGMT_RSP:
++		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
++					       ev->u.tsk_mgmt_rsp.mid,
++					       ev->u.tsk_mgmt_rsp.result);
++		break;
+ 	default:
+ 		eprintk("unknown type %d\n", nlh->nlmsg_type);
+ 		err = -EINVAL;
+@@ -143,6 +169,7 @@ static int event_recv_skb(struct sk_buff
+ 	int err;
+ 	uint32_t rlen;
+ 	struct nlmsghdr	*nlh;
++	struct tgt_event ev;
+ 
+ 	while (skb->len >= NLMSG_SPACE(0)) {
+ 		nlh = (struct nlmsghdr *) skb->data;
+@@ -158,9 +185,11 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
+-			struct tgt_event ev;
+-
++		switch (nlh->nlmsg_type) {
++		case TGT_UEVENT_CMD_RSP:
++		case TGT_UEVENT_TSK_MGMT_RSP:
++			break;
++		default:
+ 			memset(&ev, 0, sizeof(ev));
+ 			ev.k.event_rsp.err = err;
+ 			send_event_rsp(TGT_KEVENT_RSP, &ev,
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 2cbc749..5a98fc4 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -49,6 +49,7 @@ struct scsi_tgt_cmd {
+ 
+ 	struct list_head hash_list;
+ 	struct request *rq;
++	u64 tag;
+ };
+ 
+ #define TGT_HASH_ORDER	4
+@@ -106,7 +107,6 @@ static void scsi_tgt_cmd_destroy(void *d
+ 		cmd->request->flags &= ~1UL;
+ 
+ 	scsi_unmap_user_pages(tcmd);
+-	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
+ 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
+ }
+@@ -118,19 +118,11 @@ static void init_scsi_tgt_cmd(struct req
+ 	struct list_head *head;
+ 	static u32 tag = 0;
+ 
+-	tcmd->lun = rq->end_io_data;
+-	bio_list_init(&tcmd->xfer_list);
+-	bio_list_init(&tcmd->xfer_done_list);
+-
+ 	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
+ 	rq->tag = tag++;
+ 	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
+ 	list_add(&tcmd->hash_list, head);
+ 	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
+-
+-	tcmd->rq = rq;
+-	rq->end_io_data = tcmd;
+-	rq->flags |= REQ_DONTPREP;
+ }
+ 
+ static void scsi_tgt_uspace_send_fn(void *data)
+@@ -148,33 +140,22 @@ retry:
+ 	if (list_empty(&qdata->cmd_req))
+ 		return;
+ 
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd) {
+-		err = -ENOMEM;
+-		goto out;
+-	}
+-
+ 	mutex_lock(&qdata->cmd_req_mutex);
+ 
+ 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
+ 	if (list_empty(&qdata->cmd_req)) {
+ 		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 		mutex_unlock(&qdata->cmd_req_mutex);
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 		goto out;
+ 	}
+ 	rq = list_entry_rq(qdata->cmd_req.next);
+ 	list_del_init(&rq->queuelist);
+ 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 
+-	if ((rq->flags & REQ_DONTPREP)) {
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+-		tcmd = rq->end_io_data;
+-	} else
+-		init_scsi_tgt_cmd(rq, tcmd);
+-
++	tcmd = rq->end_io_data;
++	init_scsi_tgt_cmd(rq, tcmd);
+ 	cmd = rq->special;
+-	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
++	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
+ 	if (err < 0) {
+ 		eprintk("failed to send: %p %d\n", cmd, err);
+ 
+@@ -266,20 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+  * @scsilun:	scsi lun
+  * @noblock:	set to nonzero if the command should be queued
+  **/
+-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+-			    int noblock)
++int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
++			   u64 tag)
+ {
+ 	struct request_queue *q = cmd->request->q;
+ 	struct scsi_tgt_queuedata *qdata = q->queuedata;
+ 	unsigned long flags;
++	struct scsi_tgt_cmd *tcmd;
++
++	/*
++	 * It would be better to allocate scsi_tgt_cmd structure in
++	 * scsi_host_get_command and not to fail due to OOM.
++	 */
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd)
++		return -ENOMEM;
++	cmd->request->end_io_data = tcmd;
+ 
+-	cmd->request->end_io_data = scsilun;
++	bio_list_init(&tcmd->xfer_list);
++	bio_list_init(&tcmd->xfer_done_list);
++	tcmd->lun = scsilun;
++	tcmd->tag = tag;
++	tcmd->rq = cmd->request;
+ 
+ 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
+ 	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
+ 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 
+ 	queue_work(scsi_tgtd, &qdata->uspace_send_work);
++	return 0;
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -293,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
+ 
+ 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
+ 
+-	/* don't we have to call this if result is set or not */
+-	if (cmd->result) {
+-		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+-		return;
+-	}
+-
++	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+ 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
+ 	queue_work(scsi_tgtd, &tcmd->work);
+ }
+@@ -495,6 +486,18 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
++static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
++{
++	int err;
++
++	err = host->hostt->eh_abort_handler(cmd);
++	if (err)
++		eprintk("fail to abort %p\n", cmd);
++
++	scsi_tgt_cmd_destroy(cmd);
++	return err;
++}
++
+ static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
+ {
+ 	struct scsi_tgt_queuedata *qdata = q->queuedata;
+@@ -545,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
+ 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
+ 
++	if (result == TASK_ABORTED) {
++		scsi_tgt_abort_cmd(shost, cmd);
++		goto done;
++	}
+ 	/*
+ 	 * store the userspace values here, the working values are
+ 	 * in the request_* values
+@@ -585,6 +592,38 @@ done:
+ 	return err;
+ }
+ 
++int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
++			      struct scsi_lun *scsilun, void *data)
++{
++	int err;
++
++	/* TODO: need to retry if this fails. */
++	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
++					    tag, scsilun, data);
++	if (err < 0)
++		eprintk("The task management request lost!\n");
++	return err;
++}
++EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
++
++int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
++{
++	struct Scsi_Host *shost;
++	int err;
++
++	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
++
++	shost = scsi_host_lookup(host_no);
++	if (IS_ERR(shost)) {
++		printk(KERN_ERR "Could not find host no %d\n", host_no);
++		return -EINVAL;
++	}
++	err = shost->hostt->tsk_mgmt_response(mid, result);
++	scsi_host_put(shost);
++
++	return err;
++}
++
+ static int __init scsi_tgt_init(void)
+ {
+ 	int err;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 6fedcec..77a1d06 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -4,18 +4,21 @@ struct Scsi_Host;
+ struct task_struct;
+ 
+ /* tmp - will replace with SCSI logging stuff */
+-#define dprintk(fmt, args...)					\
++#define eprintk(fmt, args...)					\
+ do {								\
+ 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
+ } while (0)
+ 
+-#define eprintk dprintk
++#define dprintk eprintk
+ 
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
++extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
++				u64 tag, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+ 				unsigned long uaddr, u8 rw);
+-
++extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++					 struct scsi_lun *scsilun, void *data);
++extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
+diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
+index 8b799db..eca5721 100644
+--- a/include/scsi/scsi_host.h
++++ b/include/scsi/scsi_host.h
+@@ -153,6 +153,9 @@ struct scsi_host_template {
+ 	int (* transfer_data)(struct scsi_cmnd *,
+ 			      void (*done)(struct scsi_cmnd *));
+ 
++	/* Used as callback for the completion of task management request. */
++	int (* tsk_mgmt_response)(u64 mid, int result);
++
+ 	/*
+ 	 * This is an error handling strategy routine.  You don't need to
+ 	 * define one of these if you don't want to - there is a default
+diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
+index 91ad6bc..2d65be7 100644
+--- a/include/scsi/scsi_tgt.h
++++ b/include/scsi/scsi_tgt.h
+@@ -6,6 +6,8 @@ struct Scsi_Host;
+ struct scsi_cmnd;
+ struct scsi_lun;
+ 
+-extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
++extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
+ extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
+-extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
++extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
++extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
++				     void *);
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index ebca452..63b2e3a 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -52,7 +52,7 @@ struct tgt_event {
+ 		} cmd_rsp;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			uint64_t mid;
+ 			int result;
+ 		} tsk_mgmt_rsp;
+ 	} u;
+@@ -69,6 +69,7 @@ struct tgt_event {
+ 			uint8_t scb[16];
+ 			uint8_t lun[8];
+ 			int attribute;
++			uint64_t tag;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+@@ -77,10 +78,10 @@ struct tgt_event {
+ 		} cmd_done;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			int function;
+ 			uint64_t tag;
+ 			uint8_t lun[8];
+-			int function;
++			uint64_t mid;
+ 		} tsk_mgmt_req;
+ 	} k;
+ 
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
===================================================================
--- branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -0,0 +1,1767 @@
+diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
+index 13c40a0..e9d3388 100644
+--- a/block/ll_rw_blk.c
++++ b/block/ll_rw_blk.c
+@@ -2287,23 +2287,24 @@ int blk_rq_map_user(request_queue_t *q, 
+ 	 */
+ 	uaddr = (unsigned long) ubuf;
+ 	if (!(uaddr & queue_dma_alignment(q)) && !(len & queue_dma_alignment(q)))
+-		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
++		bio = bio_map_user(q, NULL, uaddr, len, reading);
+ 	else
+ 		bio = bio_copy_user(q, uaddr, len, reading);
+ 
+-	if (!IS_ERR(bio)) {
+-		rq->bio = rq->biotail = bio;
+-		blk_rq_bio_prep(q, rq, bio);
++	if (IS_ERR(bio))
++		return PTR_ERR(bio);
+ 
+-		rq->buffer = rq->data = NULL;
+-		rq->data_len = len;
+-		return 0;
++	if (bio->bi_size != len) {
++		bio_endio(bio, bio->bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
+ 	}
+ 
+-	/*
+-	 * bio is the err-ptr
+-	 */
+-	return PTR_ERR(bio);
++	rq->bio = rq->biotail = bio;
++	blk_rq_bio_prep(q, rq, bio);
++	rq->buffer = rq->data = NULL;
++	rq->data_len = len;
++	return 0;
+ }
+ 
+ EXPORT_SYMBOL(blk_rq_map_user);
+@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
+  *    unmapping.
+  */
+ int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
+-			struct sg_iovec *iov, int iov_count)
++			struct sg_iovec *iov, int iov_count, unsigned int len)
+ {
+ 	struct bio *bio;
+ 
+@@ -2339,11 +2340,16 @@ int blk_rq_map_user_iov(request_queue_t 
+ 	/* we don't allow misaligned data like bio_map_user() does.  If the
+ 	 * user is using sg, they're expected to know the alignment constraints
+ 	 * and respect them accordingly */
+-	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
+-				0);
++	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
+ 	if (IS_ERR(bio))
+ 		return PTR_ERR(bio);
+ 
++	if (bio->bi_size != len) {
++		bio_endio(bio, bio->bi_size, 0);
++		bio_unmap_user(bio);
++		return -EINVAL;
++	}
++
+ 	rq->bio = rq->biotail = bio;
+ 	blk_rq_bio_prep(q, rq, bio);
+ 	rq->buffer = rq->data = NULL;
+@@ -2765,16 +2771,12 @@ static void init_request_from_bio(struct
+ 
+ 	req->errors = 0;
+ 	req->hard_sector = req->sector = bio->bi_sector;
+-	req->hard_nr_sectors = req->nr_sectors = bio_sectors(bio);
+-	req->current_nr_sectors = req->hard_cur_sectors = bio_cur_sectors(bio);
+-	req->nr_phys_segments = bio_phys_segments(req->q, bio);
+-	req->nr_hw_segments = bio_hw_segments(req->q, bio);
+-	req->buffer = bio_data(bio);	/* see ->buffer comment above */
+ 	req->waiting = NULL;
+-	req->bio = req->biotail = bio;
+ 	req->ioprio = bio_prio(bio);
+ 	req->rq_disk = bio->bi_bdev->bd_disk;
+ 	req->start_time = jiffies;
++
++	blk_rq_bio_prep(req->q, req, bio);
+ }
+ 
+ static int __make_request(request_queue_t *q, struct bio *bio)
+@@ -3403,9 +3405,6 @@ EXPORT_SYMBOL(end_request);
+ 
+ void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
+ {
+-	/* first three bits are identical in rq->flags and bio->bi_rw */
+-	rq->flags |= (bio->bi_rw & 7);
+-
+ 	rq->nr_phys_segments = bio_phys_segments(q, bio);
+ 	rq->nr_hw_segments = bio_hw_segments(q, bio);
+ 	rq->current_nr_sectors = bio_cur_sectors(bio);
+diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
+index 24f7af9..ef9900d 100644
+--- a/block/scsi_ioctl.c
++++ b/block/scsi_ioctl.c
+@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
+ 			goto out;
+ 		}
+ 
+-		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
++		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
++					  hdr->dxfer_len);
+ 		kfree(iov);
+ 	} else if (hdr->dxfer_len)
+ 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
+index eaefedd..e7bd028 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.c
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
+@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
+ 			++in_use;
+ 		if (pool->events[i].ext_list) {
+ 			dma_free_coherent(hostdata->dev,
+-				  SG_ALL * sizeof(struct memory_descriptor),
++				  SG_ALL * sizeof(struct srp_direct_buf),
+ 				  pool->events[i].ext_list,
+ 				  pool->events[i].ext_list_token);
+ 		}
+@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
+ 			      struct srp_cmd *srp_cmd, 
+ 			      int numbuf)
+ {
++	u8 fmt;
++
+ 	if (numbuf == 0)
+ 		return;
+ 	
+-	if (numbuf == 1) {
++	if (numbuf == 1)
++		fmt = SRP_DATA_DESC_DIRECT;
++	else {
++		fmt = SRP_DATA_DESC_INDIRECT;
++		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
++
+ 		if (cmd->sc_data_direction == DMA_TO_DEVICE)
+-			srp_cmd->data_out_format = SRP_DIRECT_BUFFER;
+-		else 
+-			srp_cmd->data_in_format = SRP_DIRECT_BUFFER;
+-	} else {
+-		if (cmd->sc_data_direction == DMA_TO_DEVICE) {
+-			srp_cmd->data_out_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_out_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		} else {
+-			srp_cmd->data_in_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_in_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		}
++			srp_cmd->data_out_desc_cnt = numbuf;
++		else
++			srp_cmd->data_in_desc_cnt = numbuf;
+ 	}
++
++	if (cmd->sc_data_direction == DMA_TO_DEVICE)
++		srp_cmd->buf_fmt = fmt << 4;
++	else
++		srp_cmd->buf_fmt = fmt;
+ }
+ 
+-static void unmap_sg_list(int num_entries, 
++static void unmap_sg_list(int num_entries,
+ 		struct device *dev,
+-		struct memory_descriptor *md)
+-{ 
++		struct srp_direct_buf *md)
++{
+ 	int i;
+ 
+-	for (i = 0; i < num_entries; ++i) {
+-		dma_unmap_single(dev,
+-			md[i].virtual_address,
+-			md[i].length, DMA_BIDIRECTIONAL);
+-	}
++	for (i = 0; i < num_entries; ++i)
++		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
+ }
+ 
+ /**
+@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
+ 			   struct srp_event_struct *evt_struct,
+ 			   struct device *dev)
+ {
+-	if ((cmd->data_out_format == SRP_NO_BUFFER) &&
+-	    (cmd->data_in_format == SRP_NO_BUFFER))
++	u8 out_fmt, in_fmt;
++
++	out_fmt = cmd->buf_fmt >> 4;
++	in_fmt = cmd->buf_fmt & ((1U << 4) - 1);
++
++	if (out_fmt == SRP_NO_DATA_DESC && in_fmt == SRP_NO_DATA_DESC)
+ 		return;
+-	else if ((cmd->data_out_format == SRP_DIRECT_BUFFER) ||
+-		 (cmd->data_in_format == SRP_DIRECT_BUFFER)) {
+-		struct memory_descriptor *data =
+-			(struct memory_descriptor *)cmd->additional_data;
+-		dma_unmap_single(dev, data->virtual_address, data->length,
+-				 DMA_BIDIRECTIONAL);
++	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
++		 in_fmt == SRP_DATA_DESC_DIRECT) {
++		struct srp_direct_buf *data =
++			(struct srp_direct_buf *) cmd->add_data;
++		dma_unmap_single(dev, data->va, data->len, DMA_BIDIRECTIONAL);
+ 	} else {
+-		struct indirect_descriptor *indirect =
+-			(struct indirect_descriptor *)cmd->additional_data;
+-		int num_mapped = indirect->head.length / 
+-			sizeof(indirect->list[0]);
++		struct srp_indirect_buf *indirect =
++			(struct srp_indirect_buf *) cmd->add_data;
++		int num_mapped = indirect->table_desc.len /
++			sizeof(struct srp_direct_buf);
+ 
+ 		if (num_mapped <= MAX_INDIRECT_BUFS) {
+-			unmap_sg_list(num_mapped, dev, &indirect->list[0]);
++			unmap_sg_list(num_mapped, dev, &indirect->desc_list[0]);
+ 			return;
+ 		}
+ 
+@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
+ 
+ static int map_sg_list(int num_entries, 
+ 		       struct scatterlist *sg,
+-		       struct memory_descriptor *md)
++		       struct srp_direct_buf *md)
+ {
+ 	int i;
+ 	u64 total_length = 0;
+ 
+ 	for (i = 0; i < num_entries; ++i) {
+-		struct memory_descriptor *descr = md + i;
++		struct srp_direct_buf *descr = md + i;
+ 		struct scatterlist *sg_entry = &sg[i];
+-		descr->virtual_address = sg_dma_address(sg_entry);
+-		descr->length = sg_dma_len(sg_entry);
+-		descr->memory_handle = 0;
++		descr->va = sg_dma_address(sg_entry);
++		descr->len = sg_dma_len(sg_entry);
++		descr->key = 0;
+ 		total_length += sg_dma_len(sg_entry);
+  	}
+ 	return total_length;
+@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
+ 	int sg_mapped;
+ 	u64 total_length = 0;
+ 	struct scatterlist *sg = cmd->request_buffer;
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
+-	struct indirect_descriptor *indirect =
+-	    (struct indirect_descriptor *)data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
++	struct srp_indirect_buf *indirect =
++		(struct srp_indirect_buf *) data;
+ 
+ 	sg_mapped = dma_map_sg(dev, sg, cmd->use_sg, DMA_BIDIRECTIONAL);
+ 
+@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	/* special case; we can use a single direct descriptor */
+ 	if (sg_mapped == 1) {
+-		data->virtual_address = sg_dma_address(&sg[0]);
+-		data->length = sg_dma_len(&sg[0]);
+-		data->memory_handle = 0;
++		data->va = sg_dma_address(&sg[0]);
++		data->len = sg_dma_len(&sg[0]);
++		data->key = 0;
+ 		return 1;
+ 	}
+ 
+@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
+ 		return 0;
+ 	}
+ 
+-	indirect->head.virtual_address = 0;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	indirect->head.memory_handle = 0;
++	indirect->table_desc.va = 0;
++	indirect->table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
++	indirect->table_desc.key = 0;
+ 
+ 	if (sg_mapped <= MAX_INDIRECT_BUFS) {
+-		total_length = map_sg_list(sg_mapped, sg, &indirect->list[0]);
+-		indirect->total_length = total_length;
++		total_length = map_sg_list(sg_mapped, sg,
++					   &indirect->desc_list[0]);
++		indirect->len = total_length;
+ 		return 1;
+ 	}
+ 
+ 	/* get indirect table */
+ 	if (!evt_struct->ext_list) {
+-		evt_struct->ext_list =(struct memory_descriptor*)
++		evt_struct->ext_list = (struct srp_direct_buf *)
+ 			dma_alloc_coherent(dev, 
+-				SG_ALL * sizeof(struct memory_descriptor),
+-				&evt_struct->ext_list_token, 0);
++					   SG_ALL * sizeof(struct srp_direct_buf),
++					   &evt_struct->ext_list_token, 0);
+ 		if (!evt_struct->ext_list) {
+-		    printk(KERN_ERR
+-		   	"ibmvscsi: Can't allocate memory for indirect table\n");
++			printk(KERN_ERR
++			       "ibmvscsi: Can't allocate memory for indirect table\n");
+ 			return 0;
+ 			
+ 		}
+@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	total_length = map_sg_list(sg_mapped, sg, evt_struct->ext_list);	
+ 
+-	indirect->total_length = total_length;
+-	indirect->head.virtual_address = evt_struct->ext_list_token;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	memcpy(indirect->list, evt_struct->ext_list,
+-		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
++	indirect->len = total_length;
++	indirect->table_desc.va = evt_struct->ext_list_token;
++	indirect->table_desc.len = sg_mapped * sizeof(indirect->desc_list[0]);
++	memcpy(indirect->desc_list, evt_struct->ext_list,
++	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
+ 	
+  	return 1;
+ }
+@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
+ static int map_single_data(struct scsi_cmnd *cmd,
+ 			   struct srp_cmd *srp_cmd, struct device *dev)
+ {
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
+ 
+-	data->virtual_address =
++	data->va =
+ 		dma_map_single(dev, cmd->request_buffer,
+ 			       cmd->request_bufflen,
+ 			       DMA_BIDIRECTIONAL);
+-	if (dma_mapping_error(data->virtual_address)) {
++	if (dma_mapping_error(data->va)) {
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Unable to map request_buffer for command!\n");
+ 		return 0;
+ 	}
+-	data->length = cmd->request_bufflen;
+-	data->memory_handle = 0;
++	data->len = cmd->request_bufflen;
++	data->key = 0;
+ 
+ 	set_srp_direction(cmd, srp_cmd, 1);
+ 
+@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
+ 
+ 	/* Copy the IU into the transfer area */
+ 	*evt_struct->xfer_iu = evt_struct->iu;
+-	evt_struct->xfer_iu->srp.generic.tag = (u64)evt_struct;
++	evt_struct->xfer_iu->srp.rsp.tag = (u64)evt_struct;
+ 
+ 	/* Add this to the sent list.  We need to do this 
+ 	 * before we actually send 
+@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
+ 	struct srp_rsp *rsp = &evt_struct->xfer_iu->srp.rsp;
+ 	struct scsi_cmnd *cmnd = evt_struct->cmnd;
+ 
+-	if (unlikely(rsp->type != SRP_RSP_TYPE)) {
++	if (unlikely(rsp->opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: bad SRP RSP type %d\n",
+-			       rsp->type);
++			       rsp->opcode);
+ 	}
+ 	
+ 	if (cmnd) {
+ 		cmnd->result = rsp->status;
+ 		if (((cmnd->result >> 1) & 0x1f) == CHECK_CONDITION)
+ 			memcpy(cmnd->sense_buffer,
+-			       rsp->sense_and_response_data,
+-			       rsp->sense_data_list_length);
++			       rsp->data,
++			       rsp->sense_data_len);
+ 		unmap_cmd_data(&evt_struct->iu.srp.cmd, 
+ 			       evt_struct, 
+ 			       evt_struct->hostdata->dev);
+ 
+-		if (rsp->doover)
+-			cmnd->resid = rsp->data_out_residual_count;
+-		else if (rsp->diover)
+-			cmnd->resid = rsp->data_in_residual_count;
++		if (rsp->flags & SRP_RSP_FLAG_DOOVER)
++			cmnd->resid = rsp->data_out_res_cnt;
++		else if (rsp->flags & SRP_RSP_FLAG_DIOVER)
++			cmnd->resid = rsp->data_in_res_cnt;
+ 	}
+ 
+ 	if (evt_struct->cmnd_done)
+@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
+ {
+ 	struct srp_cmd *srp_cmd;
+ 	struct srp_event_struct *evt_struct;
+-	struct indirect_descriptor *indirect;
++	struct srp_indirect_buf *indirect;
+ 	struct ibmvscsi_host_data *hostdata =
+ 		(struct ibmvscsi_host_data *)&cmnd->device->host->hostdata;
+ 	u16 lun = lun_from_dev(cmnd->device);
++	u8 out_fmt, in_fmt;
+ 
+ 	evt_struct = get_event_struct(&hostdata->pool);
+ 	if (!evt_struct)
+@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
+ 
+ 	/* Set up the actual SRP IU */
+ 	srp_cmd = &evt_struct->iu.srp.cmd;
+-	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
+-	srp_cmd->type = SRP_CMD_TYPE;
++	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
++	srp_cmd->opcode = SRP_CMD;
+ 	memcpy(srp_cmd->cdb, cmnd->cmnd, sizeof(cmnd->cmnd));
+ 	srp_cmd->lun = ((u64) lun) << 48;
+ 
+@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
+ 	evt_struct->cmnd_done = done;
+ 
+ 	/* Fix up dma address of the buffer itself */
+-	indirect = (struct indirect_descriptor *)srp_cmd->additional_data;
+-	if (((srp_cmd->data_out_format == SRP_INDIRECT_BUFFER) ||
+-	    (srp_cmd->data_in_format == SRP_INDIRECT_BUFFER)) &&
+-	    (indirect->head.virtual_address == 0)) {
+-		indirect->head.virtual_address = evt_struct->crq.IU_data_ptr +
+-		    offsetof(struct srp_cmd, additional_data) +
+-		    offsetof(struct indirect_descriptor, list);
++	indirect = (struct srp_indirect_buf *) srp_cmd->add_data;
++	out_fmt = srp_cmd->buf_fmt >> 4;
++	in_fmt = srp_cmd->buf_fmt & ((1U << 4) - 1);
++	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
++	     out_fmt == SRP_DATA_DESC_INDIRECT) &&
++	    indirect->table_desc.va == 0) {
++		indirect->table_desc.va = evt_struct->crq.IU_data_ptr +
++			offsetof(struct srp_cmd, add_data) +
++			offsetof(struct srp_indirect_buf, desc_list);
+ 	}
+ 
+ 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
+@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
+ static void login_rsp(struct srp_event_struct *evt_struct)
+ {
+ 	struct ibmvscsi_host_data *hostdata = evt_struct->hostdata;
+-	switch (evt_struct->xfer_iu->srp.generic.type) {
+-	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
++	switch (evt_struct->xfer_iu->srp.login_rsp.opcode) {
++	case SRP_LOGIN_RSP:	/* it worked! */
+ 		break;
+-	case SRP_LOGIN_REJ_TYPE:	/* refused! */
++	case SRP_LOGIN_REJ:	/* refused! */
+ 		printk(KERN_INFO "ibmvscsi: SRP_LOGIN_REJ reason %u\n",
+ 		       evt_struct->xfer_iu->srp.login_rej.reason);
+ 		/* Login failed.  */
+@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
+ 	default:
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Invalid login response typecode 0x%02x!\n",
+-		       evt_struct->xfer_iu->srp.generic.type);
++		       evt_struct->xfer_iu->srp.login_rsp.opcode);
+ 		/* Login failed.  */
+ 		atomic_set(&hostdata->request_limit, -1);
+ 		return;
+@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
+ 
+ 	printk(KERN_INFO "ibmvscsi: SRP_LOGIN succeeded\n");
+ 
+-	if (evt_struct->xfer_iu->srp.login_rsp.request_limit_delta >
++	if (evt_struct->xfer_iu->srp.login_rsp.req_lim_delta >
+ 	    (max_requests - 2))
+-		evt_struct->xfer_iu->srp.login_rsp.request_limit_delta =
++		evt_struct->xfer_iu->srp.login_rsp.req_lim_delta =
+ 		    max_requests - 2;
+ 
+ 	/* Now we know what the real request-limit is */
+ 	atomic_set(&hostdata->request_limit,
+-		   evt_struct->xfer_iu->srp.login_rsp.request_limit_delta);
++		   evt_struct->xfer_iu->srp.login_rsp.req_lim_delta);
+ 
+ 	hostdata->host->can_queue =
+-	    evt_struct->xfer_iu->srp.login_rsp.request_limit_delta - 2;
++	    evt_struct->xfer_iu->srp.login_rsp.req_lim_delta - 2;
+ 
+ 	if (hostdata->host->can_queue < 1) {
+ 		printk(KERN_ERR "ibmvscsi: Invalid request_limit_delta\n");
+@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
+ 
+ 	login = &evt_struct->iu.srp.login_req;
+ 	memset(login, 0x00, sizeof(struct srp_login_req));
+-	login->type = SRP_LOGIN_REQ_TYPE;
+-	login->max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
+-	login->required_buffer_formats = 0x0006;
++	login->opcode = SRP_LOGIN_REQ;
++	login->req_it_iu_len = sizeof(union srp_iu);
++	login->req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
+ 	
+ 	/* Start out with a request limit of 1, since this is negotiated in
+ 	 * the login request we are just sending
+@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 	
+ 	/* Set up an abort SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x01;	/* ABORT TASK */
+-	tsk_mgmt->managed_task_tag = (u64) found_evt;
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_ABORT_TASK;
++	tsk_mgmt->task_tag = (u64) found_evt;
+ 
+ 	printk(KERN_INFO "ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n",
+-	       tsk_mgmt->lun, tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->lun, tsk_mgmt->task_tag);
+ 
+ 	evt->sync_srp = &srp_rsp;
+ 	init_completion(&evt->comp);
+@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: abort bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+ 	if (rsp_rc) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+-		       "ibmvscsi: abort code %d for task tag 0x%lx\n",
++			       "ibmvscsi: abort code %d for task tag 0x%lx\n",
+ 			       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 		spin_unlock_irqrestore(hostdata->host->host_lock, flags);
+ 		printk(KERN_INFO
+ 		       "ibmvscsi: aborted task tag 0x%lx completed\n",
+-		       tsk_mgmt->managed_task_tag);
++		       tsk_mgmt->task_tag);
+ 		return SUCCESS;
+ 	}
+ 
+ 	printk(KERN_INFO
+ 	       "ibmvscsi: successfully aborted task tag 0x%lx\n",
+-	       tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->task_tag);
+ 
+ 	cmd->result = (DID_ABORT << 16);
+ 	list_del(&found_evt->list);
+@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
+ 
+ 	/* Set up a lun reset SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x08;	/* LUN RESET */
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_LUN_RESET;
+ 
+ 	printk(KERN_INFO "ibmvscsi: resetting device. lun 0x%lx\n",
+ 	       tsk_mgmt->lun);
+@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset code %d for task tag 0x%lx\n",
+-		       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       rsp_rc, tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
+ 	}
+ 
+ 	if (crq->format == VIOSRP_SRP_FORMAT)
+-		atomic_add(evt_struct->xfer_iu->srp.rsp.request_limit_delta,
++		atomic_add(evt_struct->xfer_iu->srp.rsp.req_lim_delta,
+ 			   &hostdata->request_limit);
+ 
+ 	if (evt_struct->done)
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
+index 4550d71..5c6d935 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.h
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
+@@ -68,7 +68,7 @@ struct srp_event_struct {
+ 	void (*cmnd_done) (struct scsi_cmnd *);
+ 	struct completion comp;
+ 	union viosrp_iu *sync_srp;
+-	struct memory_descriptor *ext_list;
++	struct srp_direct_buf *ext_list;
+ 	dma_addr_t ext_list_token;
+ };
+ 
+diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+index f47dd87..58aa530 100644
+--- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
++++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+@@ -34,7 +34,6 @@
+ #include <linux/dma-mapping.h>
+ #include <linux/interrupt.h>
+ #include "ibmvscsi.h"
+-#include "srp.h"
+ 
+ static char partition_name[97] = "UNKNOWN";
+ static unsigned int partition_number = -1;
+diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
+deleted file mode 100644
+index 7d8e4c4..0000000
+--- a/drivers/scsi/ibmvscsi/srp.h
++++ /dev/null
+@@ -1,227 +0,0 @@
+-/*****************************************************************************/
+-/* srp.h -- SCSI RDMA Protocol definitions                                   */
+-/*                                                                           */
+-/* Written By: Colin Devilbis, IBM Corporation                               */
+-/*                                                                           */
+-/* Copyright (C) 2003 IBM Corporation                                        */
+-/*                                                                           */
+-/* This program is free software; you can redistribute it and/or modify      */
+-/* it under the terms of the GNU General Public License as published by      */
+-/* the Free Software Foundation; either version 2 of the License, or         */
+-/* (at your option) any later version.                                       */
+-/*                                                                           */
+-/* This program is distributed in the hope that it will be useful,           */
+-/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+-/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+-/* GNU General Public License for more details.                              */
+-/*                                                                           */
+-/* You should have received a copy of the GNU General Public License         */
+-/* along with this program; if not, write to the Free Software               */
+-/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+-/*                                                                           */
+-/*                                                                           */
+-/* This file contains structures and definitions for the SCSI RDMA Protocol  */
+-/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
+-/* file was based on the 16a version of the standard                         */
+-/*                                                                           */
+-/*****************************************************************************/
+-#ifndef SRP_H
+-#define SRP_H
+-
+-#define SRP_VERSION "16.a"
+-
+-#define PACKED __attribute__((packed))
+-
+-enum srp_types {
+-	SRP_LOGIN_REQ_TYPE = 0x00,
+-	SRP_LOGIN_RSP_TYPE = 0xC0,
+-	SRP_LOGIN_REJ_TYPE = 0xC2,
+-	SRP_I_LOGOUT_TYPE = 0x03,
+-	SRP_T_LOGOUT_TYPE = 0x80,
+-	SRP_TSK_MGMT_TYPE = 0x01,
+-	SRP_CMD_TYPE = 0x02,
+-	SRP_RSP_TYPE = 0xC1,
+-	SRP_CRED_REQ_TYPE = 0x81,
+-	SRP_CRED_RSP_TYPE = 0x41,
+-	SRP_AER_REQ_TYPE = 0x82,
+-	SRP_AER_RSP_TYPE = 0x42
+-};
+-
+-enum srp_descriptor_formats {
+-	SRP_NO_BUFFER = 0x00,
+-	SRP_DIRECT_BUFFER = 0x01,
+-	SRP_INDIRECT_BUFFER = 0x02
+-};
+-
+-struct memory_descriptor {
+-	u64 virtual_address;
+-	u32 memory_handle;
+-	u32 length;
+-};
+-
+-struct indirect_descriptor {
+-	struct memory_descriptor head;
+-	u32 total_length;
+-	struct memory_descriptor list[1] PACKED;
+-};
+-
+-struct srp_generic {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_login_req {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 max_requested_initiator_to_target_iulen;
+-	u32 reserved2;
+-	u16 required_buffer_formats;
+-	u8 reserved3:6;
+-	u8 multi_channel_action:2;
+-	u8 reserved4;
+-	u32 reserved5;
+-	u8 initiator_port_identifier[16];
+-	u8 target_port_identifier[16];
+-};
+-
+-struct srp_login_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 max_initiator_to_target_iulen;
+-	u32 max_target_to_initiator_iulen;
+-	u16 supported_buffer_formats;
+-	u8 reserved2:6;
+-	u8 multi_channel_result:2;
+-	u8 reserved3;
+-	u8 reserved4[24];
+-};
+-
+-struct srp_login_rej {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-	u64 reserved2;
+-	u16 supported_buffer_formats;
+-	u8 reserved3[6];
+-};
+-
+-struct srp_i_logout {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_t_logout {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-};
+-
+-struct srp_tsk_mgmt {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4;
+-	u8 task_mgmt_flags;
+-	u8 reserved5;
+-	u64 managed_task_tag;
+-	u64 reserved6;
+-};
+-
+-struct srp_cmd {
+-	u8 type;
+-	u32 reserved1 PACKED;
+-	u8 data_out_format:4;
+-	u8 data_in_format:4;
+-	u8 data_out_count;
+-	u8 data_in_count;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4:5;
+-	u8 task_attribute:3;
+-	u8 reserved5;
+-	u8 additional_cdb_len;
+-	u8 cdb[16];
+-	u8 additional_data[0x100 - 0x30];
+-};
+-
+-struct srp_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u16 reserved2;
+-	u8 reserved3:2;
+-	u8 diunder:1;
+-	u8 diover:1;
+-	u8 dounder:1;
+-	u8 doover:1;
+-	u8 snsvalid:1;
+-	u8 rspvalid:1;
+-	u8 status;
+-	u32 data_in_residual_count;
+-	u32 data_out_residual_count;
+-	u32 sense_data_list_length;
+-	u32 response_data_list_length;
+-	u8 sense_and_response_data[18];
+-};
+-
+-struct srp_cred_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-};
+-
+-struct srp_cred_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_aer_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun;
+-	u32 sense_data_list_length;
+-	u32 reserved3;
+-	u8 sense_data[20];
+-};
+-
+-struct srp_aer_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-union srp_iu {
+-	struct srp_generic generic;
+-	struct srp_login_req login_req;
+-	struct srp_login_rsp login_rsp;
+-	struct srp_login_rej login_rej;
+-	struct srp_i_logout i_logout;
+-	struct srp_t_logout t_logout;
+-	struct srp_tsk_mgmt tsk_mgmt;
+-	struct srp_cmd cmd;
+-	struct srp_rsp rsp;
+-	struct srp_cred_req cred_req;
+-	struct srp_cred_rsp cred_rsp;
+-	struct srp_aer_req aer_req;
+-	struct srp_aer_rsp aer_rsp;
+-};
+-
+-#endif
+diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
+index 6a6bba8..90f1a61 100644
+--- a/drivers/scsi/ibmvscsi/viosrp.h
++++ b/drivers/scsi/ibmvscsi/viosrp.h
+@@ -33,7 +33,22 @@
+ /*****************************************************************************/
+ #ifndef VIOSRP_H
+ #define VIOSRP_H
+-#include "srp.h"
++#include <scsi/srp.h>
++
++#define SRP_VERSION "16.a"
++#define SRP_MAX_IU_LEN	256
++
++union srp_iu {
++	struct srp_login_req login_req;
++	struct srp_login_rsp login_rsp;
++	struct srp_login_rej login_rej;
++	struct srp_i_logout i_logout;
++	struct srp_t_logout t_logout;
++	struct srp_tsk_mgmt tsk_mgmt;
++	struct srp_cmd cmd;
++	struct srp_rsp rsp;
++	u8 reserved[SRP_MAX_IU_LEN];
++};
+ 
+ enum viosrp_crq_formats {
+ 	VIOSRP_SRP_FORMAT = 0x01,
+diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
+index 3cf02b1..9c22465 100644
+--- a/drivers/scsi/scsi.c
++++ b/drivers/scsi/scsi.c
+@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
+ 	spin_unlock(&shost->free_list_lock);
+ 
+ 	spin_lock(q->queue_lock);
+-	if (blk_rq_tagged(rq))
+-		blk_queue_end_tag(q, rq);
+ 	__blk_put_request(q, rq);
+ 	spin_unlock_irqrestore(q->queue_lock, flags);
+ 
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index 38b35da..ba1b75b 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -35,15 +35,15 @@
+ static int tgtd_pid;
+ static struct sock *nl_sk;
+ 
+-static int send_event_res(uint16_t type, struct tgt_event *p,
+-			  void *data, int dlen, gfp_t flags, pid_t pid)
++static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
++			  pid_t pid)
+ {
+ 	struct tgt_event *ev;
+ 	struct nlmsghdr *nlh;
+ 	struct sk_buff *skb;
+ 	uint32_t len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + dlen);
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	skb = alloc_skb(len, flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+@@ -52,26 +52,27 @@ static int send_event_res(uint16_t type,
+ 
+ 	ev = NLMSG_DATA(nlh);
+ 	memcpy(ev, p, sizeof(*ev));
+-	if (dlen)
+-		memcpy(ev->data, data, dlen);
+ 
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+ 
+-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
++int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
++			 gfp_t flags)
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct sk_buff *skb;
+ 	struct nlmsghdr *nlh;
+ 	struct tgt_event *ev;
+-	struct tgt_cmd *tcmd;
+ 	int err, len;
+ 
+-	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
++	/* FIXME: we need scsi core to do that. */
++	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
++
++	len = NLMSG_SPACE(sizeof(*ev));
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
++	skb = alloc_skb(NLMSG_SPACE(len), flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+ 
+@@ -82,16 +83,14 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	ev->k.cmd_req.host_no = shost->host_no;
+ 	ev->k.cmd_req.cid = cmd->request->tag;
+ 	ev->k.cmd_req.data_len = cmd->request_bufflen;
+-
+-	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
+-		ev->k.cmd_req.data_len);
+-
+-	/* FIXME: we need scsi core to do that. */
+-	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
+-
+-	tcmd = (struct tgt_cmd *) ev->data;
+-	memcpy(tcmd->scb, cmd->cmnd, sizeof(tcmd->scb));
+-	memcpy(tcmd->lun, lun, sizeof(struct scsi_lun));
++	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
++	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
++	ev->k.cmd_req.attribute = cmd->tag;
++	ev->k.cmd_req.tag = tag;
++
++	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
++		ev->k.cmd_req.data_len, cmd->tag,
++		(unsigned long long) ev->k.cmd_req.tag);
+ 
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err < 0)
+@@ -104,15 +103,31 @@ int scsi_tgt_uspace_send_status(struct s
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct tgt_event ev;
+-	char dummy[sizeof(struct tgt_cmd)];
+ 
+ 	memset(&ev, 0, sizeof(ev));
+ 	ev.k.cmd_done.host_no = shost->host_no;
+ 	ev.k.cmd_done.cid = cmd->request->tag;
+ 	ev.k.cmd_done.result = cmd->result;
+ 
+-	return send_event_res(TGT_KEVENT_CMD_DONE, &ev, dummy, sizeof(dummy),
+-			      gfp_mask, tgtd_pid);
++	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
++}
++
++int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++				  struct scsi_lun *scsilun, void *data)
++{
++	struct tgt_event ev;
++
++	memset(&ev, 0, sizeof(ev));
++	ev.k.tsk_mgmt_req.host_no = host_no;
++	ev.k.tsk_mgmt_req.function = function;
++	ev.k.tsk_mgmt_req.tag = tag;
++	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
++	ev.k.tsk_mgmt_req.mid = (u64) data;
++
++	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
++		(unsigned long long) ev.k.tsk_mgmt_req.mid);
++
++	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
+ }
+ 
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+@@ -124,19 +139,22 @@ static int event_recv_msg(struct sk_buff
+ 		nlh->nlmsg_pid, current->pid);
+ 
+ 	switch (nlh->nlmsg_type) {
+-	case TGT_UEVENT_TGTD_BIND:
++	case TGT_UEVENT_REQ:
+ 		tgtd_pid = NETLINK_CREDS(skb)->pid;
+ 		break;
+-	case TGT_UEVENT_CMD_RES:
++	case TGT_UEVENT_CMD_RSP:
+ 		/* TODO: handle multiple cmds in one event */
+-		err = scsi_tgt_kspace_exec(ev->u.cmd_res.host_no,
+-					   ev->u.cmd_res.cid,
+-					   ev->u.cmd_res.result,
+-					   ev->u.cmd_res.len,
+-					   ev->u.cmd_res.offset,
+-					   ev->u.cmd_res.uaddr,
+-					   ev->u.cmd_res.rw,
+-					   ev->u.cmd_res.try_map);
++		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
++					   ev->u.cmd_rsp.cid,
++					   ev->u.cmd_rsp.result,
++					   ev->u.cmd_rsp.len,
++					   ev->u.cmd_rsp.uaddr,
++					   ev->u.cmd_rsp.rw);
++		break;
++	case TGT_UEVENT_TSK_MGMT_RSP:
++		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
++					       ev->u.tsk_mgmt_rsp.mid,
++					       ev->u.tsk_mgmt_rsp.result);
+ 		break;
+ 	default:
+ 		eprintk("unknown type %d\n", nlh->nlmsg_type);
+@@ -151,6 +169,7 @@ static int event_recv_skb(struct sk_buff
+ 	int err;
+ 	uint32_t rlen;
+ 	struct nlmsghdr	*nlh;
++	struct tgt_event ev;
+ 
+ 	while (skb->len >= NLMSG_SPACE(0)) {
+ 		nlh = (struct nlmsghdr *) skb->data;
+@@ -166,12 +185,14 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RES) {
+-			struct tgt_event ev;
+-
++		switch (nlh->nlmsg_type) {
++		case TGT_UEVENT_CMD_RSP:
++		case TGT_UEVENT_TSK_MGMT_RSP:
++			break;
++		default:
+ 			memset(&ev, 0, sizeof(ev));
+-			ev.k.event_res.err = err;
+-			send_event_res(TGT_KEVENT_RESPONSE, &ev, NULL, 0,
++			ev.k.event_rsp.err = err;
++			send_event_rsp(TGT_KEVENT_RSP, &ev,
+ 				       GFP_KERNEL | __GFP_NOFAIL,
+ 					nlh->nlmsg_pid);
+ 		}
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 8746236..5a98fc4 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -20,7 +20,7 @@
+  * 02110-1301 USA
+  */
+ #include <linux/blkdev.h>
+-#include <linux/elevator.h>
++#include <linux/hash.h>
+ #include <linux/module.h>
+ #include <linux/pagemap.h>
+ #include <scsi/scsi.h>
+@@ -46,6 +46,25 @@ struct scsi_tgt_cmd {
+ 	struct bio_list xfer_done_list;
+ 	struct bio_list xfer_list;
+ 	struct scsi_lun *lun;
++
++	struct list_head hash_list;
++	struct request *rq;
++	u64 tag;
++};
++
++#define TGT_HASH_ORDER	4
++#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
++
++struct scsi_tgt_queuedata {
++	struct Scsi_Host *shost;
++	struct list_head cmd_hash[1 << TGT_HASH_ORDER];
++	spinlock_t cmd_hash_lock;
++
++	struct work_struct uspace_send_work;
++
++	spinlock_t cmd_req_lock;
++	struct mutex cmd_req_mutex;
++	struct list_head cmd_req;
+ };
+ 
+ static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
+@@ -68,9 +87,16 @@ static void scsi_tgt_cmd_destroy(void *d
+ {
+ 	struct scsi_cmnd *cmd = data;
+ 	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
++	struct scsi_tgt_queuedata *qdata = cmd->request->q->queuedata;
++	unsigned long flags;
+ 
+ 	dprintk("cmd %p %d %lu\n", cmd, cmd->sc_data_direction,
+ 		rq_data_dir(cmd->request));
++
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	list_del(&tcmd->hash_list);
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
++
+ 	/*
+ 	 * We must set rq->flags here because bio_map_user and
+ 	 * blk_rq_bio_prep ruined ti.
+@@ -81,62 +107,71 @@ static void scsi_tgt_cmd_destroy(void *d
+ 		cmd->request->flags &= ~1UL;
+ 
+ 	scsi_unmap_user_pages(tcmd);
+-	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
+ 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
+ }
+ 
+ static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
+ {
+-	tcmd->lun = rq->end_io_data;
+-	bio_list_init(&tcmd->xfer_list);
+-	bio_list_init(&tcmd->xfer_done_list);
++	struct scsi_tgt_queuedata *qdata = rq->q->queuedata;
++	unsigned long flags;
++	struct list_head *head;
++	static u32 tag = 0;
++
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	rq->tag = tag++;
++	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
++	list_add(&tcmd->hash_list, head);
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
+ }
+ 
+-static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
+-{
+-	struct scsi_tgt_cmd *tcmd;
+-
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd)
+-		return BLKPREP_DEFER;
+-
+-	init_scsi_tgt_cmd(rq, tcmd);
+-	rq->end_io_data = tcmd;
+-	rq->flags |= REQ_DONTPREP;
+-	return BLKPREP_OK;
+-}
+-
+-static void scsi_uspace_request_fn(struct request_queue *q)
++static void scsi_tgt_uspace_send_fn(void *data)
+ {
++	struct request_queue *q = data;
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
+ 	struct request *rq;
+ 	struct scsi_cmnd *cmd;
+ 	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++	int err;
+ 
+-	/*
+-	 * TODO: just send everthing in the queue to userspace in
+-	 * one vector instead of multiple calls
+-	 */
+-	while ((rq = elv_next_request(q)) != NULL) {
+-		cmd = rq->special;
+-		tcmd = rq->end_io_data;
++retry:
++	err = 0;
++	if (list_empty(&qdata->cmd_req))
++		return;
+ 
+-		/* the completion code kicks us in case we hit this */
+-		if (blk_queue_start_tag(q, rq))
+-			break;
++	mutex_lock(&qdata->cmd_req_mutex);
+ 
+-		spin_unlock_irq(q->queue_lock);
+-		if (scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC) < 0)
+-			goto requeue;
+-		spin_lock_irq(q->queue_lock);
++	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++	if (list_empty(&qdata->cmd_req)) {
++		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++		mutex_unlock(&qdata->cmd_req_mutex);
++		goto out;
++	}
++	rq = list_entry_rq(qdata->cmd_req.next);
++	list_del_init(&rq->queuelist);
++	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++
++	tcmd = rq->end_io_data;
++	init_scsi_tgt_cmd(rq, tcmd);
++	cmd = rq->special;
++	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
++	if (err < 0) {
++		eprintk("failed to send: %p %d\n", cmd, err);
++
++		spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++		list_add(&rq->queuelist, &qdata->cmd_req);
++		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 	}
+ 
+-	return;
+-requeue:
+-	spin_lock_irq(q->queue_lock);
+-	/* need to track cnts and plug */
+-	blk_requeue_request(q, rq);
+-	spin_lock_irq(q->queue_lock);
++	mutex_unlock(&qdata->cmd_req_mutex);
++out:
++	/* TODO: proper error handling */
++	if (err < 0)
++		queue_delayed_work(scsi_tgtd, &qdata->uspace_send_work,
++				   HZ / 10);
++	else
++		goto retry;
+ }
+ 
+ /**
+@@ -150,13 +185,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ {
+ 	struct scsi_tgt_queuedata *queuedata;
+ 	struct request_queue *q;
+-	int err;
++	int err, i;
+ 
+ 	/*
+ 	 * Do we need to send a netlink event or should uspace
+ 	 * just respond to the hotplug event?
+ 	 */
+-	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
++	q = __scsi_alloc_queue(shost, NULL);
+ 	if (!q)
+ 		return -ENOMEM;
+ 
+@@ -168,19 +203,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	queuedata->shost = shost;
+ 	q->queuedata = queuedata;
+ 
+-	elevator_exit(q->elevator);
+-	err = elevator_init(q, "noop");
+-	if (err)
+-		goto free_data;
+-
+-	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
+ 	/*
+ 	 * this is a silly hack. We should probably just queue as many
+ 	 * command as is recvd to userspace. uspace can then make
+ 	 * sure we do not overload the HBA
+ 	 */
+ 	q->nr_requests = shost->hostt->can_queue;
+-	blk_queue_init_tags(q, shost->hostt->can_queue, NULL);
+ 	/*
+ 	 * We currently only support software LLDs so this does
+ 	 * not matter for now. Do we need this for the cards we support?
+@@ -189,10 +217,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
+ 	blk_queue_dma_alignment(q, 0);
+ 	shost->uspace_req_q = q;
+ 
++	for (i = 0; i < ARRAY_SIZE(queuedata->cmd_hash); i++)
++		INIT_LIST_HEAD(&queuedata->cmd_hash[i]);
++	spin_lock_init(&queuedata->cmd_hash_lock);
++
++	INIT_LIST_HEAD(&queuedata->cmd_req);
++	spin_lock_init(&queuedata->cmd_req_lock);
++	INIT_WORK(&queuedata->uspace_send_work, scsi_tgt_uspace_send_fn, q);
++	mutex_init(&queuedata->cmd_req_mutex);
++
+ 	return 0;
+ 
+-free_data:
+-	kfree(queuedata);
+ cleanup_queue:
+ 	blk_cleanup_queue(q);
+ 	return err;
+@@ -212,17 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+  * @scsilun:	scsi lun
+  * @noblock:	set to nonzero if the command should be queued
+  **/
+-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+-			    int noblock)
++int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
++			   u64 tag)
+ {
++	struct request_queue *q = cmd->request->q;
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
++	unsigned long flags;
++	struct scsi_tgt_cmd *tcmd;
++
+ 	/*
+-	 * For now this just calls the request_fn from this context.
+-	 * For HW llds though we do not want to execute from here so
+-	 * the elevator code needs something like a REQ_TGT_CMD or
+-	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
++	 * It would be better to allocate scsi_tgt_cmd structure in
++	 * scsi_host_get_command and not to fail due to OOM.
+ 	 */
+-	cmd->request->end_io_data = scsilun;
+-	elv_add_request(cmd->request->q, cmd->request, ELEVATOR_INSERT_BACK, 1);
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd)
++		return -ENOMEM;
++	cmd->request->end_io_data = tcmd;
++
++	bio_list_init(&tcmd->xfer_list);
++	bio_list_init(&tcmd->xfer_done_list);
++	tcmd->lun = scsilun;
++	tcmd->tag = tag;
++	tcmd->rq = cmd->request;
++
++	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
++	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
++	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
++
++	queue_work(scsi_tgtd, &qdata->uspace_send_work);
++	return 0;
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -236,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
+ 
+ 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
+ 
+-	/* don't we have to call this if result is set or not */
+-	if (cmd->result) {
+-		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+-		return;
+-	}
+-
++	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+ 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
+ 	queue_work(scsi_tgtd, &tcmd->work);
+ }
+@@ -315,7 +363,7 @@ static int scsi_map_user_pages(struct sc
+ 
+ 	while (len > 0) {
+ 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
+-		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
++		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
+ 		if (IS_ERR(bio)) {
+ 			err = PTR_ERR(bio);
+ 			dprintk("fail to map %lx %u %d %x\n",
+@@ -438,16 +486,49 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
+-int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
+-			 unsigned long uaddr, u8 rw, u8 try_map)
++static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
++{
++	int err;
++
++	err = host->hostt->eh_abort_handler(cmd);
++	if (err)
++		eprintk("fail to abort %p\n", cmd);
++
++	scsi_tgt_cmd_destroy(cmd);
++	return err;
++}
++
++static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
++{
++	struct scsi_tgt_queuedata *qdata = q->queuedata;
++	struct request *rq = NULL;
++	struct list_head *head;
++	struct scsi_tgt_cmd *tcmd;
++	unsigned long flags;
++
++	head = &qdata->cmd_hash[cmd_hashfn(cid)];
++	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
++	list_for_each_entry(tcmd, head, hash_list) {
++		if (tcmd->rq->tag == cid) {
++			rq = tcmd->rq;
++			break;
++		}
++	}
++	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
++
++	return rq;
++}
++
++int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
++			 unsigned long uaddr, u8 rw)
+ {
+ 	struct Scsi_Host *shost;
+ 	struct scsi_cmnd *cmd;
+ 	struct request *rq;
+ 	int err = 0;
+ 
+-	dprintk("%d %u %d %u %llu %lx %u %u\n", host_no, cid, result,
+-		len, (unsigned long long) offset, uaddr, rw, try_map);
++	dprintk("%d %u %d %u %lx %u\n", host_no, cid, result,
++		len, uaddr, rw);
+ 
+ 	/* TODO: replace with a O(1) alg */
+ 	shost = scsi_host_lookup(host_no);
+@@ -456,7 +537,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 		return -EINVAL;
+ 	}
+ 
+-	rq = blk_queue_find_tag(shost->uspace_req_q, cid);
++	rq = tgt_cmd_hash_lookup(shost->uspace_req_q, cid);
+ 	if (!rq) {
+ 		printk(KERN_ERR "Could not find cid %u\n", cid);
+ 		err = -EINVAL;
+@@ -467,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
+ 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
+ 
++	if (result == TASK_ABORTED) {
++		scsi_tgt_abort_cmd(shost, cmd);
++		goto done;
++	}
+ 	/*
+ 	 * store the userspace values here, the working values are
+ 	 * in the request_* values
+@@ -507,6 +592,38 @@ done:
+ 	return err;
+ }
+ 
++int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
++			      struct scsi_lun *scsilun, void *data)
++{
++	int err;
++
++	/* TODO: need to retry if this fails. */
++	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
++					    tag, scsilun, data);
++	if (err < 0)
++		eprintk("The task management request lost!\n");
++	return err;
++}
++EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
++
++int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
++{
++	struct Scsi_Host *shost;
++	int err;
++
++	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
++
++	shost = scsi_host_lookup(host_no);
++	if (IS_ERR(shost)) {
++		printk(KERN_ERR "Could not find host no %d\n", host_no);
++		return -EINVAL;
++	}
++	err = shost->hostt->tsk_mgmt_response(mid, result);
++	scsi_host_put(shost);
++
++	return err;
++}
++
+ static int __init scsi_tgt_init(void)
+ {
+ 	int err;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 4236e50..77a1d06 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -4,22 +4,21 @@ struct Scsi_Host;
+ struct task_struct;
+ 
+ /* tmp - will replace with SCSI logging stuff */
+-#define dprintk(fmt, args...)					\
++#define eprintk(fmt, args...)					\
+ do {								\
+ 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
+ } while (0)
+ 
+-#define eprintk dprintk
+-
+-struct scsi_tgt_queuedata {
+-	struct Scsi_Host *shost;
+-};
++#define dprintk eprintk
+ 
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
++extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
++				u64 tag, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+-				u64 offset, unsigned long uaddr, u8 rw,
+-				u8 try_map);
++				unsigned long uaddr, u8 rw);
++extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++					 struct scsi_lun *scsilun, void *data);
++extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
+diff --git a/fs/bio.c b/fs/bio.c
+index 3e940c9..f51a873 100644
+--- a/fs/bio.c
++++ b/fs/bio.c
+@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
+  *	@uaddr: start of user address
+  *	@len: length in bytes
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
+-			 unsigned long uaddr, unsigned int len, int write_to_vm,
+-			 int support_partial)
++			 unsigned long uaddr, unsigned int len, int write_to_vm)
+ {
+ 	struct sg_iovec iov;
+ 
+ 	iov.iov_base = (void __user *)uaddr;
+ 	iov.iov_len = len;
+ 
+-	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm, support_partial);
++	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm);
+ }
+ 
+ /**
+@@ -742,17 +740,15 @@ struct bio *bio_map_user(request_queue_t
+  *	@iov:	the iovec.
+  *	@iov_count: number of elements in the iovec
+  *	@write_to_vm: bool indicating writing to pages or not
+- *	@support_partial: support partial mappings
+  *
+  *	Map the user space address into a bio suitable for io to a block
+  *	device. Returns an error pointer in case of error.
+  */
+ struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
+ 			     struct sg_iovec *iov, int iov_count,
+-			     int write_to_vm, int support_partial)
++			     int write_to_vm)
+ {
+ 	struct bio *bio;
+-	int len = 0, i;
+ 
+ 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
+ 
+@@ -767,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
+ 	 */
+ 	bio_get(bio);
+ 
+-	for (i = 0; i < iov_count; i++)
+-		len += iov[i].iov_len;
+-
+-	if (bio->bi_size == len || support_partial)
+-		return bio;
+-
+-	/*
+-	 * don't support partial mappings
+-	 */
+-	bio_endio(bio, bio->bi_size, 0);
+-	bio_unmap_user(bio);
+-	return ERR_PTR(-EINVAL);
++	return bio;
+ }
+ 
+ static void __bio_unmap_user(struct bio *bio)
+diff --git a/include/linux/bio.h b/include/linux/bio.h
+index fc0906c..b60ffe3 100644
+--- a/include/linux/bio.h
++++ b/include/linux/bio.h
+@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
+ extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
+ 			   unsigned int, unsigned int);
+ extern int bio_get_nr_vecs(struct block_device *);
+-extern int __bio_get_nr_vecs(struct request_queue *);
+ extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
+-				unsigned long, unsigned int, int, int);
++				unsigned long, unsigned int, int);
+ struct sg_iovec;
+ extern struct bio *bio_map_user_iov(struct request_queue *,
+ 				    struct block_device *,
+-				    struct sg_iovec *, int, int, int);
++				    struct sg_iovec *, int, int);
+ extern void bio_unmap_user(struct bio *);
+ extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
+ 				gfp_t);
+diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
+index 860e7a4..619ef1d 100644
+--- a/include/linux/blkdev.h
++++ b/include/linux/blkdev.h
+@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
+ extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
+ extern int blk_rq_unmap_user(struct bio *, unsigned int);
+ extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
+-extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
++extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
++			       struct sg_iovec *, int, unsigned int);
+ extern int blk_execute_rq(request_queue_t *, struct gendisk *,
+ 			  struct request *, int);
+ extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
+diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
+index 8b799db..eca5721 100644
+--- a/include/scsi/scsi_host.h
++++ b/include/scsi/scsi_host.h
+@@ -153,6 +153,9 @@ struct scsi_host_template {
+ 	int (* transfer_data)(struct scsi_cmnd *,
+ 			      void (*done)(struct scsi_cmnd *));
+ 
++	/* Used as callback for the completion of task management request. */
++	int (* tsk_mgmt_response)(u64 mid, int result);
++
+ 	/*
+ 	 * This is an error handling strategy routine.  You don't need to
+ 	 * define one of these if you don't want to - there is a default
+diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
+index 91ad6bc..2d65be7 100644
+--- a/include/scsi/scsi_tgt.h
++++ b/include/scsi/scsi_tgt.h
+@@ -6,6 +6,8 @@ struct Scsi_Host;
+ struct scsi_cmnd;
+ struct scsi_lun;
+ 
+-extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
++extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
+ extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
+-extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
++extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
++extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
++				     void *);
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index da3a808..63b2e3a 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -24,65 +24,66 @@
+ 
+ enum tgt_event_type {
+ 	/* user -> kernel */
+-	TGT_UEVENT_TGTD_BIND,
+-	TGT_UEVENT_TARGET_SETUP,
+-	TGT_UEVENT_CMD_RES,
++	TGT_UEVENT_REQ,
++	TGT_UEVENT_CMD_RSP,
++	TGT_UEVENT_TSK_MGMT_RSP,
+ 
+ 	/* kernel -> user */
+-	TGT_KEVENT_RESPONSE,
++	TGT_KEVENT_RSP,
+ 	TGT_KEVENT_CMD_REQ,
+ 	TGT_KEVENT_CMD_DONE,
++	TGT_KEVENT_TSK_MGMT_REQ,
+ };
+ 
+ struct tgt_event {
+ 	/* user-> kernel */
+ 	union {
+ 		struct {
+-			int pk_fd;
+-		} tgtd_bind;
++			int type;
++			int host_no;
++		} event_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t len;
+ 			int result;
+ 			uint64_t uaddr;
+-			uint64_t offset;
+ 			uint8_t rw;
+-			uint8_t try_map;
+-		} cmd_res;
++		} cmd_rsp;
++		struct {
++			int host_no;
++			uint64_t mid;
++			int result;
++		} tsk_mgmt_rsp;
+ 	} u;
+ 
+ 	/* kernel -> user */
+ 	union {
+ 		struct {
+ 			int err;
+-		} event_res;
++		} event_rsp;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			uint32_t data_len;
+-			uint64_t dev_id;
++			uint8_t scb[16];
++			uint8_t lun[8];
++			int attribute;
++			uint64_t tag;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+ 			uint32_t cid;
+ 			int result;
+ 		} cmd_done;
++		struct {
++			int host_no;
++			int function;
++			uint64_t tag;
++			uint8_t lun[8];
++			uint64_t mid;
++		} tsk_mgmt_req;
+ 	} k;
+ 
+-	/*
+-	 * I think a pointer is a unsigned long but this struct
+-	 * gets passed around from the kernel to userspace and
+-	 * back again so to handle some ppc64 setups where userspace is
+-	 * 32 bits but the kernel is 64 we do this odd thing
+-	 */
+-	uint64_t data[0];
+-} __attribute__ ((aligned (sizeof(uint64_t))));
+-
+-struct tgt_cmd {
+-	uint8_t scb[16];
+-	uint8_t lun[8];
+-	int tags;
+ } __attribute__ ((aligned (sizeof(uint64_t))));
+-
+ #endif

Deleted: branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff
===================================================================
--- branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/tgt-2.6.16-rc5.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,573 +0,0 @@
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 03d9c82..6849859 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq->bio = rq->biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq->buffer = rq->data = NULL;
--		rq->data_len = len;
--		return 0;
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq->bio = rq->biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq->buffer = rq->data = NULL;
-+	rq->data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq->bio = rq->biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq->buffer = rq->data = NULL;
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
-+					  hdr->dxfer_len);
- 		kfree(iov);
- 	} else if (hdr->dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
-diff --git a/drivers/scsi/hosts.c b/drivers/scsi/hosts.c
-index 5881079..64e687a 100644
---- a/drivers/scsi/hosts.c
-+++ b/drivers/scsi/hosts.c
-@@ -264,6 +264,11 @@ static void scsi_host_dev_release(struct
- 	if (shost->work_q)
- 		destroy_workqueue(shost->work_q);
- 
-+	if (shost->uspace_req_q) {
-+		kfree(shost->uspace_req_q->queuedata);
-+		scsi_free_queue(shost->uspace_req_q);
-+	}
-+
- 	scsi_destroy_command_freelist(shost);
- 	kfree(shost->shost_data);
- 
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index c551bb8..3cf02b1 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -236,6 +236,58 @@ static struct scsi_cmnd *__scsi_get_comm
- }
- 
- /*
-+ * Function:	scsi_host_get_command()
-+ *
-+ * Purpose:	Allocate and setup a scsi command block and blk request
-+ *
-+ * Arguments:	shost	- scsi host
-+ *		data_dir - dma data dir
-+ *		gfp_mask- allocator flags
-+ *
-+ * Returns:	The allocated scsi command structure.
-+ *
-+ * This should be called by target LLDs to get a command.
-+ */
-+struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *shost,
-+					enum dma_data_direction data_dir,
-+					gfp_t gfp_mask)
-+{
-+	int write = (data_dir == DMA_TO_DEVICE);
-+	struct request *rq;
-+	struct scsi_cmnd *cmd;
-+
-+	/* Bail if we can't get a reference to the device */
-+	if (!get_device(&shost->shost_gendev))
-+		return NULL;
-+
-+	rq = blk_get_request(shost->uspace_req_q, write, gfp_mask);
-+	if (!rq)
-+		goto put_dev;
-+
-+	cmd = __scsi_get_command(shost, gfp_mask);
-+	if (!cmd)
-+		goto release_rq;
-+
-+	memset(cmd, 0, sizeof(*cmd));
-+	cmd->sc_data_direction = data_dir;
-+	cmd->jiffies_at_alloc = jiffies;
-+	cmd->request = rq;
-+
-+	rq->special = cmd;
-+	rq->flags |= REQ_SPECIAL | REQ_BLOCK_PC;
-+
-+	return cmd;
-+
-+release_rq:
-+	blk_put_request(rq);
-+put_dev:
-+	put_device(&shost->shost_gendev);
-+	return NULL;
-+
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_get_command);
-+
-+/*
-  * Function:	scsi_get_command()
-  *
-  * Purpose:	Allocate and setup a scsi command block
-@@ -274,6 +326,45 @@ struct scsi_cmnd *scsi_get_command(struc
- EXPORT_SYMBOL(scsi_get_command);
- 
- /*
-+ * Function:	scsi_host_put_command()
-+ *
-+ * Purpose:	Free a scsi command block
-+ *
-+ * Arguments:	shost	- scsi host
-+ * 		cmd	- command block to free
-+ *
-+ * Returns:	Nothing.
-+ *
-+ * Notes:	The command must not belong to any lists.
-+ */
-+void scsi_host_put_command(struct Scsi_Host *shost, struct scsi_cmnd *cmd)
-+{
-+	struct request_queue *q = shost->uspace_req_q;
-+	struct request *rq = cmd->request;
-+	unsigned long flags;
-+
-+	/* changing locks here, don't need to restore the irq state */
-+	spin_lock_irqsave(&shost->free_list_lock, flags);
-+	if (unlikely(list_empty(&shost->free_list))) {
-+		list_add(&cmd->list, &shost->free_list);
-+		cmd = NULL;
-+	}
-+	spin_unlock(&shost->free_list_lock);
-+
-+	spin_lock(q->queue_lock);
-+	if (blk_rq_tagged(rq))
-+		blk_queue_end_tag(q, rq);
-+	__blk_put_request(q, rq);
-+	spin_unlock_irqrestore(q->queue_lock, flags);
-+
-+	if (likely(cmd != NULL))
-+		kmem_cache_free(shost->cmd_pool->slab, cmd);
-+
-+	put_device(&shost->shost_gendev);
-+}
-+EXPORT_SYMBOL_GPL(scsi_host_put_command);
-+
-+/*
-  * Function:	scsi_put_command()
-  *
-  * Purpose:	Free a scsi command block
-diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
-index 4362dcd..7307705 100644
---- a/drivers/scsi/scsi_lib.c
-+++ b/drivers/scsi/scsi_lib.c
-@@ -804,7 +804,7 @@ static struct scsi_cmnd *scsi_end_reques
- 	return NULL;
- }
- 
--static struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
-+struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *cmd, gfp_t gfp_mask)
- {
- 	struct scsi_host_sg_pool *sgp;
- 	struct scatterlist *sgl;
-@@ -845,7 +845,9 @@ static struct scatterlist *scsi_alloc_sg
- 	return sgl;
- }
- 
--static void scsi_free_sgtable(struct scatterlist *sgl, int index)
-+EXPORT_SYMBOL(scsi_alloc_sgtable);
-+
-+void scsi_free_sgtable(struct scatterlist *sgl, int index)
- {
- 	struct scsi_host_sg_pool *sgp;
- 
-@@ -855,6 +857,8 @@ static void scsi_free_sgtable(struct sca
- 	mempool_free(sgl, sgp->pool);
- }
- 
-+EXPORT_SYMBOL(scsi_free_sgtable);
-+
- /*
-  * Function:    scsi_release_buffers()
-  *
-@@ -1687,29 +1691,40 @@ u64 scsi_calculate_bounce_limit(struct S
- }
- EXPORT_SYMBOL(scsi_calculate_bounce_limit);
- 
--struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					 request_fn_proc *request_fn)
- {
--	struct Scsi_Host *shost = sdev->host;
- 	struct request_queue *q;
- 
--	q = blk_init_queue(scsi_request_fn, NULL);
-+	q = blk_init_queue(request_fn, NULL);
- 	if (!q)
- 		return NULL;
- 
--	blk_queue_prep_rq(q, scsi_prep_fn);
--
- 	blk_queue_max_hw_segments(q, shost->sg_tablesize);
- 	blk_queue_max_phys_segments(q, SCSI_MAX_PHYS_SEGMENTS);
- 	blk_queue_max_sectors(q, shost->max_sectors);
- 	blk_queue_bounce_limit(q, scsi_calculate_bounce_limit(shost));
- 	blk_queue_segment_boundary(q, shost->dma_boundary);
--	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
--	blk_queue_softirq_done(q, scsi_softirq_done);
- 
- 	if (!shost->use_clustering)
- 		clear_bit(QUEUE_FLAG_CLUSTER, &q->queue_flags);
- 	return q;
- }
-+EXPORT_SYMBOL(__scsi_alloc_queue);
-+
-+struct request_queue *scsi_alloc_queue(struct scsi_device *sdev)
-+{
-+	struct request_queue *q;
-+
-+	q = __scsi_alloc_queue(sdev->host, scsi_request_fn);
-+	if (!q)
-+		return NULL;
-+
-+	blk_queue_prep_rq(q, scsi_prep_fn);
-+	blk_queue_issue_flush_fn(q, scsi_issue_flush_fn);
-+	blk_queue_softirq_done(q, scsi_softirq_done);
-+	return q;
-+}
- 
- void scsi_free_queue(struct request_queue *q)
- {
-diff --git a/fs/bio.c b/fs/bio.c
-index 1f3bb50..f51a873 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -620,10 +620,9 @@ static struct bio *__bio_map_user_iov(re
- 
- 		nr_pages += end - start;
- 		/*
--		 * transfer and buffer must be aligned to at least hardsector
--		 * size for now, in the future we can relax this restriction
-+		 * buffer must be aligned to at least hardsector size for now
- 		 */
--		if ((uaddr & queue_dma_alignment(q)) || (len & queue_dma_alignment(q)))
-+		if (uaddr & queue_dma_alignment(q))
- 			return ERR_PTR(-EINVAL);
- 	}
- 
-@@ -750,7 +749,6 @@ struct bio *bio_map_user_iov(request_que
- 			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -765,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i < iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio->bi_size == len)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio->bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
-diff --git a/include/linux/netlink.h b/include/linux/netlink.h
-index c256ebe..9422ae5 100644
---- a/include/linux/netlink.h
-+++ b/include/linux/netlink.h
-@@ -21,6 +21,7 @@
- #define NETLINK_DNRTMSG		14	/* DECnet routing messages */
- #define NETLINK_KOBJECT_UEVENT	15	/* Kernel messages to userspace */
- #define NETLINK_GENERIC		16
-+#define NETLINK_TGT		17	/* SCSI target */
- 
- #define MAX_LINKS 32		
- 
-diff --git a/include/scsi/scsi_cmnd.h b/include/scsi/scsi_cmnd.h
-index 7529f43..51156c7 100644
---- a/include/scsi/scsi_cmnd.h
-+++ b/include/scsi/scsi_cmnd.h
-@@ -8,6 +8,7 @@
- 
- struct request;
- struct scatterlist;
-+struct Scsi_Host;
- struct scsi_device;
- struct scsi_request;
- 
-@@ -84,6 +85,8 @@ struct scsi_cmnd {
- 	unsigned short sglist_len;	/* size of malloc'd scatter-gather list */
- 	unsigned bufflen;	/* Size of data buffer */
- 	void *buffer;		/* Data buffer */
-+	/* offset in cmd we are at (for multi-transfer tgt cmds) */
-+	unsigned offset;
- 
- 	unsigned underflow;	/* Return error if less than
- 				   this amount is transferred */
-@@ -147,9 +150,14 @@ struct scsi_cmnd {
- #define SCSI_STATE_MLQUEUE         0x100b
- 
- 
-+extern struct scsi_cmnd *scsi_host_get_command(struct Scsi_Host *,
-+					       enum dma_data_direction, gfp_t);
- extern struct scsi_cmnd *scsi_get_command(struct scsi_device *, gfp_t);
-+extern void scsi_host_put_command(struct Scsi_Host *, struct scsi_cmnd *);
- extern void scsi_put_command(struct scsi_cmnd *);
- extern void scsi_io_completion(struct scsi_cmnd *, unsigned int, unsigned int);
- extern void scsi_finish_command(struct scsi_cmnd *cmd);
-+extern struct scatterlist *scsi_alloc_sgtable(struct scsi_cmnd *, gfp_t);
-+extern void scsi_free_sgtable(struct scatterlist *, int);
- 
- #endif /* _SCSI_SCSI_CMND_H */
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8279929..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -7,6 +7,7 @@
- #include <linux/workqueue.h>
- #include <linux/mutex.h>
- 
-+struct request_queue;
- struct block_device;
- struct completion;
- struct module;
-@@ -123,6 +124,39 @@ struct scsi_host_template {
- 			     void (*done)(struct scsi_cmnd *));
- 
- 	/*
-+	 * The transfer functions are used to queue a scsi command to
-+	 * the LLD. When the driver is finished processing the command
-+	 * the done callback is invoked.
-+	 *
-+	 * return values: see queuecommand
-+	 *
-+	 * If the LLD accepts the cmd, it should set the result to an
-+	 * appropriate value when completed before calling the done function.
-+	 *
-+	 * STATUS: REQUIRED FOR TARGET DRIVERS
-+	 */
-+	/* TODO: rename */
-+	int (* transfer_response)(struct scsi_cmnd *,
-+				  void (*done)(struct scsi_cmnd *));
-+	/*
-+	 * This is called to inform the LLD to transfer cmd->request_bufflen
-+	 * bytes of the cmd at cmd->offset in the cmd. The cmd->use_sg
-+	 * speciefies the number of scatterlist entried in the command
-+	 * and cmd->request_buffer contains the scatterlist.
-+	 *
-+	 * If the command cannot be processed in one transfer_data call
-+	 * becuase a scatterlist within the LLD's limits cannot be
-+	 * created then transfer_data will be called multiple times.
-+	 * It is initially called from process context, and later
-+	 * calls are from the interrup context.
-+	 */
-+	int (* transfer_data)(struct scsi_cmnd *,
-+			      void (*done)(struct scsi_cmnd *));
-+
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
-+	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
- 	 * routine that is present that should work in most cases.  For those
-@@ -572,6 +606,12 @@ struct Scsi_Host {
- 	 */
- 	unsigned int max_host_blocked;
- 
-+	/*
-+	 * q used for scsi_tgt msgs, async events or any other requests that
-+	 * need to be processed in userspace
-+ 	 */
-+	struct request_queue *uspace_req_q;
-+
- 	/* legacy crap */
- 	unsigned long base;
- 	unsigned long io_port;
-@@ -674,6 +714,9 @@ extern void scsi_unblock_requests(struct
- extern void scsi_block_requests(struct Scsi_Host *);
- 
- struct class_container;
-+
-+extern struct request_queue *__scsi_alloc_queue(struct Scsi_Host *shost,
-+					     void (*) (struct request_queue *));
- /*
-  * These two functions are used to allocate and free a pseudo device
-  * which will connect to the host adapter itself rather than any
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-new file mode 100644
-index 0000000..3d09a1a
---- /dev/null
-+++ b/include/scsi/scsi_tgt.h
-@@ -0,0 +1,13 @@
-+/*
-+ * SCSI target definitions
-+ */
-+
-+struct Scsi_Host;
-+struct scsi_cmnd;
-+struct scsi_lun;
-+
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-new file mode 100644
-index 0000000..63b2e3a
---- /dev/null
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -0,0 +1,89 @@
-+/*
-+ * SCSI target kernel/user interface
-+ *
-+ * Copyright (C) 2005 FUJITA Tomonori <tomof at acm.org>
-+ * Copyright (C) 2005 Mike Christie <michaelc at cs.wisc.edu>
-+ *
-+ * This program is free software; you can redistribute it and/or
-+ * modify it under the terms of the GNU General Public License as
-+ * published by the Free Software Foundation; either version 2 of the
-+ * License, or (at your option) any later version.
-+ *
-+ * This program is distributed in the hope that it will be useful, but
-+ * WITHOUT ANY WARRANTY; without even the implied warranty of
-+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-+ * General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU General Public License
-+ * along with this program; if not, write to the Free Software
-+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-+ * 02110-1301 USA
-+ */
-+#ifndef __SCSI_TARGET_IF_H
-+#define __SCSI_TARGET_IF_H
-+
-+enum tgt_event_type {
-+	/* user -> kernel */
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
-+
-+	/* kernel -> user */
-+	TGT_KEVENT_RSP,
-+	TGT_KEVENT_CMD_REQ,
-+	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
-+};
-+
-+struct tgt_event {
-+	/* user-> kernel */
-+	union {
-+		struct {
-+			int type;
-+			int host_no;
-+		} event_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t len;
-+			int result;
-+			uint64_t uaddr;
-+			uint8_t rw;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			uint64_t mid;
-+			int result;
-+		} tsk_mgmt_rsp;
-+	} u;
-+
-+	/* kernel -> user */
-+	union {
-+		struct {
-+			int err;
-+		} event_rsp;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			uint32_t data_len;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
-+			uint64_t tag;
-+		} cmd_req;
-+		struct {
-+			int host_no;
-+			uint32_t cid;
-+			int result;
-+		} cmd_done;
-+		struct {
-+			int host_no;
-+			int function;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			uint64_t mid;
-+		} tsk_mgmt_req;
-+	} k;
-+
-+} __attribute__ ((aligned (sizeof(uint64_t))));
-+#endif

Deleted: branches/use-scsi-ml/patchset/tmf.diff
===================================================================
--- branches/use-scsi-ml/patchset/tmf.diff	2006-04-07 00:44:26 UTC (rev 395)
+++ branches/use-scsi-ml/patchset/tmf.diff	2006-04-07 01:34:11 UTC (rev 396)
@@ -1,60 +0,0 @@
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8b799db..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -153,6 +153,9 @@ struct scsi_host_template {
- 	int (* transfer_data)(struct scsi_cmnd *,
- 			      void (*done)(struct scsi_cmnd *));
- 
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
- 	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-index 91ad6bc..3d09a1a 100644
---- a/include/scsi/scsi_tgt.h
-+++ b/include/scsi/scsi_tgt.h
-@@ -8,4 +8,6 @@ struct scsi_lun;
- 
- extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
- extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
--extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
-+extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index ebca452..63b2e3a 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -52,7 +52,7 @@ struct tgt_event {
- 		} cmd_rsp;
- 		struct {
- 			int host_no;
--			int mid;
-+			uint64_t mid;
- 			int result;
- 		} tsk_mgmt_rsp;
- 	} u;
-@@ -69,6 +69,7 @@ struct tgt_event {
- 			uint8_t scb[16];
- 			uint8_t lun[8];
- 			int attribute;
-+			uint64_t tag;
- 		} cmd_req;
- 		struct {
- 			int host_no;
-@@ -77,10 +78,10 @@ struct tgt_event {
- 		} cmd_done;
- 		struct {
- 			int host_no;
--			int mid;
-+			int function;
- 			uint64_t tag;
- 			uint8_t lun[8];
--			int function;
-+			uint64_t mid;
- 		} tsk_mgmt_req;
- 	} k;
- 



From tomo at berlios.de  Fri Apr  7 03:39:15 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 7 Apr 2006 03:39:15 +0200
Subject: [Stgt-svn] r397 - branches/use-scsi-ml
Message-ID: <200604070139.k371dFJ4000324@sheep.berlios.de>

Author: tomo
Date: 2006-04-07 03:39:11 +0200 (Fri, 07 Apr 2006)
New Revision: 397

Modified:
   branches/use-scsi-ml/README
Log:
Update README file.

Modified: branches/use-scsi-ml/README
===================================================================
--- branches/use-scsi-ml/README	2006-04-07 01:34:11 UTC (rev 396)
+++ branches/use-scsi-ml/README	2006-04-07 01:39:11 UTC (rev 397)
@@ -12,12 +12,13 @@
 The software consists of kernel modules and user-space tools (daemon,
 management tool, dynamic libraries).
 
-First, get kernel sources from James's scsi-rc-fixes-2.6 git tree.
+First, get kernel sources from James's scsi-rc-fixes-2.6 git tree:
 
-The kernel itself requires the patches in the patchset
-directory. Apply all the patches except the 6th patch, rebuild the
-kernel, and reboot with the new kernel.
+master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-target-2.6.git
 
+Next, apply scsi-target-2.6-tree.diff in the patchset directory,
+rebuild the kernel, and reboot with the new kernel.
+
 The compilation of the kernel modules require the path to above kernel
 source:
 



From tomo at berlios.de  Sat Apr  8 03:23:09 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 8 Apr 2006 03:23:09 +0200
Subject: [Stgt-svn] r398 - in branches/use-scsi-ml/patchset/broken-out: . srp
Message-ID: <200604080123.k381N95r015970@sheep.berlios.de>

Author: tomo
Date: 2006-04-08 03:22:48 +0200 (Sat, 08 Apr 2006)
New Revision: 398

Added:
   branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt
   branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt
   branches/use-scsi-ml/patchset/broken-out/srp/
   branches/use-scsi-ml/patchset/broken-out/srp/0001-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/srp/0002-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
Removed:
   branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
   branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
Modified:
   branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
   branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
   branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
   branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
   branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
   branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
   branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
Log:
Update the patchset for the submission.

Modified: branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] block layer: revoke the original patch to add partial mappings support
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 01/10] block layer: revoke the original patch to add partial mappings support
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409079 +0900
 
 For target mode we could end up with the case where we get very large
@@ -127,4 +127,4 @@
  extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
  				gfp_t);
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] block layer: add partial mappings support to bio_map_user
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 02/10] block layer: add partial mappings support to bio_map_user
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409163 +0900
 
 This is the updated patch for partial mappings support.
@@ -146,4 +146,4 @@
  			  struct request *, int);
  extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] scsi tgt: use the original bio_map_user interface
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 03/10] scsi tgt: use the original bio_map_user interface
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409283 +0900
 
 Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
@@ -25,4 +25,4 @@
  			err = PTR_ERR(bio);
  			dprintk("fail to map %lx %u %d %x\n",
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] block layer: use blk_rq_bio_prep in init_request_from_bio
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 04/10] block layer: use blk_rq_bio_prep in init_request_from_bio
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409371 +0900
 
 Patch to use blk_rq_bio_prep in init_request_from_bio. And remove
@@ -51,4 +51,4 @@
  	rq->nr_hw_segments = bio_hw_segments(q, bio);
  	rq->current_nr_sectors = bio_cur_sectors(bio);
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] scsi tgt: kernel/user interface changes
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 05/10] scsi tgt: kernel/user interface changes
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409611 +0900
 
 - merge the tgt command structure with the the event structure for simplicity.
@@ -290,4 +290,4 @@
 -
  #endif
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] scsi tgt: fix double lock in scsi_uspace_request_fn
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 06/10] scsi tgt: fix double lock in scsi_uspace_request_fn
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142409678 +0900
 
 Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
@@ -25,4 +25,4 @@
  
  /**
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,5 +1,5 @@
-Subject: [PATCH] scsi tgt: remove blk_queue_end_tag
-From: fujita <fujita at albi.localdomain>
+Subject: [PATCH 07/10] scsi tgt: remove blk_queue_end_tag
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
 Date: 1142422083 +0900
 
 Remove blk_queue_end_tag() in scsi_host_put_command() because tgt
@@ -25,4 +25,4 @@
  	spin_unlock_irqrestore(q->queue_lock, flags);
  
 -- 
-1.1.3
+1.1.5

Modified: branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,4 +1,6 @@
-Subject: [PATCH] scsi tgt: replace the elevator code
+Subject: [PATCH 08/10] scsi tgt: replace the elevator code
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Date: 1142464394 +0900
 
 tgt uses the elevator code to send SCSI commands to the user-space
 daemon (q->request_fn sends netlink packets including commands).
@@ -335,4 +337,4 @@
  extern int scsi_tgt_if_init(void);
  
 -- 
-1.1.3
+1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0009-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,583 +0,0 @@
-Subject: [PATCH] ibmvscsi: convert the ibmvscsi driver to use include/scsi/srp.h
-From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
-Date: 1143376921 +0900
-
----
-
- drivers/scsi/ibmvscsi/ibmvscsi.c  |  247 +++++++++++++++++++------------------
- drivers/scsi/ibmvscsi/ibmvscsi.h  |    2 
- drivers/scsi/ibmvscsi/rpa_vscsi.c |    1 
- drivers/scsi/ibmvscsi/viosrp.h    |   17 ++-
- 4 files changed, 142 insertions(+), 125 deletions(-)
-
-74aa6fe8367e04be9cc7d0e7d16cc790754a73f3
-diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
-index eaefedd..e7bd028 100644
---- a/drivers/scsi/ibmvscsi/ibmvscsi.c
-+++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
-@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
- 			++in_use;
- 		if (pool->events[i].ext_list) {
- 			dma_free_coherent(hostdata->dev,
--				  SG_ALL * sizeof(struct memory_descriptor),
-+				  SG_ALL * sizeof(struct srp_direct_buf),
- 				  pool->events[i].ext_list,
- 				  pool->events[i].ext_list_token);
- 		}
-@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
- 			      struct srp_cmd *srp_cmd, 
- 			      int numbuf)
- {
-+	u8 fmt;
-+
- 	if (numbuf == 0)
- 		return;
- 	
--	if (numbuf == 1) {
-+	if (numbuf == 1)
-+		fmt = SRP_DATA_DESC_DIRECT;
-+	else {
-+		fmt = SRP_DATA_DESC_INDIRECT;
-+		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
-+
- 		if (cmd->sc_data_direction == DMA_TO_DEVICE)
--			srp_cmd->data_out_format = SRP_DIRECT_BUFFER;
--		else 
--			srp_cmd->data_in_format = SRP_DIRECT_BUFFER;
--	} else {
--		if (cmd->sc_data_direction == DMA_TO_DEVICE) {
--			srp_cmd->data_out_format = SRP_INDIRECT_BUFFER;
--			srp_cmd->data_out_count =
--				numbuf < MAX_INDIRECT_BUFS ?
--					numbuf: MAX_INDIRECT_BUFS;
--		} else {
--			srp_cmd->data_in_format = SRP_INDIRECT_BUFFER;
--			srp_cmd->data_in_count =
--				numbuf < MAX_INDIRECT_BUFS ?
--					numbuf: MAX_INDIRECT_BUFS;
--		}
-+			srp_cmd->data_out_desc_cnt = numbuf;
-+		else
-+			srp_cmd->data_in_desc_cnt = numbuf;
- 	}
-+
-+	if (cmd->sc_data_direction == DMA_TO_DEVICE)
-+		srp_cmd->buf_fmt = fmt << 4;
-+	else
-+		srp_cmd->buf_fmt = fmt;
- }
- 
--static void unmap_sg_list(int num_entries, 
-+static void unmap_sg_list(int num_entries,
- 		struct device *dev,
--		struct memory_descriptor *md)
--{ 
-+		struct srp_direct_buf *md)
-+{
- 	int i;
- 
--	for (i = 0; i < num_entries; ++i) {
--		dma_unmap_single(dev,
--			md[i].virtual_address,
--			md[i].length, DMA_BIDIRECTIONAL);
--	}
-+	for (i = 0; i < num_entries; ++i)
-+		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
- }
- 
- /**
-@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
- 			   struct srp_event_struct *evt_struct,
- 			   struct device *dev)
- {
--	if ((cmd->data_out_format == SRP_NO_BUFFER) &&
--	    (cmd->data_in_format == SRP_NO_BUFFER))
-+	u8 out_fmt, in_fmt;
-+
-+	out_fmt = cmd->buf_fmt >> 4;
-+	in_fmt = cmd->buf_fmt & ((1U << 4) - 1);
-+
-+	if (out_fmt == SRP_NO_DATA_DESC && in_fmt == SRP_NO_DATA_DESC)
- 		return;
--	else if ((cmd->data_out_format == SRP_DIRECT_BUFFER) ||
--		 (cmd->data_in_format == SRP_DIRECT_BUFFER)) {
--		struct memory_descriptor *data =
--			(struct memory_descriptor *)cmd->additional_data;
--		dma_unmap_single(dev, data->virtual_address, data->length,
--				 DMA_BIDIRECTIONAL);
-+	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
-+		 in_fmt == SRP_DATA_DESC_DIRECT) {
-+		struct srp_direct_buf *data =
-+			(struct srp_direct_buf *) cmd->add_data;
-+		dma_unmap_single(dev, data->va, data->len, DMA_BIDIRECTIONAL);
- 	} else {
--		struct indirect_descriptor *indirect =
--			(struct indirect_descriptor *)cmd->additional_data;
--		int num_mapped = indirect->head.length / 
--			sizeof(indirect->list[0]);
-+		struct srp_indirect_buf *indirect =
-+			(struct srp_indirect_buf *) cmd->add_data;
-+		int num_mapped = indirect->table_desc.len /
-+			sizeof(struct srp_direct_buf);
- 
- 		if (num_mapped <= MAX_INDIRECT_BUFS) {
--			unmap_sg_list(num_mapped, dev, &indirect->list[0]);
-+			unmap_sg_list(num_mapped, dev, &indirect->desc_list[0]);
- 			return;
- 		}
- 
-@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
- 
- static int map_sg_list(int num_entries, 
- 		       struct scatterlist *sg,
--		       struct memory_descriptor *md)
-+		       struct srp_direct_buf *md)
- {
- 	int i;
- 	u64 total_length = 0;
- 
- 	for (i = 0; i < num_entries; ++i) {
--		struct memory_descriptor *descr = md + i;
-+		struct srp_direct_buf *descr = md + i;
- 		struct scatterlist *sg_entry = &sg[i];
--		descr->virtual_address = sg_dma_address(sg_entry);
--		descr->length = sg_dma_len(sg_entry);
--		descr->memory_handle = 0;
-+		descr->va = sg_dma_address(sg_entry);
-+		descr->len = sg_dma_len(sg_entry);
-+		descr->key = 0;
- 		total_length += sg_dma_len(sg_entry);
-  	}
- 	return total_length;
-@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
- 	int sg_mapped;
- 	u64 total_length = 0;
- 	struct scatterlist *sg = cmd->request_buffer;
--	struct memory_descriptor *data =
--	    (struct memory_descriptor *)srp_cmd->additional_data;
--	struct indirect_descriptor *indirect =
--	    (struct indirect_descriptor *)data;
-+	struct srp_direct_buf *data =
-+		(struct srp_direct_buf *) srp_cmd->add_data;
-+	struct srp_indirect_buf *indirect =
-+		(struct srp_indirect_buf *) data;
- 
- 	sg_mapped = dma_map_sg(dev, sg, cmd->use_sg, DMA_BIDIRECTIONAL);
- 
-@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
- 
- 	/* special case; we can use a single direct descriptor */
- 	if (sg_mapped == 1) {
--		data->virtual_address = sg_dma_address(&sg[0]);
--		data->length = sg_dma_len(&sg[0]);
--		data->memory_handle = 0;
-+		data->va = sg_dma_address(&sg[0]);
-+		data->len = sg_dma_len(&sg[0]);
-+		data->key = 0;
- 		return 1;
- 	}
- 
-@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
- 		return 0;
- 	}
- 
--	indirect->head.virtual_address = 0;
--	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
--	indirect->head.memory_handle = 0;
-+	indirect->table_desc.va = 0;
-+	indirect->table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
-+	indirect->table_desc.key = 0;
- 
- 	if (sg_mapped <= MAX_INDIRECT_BUFS) {
--		total_length = map_sg_list(sg_mapped, sg, &indirect->list[0]);
--		indirect->total_length = total_length;
-+		total_length = map_sg_list(sg_mapped, sg,
-+					   &indirect->desc_list[0]);
-+		indirect->len = total_length;
- 		return 1;
- 	}
- 
- 	/* get indirect table */
- 	if (!evt_struct->ext_list) {
--		evt_struct->ext_list =(struct memory_descriptor*)
-+		evt_struct->ext_list = (struct srp_direct_buf *)
- 			dma_alloc_coherent(dev, 
--				SG_ALL * sizeof(struct memory_descriptor),
--				&evt_struct->ext_list_token, 0);
-+					   SG_ALL * sizeof(struct srp_direct_buf),
-+					   &evt_struct->ext_list_token, 0);
- 		if (!evt_struct->ext_list) {
--		    printk(KERN_ERR
--		   	"ibmvscsi: Can't allocate memory for indirect table\n");
-+			printk(KERN_ERR
-+			       "ibmvscsi: Can't allocate memory for indirect table\n");
- 			return 0;
- 			
- 		}
-@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
- 
- 	total_length = map_sg_list(sg_mapped, sg, evt_struct->ext_list);	
- 
--	indirect->total_length = total_length;
--	indirect->head.virtual_address = evt_struct->ext_list_token;
--	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
--	memcpy(indirect->list, evt_struct->ext_list,
--		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
-+	indirect->len = total_length;
-+	indirect->table_desc.va = evt_struct->ext_list_token;
-+	indirect->table_desc.len = sg_mapped * sizeof(indirect->desc_list[0]);
-+	memcpy(indirect->desc_list, evt_struct->ext_list,
-+	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
- 	
-  	return 1;
- }
-@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
- static int map_single_data(struct scsi_cmnd *cmd,
- 			   struct srp_cmd *srp_cmd, struct device *dev)
- {
--	struct memory_descriptor *data =
--	    (struct memory_descriptor *)srp_cmd->additional_data;
-+	struct srp_direct_buf *data =
-+		(struct srp_direct_buf *) srp_cmd->add_data;
- 
--	data->virtual_address =
-+	data->va =
- 		dma_map_single(dev, cmd->request_buffer,
- 			       cmd->request_bufflen,
- 			       DMA_BIDIRECTIONAL);
--	if (dma_mapping_error(data->virtual_address)) {
-+	if (dma_mapping_error(data->va)) {
- 		printk(KERN_ERR
- 		       "ibmvscsi: Unable to map request_buffer for command!\n");
- 		return 0;
- 	}
--	data->length = cmd->request_bufflen;
--	data->memory_handle = 0;
-+	data->len = cmd->request_bufflen;
-+	data->key = 0;
- 
- 	set_srp_direction(cmd, srp_cmd, 1);
- 
-@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
- 
- 	/* Copy the IU into the transfer area */
- 	*evt_struct->xfer_iu = evt_struct->iu;
--	evt_struct->xfer_iu->srp.generic.tag = (u64)evt_struct;
-+	evt_struct->xfer_iu->srp.rsp.tag = (u64)evt_struct;
- 
- 	/* Add this to the sent list.  We need to do this 
- 	 * before we actually send 
-@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
- 	struct srp_rsp *rsp = &evt_struct->xfer_iu->srp.rsp;
- 	struct scsi_cmnd *cmnd = evt_struct->cmnd;
- 
--	if (unlikely(rsp->type != SRP_RSP_TYPE)) {
-+	if (unlikely(rsp->opcode != SRP_RSP)) {
- 		if (printk_ratelimit())
- 			printk(KERN_WARNING 
- 			       "ibmvscsi: bad SRP RSP type %d\n",
--			       rsp->type);
-+			       rsp->opcode);
- 	}
- 	
- 	if (cmnd) {
- 		cmnd->result = rsp->status;
- 		if (((cmnd->result >> 1) & 0x1f) == CHECK_CONDITION)
- 			memcpy(cmnd->sense_buffer,
--			       rsp->sense_and_response_data,
--			       rsp->sense_data_list_length);
-+			       rsp->data,
-+			       rsp->sense_data_len);
- 		unmap_cmd_data(&evt_struct->iu.srp.cmd, 
- 			       evt_struct, 
- 			       evt_struct->hostdata->dev);
- 
--		if (rsp->doover)
--			cmnd->resid = rsp->data_out_residual_count;
--		else if (rsp->diover)
--			cmnd->resid = rsp->data_in_residual_count;
-+		if (rsp->flags & SRP_RSP_FLAG_DOOVER)
-+			cmnd->resid = rsp->data_out_res_cnt;
-+		else if (rsp->flags & SRP_RSP_FLAG_DIOVER)
-+			cmnd->resid = rsp->data_in_res_cnt;
- 	}
- 
- 	if (evt_struct->cmnd_done)
-@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
- {
- 	struct srp_cmd *srp_cmd;
- 	struct srp_event_struct *evt_struct;
--	struct indirect_descriptor *indirect;
-+	struct srp_indirect_buf *indirect;
- 	struct ibmvscsi_host_data *hostdata =
- 		(struct ibmvscsi_host_data *)&cmnd->device->host->hostdata;
- 	u16 lun = lun_from_dev(cmnd->device);
-+	u8 out_fmt, in_fmt;
- 
- 	evt_struct = get_event_struct(&hostdata->pool);
- 	if (!evt_struct)
-@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
- 
- 	/* Set up the actual SRP IU */
- 	srp_cmd = &evt_struct->iu.srp.cmd;
--	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
--	srp_cmd->type = SRP_CMD_TYPE;
-+	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
-+	srp_cmd->opcode = SRP_CMD;
- 	memcpy(srp_cmd->cdb, cmnd->cmnd, sizeof(cmnd->cmnd));
- 	srp_cmd->lun = ((u64) lun) << 48;
- 
-@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
- 	evt_struct->cmnd_done = done;
- 
- 	/* Fix up dma address of the buffer itself */
--	indirect = (struct indirect_descriptor *)srp_cmd->additional_data;
--	if (((srp_cmd->data_out_format == SRP_INDIRECT_BUFFER) ||
--	    (srp_cmd->data_in_format == SRP_INDIRECT_BUFFER)) &&
--	    (indirect->head.virtual_address == 0)) {
--		indirect->head.virtual_address = evt_struct->crq.IU_data_ptr +
--		    offsetof(struct srp_cmd, additional_data) +
--		    offsetof(struct indirect_descriptor, list);
-+	indirect = (struct srp_indirect_buf *) srp_cmd->add_data;
-+	out_fmt = srp_cmd->buf_fmt >> 4;
-+	in_fmt = srp_cmd->buf_fmt & ((1U << 4) - 1);
-+	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
-+	     out_fmt == SRP_DATA_DESC_INDIRECT) &&
-+	    indirect->table_desc.va == 0) {
-+		indirect->table_desc.va = evt_struct->crq.IU_data_ptr +
-+			offsetof(struct srp_cmd, add_data) +
-+			offsetof(struct srp_indirect_buf, desc_list);
- 	}
- 
- 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
-@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
- static void login_rsp(struct srp_event_struct *evt_struct)
- {
- 	struct ibmvscsi_host_data *hostdata = evt_struct->hostdata;
--	switch (evt_struct->xfer_iu->srp.generic.type) {
--	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
-+	switch (evt_struct->xfer_iu->srp.login_rsp.opcode) {
-+	case SRP_LOGIN_RSP:	/* it worked! */
- 		break;
--	case SRP_LOGIN_REJ_TYPE:	/* refused! */
-+	case SRP_LOGIN_REJ:	/* refused! */
- 		printk(KERN_INFO "ibmvscsi: SRP_LOGIN_REJ reason %u\n",
- 		       evt_struct->xfer_iu->srp.login_rej.reason);
- 		/* Login failed.  */
-@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
- 	default:
- 		printk(KERN_ERR
- 		       "ibmvscsi: Invalid login response typecode 0x%02x!\n",
--		       evt_struct->xfer_iu->srp.generic.type);
-+		       evt_struct->xfer_iu->srp.login_rsp.opcode);
- 		/* Login failed.  */
- 		atomic_set(&hostdata->request_limit, -1);
- 		return;
-@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
- 
- 	printk(KERN_INFO "ibmvscsi: SRP_LOGIN succeeded\n");
- 
--	if (evt_struct->xfer_iu->srp.login_rsp.request_limit_delta >
-+	if (evt_struct->xfer_iu->srp.login_rsp.req_lim_delta >
- 	    (max_requests - 2))
--		evt_struct->xfer_iu->srp.login_rsp.request_limit_delta =
-+		evt_struct->xfer_iu->srp.login_rsp.req_lim_delta =
- 		    max_requests - 2;
- 
- 	/* Now we know what the real request-limit is */
- 	atomic_set(&hostdata->request_limit,
--		   evt_struct->xfer_iu->srp.login_rsp.request_limit_delta);
-+		   evt_struct->xfer_iu->srp.login_rsp.req_lim_delta);
- 
- 	hostdata->host->can_queue =
--	    evt_struct->xfer_iu->srp.login_rsp.request_limit_delta - 2;
-+	    evt_struct->xfer_iu->srp.login_rsp.req_lim_delta - 2;
- 
- 	if (hostdata->host->can_queue < 1) {
- 		printk(KERN_ERR "ibmvscsi: Invalid request_limit_delta\n");
-@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
- 
- 	login = &evt_struct->iu.srp.login_req;
- 	memset(login, 0x00, sizeof(struct srp_login_req));
--	login->type = SRP_LOGIN_REQ_TYPE;
--	login->max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
--	login->required_buffer_formats = 0x0006;
-+	login->opcode = SRP_LOGIN_REQ;
-+	login->req_it_iu_len = sizeof(union srp_iu);
-+	login->req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
- 	
- 	/* Start out with a request limit of 1, since this is negotiated in
- 	 * the login request we are just sending
-@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
- 	
- 	/* Set up an abort SRP command */
- 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
--	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
-+	tsk_mgmt->opcode = SRP_TSK_MGMT;
- 	tsk_mgmt->lun = ((u64) lun) << 48;
--	tsk_mgmt->task_mgmt_flags = 0x01;	/* ABORT TASK */
--	tsk_mgmt->managed_task_tag = (u64) found_evt;
-+	tsk_mgmt->tsk_mgmt_func = SRP_TSK_ABORT_TASK;
-+	tsk_mgmt->task_tag = (u64) found_evt;
- 
- 	printk(KERN_INFO "ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n",
--	       tsk_mgmt->lun, tsk_mgmt->managed_task_tag);
-+	       tsk_mgmt->lun, tsk_mgmt->task_tag);
- 
- 	evt->sync_srp = &srp_rsp;
- 	init_completion(&evt->comp);
-@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
- 	wait_for_completion(&evt->comp);
- 
- 	/* make sure we got a good response */
--	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
-+	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
- 		if (printk_ratelimit())
- 			printk(KERN_WARNING 
- 			       "ibmvscsi: abort bad SRP RSP type %d\n",
--			       srp_rsp.srp.generic.type);
-+			       srp_rsp.srp.rsp.opcode);
- 		return FAILED;
- 	}
- 
--	if (srp_rsp.srp.rsp.rspvalid)
--		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
-+	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
-+		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
- 	else
- 		rsp_rc = srp_rsp.srp.rsp.status;
- 
- 	if (rsp_rc) {
- 		if (printk_ratelimit())
- 			printk(KERN_WARNING 
--		       "ibmvscsi: abort code %d for task tag 0x%lx\n",
-+			       "ibmvscsi: abort code %d for task tag 0x%lx\n",
- 			       rsp_rc,
--			       tsk_mgmt->managed_task_tag);
-+			       tsk_mgmt->task_tag);
- 		return FAILED;
- 	}
- 
-@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
- 		spin_unlock_irqrestore(hostdata->host->host_lock, flags);
- 		printk(KERN_INFO
- 		       "ibmvscsi: aborted task tag 0x%lx completed\n",
--		       tsk_mgmt->managed_task_tag);
-+		       tsk_mgmt->task_tag);
- 		return SUCCESS;
- 	}
- 
- 	printk(KERN_INFO
- 	       "ibmvscsi: successfully aborted task tag 0x%lx\n",
--	       tsk_mgmt->managed_task_tag);
-+	       tsk_mgmt->task_tag);
- 
- 	cmd->result = (DID_ABORT << 16);
- 	list_del(&found_evt->list);
-@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
- 
- 	/* Set up a lun reset SRP command */
- 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
--	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
-+	tsk_mgmt->opcode = SRP_TSK_MGMT;
- 	tsk_mgmt->lun = ((u64) lun) << 48;
--	tsk_mgmt->task_mgmt_flags = 0x08;	/* LUN RESET */
-+	tsk_mgmt->tsk_mgmt_func = SRP_TSK_LUN_RESET;
- 
- 	printk(KERN_INFO "ibmvscsi: resetting device. lun 0x%lx\n",
- 	       tsk_mgmt->lun);
-@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
- 	wait_for_completion(&evt->comp);
- 
- 	/* make sure we got a good response */
--	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
-+	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
- 		if (printk_ratelimit())
- 			printk(KERN_WARNING 
- 			       "ibmvscsi: reset bad SRP RSP type %d\n",
--			       srp_rsp.srp.generic.type);
-+			       srp_rsp.srp.rsp.opcode);
- 		return FAILED;
- 	}
- 
--	if (srp_rsp.srp.rsp.rspvalid)
--		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
-+	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
-+		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
- 	else
- 		rsp_rc = srp_rsp.srp.rsp.status;
- 
-@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
- 		if (printk_ratelimit())
- 			printk(KERN_WARNING 
- 			       "ibmvscsi: reset code %d for task tag 0x%lx\n",
--		       rsp_rc,
--			       tsk_mgmt->managed_task_tag);
-+			       rsp_rc, tsk_mgmt->task_tag);
- 		return FAILED;
- 	}
- 
-@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
- 	}
- 
- 	if (crq->format == VIOSRP_SRP_FORMAT)
--		atomic_add(evt_struct->xfer_iu->srp.rsp.request_limit_delta,
-+		atomic_add(evt_struct->xfer_iu->srp.rsp.req_lim_delta,
- 			   &hostdata->request_limit);
- 
- 	if (evt_struct->done)
-diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
-index 4550d71..5c6d935 100644
---- a/drivers/scsi/ibmvscsi/ibmvscsi.h
-+++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
-@@ -68,7 +68,7 @@ struct srp_event_struct {
- 	void (*cmnd_done) (struct scsi_cmnd *);
- 	struct completion comp;
- 	union viosrp_iu *sync_srp;
--	struct memory_descriptor *ext_list;
-+	struct srp_direct_buf *ext_list;
- 	dma_addr_t ext_list_token;
- };
- 
-diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
-index f47dd87..58aa530 100644
---- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
-+++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
-@@ -34,7 +34,6 @@
- #include <linux/dma-mapping.h>
- #include <linux/interrupt.h>
- #include "ibmvscsi.h"
--#include "srp.h"
- 
- static char partition_name[97] = "UNKNOWN";
- static unsigned int partition_number = -1;
-diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
-index 6a6bba8..90f1a61 100644
---- a/drivers/scsi/ibmvscsi/viosrp.h
-+++ b/drivers/scsi/ibmvscsi/viosrp.h
-@@ -33,7 +33,22 @@
- /*****************************************************************************/
- #ifndef VIOSRP_H
- #define VIOSRP_H
--#include "srp.h"
-+#include <scsi/srp.h>
-+
-+#define SRP_VERSION "16.a"
-+#define SRP_MAX_IU_LEN	256
-+
-+union srp_iu {
-+	struct srp_login_req login_req;
-+	struct srp_login_rsp login_rsp;
-+	struct srp_login_rej login_rej;
-+	struct srp_i_logout i_logout;
-+	struct srp_t_logout t_logout;
-+	struct srp_tsk_mgmt tsk_mgmt;
-+	struct srp_cmd cmd;
-+	struct srp_rsp rsp;
-+	u8 reserved[SRP_MAX_IU_LEN];
-+};
- 
- enum viosrp_crq_formats {
- 	VIOSRP_SRP_FORMAT = 0x01,
--- 
-1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -0,0 +1,463 @@
+Subject: [PATCH 09/10] scsi tgt: add task management function support
+From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Date: 1144370959 +0900
+
+This patch addes task management function support to tgt. This
+assumes that all the previous patchsets are applied.
+
+- add callback to task management function to scsi_host_template
+structure. It is used notify LLDs of the completion of a TMF request.
+
+- this patch doesn't use a single queue for TMF requests and SCSI
+commands yet. We'll work on it later on.
+
+- when LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command for ABORT_TASK.
+
+- when tgt aborts a command, it calls eh_abort_handler in
+scsi_host_template structure. Would be better to add
+tgt_eh_abort_handler for LLDs support target and initiator modes at
+the same time?
+
+tgt TMF works in the followings:
+
+- When LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
+need to specify unique 'tag' for each command.
+
+- LLDs call 'int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *host, int,
+u64 tag, struct scsi_lun *lun, void *data)'.
+
+- int (* tsk_mgmt_response)(u64 data, int result) is added to
+scsi_host_template.
+
+When an initiator sends a task management request, the LLD calls
+scsi_tgt_tsk_mgmt_request. the LLD can use whatever it wants for the
+data arg. The data arg is used later as the arg in the
+tsk_mgmt_response callback.
+
+tgt core just sends the task management request to user space
+(by using TGT_KEVENT_TSK_MGMT_REQ).
+
+In the case of ABORT_TASK, tgtd finds a single command to abort and
+sends TGT_UEVENT_CMD_RSP and TGT_UEVENT_TSK_MGMT_RSP events.
+
+tgt core calls eh_abort_handler for TGT_UEVENT_CMD_RSP and then
+tsk_mgmt_response for TGT_UEVENT_TSK_MGMT_RSP.
+
+If tgtd fails to find a command to abort, it sends only
+TGT_UEVENT_TSK_MGMT_RSP event (no TGT_UEVENT_CMD_RSP event).
+
+In the case of the rests task management function (like
+ABORT_TASK_SET), tgt needs to abort multiple commands. Thus, tgtd
+finds multiple commands to abort and sends multiple TGT_UEVENT_CMD_RSP
+events and a single TGT_UEVENT_TSK_MGMT_RSP event. tgt core calls
+eh_abort_handler multiple times and tsk_mgmt_response once.
+
+eh_abort_handler enables LLDs to safely free resource related with a
+command to abort.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/scsi_tgt_if.c   |   43 +++++++++++++++---
+ drivers/scsi/scsi_tgt_lib.c  |  103 +++++++++++++++++++++++++++++-------------
+ drivers/scsi/scsi_tgt_priv.h |   11 +++-
+ include/scsi/scsi_host.h     |    3 +
+ include/scsi/scsi_tgt.h      |    6 ++
+ include/scsi/scsi_tgt_if.h   |    7 ++-
+ 6 files changed, 125 insertions(+), 48 deletions(-)
+
+b9579b62f8d6309815a60da2e6f9a7638df074aa
+diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
+index a31c8d5..ba1b75b 100644
+--- a/drivers/scsi/scsi_tgt_if.c
++++ b/drivers/scsi/scsi_tgt_if.c
+@@ -56,7 +56,8 @@ static int send_event_rsp(uint16_t type,
+ 	return netlink_unicast(nl_sk, skb, pid, 0);
+ }
+ 
+-int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
++int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
++			 gfp_t flags)
+ {
+ 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
+ 	struct sk_buff *skb;
+@@ -71,7 +72,7 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	/*
+ 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
+ 	 */
+-	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
++	skb = alloc_skb(NLMSG_SPACE(len), flags);
+ 	if (!skb)
+ 		return -ENOMEM;
+ 
+@@ -85,9 +86,11 @@ int scsi_tgt_uspace_send(struct scsi_cmn
+ 	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
+ 	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
+ 	ev->k.cmd_req.attribute = cmd->tag;
++	ev->k.cmd_req.tag = tag;
+ 
+-	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
+-		ev->k.cmd_req.data_len);
++	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
++		ev->k.cmd_req.data_len, cmd->tag,
++		(unsigned long long) ev->k.cmd_req.tag);
+ 
+ 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
+ 	if (err < 0)
+@@ -109,6 +112,24 @@ int scsi_tgt_uspace_send_status(struct s
+ 	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
+ }
+ 
++int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++				  struct scsi_lun *scsilun, void *data)
++{
++	struct tgt_event ev;
++
++	memset(&ev, 0, sizeof(ev));
++	ev.k.tsk_mgmt_req.host_no = host_no;
++	ev.k.tsk_mgmt_req.function = function;
++	ev.k.tsk_mgmt_req.tag = tag;
++	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
++	ev.k.tsk_mgmt_req.mid = (u64) data;
++
++	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
++		(unsigned long long) ev.k.tsk_mgmt_req.mid);
++
++	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
++}
++
+ static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+ {
+ 	struct tgt_event *ev = NLMSG_DATA(nlh);
+@@ -130,6 +151,11 @@ static int event_recv_msg(struct sk_buff
+ 					   ev->u.cmd_rsp.uaddr,
+ 					   ev->u.cmd_rsp.rw);
+ 		break;
++	case TGT_UEVENT_TSK_MGMT_RSP:
++		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
++					       ev->u.tsk_mgmt_rsp.mid,
++					       ev->u.tsk_mgmt_rsp.result);
++		break;
+ 	default:
+ 		eprintk("unknown type %d\n", nlh->nlmsg_type);
+ 		err = -EINVAL;
+@@ -143,6 +169,7 @@ static int event_recv_skb(struct sk_buff
+ 	int err;
+ 	uint32_t rlen;
+ 	struct nlmsghdr	*nlh;
++	struct tgt_event ev;
+ 
+ 	while (skb->len >= NLMSG_SPACE(0)) {
+ 		nlh = (struct nlmsghdr *) skb->data;
+@@ -158,9 +185,11 @@ static int event_recv_skb(struct sk_buff
+ 		 * TODO for passthru commands the lower level should
+ 		 * probably handle the result or we should modify this
+ 		 */
+-		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
+-			struct tgt_event ev;
+-
++		switch (nlh->nlmsg_type) {
++		case TGT_UEVENT_CMD_RSP:
++		case TGT_UEVENT_TSK_MGMT_RSP:
++			break;
++		default:
+ 			memset(&ev, 0, sizeof(ev));
+ 			ev.k.event_rsp.err = err;
+ 			send_event_rsp(TGT_KEVENT_RSP, &ev,
+diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
+index 2cbc749..5a98fc4 100644
+--- a/drivers/scsi/scsi_tgt_lib.c
++++ b/drivers/scsi/scsi_tgt_lib.c
+@@ -49,6 +49,7 @@ struct scsi_tgt_cmd {
+ 
+ 	struct list_head hash_list;
+ 	struct request *rq;
++	u64 tag;
+ };
+ 
+ #define TGT_HASH_ORDER	4
+@@ -106,7 +107,6 @@ static void scsi_tgt_cmd_destroy(void *d
+ 		cmd->request->flags &= ~1UL;
+ 
+ 	scsi_unmap_user_pages(tcmd);
+-	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
+ 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
+ }
+@@ -118,19 +118,11 @@ static void init_scsi_tgt_cmd(struct req
+ 	struct list_head *head;
+ 	static u32 tag = 0;
+ 
+-	tcmd->lun = rq->end_io_data;
+-	bio_list_init(&tcmd->xfer_list);
+-	bio_list_init(&tcmd->xfer_done_list);
+-
+ 	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
+ 	rq->tag = tag++;
+ 	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
+ 	list_add(&tcmd->hash_list, head);
+ 	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
+-
+-	tcmd->rq = rq;
+-	rq->end_io_data = tcmd;
+-	rq->flags |= REQ_DONTPREP;
+ }
+ 
+ static void scsi_tgt_uspace_send_fn(void *data)
+@@ -148,33 +140,22 @@ retry:
+ 	if (list_empty(&qdata->cmd_req))
+ 		return;
+ 
+-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+-	if (!tcmd) {
+-		err = -ENOMEM;
+-		goto out;
+-	}
+-
+ 	mutex_lock(&qdata->cmd_req_mutex);
+ 
+ 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
+ 	if (list_empty(&qdata->cmd_req)) {
+ 		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 		mutex_unlock(&qdata->cmd_req_mutex);
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+ 		goto out;
+ 	}
+ 	rq = list_entry_rq(qdata->cmd_req.next);
+ 	list_del_init(&rq->queuelist);
+ 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 
+-	if ((rq->flags & REQ_DONTPREP)) {
+-		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
+-		tcmd = rq->end_io_data;
+-	} else
+-		init_scsi_tgt_cmd(rq, tcmd);
+-
++	tcmd = rq->end_io_data;
++	init_scsi_tgt_cmd(rq, tcmd);
+ 	cmd = rq->special;
+-	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
++	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
+ 	if (err < 0) {
+ 		eprintk("failed to send: %p %d\n", cmd, err);
+ 
+@@ -266,20 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
+  * @scsilun:	scsi lun
+  * @noblock:	set to nonzero if the command should be queued
+  **/
+-void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
+-			    int noblock)
++int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
++			   u64 tag)
+ {
+ 	struct request_queue *q = cmd->request->q;
+ 	struct scsi_tgt_queuedata *qdata = q->queuedata;
+ 	unsigned long flags;
++	struct scsi_tgt_cmd *tcmd;
++
++	/*
++	 * It would be better to allocate scsi_tgt_cmd structure in
++	 * scsi_host_get_command and not to fail due to OOM.
++	 */
++	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
++	if (!tcmd)
++		return -ENOMEM;
++	cmd->request->end_io_data = tcmd;
+ 
+-	cmd->request->end_io_data = scsilun;
++	bio_list_init(&tcmd->xfer_list);
++	bio_list_init(&tcmd->xfer_done_list);
++	tcmd->lun = scsilun;
++	tcmd->tag = tag;
++	tcmd->rq = cmd->request;
+ 
+ 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
+ 	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
+ 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
+ 
+ 	queue_work(scsi_tgtd, &qdata->uspace_send_work);
++	return 0;
+ }
+ EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
+ 
+@@ -293,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
+ 
+ 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
+ 
+-	/* don't we have to call this if result is set or not */
+-	if (cmd->result) {
+-		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+-		return;
+-	}
+-
++	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
+ 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
+ 	queue_work(scsi_tgtd, &tcmd->work);
+ }
+@@ -495,6 +486,18 @@ static int scsi_tgt_copy_sense(struct sc
+ 	return 0;
+ }
+ 
++static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
++{
++	int err;
++
++	err = host->hostt->eh_abort_handler(cmd);
++	if (err)
++		eprintk("fail to abort %p\n", cmd);
++
++	scsi_tgt_cmd_destroy(cmd);
++	return err;
++}
++
+ static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
+ {
+ 	struct scsi_tgt_queuedata *qdata = q->queuedata;
+@@ -545,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
+ 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
+ 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
+ 
++	if (result == TASK_ABORTED) {
++		scsi_tgt_abort_cmd(shost, cmd);
++		goto done;
++	}
+ 	/*
+ 	 * store the userspace values here, the working values are
+ 	 * in the request_* values
+@@ -585,6 +592,38 @@ done:
+ 	return err;
+ }
+ 
++int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
++			      struct scsi_lun *scsilun, void *data)
++{
++	int err;
++
++	/* TODO: need to retry if this fails. */
++	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
++					    tag, scsilun, data);
++	if (err < 0)
++		eprintk("The task management request lost!\n");
++	return err;
++}
++EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
++
++int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
++{
++	struct Scsi_Host *shost;
++	int err;
++
++	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
++
++	shost = scsi_host_lookup(host_no);
++	if (IS_ERR(shost)) {
++		printk(KERN_ERR "Could not find host no %d\n", host_no);
++		return -EINVAL;
++	}
++	err = shost->hostt->tsk_mgmt_response(mid, result);
++	scsi_host_put(shost);
++
++	return err;
++}
++
+ static int __init scsi_tgt_init(void)
+ {
+ 	int err;
+diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
+index 6fedcec..77a1d06 100644
+--- a/drivers/scsi/scsi_tgt_priv.h
++++ b/drivers/scsi/scsi_tgt_priv.h
+@@ -4,18 +4,21 @@ struct Scsi_Host;
+ struct task_struct;
+ 
+ /* tmp - will replace with SCSI logging stuff */
+-#define dprintk(fmt, args...)					\
++#define eprintk(fmt, args...)					\
+ do {								\
+ 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
+ } while (0)
+ 
+-#define eprintk dprintk
++#define dprintk eprintk
+ 
+ extern void scsi_tgt_if_exit(void);
+ extern int scsi_tgt_if_init(void);
+ 
+-extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
++extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
++				u64 tag, gfp_t flags);
+ extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
+ extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
+ 				unsigned long uaddr, u8 rw);
+-
++extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
++					 struct scsi_lun *scsilun, void *data);
++extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
+diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
+index 8b799db..eca5721 100644
+--- a/include/scsi/scsi_host.h
++++ b/include/scsi/scsi_host.h
+@@ -153,6 +153,9 @@ struct scsi_host_template {
+ 	int (* transfer_data)(struct scsi_cmnd *,
+ 			      void (*done)(struct scsi_cmnd *));
+ 
++	/* Used as callback for the completion of task management request. */
++	int (* tsk_mgmt_response)(u64 mid, int result);
++
+ 	/*
+ 	 * This is an error handling strategy routine.  You don't need to
+ 	 * define one of these if you don't want to - there is a default
+diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
+index 91ad6bc..2d65be7 100644
+--- a/include/scsi/scsi_tgt.h
++++ b/include/scsi/scsi_tgt.h
+@@ -6,6 +6,8 @@ struct Scsi_Host;
+ struct scsi_cmnd;
+ struct scsi_lun;
+ 
+-extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
++extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
+ extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
+-extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
++extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
++extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
++				     void *);
+diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
+index ebca452..63b2e3a 100644
+--- a/include/scsi/scsi_tgt_if.h
++++ b/include/scsi/scsi_tgt_if.h
+@@ -52,7 +52,7 @@ struct tgt_event {
+ 		} cmd_rsp;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			uint64_t mid;
+ 			int result;
+ 		} tsk_mgmt_rsp;
+ 	} u;
+@@ -69,6 +69,7 @@ struct tgt_event {
+ 			uint8_t scb[16];
+ 			uint8_t lun[8];
+ 			int attribute;
++			uint64_t tag;
+ 		} cmd_req;
+ 		struct {
+ 			int host_no;
+@@ -77,10 +78,10 @@ struct tgt_event {
+ 		} cmd_done;
+ 		struct {
+ 			int host_no;
+-			int mid;
++			int function;
+ 			uint64_t tag;
+ 			uint8_t lun[8];
+-			int function;
++			uint64_t mid;
+ 		} tsk_mgmt_req;
+ 	} k;
+ 
+-- 
+1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0010-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,246 +0,0 @@
-Subject: [PATCH] ibmvscsi: remove drivers/scsi/ibmvscsi/srp.h
-From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
-Date: 1143377151 +0900
-
----
-
- drivers/scsi/ibmvscsi/srp.h |  227 -------------------------------------------
- 1 files changed, 0 insertions(+), 227 deletions(-)
- delete mode 100644 drivers/scsi/ibmvscsi/srp.h
-
-acbd74e89dc7bcf4e2596800e46a19378db44641
-diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
-deleted file mode 100644
-index 7d8e4c4..0000000
---- a/drivers/scsi/ibmvscsi/srp.h
-+++ /dev/null
-@@ -1,227 +0,0 @@
--/*****************************************************************************/
--/* srp.h -- SCSI RDMA Protocol definitions                                   */
--/*                                                                           */
--/* Written By: Colin Devilbis, IBM Corporation                               */
--/*                                                                           */
--/* Copyright (C) 2003 IBM Corporation                                        */
--/*                                                                           */
--/* This program is free software; you can redistribute it and/or modify      */
--/* it under the terms of the GNU General Public License as published by      */
--/* the Free Software Foundation; either version 2 of the License, or         */
--/* (at your option) any later version.                                       */
--/*                                                                           */
--/* This program is distributed in the hope that it will be useful,           */
--/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
--/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
--/* GNU General Public License for more details.                              */
--/*                                                                           */
--/* You should have received a copy of the GNU General Public License         */
--/* along with this program; if not, write to the Free Software               */
--/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
--/*                                                                           */
--/*                                                                           */
--/* This file contains structures and definitions for the SCSI RDMA Protocol  */
--/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
--/* file was based on the 16a version of the standard                         */
--/*                                                                           */
--/*****************************************************************************/
--#ifndef SRP_H
--#define SRP_H
--
--#define SRP_VERSION "16.a"
--
--#define PACKED __attribute__((packed))
--
--enum srp_types {
--	SRP_LOGIN_REQ_TYPE = 0x00,
--	SRP_LOGIN_RSP_TYPE = 0xC0,
--	SRP_LOGIN_REJ_TYPE = 0xC2,
--	SRP_I_LOGOUT_TYPE = 0x03,
--	SRP_T_LOGOUT_TYPE = 0x80,
--	SRP_TSK_MGMT_TYPE = 0x01,
--	SRP_CMD_TYPE = 0x02,
--	SRP_RSP_TYPE = 0xC1,
--	SRP_CRED_REQ_TYPE = 0x81,
--	SRP_CRED_RSP_TYPE = 0x41,
--	SRP_AER_REQ_TYPE = 0x82,
--	SRP_AER_RSP_TYPE = 0x42
--};
--
--enum srp_descriptor_formats {
--	SRP_NO_BUFFER = 0x00,
--	SRP_DIRECT_BUFFER = 0x01,
--	SRP_INDIRECT_BUFFER = 0x02
--};
--
--struct memory_descriptor {
--	u64 virtual_address;
--	u32 memory_handle;
--	u32 length;
--};
--
--struct indirect_descriptor {
--	struct memory_descriptor head;
--	u32 total_length;
--	struct memory_descriptor list[1] PACKED;
--};
--
--struct srp_generic {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--};
--
--struct srp_login_req {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--	u32 max_requested_initiator_to_target_iulen;
--	u32 reserved2;
--	u16 required_buffer_formats;
--	u8 reserved3:6;
--	u8 multi_channel_action:2;
--	u8 reserved4;
--	u32 reserved5;
--	u8 initiator_port_identifier[16];
--	u8 target_port_identifier[16];
--};
--
--struct srp_login_rsp {
--	u8 type;
--	u8 reserved1[3];
--	u32 request_limit_delta;
--	u64 tag;
--	u32 max_initiator_to_target_iulen;
--	u32 max_target_to_initiator_iulen;
--	u16 supported_buffer_formats;
--	u8 reserved2:6;
--	u8 multi_channel_result:2;
--	u8 reserved3;
--	u8 reserved4[24];
--};
--
--struct srp_login_rej {
--	u8 type;
--	u8 reserved1[3];
--	u32 reason;
--	u64 tag;
--	u64 reserved2;
--	u16 supported_buffer_formats;
--	u8 reserved3[6];
--};
--
--struct srp_i_logout {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--};
--
--struct srp_t_logout {
--	u8 type;
--	u8 reserved1[3];
--	u32 reason;
--	u64 tag;
--};
--
--struct srp_tsk_mgmt {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--	u32 reserved2;
--	u64 lun PACKED;
--	u8 reserved3;
--	u8 reserved4;
--	u8 task_mgmt_flags;
--	u8 reserved5;
--	u64 managed_task_tag;
--	u64 reserved6;
--};
--
--struct srp_cmd {
--	u8 type;
--	u32 reserved1 PACKED;
--	u8 data_out_format:4;
--	u8 data_in_format:4;
--	u8 data_out_count;
--	u8 data_in_count;
--	u64 tag;
--	u32 reserved2;
--	u64 lun PACKED;
--	u8 reserved3;
--	u8 reserved4:5;
--	u8 task_attribute:3;
--	u8 reserved5;
--	u8 additional_cdb_len;
--	u8 cdb[16];
--	u8 additional_data[0x100 - 0x30];
--};
--
--struct srp_rsp {
--	u8 type;
--	u8 reserved1[3];
--	u32 request_limit_delta;
--	u64 tag;
--	u16 reserved2;
--	u8 reserved3:2;
--	u8 diunder:1;
--	u8 diover:1;
--	u8 dounder:1;
--	u8 doover:1;
--	u8 snsvalid:1;
--	u8 rspvalid:1;
--	u8 status;
--	u32 data_in_residual_count;
--	u32 data_out_residual_count;
--	u32 sense_data_list_length;
--	u32 response_data_list_length;
--	u8 sense_and_response_data[18];
--};
--
--struct srp_cred_req {
--	u8 type;
--	u8 reserved1[3];
--	u32 request_limit_delta;
--	u64 tag;
--};
--
--struct srp_cred_rsp {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--};
--
--struct srp_aer_req {
--	u8 type;
--	u8 reserved1[3];
--	u32 request_limit_delta;
--	u64 tag;
--	u32 reserved2;
--	u64 lun;
--	u32 sense_data_list_length;
--	u32 reserved3;
--	u8 sense_data[20];
--};
--
--struct srp_aer_rsp {
--	u8 type;
--	u8 reserved1[7];
--	u64 tag;
--};
--
--union srp_iu {
--	struct srp_generic generic;
--	struct srp_login_req login_req;
--	struct srp_login_rsp login_rsp;
--	struct srp_login_rej login_rej;
--	struct srp_i_logout i_logout;
--	struct srp_t_logout t_logout;
--	struct srp_tsk_mgmt tsk_mgmt;
--	struct srp_cmd cmd;
--	struct srp_rsp rsp;
--	struct srp_cred_req cred_req;
--	struct srp_cred_rsp cred_rsp;
--	struct srp_aer_req aer_req;
--	struct srp_aer_rsp aer_rsp;
--};
--
--#endif
--- 
-1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -0,0 +1,32 @@
+Subject: [PATCH 10/10] scsi tgt: add NET dependence to Kconfig
+From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
+
+> From: "Jun'ichi Nomura" <j-nomura at ce.jp.nec.com>:
+
+scsi_tgt_if.c depends on CONFIG_NET for using netlink.
+So it would be nice if the Kconfig entry checks it.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/Kconfig |    2 +-
+ 1 files changed, 1 insertions(+), 1 deletions(-)
+
+731f4924dd33579ffa5ff45ad03b7b7e933f728b
+diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
+index d09c792..5b5eeb4 100644
+--- a/drivers/scsi/Kconfig
++++ b/drivers/scsi/Kconfig
+@@ -29,7 +29,7 @@ config SCSI
+ 
+ config SCSI_TGT
+ 	tristate "SCSI target support"
+-	depends on SCSI && EXPERIMENTAL
++	depends on SCSI && NET && EXPERIMENTAL
+ 	---help---
+ 	  If you want to use SCSI target mode drivers enable this option.
+ 	  If you choose M, the module will be called scsi_tgt.
+-- 
+1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/0011-scsi-tgt-add-task-management-function-support.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -1,461 +0,0 @@
-Subject: [PATCH] scsi tgt: add task management function support
-
-This patch addes task management function support to tgt. This
-assumes that all the previous patchsets are applied.
-
-- add callback to task management function to scsi_host_template
-structure. It is used notify LLDs of the completion of a TMF request.
-
-- this patch doesn't use a single queue for TMF requests and SCSI
-commands yet. We'll work on it later on.
-
-- when LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
-need to specify unique 'tag' for each command for ABORT_TASK.
-
-- when tgt aborts a command, it calls eh_abort_handler in
-scsi_host_template structure. Would be better to add
-tgt_eh_abort_handler for LLDs support target and initiator modes at
-the same time?
-
-tgt TMF works in the followings:
-
-- When LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
-need to specify unique 'tag' for each command.
-
-- LLDs call 'int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *host, int,
-u64 tag, struct scsi_lun *lun, void *data)'.
-
-- int (* tsk_mgmt_response)(u64 data, int result) is added to
-scsi_host_template.
-
-When an initiator sends a task management request, the LLD calls
-scsi_tgt_tsk_mgmt_request. the LLD can use whatever it wants for the
-data arg. The data arg is used later as the arg in the
-tsk_mgmt_response callback.
-
-tgt core just sends the task management request to user space
-(by using TGT_KEVENT_TSK_MGMT_REQ).
-
-In the case of ABORT_TASK, tgtd finds a single command to abort and
-sends TGT_UEVENT_CMD_RSP and TGT_UEVENT_TSK_MGMT_RSP events.
-
-tgt core calls eh_abort_handler for TGT_UEVENT_CMD_RSP and then
-tsk_mgmt_response for TGT_UEVENT_TSK_MGMT_RSP.
-
-If tgtd fails to find a command to abort, it sends only
-TGT_UEVENT_TSK_MGMT_RSP event (no TGT_UEVENT_CMD_RSP event).
-
-In the case of the rests task management function (like
-ABORT_TASK_SET), tgt needs to abort multiple commands. Thus, tgtd
-finds multiple commands to abort and sends multiple TGT_UEVENT_CMD_RSP
-events and a single TGT_UEVENT_TSK_MGMT_RSP event. tgt core calls
-eh_abort_handler multiple times and tsk_mgmt_response once.
-
-eh_abort_handler enables LLDs to safely free resource related with a
-command to abort.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_if.c   |   43 +++++++++++++++---
- drivers/scsi/scsi_tgt_lib.c  |  103 +++++++++++++++++++++++++++++-------------
- drivers/scsi/scsi_tgt_priv.h |   11 +++-
- include/scsi/scsi_host.h     |    3 +
- include/scsi/scsi_tgt.h      |    6 ++
- include/scsi/scsi_tgt_if.h   |    7 ++-
- 6 files changed, 125 insertions(+), 48 deletions(-)
-
-b9579b62f8d6309815a60da2e6f9a7638df074aa
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-index a31c8d5..ba1b75b 100644
---- a/drivers/scsi/scsi_tgt_if.c
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -56,7 +56,8 @@ static int send_event_rsp(uint16_t type,
- 	return netlink_unicast(nl_sk, skb, pid, 0);
- }
- 
--int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
-+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
-+			 gfp_t flags)
- {
- 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
- 	struct sk_buff *skb;
-@@ -71,7 +72,7 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	/*
- 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
- 	 */
--	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
-+	skb = alloc_skb(NLMSG_SPACE(len), flags);
- 	if (!skb)
- 		return -ENOMEM;
- 
-@@ -85,9 +86,11 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
- 	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
- 	ev->k.cmd_req.attribute = cmd->tag;
-+	ev->k.cmd_req.tag = tag;
- 
--	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
--		ev->k.cmd_req.data_len);
-+	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
-+		ev->k.cmd_req.data_len, cmd->tag,
-+		(unsigned long long) ev->k.cmd_req.tag);
- 
- 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
- 	if (err < 0)
-@@ -109,6 +112,24 @@ int scsi_tgt_uspace_send_status(struct s
- 	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
- }
- 
-+int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+				  struct scsi_lun *scsilun, void *data)
-+{
-+	struct tgt_event ev;
-+
-+	memset(&ev, 0, sizeof(ev));
-+	ev.k.tsk_mgmt_req.host_no = host_no;
-+	ev.k.tsk_mgmt_req.function = function;
-+	ev.k.tsk_mgmt_req.tag = tag;
-+	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
-+	ev.k.tsk_mgmt_req.mid = (u64) data;
-+
-+	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
-+		(unsigned long long) ev.k.tsk_mgmt_req.mid);
-+
-+	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
-+}
-+
- static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
- {
- 	struct tgt_event *ev = NLMSG_DATA(nlh);
-@@ -130,6 +151,11 @@ static int event_recv_msg(struct sk_buff
- 					   ev->u.cmd_rsp.uaddr,
- 					   ev->u.cmd_rsp.rw);
- 		break;
-+	case TGT_UEVENT_TSK_MGMT_RSP:
-+		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
-+					       ev->u.tsk_mgmt_rsp.mid,
-+					       ev->u.tsk_mgmt_rsp.result);
-+		break;
- 	default:
- 		eprintk("unknown type %d\n", nlh->nlmsg_type);
- 		err = -EINVAL;
-@@ -143,6 +169,7 @@ static int event_recv_skb(struct sk_buff
- 	int err;
- 	uint32_t rlen;
- 	struct nlmsghdr	*nlh;
-+	struct tgt_event ev;
- 
- 	while (skb->len >= NLMSG_SPACE(0)) {
- 		nlh = (struct nlmsghdr *) skb->data;
-@@ -158,9 +185,11 @@ static int event_recv_skb(struct sk_buff
- 		 * TODO for passthru commands the lower level should
- 		 * probably handle the result or we should modify this
- 		 */
--		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
--			struct tgt_event ev;
--
-+		switch (nlh->nlmsg_type) {
-+		case TGT_UEVENT_CMD_RSP:
-+		case TGT_UEVENT_TSK_MGMT_RSP:
-+			break;
-+		default:
- 			memset(&ev, 0, sizeof(ev));
- 			ev.k.event_rsp.err = err;
- 			send_event_rsp(TGT_KEVENT_RSP, &ev,
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 2cbc749..5a98fc4 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -49,6 +49,7 @@ struct scsi_tgt_cmd {
- 
- 	struct list_head hash_list;
- 	struct request *rq;
-+	u64 tag;
- };
- 
- #define TGT_HASH_ORDER	4
-@@ -106,7 +107,6 @@ static void scsi_tgt_cmd_destroy(void *d
- 		cmd->request->flags &= ~1UL;
- 
- 	scsi_unmap_user_pages(tcmd);
--	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
- 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
- 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
- }
-@@ -118,19 +118,11 @@ static void init_scsi_tgt_cmd(struct req
- 	struct list_head *head;
- 	static u32 tag = 0;
- 
--	tcmd->lun = rq->end_io_data;
--	bio_list_init(&tcmd->xfer_list);
--	bio_list_init(&tcmd->xfer_done_list);
--
- 	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
- 	rq->tag = tag++;
- 	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
- 	list_add(&tcmd->hash_list, head);
- 	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
--
--	tcmd->rq = rq;
--	rq->end_io_data = tcmd;
--	rq->flags |= REQ_DONTPREP;
- }
- 
- static void scsi_tgt_uspace_send_fn(void *data)
-@@ -148,33 +140,22 @@ retry:
- 	if (list_empty(&qdata->cmd_req))
- 		return;
- 
--	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
--	if (!tcmd) {
--		err = -ENOMEM;
--		goto out;
--	}
--
- 	mutex_lock(&qdata->cmd_req_mutex);
- 
- 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
- 	if (list_empty(&qdata->cmd_req)) {
- 		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 		mutex_unlock(&qdata->cmd_req_mutex);
--		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
- 		goto out;
- 	}
- 	rq = list_entry_rq(qdata->cmd_req.next);
- 	list_del_init(&rq->queuelist);
- 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 
--	if ((rq->flags & REQ_DONTPREP)) {
--		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
--		tcmd = rq->end_io_data;
--	} else
--		init_scsi_tgt_cmd(rq, tcmd);
--
-+	tcmd = rq->end_io_data;
-+	init_scsi_tgt_cmd(rq, tcmd);
- 	cmd = rq->special;
--	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
-+	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
- 	if (err < 0) {
- 		eprintk("failed to send: %p %d\n", cmd, err);
- 
-@@ -266,20 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
-  * @scsilun:	scsi lun
-  * @noblock:	set to nonzero if the command should be queued
-  **/
--void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
--			    int noblock)
-+int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-+			   u64 tag)
- {
- 	struct request_queue *q = cmd->request->q;
- 	struct scsi_tgt_queuedata *qdata = q->queuedata;
- 	unsigned long flags;
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	/*
-+	 * It would be better to allocate scsi_tgt_cmd structure in
-+	 * scsi_host_get_command and not to fail due to OOM.
-+	 */
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd)
-+		return -ENOMEM;
-+	cmd->request->end_io_data = tcmd;
- 
--	cmd->request->end_io_data = scsilun;
-+	bio_list_init(&tcmd->xfer_list);
-+	bio_list_init(&tcmd->xfer_done_list);
-+	tcmd->lun = scsilun;
-+	tcmd->tag = tag;
-+	tcmd->rq = cmd->request;
- 
- 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
- 	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
- 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 
- 	queue_work(scsi_tgtd, &qdata->uspace_send_work);
-+	return 0;
- }
- EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
- 
-@@ -293,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
- 
- 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
- 
--	/* don't we have to call this if result is set or not */
--	if (cmd->result) {
--		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
--		return;
--	}
--
-+	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
- 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
- 	queue_work(scsi_tgtd, &tcmd->work);
- }
-@@ -495,6 +486,18 @@ static int scsi_tgt_copy_sense(struct sc
- 	return 0;
- }
- 
-+static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
-+{
-+	int err;
-+
-+	err = host->hostt->eh_abort_handler(cmd);
-+	if (err)
-+		eprintk("fail to abort %p\n", cmd);
-+
-+	scsi_tgt_cmd_destroy(cmd);
-+	return err;
-+}
-+
- static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
- {
- 	struct scsi_tgt_queuedata *qdata = q->queuedata;
-@@ -545,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
- 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
- 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
- 
-+	if (result == TASK_ABORTED) {
-+		scsi_tgt_abort_cmd(shost, cmd);
-+		goto done;
-+	}
- 	/*
- 	 * store the userspace values here, the working values are
- 	 * in the request_* values
-@@ -585,6 +592,38 @@ done:
- 	return err;
- }
- 
-+int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
-+			      struct scsi_lun *scsilun, void *data)
-+{
-+	int err;
-+
-+	/* TODO: need to retry if this fails. */
-+	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
-+					    tag, scsilun, data);
-+	if (err < 0)
-+		eprintk("The task management request lost!\n");
-+	return err;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
-+
-+int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
-+{
-+	struct Scsi_Host *shost;
-+	int err;
-+
-+	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
-+
-+	shost = scsi_host_lookup(host_no);
-+	if (IS_ERR(shost)) {
-+		printk(KERN_ERR "Could not find host no %d\n", host_no);
-+		return -EINVAL;
-+	}
-+	err = shost->hostt->tsk_mgmt_response(mid, result);
-+	scsi_host_put(shost);
-+
-+	return err;
-+}
-+
- static int __init scsi_tgt_init(void)
- {
- 	int err;
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-index 6fedcec..77a1d06 100644
---- a/drivers/scsi/scsi_tgt_priv.h
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -4,18 +4,21 @@ struct Scsi_Host;
- struct task_struct;
- 
- /* tmp - will replace with SCSI logging stuff */
--#define dprintk(fmt, args...)					\
-+#define eprintk(fmt, args...)					\
- do {								\
- 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
- } while (0)
- 
--#define eprintk dprintk
-+#define dprintk eprintk
- 
- extern void scsi_tgt_if_exit(void);
- extern int scsi_tgt_if_init(void);
- 
--extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
-+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
-+				u64 tag, gfp_t flags);
- extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
- extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
- 				unsigned long uaddr, u8 rw);
--
-+extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+					 struct scsi_lun *scsilun, void *data);
-+extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8b799db..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -153,6 +153,9 @@ struct scsi_host_template {
- 	int (* transfer_data)(struct scsi_cmnd *,
- 			      void (*done)(struct scsi_cmnd *));
- 
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
- 	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-index 91ad6bc..2d65be7 100644
---- a/include/scsi/scsi_tgt.h
-+++ b/include/scsi/scsi_tgt.h
-@@ -6,6 +6,8 @@ struct Scsi_Host;
- struct scsi_cmnd;
- struct scsi_lun;
- 
--extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
- extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
--extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
-+extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index ebca452..63b2e3a 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -52,7 +52,7 @@ struct tgt_event {
- 		} cmd_rsp;
- 		struct {
- 			int host_no;
--			int mid;
-+			uint64_t mid;
- 			int result;
- 		} tsk_mgmt_rsp;
- 	} u;
-@@ -69,6 +69,7 @@ struct tgt_event {
- 			uint8_t scb[16];
- 			uint8_t lun[8];
- 			int attribute;
-+			uint64_t tag;
- 		} cmd_req;
- 		struct {
- 			int host_no;
-@@ -77,10 +78,10 @@ struct tgt_event {
- 		} cmd_done;
- 		struct {
- 			int host_no;
--			int mid;
-+			int function;
- 			uint64_t tag;
- 			uint8_t lun[8];
--			int function;
-+			uint64_t mid;
- 		} tsk_mgmt_req;
- 	} k;
- 
--- 
-1.1.3

Added: branches/use-scsi-ml/patchset/broken-out/srp/0001-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/srp/0001-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/srp/0001-ibmvscsi-convert-the-ibmvscsi-driver-to-use-include-scsi-srp.h.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -0,0 +1,582 @@
+Subject: [PATCH 1/2] ibmvscsi: convert the ibmvscsi driver to use include/scsi/srp.h
+From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
+
+---
+
+ drivers/scsi/ibmvscsi/ibmvscsi.c  |  247 +++++++++++++++++++------------------
+ drivers/scsi/ibmvscsi/ibmvscsi.h  |    2 
+ drivers/scsi/ibmvscsi/rpa_vscsi.c |    1 
+ drivers/scsi/ibmvscsi/viosrp.h    |   17 ++-
+ 4 files changed, 142 insertions(+), 125 deletions(-)
+
+74aa6fe8367e04be9cc7d0e7d16cc790754a73f3
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
+index eaefedd..e7bd028 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.c
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.c
+@@ -168,7 +168,7 @@ static void release_event_pool(struct ev
+ 			++in_use;
+ 		if (pool->events[i].ext_list) {
+ 			dma_free_coherent(hostdata->dev,
+-				  SG_ALL * sizeof(struct memory_descriptor),
++				  SG_ALL * sizeof(struct srp_direct_buf),
+ 				  pool->events[i].ext_list,
+ 				  pool->events[i].ext_list_token);
+ 		}
+@@ -284,40 +284,37 @@ static void set_srp_direction(struct scs
+ 			      struct srp_cmd *srp_cmd, 
+ 			      int numbuf)
+ {
++	u8 fmt;
++
+ 	if (numbuf == 0)
+ 		return;
+ 	
+-	if (numbuf == 1) {
++	if (numbuf == 1)
++		fmt = SRP_DATA_DESC_DIRECT;
++	else {
++		fmt = SRP_DATA_DESC_INDIRECT;
++		numbuf = min(numbuf, MAX_INDIRECT_BUFS);
++
+ 		if (cmd->sc_data_direction == DMA_TO_DEVICE)
+-			srp_cmd->data_out_format = SRP_DIRECT_BUFFER;
+-		else 
+-			srp_cmd->data_in_format = SRP_DIRECT_BUFFER;
+-	} else {
+-		if (cmd->sc_data_direction == DMA_TO_DEVICE) {
+-			srp_cmd->data_out_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_out_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		} else {
+-			srp_cmd->data_in_format = SRP_INDIRECT_BUFFER;
+-			srp_cmd->data_in_count =
+-				numbuf < MAX_INDIRECT_BUFS ?
+-					numbuf: MAX_INDIRECT_BUFS;
+-		}
++			srp_cmd->data_out_desc_cnt = numbuf;
++		else
++			srp_cmd->data_in_desc_cnt = numbuf;
+ 	}
++
++	if (cmd->sc_data_direction == DMA_TO_DEVICE)
++		srp_cmd->buf_fmt = fmt << 4;
++	else
++		srp_cmd->buf_fmt = fmt;
+ }
+ 
+-static void unmap_sg_list(int num_entries, 
++static void unmap_sg_list(int num_entries,
+ 		struct device *dev,
+-		struct memory_descriptor *md)
+-{ 
++		struct srp_direct_buf *md)
++{
+ 	int i;
+ 
+-	for (i = 0; i < num_entries; ++i) {
+-		dma_unmap_single(dev,
+-			md[i].virtual_address,
+-			md[i].length, DMA_BIDIRECTIONAL);
+-	}
++	for (i = 0; i < num_entries; ++i)
++		dma_unmap_single(dev, md[i].va, md[i].len, DMA_BIDIRECTIONAL);
+ }
+ 
+ /**
+@@ -330,23 +327,26 @@ static void unmap_cmd_data(struct srp_cm
+ 			   struct srp_event_struct *evt_struct,
+ 			   struct device *dev)
+ {
+-	if ((cmd->data_out_format == SRP_NO_BUFFER) &&
+-	    (cmd->data_in_format == SRP_NO_BUFFER))
++	u8 out_fmt, in_fmt;
++
++	out_fmt = cmd->buf_fmt >> 4;
++	in_fmt = cmd->buf_fmt & ((1U << 4) - 1);
++
++	if (out_fmt == SRP_NO_DATA_DESC && in_fmt == SRP_NO_DATA_DESC)
+ 		return;
+-	else if ((cmd->data_out_format == SRP_DIRECT_BUFFER) ||
+-		 (cmd->data_in_format == SRP_DIRECT_BUFFER)) {
+-		struct memory_descriptor *data =
+-			(struct memory_descriptor *)cmd->additional_data;
+-		dma_unmap_single(dev, data->virtual_address, data->length,
+-				 DMA_BIDIRECTIONAL);
++	else if (out_fmt == SRP_DATA_DESC_DIRECT ||
++		 in_fmt == SRP_DATA_DESC_DIRECT) {
++		struct srp_direct_buf *data =
++			(struct srp_direct_buf *) cmd->add_data;
++		dma_unmap_single(dev, data->va, data->len, DMA_BIDIRECTIONAL);
+ 	} else {
+-		struct indirect_descriptor *indirect =
+-			(struct indirect_descriptor *)cmd->additional_data;
+-		int num_mapped = indirect->head.length / 
+-			sizeof(indirect->list[0]);
++		struct srp_indirect_buf *indirect =
++			(struct srp_indirect_buf *) cmd->add_data;
++		int num_mapped = indirect->table_desc.len /
++			sizeof(struct srp_direct_buf);
+ 
+ 		if (num_mapped <= MAX_INDIRECT_BUFS) {
+-			unmap_sg_list(num_mapped, dev, &indirect->list[0]);
++			unmap_sg_list(num_mapped, dev, &indirect->desc_list[0]);
+ 			return;
+ 		}
+ 
+@@ -356,17 +356,17 @@ static void unmap_cmd_data(struct srp_cm
+ 
+ static int map_sg_list(int num_entries, 
+ 		       struct scatterlist *sg,
+-		       struct memory_descriptor *md)
++		       struct srp_direct_buf *md)
+ {
+ 	int i;
+ 	u64 total_length = 0;
+ 
+ 	for (i = 0; i < num_entries; ++i) {
+-		struct memory_descriptor *descr = md + i;
++		struct srp_direct_buf *descr = md + i;
+ 		struct scatterlist *sg_entry = &sg[i];
+-		descr->virtual_address = sg_dma_address(sg_entry);
+-		descr->length = sg_dma_len(sg_entry);
+-		descr->memory_handle = 0;
++		descr->va = sg_dma_address(sg_entry);
++		descr->len = sg_dma_len(sg_entry);
++		descr->key = 0;
+ 		total_length += sg_dma_len(sg_entry);
+  	}
+ 	return total_length;
+@@ -389,10 +389,10 @@ static int map_sg_data(struct scsi_cmnd 
+ 	int sg_mapped;
+ 	u64 total_length = 0;
+ 	struct scatterlist *sg = cmd->request_buffer;
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
+-	struct indirect_descriptor *indirect =
+-	    (struct indirect_descriptor *)data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
++	struct srp_indirect_buf *indirect =
++		(struct srp_indirect_buf *) data;
+ 
+ 	sg_mapped = dma_map_sg(dev, sg, cmd->use_sg, DMA_BIDIRECTIONAL);
+ 
+@@ -403,9 +403,9 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	/* special case; we can use a single direct descriptor */
+ 	if (sg_mapped == 1) {
+-		data->virtual_address = sg_dma_address(&sg[0]);
+-		data->length = sg_dma_len(&sg[0]);
+-		data->memory_handle = 0;
++		data->va = sg_dma_address(&sg[0]);
++		data->len = sg_dma_len(&sg[0]);
++		data->key = 0;
+ 		return 1;
+ 	}
+ 
+@@ -416,25 +416,26 @@ static int map_sg_data(struct scsi_cmnd 
+ 		return 0;
+ 	}
+ 
+-	indirect->head.virtual_address = 0;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	indirect->head.memory_handle = 0;
++	indirect->table_desc.va = 0;
++	indirect->table_desc.len = sg_mapped * sizeof(struct srp_direct_buf);
++	indirect->table_desc.key = 0;
+ 
+ 	if (sg_mapped <= MAX_INDIRECT_BUFS) {
+-		total_length = map_sg_list(sg_mapped, sg, &indirect->list[0]);
+-		indirect->total_length = total_length;
++		total_length = map_sg_list(sg_mapped, sg,
++					   &indirect->desc_list[0]);
++		indirect->len = total_length;
+ 		return 1;
+ 	}
+ 
+ 	/* get indirect table */
+ 	if (!evt_struct->ext_list) {
+-		evt_struct->ext_list =(struct memory_descriptor*)
++		evt_struct->ext_list = (struct srp_direct_buf *)
+ 			dma_alloc_coherent(dev, 
+-				SG_ALL * sizeof(struct memory_descriptor),
+-				&evt_struct->ext_list_token, 0);
++					   SG_ALL * sizeof(struct srp_direct_buf),
++					   &evt_struct->ext_list_token, 0);
+ 		if (!evt_struct->ext_list) {
+-		    printk(KERN_ERR
+-		   	"ibmvscsi: Can't allocate memory for indirect table\n");
++			printk(KERN_ERR
++			       "ibmvscsi: Can't allocate memory for indirect table\n");
+ 			return 0;
+ 			
+ 		}
+@@ -442,11 +443,11 @@ static int map_sg_data(struct scsi_cmnd 
+ 
+ 	total_length = map_sg_list(sg_mapped, sg, evt_struct->ext_list);	
+ 
+-	indirect->total_length = total_length;
+-	indirect->head.virtual_address = evt_struct->ext_list_token;
+-	indirect->head.length = sg_mapped * sizeof(indirect->list[0]);
+-	memcpy(indirect->list, evt_struct->ext_list,
+-		MAX_INDIRECT_BUFS * sizeof(struct memory_descriptor));
++	indirect->len = total_length;
++	indirect->table_desc.va = evt_struct->ext_list_token;
++	indirect->table_desc.len = sg_mapped * sizeof(indirect->desc_list[0]);
++	memcpy(indirect->desc_list, evt_struct->ext_list,
++	       MAX_INDIRECT_BUFS * sizeof(struct srp_direct_buf));
+ 	
+  	return 1;
+ }
+@@ -463,20 +464,20 @@ static int map_sg_data(struct scsi_cmnd 
+ static int map_single_data(struct scsi_cmnd *cmd,
+ 			   struct srp_cmd *srp_cmd, struct device *dev)
+ {
+-	struct memory_descriptor *data =
+-	    (struct memory_descriptor *)srp_cmd->additional_data;
++	struct srp_direct_buf *data =
++		(struct srp_direct_buf *) srp_cmd->add_data;
+ 
+-	data->virtual_address =
++	data->va =
+ 		dma_map_single(dev, cmd->request_buffer,
+ 			       cmd->request_bufflen,
+ 			       DMA_BIDIRECTIONAL);
+-	if (dma_mapping_error(data->virtual_address)) {
++	if (dma_mapping_error(data->va)) {
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Unable to map request_buffer for command!\n");
+ 		return 0;
+ 	}
+-	data->length = cmd->request_bufflen;
+-	data->memory_handle = 0;
++	data->len = cmd->request_bufflen;
++	data->key = 0;
+ 
+ 	set_srp_direction(cmd, srp_cmd, 1);
+ 
+@@ -548,7 +549,7 @@ static int ibmvscsi_send_srp_event(struc
+ 
+ 	/* Copy the IU into the transfer area */
+ 	*evt_struct->xfer_iu = evt_struct->iu;
+-	evt_struct->xfer_iu->srp.generic.tag = (u64)evt_struct;
++	evt_struct->xfer_iu->srp.rsp.tag = (u64)evt_struct;
+ 
+ 	/* Add this to the sent list.  We need to do this 
+ 	 * before we actually send 
+@@ -586,27 +587,27 @@ static void handle_cmd_rsp(struct srp_ev
+ 	struct srp_rsp *rsp = &evt_struct->xfer_iu->srp.rsp;
+ 	struct scsi_cmnd *cmnd = evt_struct->cmnd;
+ 
+-	if (unlikely(rsp->type != SRP_RSP_TYPE)) {
++	if (unlikely(rsp->opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: bad SRP RSP type %d\n",
+-			       rsp->type);
++			       rsp->opcode);
+ 	}
+ 	
+ 	if (cmnd) {
+ 		cmnd->result = rsp->status;
+ 		if (((cmnd->result >> 1) & 0x1f) == CHECK_CONDITION)
+ 			memcpy(cmnd->sense_buffer,
+-			       rsp->sense_and_response_data,
+-			       rsp->sense_data_list_length);
++			       rsp->data,
++			       rsp->sense_data_len);
+ 		unmap_cmd_data(&evt_struct->iu.srp.cmd, 
+ 			       evt_struct, 
+ 			       evt_struct->hostdata->dev);
+ 
+-		if (rsp->doover)
+-			cmnd->resid = rsp->data_out_residual_count;
+-		else if (rsp->diover)
+-			cmnd->resid = rsp->data_in_residual_count;
++		if (rsp->flags & SRP_RSP_FLAG_DOOVER)
++			cmnd->resid = rsp->data_out_res_cnt;
++		else if (rsp->flags & SRP_RSP_FLAG_DIOVER)
++			cmnd->resid = rsp->data_in_res_cnt;
+ 	}
+ 
+ 	if (evt_struct->cmnd_done)
+@@ -633,10 +634,11 @@ static int ibmvscsi_queuecommand(struct 
+ {
+ 	struct srp_cmd *srp_cmd;
+ 	struct srp_event_struct *evt_struct;
+-	struct indirect_descriptor *indirect;
++	struct srp_indirect_buf *indirect;
+ 	struct ibmvscsi_host_data *hostdata =
+ 		(struct ibmvscsi_host_data *)&cmnd->device->host->hostdata;
+ 	u16 lun = lun_from_dev(cmnd->device);
++	u8 out_fmt, in_fmt;
+ 
+ 	evt_struct = get_event_struct(&hostdata->pool);
+ 	if (!evt_struct)
+@@ -644,8 +646,8 @@ static int ibmvscsi_queuecommand(struct 
+ 
+ 	/* Set up the actual SRP IU */
+ 	srp_cmd = &evt_struct->iu.srp.cmd;
+-	memset(srp_cmd, 0x00, sizeof(*srp_cmd));
+-	srp_cmd->type = SRP_CMD_TYPE;
++	memset(srp_cmd, 0x00, SRP_MAX_IU_LEN);
++	srp_cmd->opcode = SRP_CMD;
+ 	memcpy(srp_cmd->cdb, cmnd->cmnd, sizeof(cmnd->cmnd));
+ 	srp_cmd->lun = ((u64) lun) << 48;
+ 
+@@ -664,13 +666,15 @@ static int ibmvscsi_queuecommand(struct 
+ 	evt_struct->cmnd_done = done;
+ 
+ 	/* Fix up dma address of the buffer itself */
+-	indirect = (struct indirect_descriptor *)srp_cmd->additional_data;
+-	if (((srp_cmd->data_out_format == SRP_INDIRECT_BUFFER) ||
+-	    (srp_cmd->data_in_format == SRP_INDIRECT_BUFFER)) &&
+-	    (indirect->head.virtual_address == 0)) {
+-		indirect->head.virtual_address = evt_struct->crq.IU_data_ptr +
+-		    offsetof(struct srp_cmd, additional_data) +
+-		    offsetof(struct indirect_descriptor, list);
++	indirect = (struct srp_indirect_buf *) srp_cmd->add_data;
++	out_fmt = srp_cmd->buf_fmt >> 4;
++	in_fmt = srp_cmd->buf_fmt & ((1U << 4) - 1);
++	if ((in_fmt == SRP_DATA_DESC_INDIRECT ||
++	     out_fmt == SRP_DATA_DESC_INDIRECT) &&
++	    indirect->table_desc.va == 0) {
++		indirect->table_desc.va = evt_struct->crq.IU_data_ptr +
++			offsetof(struct srp_cmd, add_data) +
++			offsetof(struct srp_indirect_buf, desc_list);
+ 	}
+ 
+ 	return ibmvscsi_send_srp_event(evt_struct, hostdata);
+@@ -780,10 +784,10 @@ static void send_mad_adapter_info(struct
+ static void login_rsp(struct srp_event_struct *evt_struct)
+ {
+ 	struct ibmvscsi_host_data *hostdata = evt_struct->hostdata;
+-	switch (evt_struct->xfer_iu->srp.generic.type) {
+-	case SRP_LOGIN_RSP_TYPE:	/* it worked! */
++	switch (evt_struct->xfer_iu->srp.login_rsp.opcode) {
++	case SRP_LOGIN_RSP:	/* it worked! */
+ 		break;
+-	case SRP_LOGIN_REJ_TYPE:	/* refused! */
++	case SRP_LOGIN_REJ:	/* refused! */
+ 		printk(KERN_INFO "ibmvscsi: SRP_LOGIN_REJ reason %u\n",
+ 		       evt_struct->xfer_iu->srp.login_rej.reason);
+ 		/* Login failed.  */
+@@ -792,7 +796,7 @@ static void login_rsp(struct srp_event_s
+ 	default:
+ 		printk(KERN_ERR
+ 		       "ibmvscsi: Invalid login response typecode 0x%02x!\n",
+-		       evt_struct->xfer_iu->srp.generic.type);
++		       evt_struct->xfer_iu->srp.login_rsp.opcode);
+ 		/* Login failed.  */
+ 		atomic_set(&hostdata->request_limit, -1);
+ 		return;
+@@ -800,17 +804,17 @@ static void login_rsp(struct srp_event_s
+ 
+ 	printk(KERN_INFO "ibmvscsi: SRP_LOGIN succeeded\n");
+ 
+-	if (evt_struct->xfer_iu->srp.login_rsp.request_limit_delta >
++	if (evt_struct->xfer_iu->srp.login_rsp.req_lim_delta >
+ 	    (max_requests - 2))
+-		evt_struct->xfer_iu->srp.login_rsp.request_limit_delta =
++		evt_struct->xfer_iu->srp.login_rsp.req_lim_delta =
+ 		    max_requests - 2;
+ 
+ 	/* Now we know what the real request-limit is */
+ 	atomic_set(&hostdata->request_limit,
+-		   evt_struct->xfer_iu->srp.login_rsp.request_limit_delta);
++		   evt_struct->xfer_iu->srp.login_rsp.req_lim_delta);
+ 
+ 	hostdata->host->can_queue =
+-	    evt_struct->xfer_iu->srp.login_rsp.request_limit_delta - 2;
++	    evt_struct->xfer_iu->srp.login_rsp.req_lim_delta - 2;
+ 
+ 	if (hostdata->host->can_queue < 1) {
+ 		printk(KERN_ERR "ibmvscsi: Invalid request_limit_delta\n");
+@@ -849,9 +853,9 @@ static int send_srp_login(struct ibmvscs
+ 
+ 	login = &evt_struct->iu.srp.login_req;
+ 	memset(login, 0x00, sizeof(struct srp_login_req));
+-	login->type = SRP_LOGIN_REQ_TYPE;
+-	login->max_requested_initiator_to_target_iulen = sizeof(union srp_iu);
+-	login->required_buffer_formats = 0x0006;
++	login->opcode = SRP_LOGIN_REQ;
++	login->req_it_iu_len = sizeof(union srp_iu);
++	login->req_buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
+ 	
+ 	/* Start out with a request limit of 1, since this is negotiated in
+ 	 * the login request we are just sending
+@@ -928,13 +932,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 	
+ 	/* Set up an abort SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x01;	/* ABORT TASK */
+-	tsk_mgmt->managed_task_tag = (u64) found_evt;
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_ABORT_TASK;
++	tsk_mgmt->task_tag = (u64) found_evt;
+ 
+ 	printk(KERN_INFO "ibmvscsi: aborting command. lun 0x%lx, tag 0x%lx\n",
+-	       tsk_mgmt->lun, tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->lun, tsk_mgmt->task_tag);
+ 
+ 	evt->sync_srp = &srp_rsp;
+ 	init_completion(&evt->comp);
+@@ -948,25 +952,25 @@ static int ibmvscsi_eh_abort_handler(str
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: abort bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+ 	if (rsp_rc) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+-		       "ibmvscsi: abort code %d for task tag 0x%lx\n",
++			       "ibmvscsi: abort code %d for task tag 0x%lx\n",
+ 			       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -987,13 +991,13 @@ static int ibmvscsi_eh_abort_handler(str
+ 		spin_unlock_irqrestore(hostdata->host->host_lock, flags);
+ 		printk(KERN_INFO
+ 		       "ibmvscsi: aborted task tag 0x%lx completed\n",
+-		       tsk_mgmt->managed_task_tag);
++		       tsk_mgmt->task_tag);
+ 		return SUCCESS;
+ 	}
+ 
+ 	printk(KERN_INFO
+ 	       "ibmvscsi: successfully aborted task tag 0x%lx\n",
+-	       tsk_mgmt->managed_task_tag);
++	       tsk_mgmt->task_tag);
+ 
+ 	cmd->result = (DID_ABORT << 16);
+ 	list_del(&found_evt->list);
+@@ -1040,9 +1044,9 @@ static int ibmvscsi_eh_device_reset_hand
+ 
+ 	/* Set up a lun reset SRP command */
+ 	memset(tsk_mgmt, 0x00, sizeof(*tsk_mgmt));
+-	tsk_mgmt->type = SRP_TSK_MGMT_TYPE;
++	tsk_mgmt->opcode = SRP_TSK_MGMT;
+ 	tsk_mgmt->lun = ((u64) lun) << 48;
+-	tsk_mgmt->task_mgmt_flags = 0x08;	/* LUN RESET */
++	tsk_mgmt->tsk_mgmt_func = SRP_TSK_LUN_RESET;
+ 
+ 	printk(KERN_INFO "ibmvscsi: resetting device. lun 0x%lx\n",
+ 	       tsk_mgmt->lun);
+@@ -1059,16 +1063,16 @@ static int ibmvscsi_eh_device_reset_hand
+ 	wait_for_completion(&evt->comp);
+ 
+ 	/* make sure we got a good response */
+-	if (unlikely(srp_rsp.srp.generic.type != SRP_RSP_TYPE)) {
++	if (unlikely(srp_rsp.srp.rsp.opcode != SRP_RSP)) {
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset bad SRP RSP type %d\n",
+-			       srp_rsp.srp.generic.type);
++			       srp_rsp.srp.rsp.opcode);
+ 		return FAILED;
+ 	}
+ 
+-	if (srp_rsp.srp.rsp.rspvalid)
+-		rsp_rc = *((int *)srp_rsp.srp.rsp.sense_and_response_data);
++	if (srp_rsp.srp.rsp.flags & SRP_RSP_FLAG_RSPVALID)
++		rsp_rc = *((int *)srp_rsp.srp.rsp.data);
+ 	else
+ 		rsp_rc = srp_rsp.srp.rsp.status;
+ 
+@@ -1076,8 +1080,7 @@ static int ibmvscsi_eh_device_reset_hand
+ 		if (printk_ratelimit())
+ 			printk(KERN_WARNING 
+ 			       "ibmvscsi: reset code %d for task tag 0x%lx\n",
+-		       rsp_rc,
+-			       tsk_mgmt->managed_task_tag);
++			       rsp_rc, tsk_mgmt->task_tag);
+ 		return FAILED;
+ 	}
+ 
+@@ -1226,7 +1229,7 @@ void ibmvscsi_handle_crq(struct viosrp_c
+ 	}
+ 
+ 	if (crq->format == VIOSRP_SRP_FORMAT)
+-		atomic_add(evt_struct->xfer_iu->srp.rsp.request_limit_delta,
++		atomic_add(evt_struct->xfer_iu->srp.rsp.req_lim_delta,
+ 			   &hostdata->request_limit);
+ 
+ 	if (evt_struct->done)
+diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.h b/drivers/scsi/ibmvscsi/ibmvscsi.h
+index 4550d71..5c6d935 100644
+--- a/drivers/scsi/ibmvscsi/ibmvscsi.h
++++ b/drivers/scsi/ibmvscsi/ibmvscsi.h
+@@ -68,7 +68,7 @@ struct srp_event_struct {
+ 	void (*cmnd_done) (struct scsi_cmnd *);
+ 	struct completion comp;
+ 	union viosrp_iu *sync_srp;
+-	struct memory_descriptor *ext_list;
++	struct srp_direct_buf *ext_list;
+ 	dma_addr_t ext_list_token;
+ };
+ 
+diff --git a/drivers/scsi/ibmvscsi/rpa_vscsi.c b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+index f47dd87..58aa530 100644
+--- a/drivers/scsi/ibmvscsi/rpa_vscsi.c
++++ b/drivers/scsi/ibmvscsi/rpa_vscsi.c
+@@ -34,7 +34,6 @@
+ #include <linux/dma-mapping.h>
+ #include <linux/interrupt.h>
+ #include "ibmvscsi.h"
+-#include "srp.h"
+ 
+ static char partition_name[97] = "UNKNOWN";
+ static unsigned int partition_number = -1;
+diff --git a/drivers/scsi/ibmvscsi/viosrp.h b/drivers/scsi/ibmvscsi/viosrp.h
+index 6a6bba8..90f1a61 100644
+--- a/drivers/scsi/ibmvscsi/viosrp.h
++++ b/drivers/scsi/ibmvscsi/viosrp.h
+@@ -33,7 +33,22 @@
+ /*****************************************************************************/
+ #ifndef VIOSRP_H
+ #define VIOSRP_H
+-#include "srp.h"
++#include <scsi/srp.h>
++
++#define SRP_VERSION "16.a"
++#define SRP_MAX_IU_LEN	256
++
++union srp_iu {
++	struct srp_login_req login_req;
++	struct srp_login_rsp login_rsp;
++	struct srp_login_rej login_rej;
++	struct srp_i_logout i_logout;
++	struct srp_t_logout t_logout;
++	struct srp_tsk_mgmt tsk_mgmt;
++	struct srp_cmd cmd;
++	struct srp_rsp rsp;
++	u8 reserved[SRP_MAX_IU_LEN];
++};
+ 
+ enum viosrp_crq_formats {
+ 	VIOSRP_SRP_FORMAT = 0x01,
+-- 
+1.1.5

Added: branches/use-scsi-ml/patchset/broken-out/srp/0002-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/srp/0002-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-07 01:39:11 UTC (rev 397)
+++ branches/use-scsi-ml/patchset/broken-out/srp/0002-ibmvscsi-remove-drivers-scsi-ibmvscsi-srp.h.txt	2006-04-08 01:22:48 UTC (rev 398)
@@ -0,0 +1,245 @@
+Subject: [PATCH 2/2] ibmvscsi: remove drivers/scsi/ibmvscsi/srp.h
+From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
+
+---
+
+ drivers/scsi/ibmvscsi/srp.h |  227 -------------------------------------------
+ 1 files changed, 0 insertions(+), 227 deletions(-)
+ delete mode 100644 drivers/scsi/ibmvscsi/srp.h
+
+acbd74e89dc7bcf4e2596800e46a19378db44641
+diff --git a/drivers/scsi/ibmvscsi/srp.h b/drivers/scsi/ibmvscsi/srp.h
+deleted file mode 100644
+index 7d8e4c4..0000000
+--- a/drivers/scsi/ibmvscsi/srp.h
++++ /dev/null
+@@ -1,227 +0,0 @@
+-/*****************************************************************************/
+-/* srp.h -- SCSI RDMA Protocol definitions                                   */
+-/*                                                                           */
+-/* Written By: Colin Devilbis, IBM Corporation                               */
+-/*                                                                           */
+-/* Copyright (C) 2003 IBM Corporation                                        */
+-/*                                                                           */
+-/* This program is free software; you can redistribute it and/or modify      */
+-/* it under the terms of the GNU General Public License as published by      */
+-/* the Free Software Foundation; either version 2 of the License, or         */
+-/* (at your option) any later version.                                       */
+-/*                                                                           */
+-/* This program is distributed in the hope that it will be useful,           */
+-/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+-/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+-/* GNU General Public License for more details.                              */
+-/*                                                                           */
+-/* You should have received a copy of the GNU General Public License         */
+-/* along with this program; if not, write to the Free Software               */
+-/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+-/*                                                                           */
+-/*                                                                           */
+-/* This file contains structures and definitions for the SCSI RDMA Protocol  */
+-/* (SRP) as defined in the T10 standard available at www.t10.org.  This      */
+-/* file was based on the 16a version of the standard                         */
+-/*                                                                           */
+-/*****************************************************************************/
+-#ifndef SRP_H
+-#define SRP_H
+-
+-#define SRP_VERSION "16.a"
+-
+-#define PACKED __attribute__((packed))
+-
+-enum srp_types {
+-	SRP_LOGIN_REQ_TYPE = 0x00,
+-	SRP_LOGIN_RSP_TYPE = 0xC0,
+-	SRP_LOGIN_REJ_TYPE = 0xC2,
+-	SRP_I_LOGOUT_TYPE = 0x03,
+-	SRP_T_LOGOUT_TYPE = 0x80,
+-	SRP_TSK_MGMT_TYPE = 0x01,
+-	SRP_CMD_TYPE = 0x02,
+-	SRP_RSP_TYPE = 0xC1,
+-	SRP_CRED_REQ_TYPE = 0x81,
+-	SRP_CRED_RSP_TYPE = 0x41,
+-	SRP_AER_REQ_TYPE = 0x82,
+-	SRP_AER_RSP_TYPE = 0x42
+-};
+-
+-enum srp_descriptor_formats {
+-	SRP_NO_BUFFER = 0x00,
+-	SRP_DIRECT_BUFFER = 0x01,
+-	SRP_INDIRECT_BUFFER = 0x02
+-};
+-
+-struct memory_descriptor {
+-	u64 virtual_address;
+-	u32 memory_handle;
+-	u32 length;
+-};
+-
+-struct indirect_descriptor {
+-	struct memory_descriptor head;
+-	u32 total_length;
+-	struct memory_descriptor list[1] PACKED;
+-};
+-
+-struct srp_generic {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_login_req {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 max_requested_initiator_to_target_iulen;
+-	u32 reserved2;
+-	u16 required_buffer_formats;
+-	u8 reserved3:6;
+-	u8 multi_channel_action:2;
+-	u8 reserved4;
+-	u32 reserved5;
+-	u8 initiator_port_identifier[16];
+-	u8 target_port_identifier[16];
+-};
+-
+-struct srp_login_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 max_initiator_to_target_iulen;
+-	u32 max_target_to_initiator_iulen;
+-	u16 supported_buffer_formats;
+-	u8 reserved2:6;
+-	u8 multi_channel_result:2;
+-	u8 reserved3;
+-	u8 reserved4[24];
+-};
+-
+-struct srp_login_rej {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-	u64 reserved2;
+-	u16 supported_buffer_formats;
+-	u8 reserved3[6];
+-};
+-
+-struct srp_i_logout {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_t_logout {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 reason;
+-	u64 tag;
+-};
+-
+-struct srp_tsk_mgmt {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4;
+-	u8 task_mgmt_flags;
+-	u8 reserved5;
+-	u64 managed_task_tag;
+-	u64 reserved6;
+-};
+-
+-struct srp_cmd {
+-	u8 type;
+-	u32 reserved1 PACKED;
+-	u8 data_out_format:4;
+-	u8 data_in_format:4;
+-	u8 data_out_count;
+-	u8 data_in_count;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun PACKED;
+-	u8 reserved3;
+-	u8 reserved4:5;
+-	u8 task_attribute:3;
+-	u8 reserved5;
+-	u8 additional_cdb_len;
+-	u8 cdb[16];
+-	u8 additional_data[0x100 - 0x30];
+-};
+-
+-struct srp_rsp {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u16 reserved2;
+-	u8 reserved3:2;
+-	u8 diunder:1;
+-	u8 diover:1;
+-	u8 dounder:1;
+-	u8 doover:1;
+-	u8 snsvalid:1;
+-	u8 rspvalid:1;
+-	u8 status;
+-	u32 data_in_residual_count;
+-	u32 data_out_residual_count;
+-	u32 sense_data_list_length;
+-	u32 response_data_list_length;
+-	u8 sense_and_response_data[18];
+-};
+-
+-struct srp_cred_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-};
+-
+-struct srp_cred_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-struct srp_aer_req {
+-	u8 type;
+-	u8 reserved1[3];
+-	u32 request_limit_delta;
+-	u64 tag;
+-	u32 reserved2;
+-	u64 lun;
+-	u32 sense_data_list_length;
+-	u32 reserved3;
+-	u8 sense_data[20];
+-};
+-
+-struct srp_aer_rsp {
+-	u8 type;
+-	u8 reserved1[7];
+-	u64 tag;
+-};
+-
+-union srp_iu {
+-	struct srp_generic generic;
+-	struct srp_login_req login_req;
+-	struct srp_login_rsp login_rsp;
+-	struct srp_login_rej login_rej;
+-	struct srp_i_logout i_logout;
+-	struct srp_t_logout t_logout;
+-	struct srp_tsk_mgmt tsk_mgmt;
+-	struct srp_cmd cmd;
+-	struct srp_rsp rsp;
+-	struct srp_cred_req cred_req;
+-	struct srp_cred_rsp cred_rsp;
+-	struct srp_aer_req aer_req;
+-	struct srp_aer_rsp aer_rsp;
+-};
+-
+-#endif
+-- 
+1.1.5



From tomo at berlios.de  Sat Apr  8 03:28:47 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 8 Apr 2006 03:28:47 +0200
Subject: [Stgt-svn] r399 - branches/use-scsi-ml/patchset/broken-out
Message-ID: <200604080128.k381SlH7017738@sheep.berlios.de>

Author: tomo
Date: 2006-04-08 03:28:40 +0200 (Sat, 08 Apr 2006)
New Revision: 399

Modified:
   branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
Log:
Update the patchset for the submission again.

Modified: branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-08 01:22:48 UTC (rev 398)
+++ branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-08 01:28:40 UTC (rev 399)
@@ -5,6 +5,10 @@
 Remove blk_queue_end_tag() in scsi_host_put_command() because tgt
 doesn't use the elevator code.
 
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
 ---
 
  drivers/scsi/scsi.c |    2 --



From tomo at berlios.de  Sat Apr  8 13:17:28 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 8 Apr 2006 13:17:28 +0200
Subject: [Stgt-svn] r400 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604081117.k38BHS0B014729@sheep.berlios.de>

Author: tomo
Date: 2006-04-08 13:17:20 +0200 (Sat, 08 Apr 2006)
New Revision: 400

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Fix the data_out_desc_size() bug.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-08 01:28:40 UTC (rev 399)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-08 11:17:20 UTC (rev 400)
@@ -266,7 +266,7 @@
 		break;
 	case SRP_DATA_DESC_INDIRECT:
 		size = sizeof(struct srp_indirect_buf) +
-			sizeof(struct srp_direct_buf) * (cmd->data_out_desc_cnt - 1);
+			sizeof(struct srp_direct_buf) * cmd->data_out_desc_cnt;
 		break;
 	default:
 		eprintk("client error. Invalid data_out_format %x\n", fmt);



From tomo at berlios.de  Sat Apr  8 13:18:01 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 8 Apr 2006 13:18:01 +0200
Subject: [Stgt-svn] r401 - branches/use-scsi-ml/ibmvstgt
Message-ID: <200604081118.k38BI1ql014889@sheep.berlios.de>

Author: tomo
Date: 2006-04-08 13:17:57 +0200 (Sat, 08 Apr 2006)
New Revision: 401

Modified:
   branches/use-scsi-ml/ibmvstgt/Makefile
Log:
Fix ibmvstgt Makefile.

Modified: branches/use-scsi-ml/ibmvstgt/Makefile
===================================================================
--- branches/use-scsi-ml/ibmvstgt/Makefile	2006-04-08 11:17:20 UTC (rev 400)
+++ branches/use-scsi-ml/ibmvstgt/Makefile	2006-04-08 11:17:57 UTC (rev 401)
@@ -4,7 +4,7 @@
 	KERNELSRC ?= /lib/modules/$(shell uname -r)/build
 endif
 
-all: mods usr
+all: mods libs
 
 mods:
 	$(MAKE) -C $(KERNELSRC) SUBDIRS=$(shell pwd)/kernel modules



From tomo at berlios.de  Fri Apr 14 04:54:04 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 04:54:04 +0200
Subject: [Stgt-svn] r402 - in branches/use-scsi-ml: . patchset patchset/broken-out
Message-ID: <200604140254.k3E2s4R9002376@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 04:53:14 +0200 (Fri, 14 Apr 2006)
New Revision: 402

Removed:
   branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
   branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
   branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
   branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
   branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
   branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
   branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
   branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
Modified:
   branches/use-scsi-ml/README
   branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
Log:
The patchset was merged into the scsi-target-2.6 tree.


Modified: branches/use-scsi-ml/README
===================================================================
--- branches/use-scsi-ml/README	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/README	2006-04-14 02:53:14 UTC (rev 402)
@@ -16,9 +16,11 @@
 
 master.kernel.org:/pub/scm/linux/kernel/git/jejb/scsi-target-2.6.git
 
-Next, apply scsi-target-2.6-tree.diff in the patchset directory,
-rebuild the kernel, and reboot with the new kernel.
+Second, if you use ibmvstgt, apply scsi-target-2.6-tree.diff in the
+patchset directory. If not, you can skip this.
 
+Third, rebuild the kernel, and reboot with the new kernel.
+
 The compilation of the kernel modules require the path to above kernel
 source:
 

Deleted: branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0001-block-layer-revoke-the-original-patch-to-add-partial-mappings-support.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,130 +0,0 @@
-Subject: [PATCH 01/10] block layer: revoke the original patch to add partial mappings support
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409079 +0900
-
-For target mode we could end up with the case where we get very large
-request from the initiator. The request could be so large that we
-cannot transfer all the data in one operation. For example the
-HBA's segment or max_sector limits might limit us to a 1 MB transfer.
-To send a 5 MB command then we need to transfer the command chunk by chunk.
-
-To do this, tgt core will map in as much data as possible into a bio,
-send this off, then when that transfer is completed we send off another
-request/bio. To be able to pack as much data into a bio as possible
-we need bio_map_user to support partially mapped bios.
-
-Following the comments from Jens Axboe on the original patch:
-
-http://marc.theaimsgroup.com/?l=linux-scsi&m=114012008928530&w=2
-
-This patch will revoke changes by the original patch.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- block/ll_rw_blk.c   |    5 ++---
- fs/bio.c            |   11 ++++-------
- include/linux/bio.h |    5 ++---
- 3 files changed, 8 insertions(+), 13 deletions(-)
-
-4d84a7a7218de12ef1e3f58a0a5514a730994848
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 13c40a0..03d9c82 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2287,7 +2287,7 @@ int blk_rq_map_user(request_queue_t *q, 
- 	 */
- 	uaddr = (unsigned long) ubuf;
- 	if (!(uaddr & queue_dma_alignment(q)) && !(len & queue_dma_alignment(q)))
--		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
-+		bio = bio_map_user(q, NULL, uaddr, len, reading);
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
-@@ -2339,8 +2339,7 @@ int blk_rq_map_user_iov(request_queue_t 
- 	/* we don't allow misaligned data like bio_map_user() does.  If the
- 	 * user is using sg, they're expected to know the alignment constraints
- 	 * and respect them accordingly */
--	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
--				0);
-+	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-diff --git a/fs/bio.c b/fs/bio.c
-index 3e940c9..d8259d9 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
-  *	@uaddr: start of user address
-  *	@len: length in bytes
-  *	@write_to_vm: bool indicating writing to pages or not
-- *	@support_partial: support partial mappings
-  *
-  *	Map the user space address into a bio suitable for io to a block
-  *	device. Returns an error pointer in case of error.
-  */
- struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
--			 unsigned long uaddr, unsigned int len, int write_to_vm,
--			 int support_partial)
-+			 unsigned long uaddr, unsigned int len, int write_to_vm)
- {
- 	struct sg_iovec iov;
- 
- 	iov.iov_base = (void __user *)uaddr;
- 	iov.iov_len = len;
- 
--	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm, support_partial);
-+	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm);
- }
- 
- /**
-@@ -742,14 +740,13 @@ struct bio *bio_map_user(request_queue_t
-  *	@iov:	the iovec.
-  *	@iov_count: number of elements in the iovec
-  *	@write_to_vm: bool indicating writing to pages or not
-- *	@support_partial: support partial mappings
-  *
-  *	Map the user space address into a bio suitable for io to a block
-  *	device. Returns an error pointer in case of error.
-  */
- struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
- 			     struct sg_iovec *iov, int iov_count,
--			     int write_to_vm, int support_partial)
-+			     int write_to_vm)
- {
- 	struct bio *bio;
- 	int len = 0, i;
-@@ -770,7 +767,7 @@ struct bio *bio_map_user_iov(request_que
- 	for (i = 0; i < iov_count; i++)
- 		len += iov[i].iov_len;
- 
--	if (bio->bi_size == len || support_partial)
-+	if (bio->bi_size == len)
- 		return bio;
- 
- 	/*
-diff --git a/include/linux/bio.h b/include/linux/bio.h
-index fc0906c..b60ffe3 100644
---- a/include/linux/bio.h
-+++ b/include/linux/bio.h
-@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
- extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
- 			   unsigned int, unsigned int);
- extern int bio_get_nr_vecs(struct block_device *);
--extern int __bio_get_nr_vecs(struct request_queue *);
- extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
--				unsigned long, unsigned int, int, int);
-+				unsigned long, unsigned int, int);
- struct sg_iovec;
- extern struct bio *bio_map_user_iov(struct request_queue *,
- 				    struct block_device *,
--				    struct sg_iovec *, int, int, int);
-+				    struct sg_iovec *, int, int);
- extern void bio_unmap_user(struct bio *);
- extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
- 				gfp_t);
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0002-block-layer-add-partial-mappings-support-to-bio_map_user.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,149 +0,0 @@
-Subject: [PATCH 02/10] block layer: add partial mappings support to bio_map_user
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409163 +0900
-
-This is the updated patch for partial mappings support.
-
-- bio_map_user_iov always allows partial mappings.
-
-- The two users (blk_rq_map_user and blk_rq_map_user_iov) will fails
-if the bio is partially mapped.
-
-- Added a length argument to blk_rq_map_user_iov in order to avoid
-including sg.h in ll_rw_blk.c for struct sg_iovec.
-
-This is a resend:
-
-http://marc.theaimsgroup.com/?l=linux-scsi&m=114086655400806&w=2
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- block/ll_rw_blk.c      |   29 ++++++++++++++++++-----------
- block/scsi_ioctl.c     |    3 ++-
- fs/bio.c               |   14 +-------------
- include/linux/blkdev.h |    3 ++-
- 4 files changed, 23 insertions(+), 26 deletions(-)
-
-d43dcc5c747b5896c795e1fe1f8a6d5df525daa6
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 03d9c82..6849859 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2291,19 +2291,20 @@ int blk_rq_map_user(request_queue_t *q, 
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq->bio = rq->biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq->buffer = rq->data = NULL;
--		rq->data_len = len;
--		return 0;
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq->bio = rq->biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq->buffer = rq->data = NULL;
-+	rq->data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2343,6 +2344,12 @@ int blk_rq_map_user_iov(request_queue_t 
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq->bio = rq->biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq->buffer = rq->data = NULL;
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
-+					  hdr->dxfer_len);
- 		kfree(iov);
- 	} else if (hdr->dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
-diff --git a/fs/bio.c b/fs/bio.c
-index d8259d9..f51a873 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -749,7 +749,6 @@ struct bio *bio_map_user_iov(request_que
- 			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -764,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i < iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio->bi_size == len)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio->bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0003-scsi-tgt-use-the-original-bio_map_user-interface.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,28 +0,0 @@
-Subject: [PATCH 03/10] scsi tgt: use the original bio_map_user interface
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409283 +0900
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_lib.c |    2 +-
- 1 files changed, 1 insertions(+), 1 deletions(-)
-
-2c78c6353dc183a16ef3e12b9c5618dd5b89679c
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 8746236..941dd64 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
- 
- 	while (len > 0) {
- 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
--		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
-+		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
- 		if (IS_ERR(bio)) {
- 			err = PTR_ERR(bio);
- 			dprintk("fail to map %lx %u %d %x\n",
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0004-block-layer-use-blk_rq_bio_prep-in-init_request_from_bio.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,54 +0,0 @@
-Subject: [PATCH 04/10] block layer: use blk_rq_bio_prep in init_request_from_bio
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409371 +0900
-
-Patch to use blk_rq_bio_prep in init_request_from_bio. And remove
-blk_rq_bio_prep's flags copying. The first three bits have not been
-the same for some time so that has been broken. The user of
-blk_rq_bio_prep will setup the request flags so if it wanted failfast
-or to be a barrier it will set the correct flag itself.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- block/ll_rw_blk.c |   11 ++---------
- 1 files changed, 2 insertions(+), 9 deletions(-)
-
-4b387c65f0645e86794c06eb3e734b0ec6e5733c
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 13c40a0..da2c57d 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2765,16 +2765,12 @@ static void init_request_from_bio(struct
- 
- 	req->errors = 0;
- 	req->hard_sector = req->sector = bio->bi_sector;
--	req->hard_nr_sectors = req->nr_sectors = bio_sectors(bio);
--	req->current_nr_sectors = req->hard_cur_sectors = bio_cur_sectors(bio);
--	req->nr_phys_segments = bio_phys_segments(req->q, bio);
--	req->nr_hw_segments = bio_hw_segments(req->q, bio);
--	req->buffer = bio_data(bio);	/* see ->buffer comment above */
- 	req->waiting = NULL;
--	req->bio = req->biotail = bio;
- 	req->ioprio = bio_prio(bio);
- 	req->rq_disk = bio->bi_bdev->bd_disk;
- 	req->start_time = jiffies;
-+
-+	blk_rq_bio_prep(req->q, req, bio);
- }
- 
- static int __make_request(request_queue_t *q, struct bio *bio)
-@@ -3403,9 +3399,6 @@ EXPORT_SYMBOL(end_request);
- 
- void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
- {
--	/* first three bits are identical in rq->flags and bio->bi_rw */
--	rq->flags |= (bio->bi_rw & 7);
--
- 	rq->nr_phys_segments = bio_phys_segments(q, bio);
- 	rq->nr_hw_segments = bio_hw_segments(q, bio);
- 	rq->current_nr_sectors = bio_cur_sectors(bio);
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0005-scsi-tgt-kernel-user-interface-changes.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,293 +0,0 @@
-Subject: [PATCH 05/10] scsi tgt: kernel/user interface changes
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409611 +0900
-
-- merge the tgt command structure with the the event structure for simplicity.
-- add a new event type for task management.
-- remove some of unused event types.
-- send task attributes to user-space daemon.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_if.c   |   52 ++++++++++++++++++------------------------
- drivers/scsi/scsi_tgt_lib.c  |   10 ++++----
- drivers/scsi/scsi_tgt_priv.h |    4 ++-
- include/scsi/scsi_tgt_if.h   |   50 ++++++++++++++++++++--------------------
- 4 files changed, 54 insertions(+), 62 deletions(-)
-
-5804be31dad9a5ca05bef0ff2674cde90299ac3d
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-index 38b35da..a31c8d5 100644
---- a/drivers/scsi/scsi_tgt_if.c
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -35,15 +35,15 @@
- static int tgtd_pid;
- static struct sock *nl_sk;
- 
--static int send_event_res(uint16_t type, struct tgt_event *p,
--			  void *data, int dlen, gfp_t flags, pid_t pid)
-+static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
-+			  pid_t pid)
- {
- 	struct tgt_event *ev;
- 	struct nlmsghdr *nlh;
- 	struct sk_buff *skb;
- 	uint32_t len;
- 
--	len = NLMSG_SPACE(sizeof(*ev) + dlen);
-+	len = NLMSG_SPACE(sizeof(*ev));
- 	skb = alloc_skb(len, flags);
- 	if (!skb)
- 		return -ENOMEM;
-@@ -52,8 +52,6 @@ static int send_event_res(uint16_t type,
- 
- 	ev = NLMSG_DATA(nlh);
- 	memcpy(ev, p, sizeof(*ev));
--	if (dlen)
--		memcpy(ev->data, data, dlen);
- 
- 	return netlink_unicast(nl_sk, skb, pid, 0);
- }
-@@ -64,10 +62,12 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	struct sk_buff *skb;
- 	struct nlmsghdr *nlh;
- 	struct tgt_event *ev;
--	struct tgt_cmd *tcmd;
- 	int err, len;
- 
--	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
-+	/* FIXME: we need scsi core to do that. */
-+	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
- 	/*
- 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
- 	 */
-@@ -82,17 +82,13 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	ev->k.cmd_req.host_no = shost->host_no;
- 	ev->k.cmd_req.cid = cmd->request->tag;
- 	ev->k.cmd_req.data_len = cmd->request_bufflen;
-+	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
-+	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
-+	ev->k.cmd_req.attribute = cmd->tag;
- 
- 	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
- 		ev->k.cmd_req.data_len);
- 
--	/* FIXME: we need scsi core to do that. */
--	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
--
--	tcmd = (struct tgt_cmd *) ev->data;
--	memcpy(tcmd->scb, cmd->cmnd, sizeof(tcmd->scb));
--	memcpy(tcmd->lun, lun, sizeof(struct scsi_lun));
--
- 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
- 	if (err < 0)
- 		printk(KERN_ERR "scsi_tgt_uspace_send: could not send skb %d\n",
-@@ -104,15 +100,13 @@ int scsi_tgt_uspace_send_status(struct s
- {
- 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
- 	struct tgt_event ev;
--	char dummy[sizeof(struct tgt_cmd)];
- 
- 	memset(&ev, 0, sizeof(ev));
- 	ev.k.cmd_done.host_no = shost->host_no;
- 	ev.k.cmd_done.cid = cmd->request->tag;
- 	ev.k.cmd_done.result = cmd->result;
- 
--	return send_event_res(TGT_KEVENT_CMD_DONE, &ev, dummy, sizeof(dummy),
--			      gfp_mask, tgtd_pid);
-+	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
- }
- 
- static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
-@@ -124,19 +118,17 @@ static int event_recv_msg(struct sk_buff
- 		nlh->nlmsg_pid, current->pid);
- 
- 	switch (nlh->nlmsg_type) {
--	case TGT_UEVENT_TGTD_BIND:
-+	case TGT_UEVENT_REQ:
- 		tgtd_pid = NETLINK_CREDS(skb)->pid;
- 		break;
--	case TGT_UEVENT_CMD_RES:
-+	case TGT_UEVENT_CMD_RSP:
- 		/* TODO: handle multiple cmds in one event */
--		err = scsi_tgt_kspace_exec(ev->u.cmd_res.host_no,
--					   ev->u.cmd_res.cid,
--					   ev->u.cmd_res.result,
--					   ev->u.cmd_res.len,
--					   ev->u.cmd_res.offset,
--					   ev->u.cmd_res.uaddr,
--					   ev->u.cmd_res.rw,
--					   ev->u.cmd_res.try_map);
-+		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
-+					   ev->u.cmd_rsp.cid,
-+					   ev->u.cmd_rsp.result,
-+					   ev->u.cmd_rsp.len,
-+					   ev->u.cmd_rsp.uaddr,
-+					   ev->u.cmd_rsp.rw);
- 		break;
- 	default:
- 		eprintk("unknown type %d\n", nlh->nlmsg_type);
-@@ -166,12 +158,12 @@ static int event_recv_skb(struct sk_buff
- 		 * TODO for passthru commands the lower level should
- 		 * probably handle the result or we should modify this
- 		 */
--		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RES) {
-+		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
- 			struct tgt_event ev;
- 
- 			memset(&ev, 0, sizeof(ev));
--			ev.k.event_res.err = err;
--			send_event_res(TGT_KEVENT_RESPONSE, &ev, NULL, 0,
-+			ev.k.event_rsp.err = err;
-+			send_event_rsp(TGT_KEVENT_RSP, &ev,
- 				       GFP_KERNEL | __GFP_NOFAIL,
- 					nlh->nlmsg_pid);
- 		}
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 8746236..3549e7c 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -315,7 +315,7 @@ static int scsi_map_user_pages(struct sc
- 
- 	while (len > 0) {
- 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
--		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
-+		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
- 		if (IS_ERR(bio)) {
- 			err = PTR_ERR(bio);
- 			dprintk("fail to map %lx %u %d %x\n",
-@@ -438,16 +438,16 @@ static int scsi_tgt_copy_sense(struct sc
- 	return 0;
- }
- 
--int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
--			 unsigned long uaddr, u8 rw, u8 try_map)
-+int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+			 unsigned long uaddr, u8 rw)
- {
- 	struct Scsi_Host *shost;
- 	struct scsi_cmnd *cmd;
- 	struct request *rq;
- 	int err = 0;
- 
--	dprintk("%d %u %d %u %llu %lx %u %u\n", host_no, cid, result,
--		len, (unsigned long long) offset, uaddr, rw, try_map);
-+	dprintk("%d %u %d %u %lx %u\n", host_no, cid, result,
-+		len, uaddr, rw);
- 
- 	/* TODO: replace with a O(1) alg */
- 	shost = scsi_host_lookup(host_no);
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-index 4236e50..fcf2ec6 100644
---- a/drivers/scsi/scsi_tgt_priv.h
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -21,5 +21,5 @@ extern int scsi_tgt_if_init(void);
- extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
- extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
- extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
--				u64 offset, unsigned long uaddr, u8 rw,
--				u8 try_map);
-+				unsigned long uaddr, u8 rw);
-+
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index da3a808..ebca452 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -24,65 +24,65 @@
- 
- enum tgt_event_type {
- 	/* user -> kernel */
--	TGT_UEVENT_TGTD_BIND,
--	TGT_UEVENT_TARGET_SETUP,
--	TGT_UEVENT_CMD_RES,
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
- 
- 	/* kernel -> user */
--	TGT_KEVENT_RESPONSE,
-+	TGT_KEVENT_RSP,
- 	TGT_KEVENT_CMD_REQ,
- 	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
- };
- 
- struct tgt_event {
- 	/* user-> kernel */
- 	union {
- 		struct {
--			int pk_fd;
--		} tgtd_bind;
-+			int type;
-+			int host_no;
-+		} event_req;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			uint32_t len;
- 			int result;
- 			uint64_t uaddr;
--			uint64_t offset;
- 			uint8_t rw;
--			uint8_t try_map;
--		} cmd_res;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			int mid;
-+			int result;
-+		} tsk_mgmt_rsp;
- 	} u;
- 
- 	/* kernel -> user */
- 	union {
- 		struct {
- 			int err;
--		} event_res;
-+		} event_rsp;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			uint32_t data_len;
--			uint64_t dev_id;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
- 		} cmd_req;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			int result;
- 		} cmd_done;
-+		struct {
-+			int host_no;
-+			int mid;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			int function;
-+		} tsk_mgmt_req;
- 	} k;
- 
--	/*
--	 * I think a pointer is a unsigned long but this struct
--	 * gets passed around from the kernel to userspace and
--	 * back again so to handle some ppc64 setups where userspace is
--	 * 32 bits but the kernel is 64 we do this odd thing
--	 */
--	uint64_t data[0];
--} __attribute__ ((aligned (sizeof(uint64_t))));
--
--struct tgt_cmd {
--	uint8_t scb[16];
--	uint8_t lun[8];
--	int tags;
- } __attribute__ ((aligned (sizeof(uint64_t))));
--
- #endif
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0006-scsi-tgt-fix-double-lock-in-scsi_uspace_request_fn.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,28 +0,0 @@
-Subject: [PATCH 06/10] scsi tgt: fix double lock in scsi_uspace_request_fn
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142409678 +0900
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_lib.c |    2 +-
- 1 files changed, 1 insertions(+), 1 deletions(-)
-
-1ddfd113a764450e7998cc16dd07dcc37077b05b
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 8746236..5d76078 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -136,7 +136,7 @@ requeue:
- 	spin_lock_irq(q->queue_lock);
- 	/* need to track cnts and plug */
- 	blk_requeue_request(q, rq);
--	spin_lock_irq(q->queue_lock);
-+	spin_unlock_irq(q->queue_lock);
- }
- 
- /**
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0007-scsi-tgt-remove-blk_queue_end_tag.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,32 +0,0 @@
-Subject: [PATCH 07/10] scsi tgt: remove blk_queue_end_tag
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142422083 +0900
-
-Remove blk_queue_end_tag() in scsi_host_put_command() because tgt
-doesn't use the elevator code.
-
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi.c |    2 --
- 1 files changed, 0 insertions(+), 2 deletions(-)
-
-fd45c05acbc00cd21fa7c82f6aed5a5ef3e5b98a
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index 3cf02b1..9c22465 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
- 	spin_unlock(&shost->free_list_lock);
- 
- 	spin_lock(q->queue_lock);
--	if (blk_rq_tagged(rq))
--		blk_queue_end_tag(q, rq);
- 	__blk_put_request(q, rq);
- 	spin_unlock_irqrestore(q->queue_lock, flags);
- 
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/broken-out/0008-scsi-tgt-replace-the-elevator-code.txt	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,340 +0,0 @@
-Subject: [PATCH 08/10] scsi tgt: replace the elevator code
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1142464394 +0900
-
-tgt uses the elevator code to send SCSI commands to the user-space
-daemon (q->request_fn sends netlink packets including commands).
-
-This patch replaces the elevator code with a simple list.
-
-This is mainly because tgt also needs to send TMF requests to the
-user-space daemon (the daemon does all the SCSI state machine
-stuff). tgt must send SCSI commands and TMF requests in an exact order
-so that it would be preferable to use a single queue (per host) for
-both. To uses the elevator code for TMF requests, tgt needs to
-allocate request structures for them. That's wasteful because request
-structures is useless for TMF requests, which don't perform any I/Os.
-
-We basically have a netdev queue of events to send to userspace so by
-using the request_queue and netdev queue we are basically double
-queueing and wasting resources and it is affecting performance
-
-We like to use shared memory stuff between kernel and user spaces
-instead of netlink in the future. These queues would go away.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_lib.c  |  180 ++++++++++++++++++++++++++++++------------
- drivers/scsi/scsi_tgt_priv.h |    4 -
- 2 files changed, 129 insertions(+), 55 deletions(-)
-
-c4bb05742e1834d664a7d8e721ecea71d42fd7f7
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 274d929..2cbc749 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -20,7 +20,7 @@
-  * 02110-1301 USA
-  */
- #include <linux/blkdev.h>
--#include <linux/elevator.h>
-+#include <linux/hash.h>
- #include <linux/module.h>
- #include <linux/pagemap.h>
- #include <scsi/scsi.h>
-@@ -46,6 +46,24 @@ struct scsi_tgt_cmd {
- 	struct bio_list xfer_done_list;
- 	struct bio_list xfer_list;
- 	struct scsi_lun *lun;
-+
-+	struct list_head hash_list;
-+	struct request *rq;
-+};
-+
-+#define TGT_HASH_ORDER	4
-+#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
-+
-+struct scsi_tgt_queuedata {
-+	struct Scsi_Host *shost;
-+	struct list_head cmd_hash[1 << TGT_HASH_ORDER];
-+	spinlock_t cmd_hash_lock;
-+
-+	struct work_struct uspace_send_work;
-+
-+	spinlock_t cmd_req_lock;
-+	struct mutex cmd_req_mutex;
-+	struct list_head cmd_req;
- };
- 
- static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
-@@ -68,9 +86,16 @@ static void scsi_tgt_cmd_destroy(void *d
- {
- 	struct scsi_cmnd *cmd = data;
- 	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
-+	struct scsi_tgt_queuedata *qdata = cmd->request->q->queuedata;
-+	unsigned long flags;
- 
- 	dprintk("cmd %p %d %lu\n", cmd, cmd->sc_data_direction,
- 		rq_data_dir(cmd->request));
-+
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	list_del(&tcmd->hash_list);
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
-+
- 	/*
- 	 * We must set rq->flags here because bio_map_user and
- 	 * blk_rq_bio_prep ruined ti.
-@@ -88,55 +113,84 @@ static void scsi_tgt_cmd_destroy(void *d
- 
- static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
- {
-+	struct scsi_tgt_queuedata *qdata = rq->q->queuedata;
-+	unsigned long flags;
-+	struct list_head *head;
-+	static u32 tag = 0;
-+
- 	tcmd->lun = rq->end_io_data;
- 	bio_list_init(&tcmd->xfer_list);
- 	bio_list_init(&tcmd->xfer_done_list);
--}
--
--static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
--{
--	struct scsi_tgt_cmd *tcmd;
- 
--	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
--	if (!tcmd)
--		return BLKPREP_DEFER;
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	rq->tag = tag++;
-+	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
-+	list_add(&tcmd->hash_list, head);
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
- 
--	init_scsi_tgt_cmd(rq, tcmd);
-+	tcmd->rq = rq;
- 	rq->end_io_data = tcmd;
- 	rq->flags |= REQ_DONTPREP;
--	return BLKPREP_OK;
- }
- 
--static void scsi_uspace_request_fn(struct request_queue *q)
-+static void scsi_tgt_uspace_send_fn(void *data)
- {
-+	struct request_queue *q = data;
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
- 	struct request *rq;
- 	struct scsi_cmnd *cmd;
- 	struct scsi_tgt_cmd *tcmd;
-+	unsigned long flags;
-+	int err;
- 
--	/*
--	 * TODO: just send everthing in the queue to userspace in
--	 * one vector instead of multiple calls
--	 */
--	while ((rq = elv_next_request(q)) != NULL) {
--		cmd = rq->special;
--		tcmd = rq->end_io_data;
-+retry:
-+	err = 0;
-+	if (list_empty(&qdata->cmd_req))
-+		return;
- 
--		/* the completion code kicks us in case we hit this */
--		if (blk_queue_start_tag(q, rq))
--			break;
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd) {
-+		err = -ENOMEM;
-+		goto out;
-+	}
-+
-+	mutex_lock(&qdata->cmd_req_mutex);
- 
--		spin_unlock_irq(q->queue_lock);
--		if (scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC) < 0)
--			goto requeue;
--		spin_lock_irq(q->queue_lock);
-+	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+	if (list_empty(&qdata->cmd_req)) {
-+		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+		mutex_unlock(&qdata->cmd_req_mutex);
-+		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
-+		goto out;
- 	}
-+	rq = list_entry_rq(qdata->cmd_req.next);
-+	list_del_init(&rq->queuelist);
-+	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 
--	return;
--requeue:
--	spin_lock_irq(q->queue_lock);
--	/* need to track cnts and plug */
--	blk_requeue_request(q, rq);
--	spin_unlock_irq(q->queue_lock);
-+	if ((rq->flags & REQ_DONTPREP)) {
-+		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
-+		tcmd = rq->end_io_data;
-+	} else
-+		init_scsi_tgt_cmd(rq, tcmd);
-+
-+	cmd = rq->special;
-+	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
-+	if (err < 0) {
-+		eprintk("failed to send: %p %d\n", cmd, err);
-+
-+		spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+		list_add(&rq->queuelist, &qdata->cmd_req);
-+		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+	}
-+
-+	mutex_unlock(&qdata->cmd_req_mutex);
-+out:
-+	/* TODO: proper error handling */
-+	if (err < 0)
-+		queue_delayed_work(scsi_tgtd, &qdata->uspace_send_work,
-+				   HZ / 10);
-+	else
-+		goto retry;
- }
- 
- /**
-@@ -150,13 +204,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- {
- 	struct scsi_tgt_queuedata *queuedata;
- 	struct request_queue *q;
--	int err;
-+	int err, i;
- 
- 	/*
- 	 * Do we need to send a netlink event or should uspace
- 	 * just respond to the hotplug event?
- 	 */
--	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
-+	q = __scsi_alloc_queue(shost, NULL);
- 	if (!q)
- 		return -ENOMEM;
- 
-@@ -168,19 +222,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- 	queuedata->shost = shost;
- 	q->queuedata = queuedata;
- 
--	elevator_exit(q->elevator);
--	err = elevator_init(q, "noop");
--	if (err)
--		goto free_data;
--
--	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
- 	/*
- 	 * this is a silly hack. We should probably just queue as many
- 	 * command as is recvd to userspace. uspace can then make
- 	 * sure we do not overload the HBA
- 	 */
- 	q->nr_requests = shost->hostt->can_queue;
--	blk_queue_init_tags(q, shost->hostt->can_queue, NULL);
- 	/*
- 	 * We currently only support software LLDs so this does
- 	 * not matter for now. Do we need this for the cards we support?
-@@ -189,10 +236,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- 	blk_queue_dma_alignment(q, 0);
- 	shost->uspace_req_q = q;
- 
-+	for (i = 0; i < ARRAY_SIZE(queuedata->cmd_hash); i++)
-+		INIT_LIST_HEAD(&queuedata->cmd_hash[i]);
-+	spin_lock_init(&queuedata->cmd_hash_lock);
-+
-+	INIT_LIST_HEAD(&queuedata->cmd_req);
-+	spin_lock_init(&queuedata->cmd_req_lock);
-+	INIT_WORK(&queuedata->uspace_send_work, scsi_tgt_uspace_send_fn, q);
-+	mutex_init(&queuedata->cmd_req_mutex);
-+
- 	return 0;
- 
--free_data:
--	kfree(queuedata);
- cleanup_queue:
- 	blk_cleanup_queue(q);
- 	return err;
-@@ -215,14 +269,17 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
- void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
- 			    int noblock)
- {
--	/*
--	 * For now this just calls the request_fn from this context.
--	 * For HW llds though we do not want to execute from here so
--	 * the elevator code needs something like a REQ_TGT_CMD or
--	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
--	 */
-+	struct request_queue *q = cmd->request->q;
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
-+	unsigned long flags;
-+
- 	cmd->request->end_io_data = scsilun;
--	elv_add_request(cmd->request->q, cmd->request, ELEVATOR_INSERT_BACK, 1);
-+
-+	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
-+	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+
-+	queue_work(scsi_tgtd, &qdata->uspace_send_work);
- }
- EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
- 
-@@ -438,6 +495,27 @@ static int scsi_tgt_copy_sense(struct sc
- 	return 0;
- }
- 
-+static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
-+{
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
-+	struct request *rq = NULL;
-+	struct list_head *head;
-+	struct scsi_tgt_cmd *tcmd;
-+	unsigned long flags;
-+
-+	head = &qdata->cmd_hash[cmd_hashfn(cid)];
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	list_for_each_entry(tcmd, head, hash_list) {
-+		if (tcmd->rq->tag == cid) {
-+			rq = tcmd->rq;
-+			break;
-+		}
-+	}
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
-+
-+	return rq;
-+}
-+
- int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
- 			 unsigned long uaddr, u8 rw)
- {
-@@ -456,7 +534,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
- 		return -EINVAL;
- 	}
- 
--	rq = blk_queue_find_tag(shost->uspace_req_q, cid);
-+	rq = tgt_cmd_hash_lookup(shost->uspace_req_q, cid);
- 	if (!rq) {
- 		printk(KERN_ERR "Could not find cid %u\n", cid);
- 		err = -EINVAL;
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-index fcf2ec6..6fedcec 100644
---- a/drivers/scsi/scsi_tgt_priv.h
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -11,10 +11,6 @@ do {								\
- 
- #define eprintk dprintk
- 
--struct scsi_tgt_queuedata {
--	struct Scsi_Host *shost;
--};
--
- extern void scsi_tgt_if_exit(void);
- extern int scsi_tgt_if_init(void);
- 
--- 
-1.1.5

Modified: branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff
===================================================================
--- branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-08 11:17:57 UTC (rev 401)
+++ branches/use-scsi-ml/patchset/scsi-target-2.6-tree.diff	2006-04-14 02:53:14 UTC (rev 402)
@@ -1,114 +1,3 @@
-diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
-index 13c40a0..e9d3388 100644
---- a/block/ll_rw_blk.c
-+++ b/block/ll_rw_blk.c
-@@ -2287,23 +2287,24 @@ int blk_rq_map_user(request_queue_t *q, 
- 	 */
- 	uaddr = (unsigned long) ubuf;
- 	if (!(uaddr & queue_dma_alignment(q)) && !(len & queue_dma_alignment(q)))
--		bio = bio_map_user(q, NULL, uaddr, len, reading, 0);
-+		bio = bio_map_user(q, NULL, uaddr, len, reading);
- 	else
- 		bio = bio_copy_user(q, uaddr, len, reading);
- 
--	if (!IS_ERR(bio)) {
--		rq->bio = rq->biotail = bio;
--		blk_rq_bio_prep(q, rq, bio);
-+	if (IS_ERR(bio))
-+		return PTR_ERR(bio);
- 
--		rq->buffer = rq->data = NULL;
--		rq->data_len = len;
--		return 0;
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
- 	}
- 
--	/*
--	 * bio is the err-ptr
--	 */
--	return PTR_ERR(bio);
-+	rq->bio = rq->biotail = bio;
-+	blk_rq_bio_prep(q, rq, bio);
-+	rq->buffer = rq->data = NULL;
-+	rq->data_len = len;
-+	return 0;
- }
- 
- EXPORT_SYMBOL(blk_rq_map_user);
-@@ -2329,7 +2330,7 @@ EXPORT_SYMBOL(blk_rq_map_user);
-  *    unmapping.
-  */
- int blk_rq_map_user_iov(request_queue_t *q, struct request *rq,
--			struct sg_iovec *iov, int iov_count)
-+			struct sg_iovec *iov, int iov_count, unsigned int len)
- {
- 	struct bio *bio;
- 
-@@ -2339,11 +2340,16 @@ int blk_rq_map_user_iov(request_queue_t 
- 	/* we don't allow misaligned data like bio_map_user() does.  If the
- 	 * user is using sg, they're expected to know the alignment constraints
- 	 * and respect them accordingly */
--	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ,
--				0);
-+	bio = bio_map_user_iov(q, NULL, iov, iov_count, rq_data_dir(rq)== READ);
- 	if (IS_ERR(bio))
- 		return PTR_ERR(bio);
- 
-+	if (bio->bi_size != len) {
-+		bio_endio(bio, bio->bi_size, 0);
-+		bio_unmap_user(bio);
-+		return -EINVAL;
-+	}
-+
- 	rq->bio = rq->biotail = bio;
- 	blk_rq_bio_prep(q, rq, bio);
- 	rq->buffer = rq->data = NULL;
-@@ -2765,16 +2771,12 @@ static void init_request_from_bio(struct
- 
- 	req->errors = 0;
- 	req->hard_sector = req->sector = bio->bi_sector;
--	req->hard_nr_sectors = req->nr_sectors = bio_sectors(bio);
--	req->current_nr_sectors = req->hard_cur_sectors = bio_cur_sectors(bio);
--	req->nr_phys_segments = bio_phys_segments(req->q, bio);
--	req->nr_hw_segments = bio_hw_segments(req->q, bio);
--	req->buffer = bio_data(bio);	/* see ->buffer comment above */
- 	req->waiting = NULL;
--	req->bio = req->biotail = bio;
- 	req->ioprio = bio_prio(bio);
- 	req->rq_disk = bio->bi_bdev->bd_disk;
- 	req->start_time = jiffies;
-+
-+	blk_rq_bio_prep(req->q, req, bio);
- }
- 
- static int __make_request(request_queue_t *q, struct bio *bio)
-@@ -3403,9 +3405,6 @@ EXPORT_SYMBOL(end_request);
- 
- void blk_rq_bio_prep(request_queue_t *q, struct request *rq, struct bio *bio)
- {
--	/* first three bits are identical in rq->flags and bio->bi_rw */
--	rq->flags |= (bio->bi_rw & 7);
--
- 	rq->nr_phys_segments = bio_phys_segments(q, bio);
- 	rq->nr_hw_segments = bio_hw_segments(q, bio);
- 	rq->current_nr_sectors = bio_cur_sectors(bio);
-diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
-index 24f7af9..ef9900d 100644
---- a/block/scsi_ioctl.c
-+++ b/block/scsi_ioctl.c
-@@ -274,7 +274,8 @@ static int sg_io(struct file *file, requ
- 			goto out;
- 		}
- 
--		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count);
-+		ret = blk_rq_map_user_iov(q, rq, iov, hdr->iovec_count,
-+					  hdr->dxfer_len);
- 		kfree(iov);
- 	} else if (hdr->dxfer_len)
- 		ret = blk_rq_map_user(q, rq, hdr->dxferp, hdr->dxfer_len);
 diff --git a/drivers/scsi/ibmvscsi/ibmvscsi.c b/drivers/scsi/ibmvscsi/ibmvscsi.c
 index eaefedd..e7bd028 100644
 --- a/drivers/scsi/ibmvscsi/ibmvscsi.c
@@ -910,858 +799,3 @@
  
  enum viosrp_crq_formats {
  	VIOSRP_SRP_FORMAT = 0x01,
-diff --git a/drivers/scsi/scsi.c b/drivers/scsi/scsi.c
-index 3cf02b1..9c22465 100644
---- a/drivers/scsi/scsi.c
-+++ b/drivers/scsi/scsi.c
-@@ -352,8 +352,6 @@ void scsi_host_put_command(struct Scsi_H
- 	spin_unlock(&shost->free_list_lock);
- 
- 	spin_lock(q->queue_lock);
--	if (blk_rq_tagged(rq))
--		blk_queue_end_tag(q, rq);
- 	__blk_put_request(q, rq);
- 	spin_unlock_irqrestore(q->queue_lock, flags);
- 
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-index 38b35da..ba1b75b 100644
---- a/drivers/scsi/scsi_tgt_if.c
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -35,15 +35,15 @@
- static int tgtd_pid;
- static struct sock *nl_sk;
- 
--static int send_event_res(uint16_t type, struct tgt_event *p,
--			  void *data, int dlen, gfp_t flags, pid_t pid)
-+static int send_event_rsp(uint16_t type, struct tgt_event *p, gfp_t flags,
-+			  pid_t pid)
- {
- 	struct tgt_event *ev;
- 	struct nlmsghdr *nlh;
- 	struct sk_buff *skb;
- 	uint32_t len;
- 
--	len = NLMSG_SPACE(sizeof(*ev) + dlen);
-+	len = NLMSG_SPACE(sizeof(*ev));
- 	skb = alloc_skb(len, flags);
- 	if (!skb)
- 		return -ENOMEM;
-@@ -52,26 +52,27 @@ static int send_event_res(uint16_t type,
- 
- 	ev = NLMSG_DATA(nlh);
- 	memcpy(ev, p, sizeof(*ev));
--	if (dlen)
--		memcpy(ev->data, data, dlen);
- 
- 	return netlink_unicast(nl_sk, skb, pid, 0);
- }
- 
--int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
-+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
-+			 gfp_t flags)
- {
- 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
- 	struct sk_buff *skb;
- 	struct nlmsghdr *nlh;
- 	struct tgt_event *ev;
--	struct tgt_cmd *tcmd;
- 	int err, len;
- 
--	len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct tgt_cmd));
-+	/* FIXME: we need scsi core to do that. */
-+	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
-+
-+	len = NLMSG_SPACE(sizeof(*ev));
- 	/*
- 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
- 	 */
--	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
-+	skb = alloc_skb(NLMSG_SPACE(len), flags);
- 	if (!skb)
- 		return -ENOMEM;
- 
-@@ -82,16 +83,14 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	ev->k.cmd_req.host_no = shost->host_no;
- 	ev->k.cmd_req.cid = cmd->request->tag;
- 	ev->k.cmd_req.data_len = cmd->request_bufflen;
--
--	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
--		ev->k.cmd_req.data_len);
--
--	/* FIXME: we need scsi core to do that. */
--	memcpy(cmd->cmnd, cmd->data_cmnd, MAX_COMMAND_SIZE);
--
--	tcmd = (struct tgt_cmd *) ev->data;
--	memcpy(tcmd->scb, cmd->cmnd, sizeof(tcmd->scb));
--	memcpy(tcmd->lun, lun, sizeof(struct scsi_lun));
-+	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
-+	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
-+	ev->k.cmd_req.attribute = cmd->tag;
-+	ev->k.cmd_req.tag = tag;
-+
-+	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
-+		ev->k.cmd_req.data_len, cmd->tag,
-+		(unsigned long long) ev->k.cmd_req.tag);
- 
- 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
- 	if (err < 0)
-@@ -104,15 +103,31 @@ int scsi_tgt_uspace_send_status(struct s
- {
- 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
- 	struct tgt_event ev;
--	char dummy[sizeof(struct tgt_cmd)];
- 
- 	memset(&ev, 0, sizeof(ev));
- 	ev.k.cmd_done.host_no = shost->host_no;
- 	ev.k.cmd_done.cid = cmd->request->tag;
- 	ev.k.cmd_done.result = cmd->result;
- 
--	return send_event_res(TGT_KEVENT_CMD_DONE, &ev, dummy, sizeof(dummy),
--			      gfp_mask, tgtd_pid);
-+	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
-+}
-+
-+int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+				  struct scsi_lun *scsilun, void *data)
-+{
-+	struct tgt_event ev;
-+
-+	memset(&ev, 0, sizeof(ev));
-+	ev.k.tsk_mgmt_req.host_no = host_no;
-+	ev.k.tsk_mgmt_req.function = function;
-+	ev.k.tsk_mgmt_req.tag = tag;
-+	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
-+	ev.k.tsk_mgmt_req.mid = (u64) data;
-+
-+	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
-+		(unsigned long long) ev.k.tsk_mgmt_req.mid);
-+
-+	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
- }
- 
- static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
-@@ -124,19 +139,22 @@ static int event_recv_msg(struct sk_buff
- 		nlh->nlmsg_pid, current->pid);
- 
- 	switch (nlh->nlmsg_type) {
--	case TGT_UEVENT_TGTD_BIND:
-+	case TGT_UEVENT_REQ:
- 		tgtd_pid = NETLINK_CREDS(skb)->pid;
- 		break;
--	case TGT_UEVENT_CMD_RES:
-+	case TGT_UEVENT_CMD_RSP:
- 		/* TODO: handle multiple cmds in one event */
--		err = scsi_tgt_kspace_exec(ev->u.cmd_res.host_no,
--					   ev->u.cmd_res.cid,
--					   ev->u.cmd_res.result,
--					   ev->u.cmd_res.len,
--					   ev->u.cmd_res.offset,
--					   ev->u.cmd_res.uaddr,
--					   ev->u.cmd_res.rw,
--					   ev->u.cmd_res.try_map);
-+		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
-+					   ev->u.cmd_rsp.cid,
-+					   ev->u.cmd_rsp.result,
-+					   ev->u.cmd_rsp.len,
-+					   ev->u.cmd_rsp.uaddr,
-+					   ev->u.cmd_rsp.rw);
-+		break;
-+	case TGT_UEVENT_TSK_MGMT_RSP:
-+		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
-+					       ev->u.tsk_mgmt_rsp.mid,
-+					       ev->u.tsk_mgmt_rsp.result);
- 		break;
- 	default:
- 		eprintk("unknown type %d\n", nlh->nlmsg_type);
-@@ -151,6 +169,7 @@ static int event_recv_skb(struct sk_buff
- 	int err;
- 	uint32_t rlen;
- 	struct nlmsghdr	*nlh;
-+	struct tgt_event ev;
- 
- 	while (skb->len >= NLMSG_SPACE(0)) {
- 		nlh = (struct nlmsghdr *) skb->data;
-@@ -166,12 +185,14 @@ static int event_recv_skb(struct sk_buff
- 		 * TODO for passthru commands the lower level should
- 		 * probably handle the result or we should modify this
- 		 */
--		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RES) {
--			struct tgt_event ev;
--
-+		switch (nlh->nlmsg_type) {
-+		case TGT_UEVENT_CMD_RSP:
-+		case TGT_UEVENT_TSK_MGMT_RSP:
-+			break;
-+		default:
- 			memset(&ev, 0, sizeof(ev));
--			ev.k.event_res.err = err;
--			send_event_res(TGT_KEVENT_RESPONSE, &ev, NULL, 0,
-+			ev.k.event_rsp.err = err;
-+			send_event_rsp(TGT_KEVENT_RSP, &ev,
- 				       GFP_KERNEL | __GFP_NOFAIL,
- 					nlh->nlmsg_pid);
- 		}
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 8746236..5a98fc4 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -20,7 +20,7 @@
-  * 02110-1301 USA
-  */
- #include <linux/blkdev.h>
--#include <linux/elevator.h>
-+#include <linux/hash.h>
- #include <linux/module.h>
- #include <linux/pagemap.h>
- #include <scsi/scsi.h>
-@@ -46,6 +46,25 @@ struct scsi_tgt_cmd {
- 	struct bio_list xfer_done_list;
- 	struct bio_list xfer_list;
- 	struct scsi_lun *lun;
-+
-+	struct list_head hash_list;
-+	struct request *rq;
-+	u64 tag;
-+};
-+
-+#define TGT_HASH_ORDER	4
-+#define cmd_hashfn(cid)	hash_long((cid), TGT_HASH_ORDER)
-+
-+struct scsi_tgt_queuedata {
-+	struct Scsi_Host *shost;
-+	struct list_head cmd_hash[1 << TGT_HASH_ORDER];
-+	spinlock_t cmd_hash_lock;
-+
-+	struct work_struct uspace_send_work;
-+
-+	spinlock_t cmd_req_lock;
-+	struct mutex cmd_req_mutex;
-+	struct list_head cmd_req;
- };
- 
- static void scsi_unmap_user_pages(struct scsi_tgt_cmd *tcmd)
-@@ -68,9 +87,16 @@ static void scsi_tgt_cmd_destroy(void *d
- {
- 	struct scsi_cmnd *cmd = data;
- 	struct scsi_tgt_cmd *tcmd = cmd->request->end_io_data;
-+	struct scsi_tgt_queuedata *qdata = cmd->request->q->queuedata;
-+	unsigned long flags;
- 
- 	dprintk("cmd %p %d %lu\n", cmd, cmd->sc_data_direction,
- 		rq_data_dir(cmd->request));
-+
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	list_del(&tcmd->hash_list);
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
-+
- 	/*
- 	 * We must set rq->flags here because bio_map_user and
- 	 * blk_rq_bio_prep ruined ti.
-@@ -81,62 +107,71 @@ static void scsi_tgt_cmd_destroy(void *d
- 		cmd->request->flags &= ~1UL;
- 
- 	scsi_unmap_user_pages(tcmd);
--	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
- 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
- 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
- }
- 
- static void init_scsi_tgt_cmd(struct request *rq, struct scsi_tgt_cmd *tcmd)
- {
--	tcmd->lun = rq->end_io_data;
--	bio_list_init(&tcmd->xfer_list);
--	bio_list_init(&tcmd->xfer_done_list);
-+	struct scsi_tgt_queuedata *qdata = rq->q->queuedata;
-+	unsigned long flags;
-+	struct list_head *head;
-+	static u32 tag = 0;
-+
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	rq->tag = tag++;
-+	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
-+	list_add(&tcmd->hash_list, head);
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
- }
- 
--static int scsi_uspace_prep_fn(struct request_queue *q, struct request *rq)
--{
--	struct scsi_tgt_cmd *tcmd;
--
--	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
--	if (!tcmd)
--		return BLKPREP_DEFER;
--
--	init_scsi_tgt_cmd(rq, tcmd);
--	rq->end_io_data = tcmd;
--	rq->flags |= REQ_DONTPREP;
--	return BLKPREP_OK;
--}
--
--static void scsi_uspace_request_fn(struct request_queue *q)
-+static void scsi_tgt_uspace_send_fn(void *data)
- {
-+	struct request_queue *q = data;
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
- 	struct request *rq;
- 	struct scsi_cmnd *cmd;
- 	struct scsi_tgt_cmd *tcmd;
-+	unsigned long flags;
-+	int err;
- 
--	/*
--	 * TODO: just send everthing in the queue to userspace in
--	 * one vector instead of multiple calls
--	 */
--	while ((rq = elv_next_request(q)) != NULL) {
--		cmd = rq->special;
--		tcmd = rq->end_io_data;
-+retry:
-+	err = 0;
-+	if (list_empty(&qdata->cmd_req))
-+		return;
- 
--		/* the completion code kicks us in case we hit this */
--		if (blk_queue_start_tag(q, rq))
--			break;
-+	mutex_lock(&qdata->cmd_req_mutex);
- 
--		spin_unlock_irq(q->queue_lock);
--		if (scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC) < 0)
--			goto requeue;
--		spin_lock_irq(q->queue_lock);
-+	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+	if (list_empty(&qdata->cmd_req)) {
-+		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+		mutex_unlock(&qdata->cmd_req_mutex);
-+		goto out;
-+	}
-+	rq = list_entry_rq(qdata->cmd_req.next);
-+	list_del_init(&rq->queuelist);
-+	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+
-+	tcmd = rq->end_io_data;
-+	init_scsi_tgt_cmd(rq, tcmd);
-+	cmd = rq->special;
-+	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
-+	if (err < 0) {
-+		eprintk("failed to send: %p %d\n", cmd, err);
-+
-+		spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+		list_add(&rq->queuelist, &qdata->cmd_req);
-+		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 	}
- 
--	return;
--requeue:
--	spin_lock_irq(q->queue_lock);
--	/* need to track cnts and plug */
--	blk_requeue_request(q, rq);
--	spin_lock_irq(q->queue_lock);
-+	mutex_unlock(&qdata->cmd_req_mutex);
-+out:
-+	/* TODO: proper error handling */
-+	if (err < 0)
-+		queue_delayed_work(scsi_tgtd, &qdata->uspace_send_work,
-+				   HZ / 10);
-+	else
-+		goto retry;
- }
- 
- /**
-@@ -150,13 +185,13 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- {
- 	struct scsi_tgt_queuedata *queuedata;
- 	struct request_queue *q;
--	int err;
-+	int err, i;
- 
- 	/*
- 	 * Do we need to send a netlink event or should uspace
- 	 * just respond to the hotplug event?
- 	 */
--	q = __scsi_alloc_queue(shost, scsi_uspace_request_fn);
-+	q = __scsi_alloc_queue(shost, NULL);
- 	if (!q)
- 		return -ENOMEM;
- 
-@@ -168,19 +203,12 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- 	queuedata->shost = shost;
- 	q->queuedata = queuedata;
- 
--	elevator_exit(q->elevator);
--	err = elevator_init(q, "noop");
--	if (err)
--		goto free_data;
--
--	blk_queue_prep_rq(q, scsi_uspace_prep_fn);
- 	/*
- 	 * this is a silly hack. We should probably just queue as many
- 	 * command as is recvd to userspace. uspace can then make
- 	 * sure we do not overload the HBA
- 	 */
- 	q->nr_requests = shost->hostt->can_queue;
--	blk_queue_init_tags(q, shost->hostt->can_queue, NULL);
- 	/*
- 	 * We currently only support software LLDs so this does
- 	 * not matter for now. Do we need this for the cards we support?
-@@ -189,10 +217,17 @@ int scsi_tgt_alloc_queue(struct Scsi_Hos
- 	blk_queue_dma_alignment(q, 0);
- 	shost->uspace_req_q = q;
- 
-+	for (i = 0; i < ARRAY_SIZE(queuedata->cmd_hash); i++)
-+		INIT_LIST_HEAD(&queuedata->cmd_hash[i]);
-+	spin_lock_init(&queuedata->cmd_hash_lock);
-+
-+	INIT_LIST_HEAD(&queuedata->cmd_req);
-+	spin_lock_init(&queuedata->cmd_req_lock);
-+	INIT_WORK(&queuedata->uspace_send_work, scsi_tgt_uspace_send_fn, q);
-+	mutex_init(&queuedata->cmd_req_mutex);
-+
- 	return 0;
- 
--free_data:
--	kfree(queuedata);
- cleanup_queue:
- 	blk_cleanup_queue(q);
- 	return err;
-@@ -212,17 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
-  * @scsilun:	scsi lun
-  * @noblock:	set to nonzero if the command should be queued
-  **/
--void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
--			    int noblock)
-+int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-+			   u64 tag)
- {
-+	struct request_queue *q = cmd->request->q;
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
-+	unsigned long flags;
-+	struct scsi_tgt_cmd *tcmd;
-+
- 	/*
--	 * For now this just calls the request_fn from this context.
--	 * For HW llds though we do not want to execute from here so
--	 * the elevator code needs something like a REQ_TGT_CMD or
--	 * REQ_MSG_DONT_UNPLUG_IMMED_BECUASE_WE_WILL_HANDLE_IT
-+	 * It would be better to allocate scsi_tgt_cmd structure in
-+	 * scsi_host_get_command and not to fail due to OOM.
- 	 */
--	cmd->request->end_io_data = scsilun;
--	elv_add_request(cmd->request->q, cmd->request, ELEVATOR_INSERT_BACK, 1);
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd)
-+		return -ENOMEM;
-+	cmd->request->end_io_data = tcmd;
-+
-+	bio_list_init(&tcmd->xfer_list);
-+	bio_list_init(&tcmd->xfer_done_list);
-+	tcmd->lun = scsilun;
-+	tcmd->tag = tag;
-+	tcmd->rq = cmd->request;
-+
-+	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
-+	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
-+	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
-+
-+	queue_work(scsi_tgtd, &qdata->uspace_send_work);
-+	return 0;
- }
- EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
- 
-@@ -236,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
- 
- 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
- 
--	/* don't we have to call this if result is set or not */
--	if (cmd->result) {
--		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
--		return;
--	}
--
-+	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
- 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
- 	queue_work(scsi_tgtd, &tcmd->work);
- }
-@@ -315,7 +363,7 @@ static int scsi_map_user_pages(struct sc
- 
- 	while (len > 0) {
- 		dprintk("%lx %u\n", (unsigned long) uaddr, len);
--		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw, 1);
-+		bio = bio_map_user(q, NULL, (unsigned long) uaddr, len, rw);
- 		if (IS_ERR(bio)) {
- 			err = PTR_ERR(bio);
- 			dprintk("fail to map %lx %u %d %x\n",
-@@ -438,16 +486,49 @@ static int scsi_tgt_copy_sense(struct sc
- 	return 0;
- }
- 
--int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len, u64 offset,
--			 unsigned long uaddr, u8 rw, u8 try_map)
-+static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
-+{
-+	int err;
-+
-+	err = host->hostt->eh_abort_handler(cmd);
-+	if (err)
-+		eprintk("fail to abort %p\n", cmd);
-+
-+	scsi_tgt_cmd_destroy(cmd);
-+	return err;
-+}
-+
-+static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
-+{
-+	struct scsi_tgt_queuedata *qdata = q->queuedata;
-+	struct request *rq = NULL;
-+	struct list_head *head;
-+	struct scsi_tgt_cmd *tcmd;
-+	unsigned long flags;
-+
-+	head = &qdata->cmd_hash[cmd_hashfn(cid)];
-+	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
-+	list_for_each_entry(tcmd, head, hash_list) {
-+		if (tcmd->rq->tag == cid) {
-+			rq = tcmd->rq;
-+			break;
-+		}
-+	}
-+	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
-+
-+	return rq;
-+}
-+
-+int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
-+			 unsigned long uaddr, u8 rw)
- {
- 	struct Scsi_Host *shost;
- 	struct scsi_cmnd *cmd;
- 	struct request *rq;
- 	int err = 0;
- 
--	dprintk("%d %u %d %u %llu %lx %u %u\n", host_no, cid, result,
--		len, (unsigned long long) offset, uaddr, rw, try_map);
-+	dprintk("%d %u %d %u %lx %u\n", host_no, cid, result,
-+		len, uaddr, rw);
- 
- 	/* TODO: replace with a O(1) alg */
- 	shost = scsi_host_lookup(host_no);
-@@ -456,7 +537,7 @@ int scsi_tgt_kspace_exec(int host_no, u3
- 		return -EINVAL;
- 	}
- 
--	rq = blk_queue_find_tag(shost->uspace_req_q, cid);
-+	rq = tgt_cmd_hash_lookup(shost->uspace_req_q, cid);
- 	if (!rq) {
- 		printk(KERN_ERR "Could not find cid %u\n", cid);
- 		err = -EINVAL;
-@@ -467,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
- 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
- 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
- 
-+	if (result == TASK_ABORTED) {
-+		scsi_tgt_abort_cmd(shost, cmd);
-+		goto done;
-+	}
- 	/*
- 	 * store the userspace values here, the working values are
- 	 * in the request_* values
-@@ -507,6 +592,38 @@ done:
- 	return err;
- }
- 
-+int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
-+			      struct scsi_lun *scsilun, void *data)
-+{
-+	int err;
-+
-+	/* TODO: need to retry if this fails. */
-+	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
-+					    tag, scsilun, data);
-+	if (err < 0)
-+		eprintk("The task management request lost!\n");
-+	return err;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
-+
-+int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
-+{
-+	struct Scsi_Host *shost;
-+	int err;
-+
-+	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
-+
-+	shost = scsi_host_lookup(host_no);
-+	if (IS_ERR(shost)) {
-+		printk(KERN_ERR "Could not find host no %d\n", host_no);
-+		return -EINVAL;
-+	}
-+	err = shost->hostt->tsk_mgmt_response(mid, result);
-+	scsi_host_put(shost);
-+
-+	return err;
-+}
-+
- static int __init scsi_tgt_init(void)
- {
- 	int err;
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-index 4236e50..77a1d06 100644
---- a/drivers/scsi/scsi_tgt_priv.h
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -4,22 +4,21 @@ struct Scsi_Host;
- struct task_struct;
- 
- /* tmp - will replace with SCSI logging stuff */
--#define dprintk(fmt, args...)					\
-+#define eprintk(fmt, args...)					\
- do {								\
- 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
- } while (0)
- 
--#define eprintk dprintk
--
--struct scsi_tgt_queuedata {
--	struct Scsi_Host *shost;
--};
-+#define dprintk eprintk
- 
- extern void scsi_tgt_if_exit(void);
- extern int scsi_tgt_if_init(void);
- 
--extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
-+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
-+				u64 tag, gfp_t flags);
- extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
- extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
--				u64 offset, unsigned long uaddr, u8 rw,
--				u8 try_map);
-+				unsigned long uaddr, u8 rw);
-+extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+					 struct scsi_lun *scsilun, void *data);
-+extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
-diff --git a/fs/bio.c b/fs/bio.c
-index 3e940c9..f51a873 100644
---- a/fs/bio.c
-+++ b/fs/bio.c
-@@ -718,21 +718,19 @@ static struct bio *__bio_map_user_iov(re
-  *	@uaddr: start of user address
-  *	@len: length in bytes
-  *	@write_to_vm: bool indicating writing to pages or not
-- *	@support_partial: support partial mappings
-  *
-  *	Map the user space address into a bio suitable for io to a block
-  *	device. Returns an error pointer in case of error.
-  */
- struct bio *bio_map_user(request_queue_t *q, struct block_device *bdev,
--			 unsigned long uaddr, unsigned int len, int write_to_vm,
--			 int support_partial)
-+			 unsigned long uaddr, unsigned int len, int write_to_vm)
- {
- 	struct sg_iovec iov;
- 
- 	iov.iov_base = (void __user *)uaddr;
- 	iov.iov_len = len;
- 
--	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm, support_partial);
-+	return bio_map_user_iov(q, bdev, &iov, 1, write_to_vm);
- }
- 
- /**
-@@ -742,17 +740,15 @@ struct bio *bio_map_user(request_queue_t
-  *	@iov:	the iovec.
-  *	@iov_count: number of elements in the iovec
-  *	@write_to_vm: bool indicating writing to pages or not
-- *	@support_partial: support partial mappings
-  *
-  *	Map the user space address into a bio suitable for io to a block
-  *	device. Returns an error pointer in case of error.
-  */
- struct bio *bio_map_user_iov(request_queue_t *q, struct block_device *bdev,
- 			     struct sg_iovec *iov, int iov_count,
--			     int write_to_vm, int support_partial)
-+			     int write_to_vm)
- {
- 	struct bio *bio;
--	int len = 0, i;
- 
- 	bio = __bio_map_user_iov(q, bdev, iov, iov_count, write_to_vm);
- 
-@@ -767,18 +763,7 @@ struct bio *bio_map_user_iov(request_que
- 	 */
- 	bio_get(bio);
- 
--	for (i = 0; i < iov_count; i++)
--		len += iov[i].iov_len;
--
--	if (bio->bi_size == len || support_partial)
--		return bio;
--
--	/*
--	 * don't support partial mappings
--	 */
--	bio_endio(bio, bio->bi_size, 0);
--	bio_unmap_user(bio);
--	return ERR_PTR(-EINVAL);
-+	return bio;
- }
- 
- static void __bio_unmap_user(struct bio *bio)
-diff --git a/include/linux/bio.h b/include/linux/bio.h
-index fc0906c..b60ffe3 100644
---- a/include/linux/bio.h
-+++ b/include/linux/bio.h
-@@ -295,13 +295,12 @@ extern int bio_add_page(struct bio *, st
- extern int bio_add_pc_page(struct request_queue *, struct bio *, struct page *,
- 			   unsigned int, unsigned int);
- extern int bio_get_nr_vecs(struct block_device *);
--extern int __bio_get_nr_vecs(struct request_queue *);
- extern struct bio *bio_map_user(struct request_queue *, struct block_device *,
--				unsigned long, unsigned int, int, int);
-+				unsigned long, unsigned int, int);
- struct sg_iovec;
- extern struct bio *bio_map_user_iov(struct request_queue *,
- 				    struct block_device *,
--				    struct sg_iovec *, int, int, int);
-+				    struct sg_iovec *, int, int);
- extern void bio_unmap_user(struct bio *);
- extern struct bio *bio_map_kern(struct request_queue *, void *, unsigned int,
- 				gfp_t);
-diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
-index 860e7a4..619ef1d 100644
---- a/include/linux/blkdev.h
-+++ b/include/linux/blkdev.h
-@@ -611,7 +611,8 @@ extern void blk_queue_activity_fn(reques
- extern int blk_rq_map_user(request_queue_t *, struct request *, void __user *, unsigned int);
- extern int blk_rq_unmap_user(struct bio *, unsigned int);
- extern int blk_rq_map_kern(request_queue_t *, struct request *, void *, unsigned int, gfp_t);
--extern int blk_rq_map_user_iov(request_queue_t *, struct request *, struct sg_iovec *, int);
-+extern int blk_rq_map_user_iov(request_queue_t *, struct request *,
-+			       struct sg_iovec *, int, unsigned int);
- extern int blk_execute_rq(request_queue_t *, struct gendisk *,
- 			  struct request *, int);
- extern void blk_execute_rq_nowait(request_queue_t *, struct gendisk *,
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8b799db..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -153,6 +153,9 @@ struct scsi_host_template {
- 	int (* transfer_data)(struct scsi_cmnd *,
- 			      void (*done)(struct scsi_cmnd *));
- 
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
- 	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-index 91ad6bc..2d65be7 100644
---- a/include/scsi/scsi_tgt.h
-+++ b/include/scsi/scsi_tgt.h
-@@ -6,6 +6,8 @@ struct Scsi_Host;
- struct scsi_cmnd;
- struct scsi_lun;
- 
--extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
- extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
--extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
-+extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index da3a808..63b2e3a 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -24,65 +24,66 @@
- 
- enum tgt_event_type {
- 	/* user -> kernel */
--	TGT_UEVENT_TGTD_BIND,
--	TGT_UEVENT_TARGET_SETUP,
--	TGT_UEVENT_CMD_RES,
-+	TGT_UEVENT_REQ,
-+	TGT_UEVENT_CMD_RSP,
-+	TGT_UEVENT_TSK_MGMT_RSP,
- 
- 	/* kernel -> user */
--	TGT_KEVENT_RESPONSE,
-+	TGT_KEVENT_RSP,
- 	TGT_KEVENT_CMD_REQ,
- 	TGT_KEVENT_CMD_DONE,
-+	TGT_KEVENT_TSK_MGMT_REQ,
- };
- 
- struct tgt_event {
- 	/* user-> kernel */
- 	union {
- 		struct {
--			int pk_fd;
--		} tgtd_bind;
-+			int type;
-+			int host_no;
-+		} event_req;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			uint32_t len;
- 			int result;
- 			uint64_t uaddr;
--			uint64_t offset;
- 			uint8_t rw;
--			uint8_t try_map;
--		} cmd_res;
-+		} cmd_rsp;
-+		struct {
-+			int host_no;
-+			uint64_t mid;
-+			int result;
-+		} tsk_mgmt_rsp;
- 	} u;
- 
- 	/* kernel -> user */
- 	union {
- 		struct {
- 			int err;
--		} event_res;
-+		} event_rsp;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			uint32_t data_len;
--			uint64_t dev_id;
-+			uint8_t scb[16];
-+			uint8_t lun[8];
-+			int attribute;
-+			uint64_t tag;
- 		} cmd_req;
- 		struct {
- 			int host_no;
- 			uint32_t cid;
- 			int result;
- 		} cmd_done;
-+		struct {
-+			int host_no;
-+			int function;
-+			uint64_t tag;
-+			uint8_t lun[8];
-+			uint64_t mid;
-+		} tsk_mgmt_req;
- 	} k;
- 
--	/*
--	 * I think a pointer is a unsigned long but this struct
--	 * gets passed around from the kernel to userspace and
--	 * back again so to handle some ppc64 setups where userspace is
--	 * 32 bits but the kernel is 64 we do this odd thing
--	 */
--	uint64_t data[0];
--} __attribute__ ((aligned (sizeof(uint64_t))));
--
--struct tgt_cmd {
--	uint8_t scb[16];
--	uint8_t lun[8];
--	int tags;
- } __attribute__ ((aligned (sizeof(uint64_t))));
--
- #endif



From tomo at berlios.de  Fri Apr 14 07:25:08 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 07:25:08 +0200
Subject: [Stgt-svn] r403 - branches/use-scsi-ml/usr
Message-ID: <200604140525.k3E5P8dD012431@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 07:24:56 +0200 (Fri, 14 Apr 2006)
New Revision: 403

Modified:
   branches/use-scsi-ml/usr/tgtadm.c
Log:
Use device names to bind a host to a target

Examples:

tgtadm --driver ibmvstgt --op bind --tid 1 --bus vio,30000003

lilac:/sys/bus/vio/devices/30000003# ls
bus  devspec  driver  host1  name  uevent

host1 will be binded to target1.


tgtadm --driver qla2xxx --op bind --tid 1 --bus pci,0000:02:05.0

this goes to /sys/bus/pci/devices/0000:02:05.0

arras:/sys/bus/pci/devices/0000:02:05.0# ls
bus@    device   irq         power/     resource1  subsystem_device
class   driver@  local_cpus  resource   resource3  subsystem_vendor
config  host0/   modalias    resource0  rom        vendor

host0 will be binded to target1.




Modified: branches/use-scsi-ml/usr/tgtadm.c
===================================================================
--- branches/use-scsi-ml/usr/tgtadm.c	2006-04-14 02:53:14 UTC (rev 402)
+++ branches/use-scsi-ml/usr/tgtadm.c	2006-04-14 05:24:56 UTC (rev 403)
@@ -61,7 +61,7 @@
 	{"lun", required_argument, NULL, 'l'},
 	{"params", required_argument, NULL, 'p'},
 	{"user", no_argument, NULL, 'u'},
-	{"hostno", required_argument, NULL, 'b'},
+	{"bus", required_argument, NULL, 'b'},
 	{"version", no_argument, NULL, 'v'},
 	{"help", no_argument, NULL, 'h'},
 	{NULL, 0, NULL, 0},
@@ -375,6 +375,37 @@
 	return id;
 }
 
+static int bus_to_host(char *bus)
+{
+	int i, nr, host = -1;
+	char path[PATH_MAX], *p;
+	char key[] = "host";
+	struct dirent **namelist;
+
+	p = strchr(bus, ',');
+	if (!p)
+		return -EINVAL;
+	*(p++) = '\0';
+
+	snprintf(path, sizeof(path), "/sys/bus/%s/devices/%s", bus, p);
+	nr = scandir(path, &namelist, filter, alphasort);
+	if (!nr)
+		return -ENOENT;
+
+	for (i = 0; i < nr; i++) {
+		if (strncmp(namelist[i]->d_name, key, strlen(key)))
+			continue;
+		p = namelist[i]->d_name + strlen(key);
+		host = strtoull(p, NULL, 10);
+	}
+
+	for (i = 0; i < nr; i++)
+		free(namelist[i]);
+	free(namelist);
+
+	return host;
+}
+
 static int lld_id_get(int argc, char **argv)
 {
 	int ch, longindex, id = -EINVAL;
@@ -442,7 +473,7 @@
 			set |= (1 << MODE_DEVICE);
 			break;
 		case 'b':
-			hostno = strtol(optarg, NULL, 10);
+			hostno = bus_to_host(optarg);
 			break;
 		case 'p':
 			params = optarg;



From tomo at berlios.de  Fri Apr 14 07:26:26 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 07:26:26 +0200
Subject: [Stgt-svn] r404 - branches/use-scsi-ml
Message-ID: <200604140526.k3E5QQGW012750@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 07:26:21 +0200 (Fri, 14 Apr 2006)
New Revision: 404

Modified:
   branches/use-scsi-ml/ibmv
Log:
Update the makeshift ibmvstgt script.

Modified: branches/use-scsi-ml/ibmv
===================================================================
--- branches/use-scsi-ml/ibmv	2006-04-14 05:24:56 UTC (rev 403)
+++ branches/use-scsi-ml/ibmv	2006-04-14 05:26:21 UTC (rev 404)
@@ -6,5 +6,5 @@
 PATH=/sbin:/bin:/usr/sbin:/usr/bin
 
 ${PWD}/usr/tgtadm --driver ibmvstgt --op new --tid 1
-${PWD}/usr/tgtadm --driver ibmvstgt --op bind --tid 1 --hostno $1
+${PWD}/usr/tgtadm --driver ibmvstgt --op bind --tid 1 --bus vio,30000003
 ${PWD}/usr/tgtadm --driver ibmvstgt --op new --tid 1 --lun 0 --params Path=/dev/sdb1



From tomo at berlios.de  Fri Apr 14 14:59:50 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 14:59:50 +0200
Subject: [Stgt-svn] r405 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604141259.k3ECxobe026182@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 14:59:42 +0200 (Fri, 14 Apr 2006)
New Revision: 405

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Include ibmvscsi.h for crq_queue structure.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 05:26:21 UTC (rev 404)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 12:59:42 UTC (rev 405)
@@ -35,7 +35,7 @@
 #include <asm/prom.h>
 #include <asm/vio.h>
 
-#include "viosrp.h"
+#include "ibmvscsi.h"
 
 #define DEFAULT_TIMEOUT		30*HZ
 #define	INITIAL_SRP_LIMIT	16
@@ -75,17 +75,6 @@
 #define dprintk eprintk
 /* #define dprintk(fmt, args...) */
 
-/*
- * an RPA command/response transport queue.  This is our structure
- * that points to the actual queue (not architected by firmware)
- */
-struct crq_queue {
-	struct viosrp_crq *msgs;
-	int size, cur;
-	dma_addr_t msg_token;
-	spinlock_t lock;
-};
-
 /* all driver data associated with a host adapter */
 struct server_adapter {
 	struct device *dev;



From tomo at berlios.de  Fri Apr 14 15:01:05 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 15:01:05 +0200
Subject: [Stgt-svn] r406 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604141301.k3ED15HL026448@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 15:00:44 +0200 (Fri, 14 Apr 2006)
New Revision: 406

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Kill next_rsp_delta.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 12:59:42 UTC (rev 405)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 13:00:44 UTC (rev 406)
@@ -84,9 +84,8 @@
 	struct work_struct crq_work;
 	mempool_t *iu_pool;
 
-	spinlock_t lock; /* cmd_queue and next_rsp_delta */
+	spinlock_t lock; /* cmd_queue */
 	struct list_head cmd_queue;
-	int next_rsp_delta;
 
 	unsigned long liobn;
 	unsigned long riobn;
@@ -196,8 +195,7 @@
 	memset(iu, 0, sizeof(struct srp_rsp));
 	iu->srp.rsp.opcode = SRP_RSP;
 	spin_lock_irqsave(&iue->adapter->lock, flags);
-	iu->srp.rsp.req_lim_delta = 1 + iue->adapter->next_rsp_delta;
-	iue->adapter->next_rsp_delta = 0;
+	iu->srp.rsp.req_lim_delta = 1;
 	spin_unlock_irqrestore(&iue->adapter->lock, flags);
 	iu->srp.rsp.tag = tag;
 
@@ -1179,7 +1177,6 @@
 	adapter->dma_dev = dev;
 	adapter->dev = &dev->dev;
 	adapter->dev->driver_data = adapter;
-	adapter->next_rsp_delta = 0;
 	spin_lock_init(&adapter->lock);
 
 	dma = (unsigned int *)



From tomo at berlios.de  Fri Apr 14 15:02:03 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 15:02:03 +0200
Subject: [Stgt-svn] r407 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604141302.k3ED23qQ027184@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 15:01:38 +0200 (Fri, 14 Apr 2006)
New Revision: 407

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Kill unused macro.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 13:00:44 UTC (rev 406)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 13:01:38 UTC (rev 407)
@@ -46,10 +46,6 @@
 #define	vio_iu(iue)\
 	((union viosrp_iu *) ((char *) (iue) + sizeof(struct iu_entry)))
 
-#define GETBUS(x) ((int)((((uint64_t)(x)) >> 53) & 0x0007))
-#define GETTARGET(x) ((int)((((uint64_t)(x)) >> 56) & 0x003f))
-#define GETLUN(x) ((int)((((uint64_t)(x)) >> 48) & 0x001f))
-
 /*
  * Hypervisor calls.
  */



From tomo at berlios.de  Fri Apr 14 15:09:58 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 15:09:58 +0200
Subject: [Stgt-svn] r408 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604141309.k3ED9wEX029443@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 15:09:29 +0200 (Fri, 14 Apr 2006)
New Revision: 408

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/Makefile
Log:
Clean up Makefile.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/Makefile	2006-04-14 13:01:38 UTC (rev 407)
+++ branches/use-scsi-ml/ibmvstgt/kernel/Makefile	2006-04-14 13:09:29 UTC (rev 408)
@@ -1,5 +1,4 @@
-EXTRA_CFLAGS += -I$(obj) -I$(obj)/../include -I$(obj)/../../kernel \
-		-I$(KERNELSRC)/drivers/scsi/ibmvscsi/
+EXTRA_CFLAGS += -I$(KERNELSRC)/drivers/scsi/ibmvscsi/
 
 ifneq ($(KERNELRELEASE),)
 obj-m		+= ibmvstgt.o



From tomo at berlios.de  Fri Apr 14 17:44:20 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 14 Apr 2006 17:44:20 +0200
Subject: [Stgt-svn] r409 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604141544.k3EFiKIA025543@sheep.berlios.de>

Author: tomo
Date: 2006-04-14 17:44:20 +0200 (Fri, 14 Apr 2006)
New Revision: 409

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
kill sense in iu_entry structure.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 13:09:29 UTC (rev 408)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 15:44:20 UTC (rev 409)
@@ -116,7 +116,6 @@
 
 	struct {
 		dma_addr_t remote_token;
-		char *sense;
 		unsigned long flags;
 		int data_out_residual_count;
 		int data_in_residual_count;
@@ -180,7 +179,6 @@
 		    unsigned char asc)
 {
 	union viosrp_iu *iu = vio_iu(iue);
-	uint8_t *sense = iu->srp.rsp.data;
 	uint64_t tag = iu->srp.rsp.tag;
 	unsigned long flags;
 
@@ -204,30 +202,29 @@
 	iu->srp.rsp.flags &= ~SRP_RSP_FLAG_RSPVALID;
 
 	iu->srp.rsp.resp_data_len = 0;
+	iu->srp.rsp.status = status;
+	if (status) {
+		uint8_t *sense = iu->srp.rsp.data;
 
-	if (status && !iue->req.sense) {
-		iu->srp.rsp.status = SAM_STAT_CHECK_CONDITION;
-		iu->srp.rsp.flags |= SRP_RSP_FLAG_SNSVALID;
-		iu->srp.rsp.sense_data_len = SRP_RSP_SENSE_DATA_LEN;
-
-		/* Valid bit and 'current errors' */
-		sense[0] = (0x1 << 7 | 0x70);
-
-		/* Sense key */
-		sense[2] = status;
-
-		/* Additional sense length */
-		sense[7] = 0xa;	/* 10 bytes */
-
-		/* Additional sense code */
-		sense[12] = asc;
-	} else {
-		if (iue->req.sense) {
+		if (iue->scmd) {
 			iu->srp.rsp.flags |= SRP_RSP_FLAG_SNSVALID;
 			iu->srp.rsp.sense_data_len = SCSI_SENSE_BUFFERSIZE;
-			memcpy(sense, iue->req.sense, SCSI_SENSE_BUFFERSIZE);
+			memcpy(sense, iue->scmd->sense_buffer,
+			       SCSI_SENSE_BUFFERSIZE);
+		} else {
+			iu->srp.rsp.status = SAM_STAT_CHECK_CONDITION;
+			iu->srp.rsp.flags |= SRP_RSP_FLAG_SNSVALID;
+			iu->srp.rsp.sense_data_len = SRP_RSP_SENSE_DATA_LEN;
+
+			/* Valid bit and 'current errors' */
+			sense[0] = (0x1 << 7 | 0x70);
+			/* Sense key */
+			sense[2] = status;
+			/* Additional sense length */
+			sense[7] = 0xa;	/* 10 bytes */
+			/* Additional sense code */
+			sense[12] = asc;
 		}
-		iu->srp.rsp.status = status;
 	}
 
 	send_iu(iue, sizeof(iu->srp.rsp) + SRP_RSP_SENSE_DATA_LEN,
@@ -608,6 +605,7 @@
 
 	memset(&iue->req, 0, sizeof(iue->req));
 	iue->adapter = adapter;
+	iue->scmd = NULL;
 	INIT_LIST_HEAD(&iue->ilist);
 
 	iue->iu_token = dma_map_single(adapter->dev, vio_iu(iue),



From tomo at berlios.de  Sat Apr 15 01:14:17 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 01:14:17 +0200
Subject: [Stgt-svn] r410 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604142314.k3ENEHZs000250@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 01:13:23 +0200 (Sat, 15 Apr 2006)
New Revision: 410

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Kill timeout in iu_entry structure.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 15:44:20 UTC (rev 409)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:13:23 UTC (rev 410)
@@ -37,7 +37,6 @@
 
 #include "ibmvscsi.h"
 
-#define DEFAULT_TIMEOUT		30*HZ
 #define	INITIAL_SRP_LIMIT	16
 #define	DEFAULT_MAX_SECTORS	512
 
@@ -119,7 +118,6 @@
 		unsigned long flags;
 		int data_out_residual_count;
 		int data_in_residual_count;
-		int timeout;
 	} req;
 };
 
@@ -862,7 +860,6 @@
 	dprintk("%p %p\n", adapter, iue);
 
 	iue->req.remote_token = crq->IU_data_ptr;
-	iue->req.timeout= crq->timeout ? crq->timeout * HZ : DEFAULT_TIMEOUT;
 
 	err = h_copy_rdma(crq->IU_length, iue->adapter->riobn,
 			  iue->req.remote_token, adapter->liobn, iue->iu_token);



From tomo at berlios.de  Sat Apr 15 01:16:30 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 01:16:30 +0200
Subject: [Stgt-svn] r411 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604142316.k3ENGUgD000816@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 01:16:25 +0200 (Sat, 15 Apr 2006)
New Revision: 411

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Kill data_in_res_cnt and data_out_res_cnt in iu_entry structure.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:13:23 UTC (rev 410)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:16:25 UTC (rev 411)
@@ -116,8 +116,6 @@
 	struct {
 		dma_addr_t remote_token;
 		unsigned long flags;
-		int data_out_residual_count;
-		int data_in_residual_count;
 	} req;
 };
 
@@ -194,8 +192,8 @@
 	if (test_bit(V_DIOVER, &iue->req.flags))
 		iu->srp.rsp.flags |= SRP_RSP_FLAG_DIOVER;
 
-	iu->srp.rsp.data_in_res_cnt = iue->req.data_in_residual_count;
-	iu->srp.rsp.data_out_res_cnt = iue->req.data_out_residual_count;
+	iu->srp.rsp.data_in_res_cnt = 0;
+	iu->srp.rsp.data_out_res_cnt = 0;
 
 	iu->srp.rsp.flags &= ~SRP_RSP_FLAG_RSPVALID;
 



From tomo at berlios.de  Sat Apr 15 01:21:09 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 01:21:09 +0200
Subject: [Stgt-svn] r412 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604142321.k3ENL9HQ001389@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 01:20:00 +0200 (Sat, 15 Apr 2006)
New Revision: 412

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Clean up iu_entry.

Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:16:25 UTC (rev 411)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:20:00 UTC (rev 412)
@@ -109,17 +109,14 @@
  */
 struct iu_entry {
 	struct server_adapter *adapter;
-	struct list_head ilist;
-	dma_addr_t iu_token;
 	struct scsi_cmnd *scmd;
 
-	struct {
-		dma_addr_t remote_token;
-		unsigned long flags;
-	} req;
+	struct list_head ilist;
+	dma_addr_t iu_token;
+	dma_addr_t remote_token;
+	unsigned long flags;
 };
 
-
 static struct workqueue_struct *vtgtd;
 static kmem_cache_t *iu_cache;
 
@@ -141,7 +138,7 @@
 
 	/* First copy the SRP */
 	rc = h_copy_rdma(length, iue->adapter->liobn, iue->iu_token,
-			 iue->adapter->riobn, iue->req.remote_token);
+			 iue->adapter->riobn, iue->remote_token);
 
 	if (rc)
 		eprintk("Error %ld transferring data\n", rc);
@@ -179,7 +176,7 @@
 	unsigned long flags;
 
 	/* If the linked bit is on and status is good */
-	if (test_bit(V_LINKED, &iue->req.flags) && (status == NO_SENSE))
+	if (test_bit(V_LINKED, &iue->flags) && (status == NO_SENSE))
 		status = 0x10;
 
 	memset(iu, 0, sizeof(struct srp_rsp));
@@ -189,7 +186,7 @@
 	spin_unlock_irqrestore(&iue->adapter->lock, flags);
 	iu->srp.rsp.tag = tag;
 
-	if (test_bit(V_DIOVER, &iue->req.flags))
+	if (test_bit(V_DIOVER, &iue->flags))
 		iu->srp.rsp.flags |= SRP_RSP_FLAG_DIOVER;
 
 	iu->srp.rsp.data_in_res_cnt = 0;
@@ -304,7 +301,7 @@
 	dprintk("%p %p\n", iue->adapter, iue);
 
 	if (getlink(iue))
-		__set_bit(V_LINKED, &iue->req.flags);
+		__set_bit(V_LINKED, &iue->flags);
 
 	tag = MSG_SIMPLE_TAG;
 
@@ -330,7 +327,7 @@
 	case WRITE_VERIFY:
 	case WRITE_12:
 	case WRITE_VERIFY_12:
-		__set_bit(V_WRITE, &iue->req.flags);
+		__set_bit(V_WRITE, &iue->flags);
 	}
 
 	if (iu->srp.cmd.buf_fmt >> 4)
@@ -369,7 +366,7 @@
 	spin_lock_irqsave(&adapter->lock, flags);
 
 	list_for_each_entry(iue, &adapter->cmd_queue, ilist) {
-		if (!test_and_set_bit(V_FLYING, &iue->req.flags)) {
+		if (!test_and_set_bit(V_FLYING, &iue->flags)) {
 			spin_unlock_irqrestore(&adapter->lock, flags);
 			process_cmd(iue);
 			goto retry;
@@ -582,7 +579,7 @@
 	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
 	enum dma_data_direction dir;
 
-	if (test_bit(V_WRITE, &iue->req.flags))
+	if (test_bit(V_WRITE, &iue->flags))
 		dir = DMA_TO_DEVICE;
 	else
 		dir = DMA_FROM_DEVICE;
@@ -599,9 +596,8 @@
 	if (!iue)
 		return NULL;
 
-	memset(&iue->req, 0, sizeof(iue->req));
+	memset(iue, 0, sizeof(struct iu_entry));
 	iue->adapter = adapter;
-	iue->scmd = NULL;
 	INIT_LIST_HEAD(&iue->ilist);
 
 	iue->iu_token = dma_map_single(adapter->dev, vio_iu(iue),
@@ -857,10 +853,10 @@
 
 	dprintk("%p %p\n", adapter, iue);
 
-	iue->req.remote_token = crq->IU_data_ptr;
+	iue->remote_token = crq->IU_data_ptr;
 
 	err = h_copy_rdma(crq->IU_length, iue->adapter->riobn,
-			  iue->req.remote_token, adapter->liobn, iue->iu_token);
+			  iue->remote_token, adapter->liobn, iue->iu_token);
 
 	if (err != H_Success)
 		eprintk("%ld transferring data error %p\n", err, iue);



From tomo at berlios.de  Sat Apr 15 05:24:44 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 05:24:44 +0200
Subject: [Stgt-svn] r413 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604150324.k3F3OiYs000424@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 05:24:39 +0200 (Sat, 15 Apr 2006)
New Revision: 413

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Changes for libsrp


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-14 23:20:00 UTC (rev 412)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 03:24:39 UTC (rev 413)
@@ -24,7 +24,7 @@
 
 #include <linux/interrupt.h>
 #include <linux/module.h>
-#include <linux/mempool.h>
+#include <linux/kfifo.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_tcq.h>
@@ -42,9 +42,6 @@
 
 #define	TGT_NAME	"ibmvstgt"
 
-#define	vio_iu(iue)\
-	((union viosrp_iu *) ((char *) (iue) + sizeof(struct iu_entry)))
-
 /*
  * Hypervisor calls.
  */
@@ -70,55 +67,63 @@
 #define dprintk eprintk
 /* #define dprintk(fmt, args...) */
 
-/* all driver data associated with a host adapter */
+enum iue_flags {
+	V_DIOVER,
+	V_WRITE,
+	V_LINKED,
+	V_FLYING,
+};
+
+enum srp_task_attributes {
+	SRP_SIMPLE_TASK = 0,
+	SRP_HEAD_TASK = 1,
+	SRP_ORDERED_TASK = 2,
+	SRP_ACA_TASK = 4
+};
+
+struct srp_buf {
+	dma_addr_t dma;
+	void *buf;
+};
+
+struct srp_queue {
+	void *pool;
+	void *items;
+	struct kfifo *queue;
+	spinlock_t lock;
+};
+
 struct server_adapter {
 	struct device *dev;
 	struct vio_dev *dma_dev;
 
 	struct crq_queue crq_queue;
 	struct work_struct crq_work;
-	mempool_t *iu_pool;
 
 	spinlock_t lock; /* cmd_queue */
 	struct list_head cmd_queue;
 
+	struct srp_queue iu_queue;
+	struct srp_buf *rx_ring[INITIAL_SRP_LIMIT];
+
 	unsigned long liobn;
 	unsigned long riobn;
 
 	struct Scsi_Host *shost;
 };
 
-enum iue_flags {
-	V_DIOVER,
-	V_WRITE,
-	V_LINKED,
-	V_FLYING,
-};
-
-enum srp_task_attributes {
-	SRP_SIMPLE_TASK = 0,
-	SRP_HEAD_TASK = 1,
-	SRP_ORDERED_TASK = 2,
-	SRP_ACA_TASK = 4
-};
-
-/*
- * This structure tracks our fundamental unit of work.  Whenever
- * an SRP Information Unit (IU) arrives, we track all the good stuff
- * here
- */
 struct iu_entry {
 	struct server_adapter *adapter;
 	struct scsi_cmnd *scmd;
 
 	struct list_head ilist;
-	dma_addr_t iu_token;
 	dma_addr_t remote_token;
 	unsigned long flags;
+
+	struct srp_buf *sbuf;
 };
 
 static struct workqueue_struct *vtgtd;
-static kmem_cache_t *iu_cache;
 
 /*
  * These are fixed for the system and come from the Open Firmware device tree.
@@ -128,6 +133,85 @@
 static char partition_name[97] = "UNKNOWN";
 static unsigned int partition_number = -1;
 
+static union viosrp_iu *vio_iu(struct iu_entry *iue)
+{
+	return (union viosrp_iu *) (iue->sbuf->buf);
+}
+
+static int iu_pool_alloc(struct srp_queue *q, size_t max, struct srp_buf **ring)
+{
+	int i;
+	struct iu_entry *iue;
+
+	q->pool = kcalloc(max, sizeof(struct iu_entry *), GFP_KERNEL);
+	if (!q->pool)
+		return -ENOMEM;
+	q->items = kcalloc(max, sizeof(struct iu_entry), GFP_KERNEL);
+	if (!q->items)
+		goto free_pool;
+
+	spin_lock_init(&q->lock);
+	q->queue = kfifo_init((void *) q->pool, max * sizeof(void *),
+			      GFP_KERNEL, &q->lock);
+	if (IS_ERR(q->queue))
+		goto free_item;
+
+	for (i = 0, iue = q->items; i < max; i++) {
+		__kfifo_put(q->queue, (void *) &iue, sizeof(void *));
+		iue->sbuf = ring[i];
+		iue++;
+	}
+	return 0;
+
+free_item:
+	kfree(q->items);
+free_pool:
+	kfree(q->pool);
+	return -ENOMEM;
+}
+
+static void iu_pool_free(struct srp_queue *q)
+{
+	kfree(q->items);
+	kfree(q->pool);
+}
+
+static int srp_ring_alloc(struct device *dev, struct srp_buf **ring,
+			  size_t max, size_t size)
+{
+	int i;
+
+	for (i = 0; i < max; i++) {
+		ring[i] = kzalloc(sizeof(struct srp_buf), GFP_KERNEL);
+		if (!ring[i])
+			goto out;
+		ring[i]->buf = dma_alloc_coherent(dev, size, &ring[i]->dma,
+						  GFP_KERNEL);
+		if (!ring[i]->buf)
+			goto out;
+	}
+	return 0;
+
+out:
+	for (i = 0; i < max && ring[i]; i++) {
+		if (ring[i]->buf)
+			dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
+		kfree(ring[i]);
+	}
+	return -ENOMEM;
+}
+
+static void srp_ring_free(struct device *dev, struct srp_buf **ring, size_t max,
+			  size_t size)
+{
+	int i;
+
+	for (i = 0; i < max; i++) {
+		dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
+		kfree(ring[i]);
+	}
+}
+
 static int send_iu(struct iu_entry *iue, uint64_t length, uint8_t format)
 {
 	long rc, rc1;
@@ -137,7 +221,7 @@
 	} crq;
 
 	/* First copy the SRP */
-	rc = h_copy_rdma(length, iue->adapter->liobn, iue->iu_token,
+	rc = h_copy_rdma(length, iue->adapter->liobn, iue->sbuf->dma,
 			 iue->adapter->riobn, iue->remote_token);
 
 	if (rc)
@@ -590,36 +674,22 @@
 
 static struct iu_entry *get_iu(struct server_adapter *adapter)
 {
-	struct iu_entry *iue;
+	struct iu_entry *iue = NULL;
 
-	iue = mempool_alloc(adapter->iu_pool, GFP_ATOMIC);
-	if (!iue)
-		return NULL;
+	kfifo_get(adapter->iu_queue.queue, (void *) &iue, sizeof(void *));
+	BUG_ON(!iue);
 
-	memset(iue, 0, sizeof(struct iu_entry));
 	iue->adapter = adapter;
+	iue->scmd = NULL;
 	INIT_LIST_HEAD(&iue->ilist);
+	iue->flags = 0;
 
-	iue->iu_token = dma_map_single(adapter->dev, vio_iu(iue),
-				       sizeof(union viosrp_iu),
-				       DMA_BIDIRECTIONAL);
-	if (dma_mapping_error(iue->iu_token)) {
-		mempool_free(iue, adapter->iu_pool);
-		iue = NULL;
-	}
-
 	return iue;
 }
 
 static void put_iu(struct iu_entry *iue)
 {
-	struct server_adapter *adapter = iue->adapter;
-
-	dprintk("%p %p\n", adapter, iue);
-
-	dma_unmap_single(adapter->dev, iue->iu_token,
-			 sizeof(union viosrp_iu), DMA_BIDIRECTIONAL);
-	mempool_free(iue, adapter->iu_pool);
+	kfifo_put(iue->adapter->iu_queue.queue, (void *) &iue, sizeof(void *));
 }
 
 static int ibmvstgt_cmd_done(struct scsi_cmnd *scmd,
@@ -856,7 +926,7 @@
 	iue->remote_token = crq->IU_data_ptr;
 
 	err = h_copy_rdma(crq->IU_length, iue->adapter->riobn,
-			  iue->remote_token, adapter->liobn, iue->iu_token);
+			  iue->remote_token, adapter->liobn, iue->sbuf->dma);
 
 	if (err != H_Success)
 		eprintk("%ld transferring data error %p\n", err, iue);
@@ -1178,11 +1248,14 @@
 	INIT_WORK(&adapter->crq_work, handle_crq, adapter);
 	INIT_LIST_HEAD(&adapter->cmd_queue);
 
-	adapter->iu_pool = mempool_create(INITIAL_SRP_LIMIT,
-					  mempool_alloc_slab,
-					  mempool_free_slab, iu_cache);
-	if (!adapter->iu_pool)
+	err = srp_ring_alloc(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
+			     SRP_MAX_IU_LEN);
+	if (err)
 		goto put_host;
+	err = iu_pool_alloc(&adapter->iu_queue, INITIAL_SRP_LIMIT,
+			    adapter->rx_ring);
+	if (err)
+		goto free_ring;
 
 	err = crq_queue_create(&adapter->crq_queue, adapter);
 	if (err)
@@ -1195,7 +1268,10 @@
 destroy_queue:
 	crq_queue_destroy(adapter);
 free_pool:
-	mempool_destroy(adapter->iu_pool);
+	iu_pool_free(&adapter->iu_queue);
+free_ring:
+	srp_ring_free(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
+		      SRP_MAX_IU_LEN);
 put_host:
 	scsi_host_put(shost);
 
@@ -1209,7 +1285,9 @@
 	struct Scsi_Host *shost = adapter->shost;
 
 	crq_queue_destroy(adapter);
-	mempool_destroy(adapter->iu_pool);
+	srp_ring_free(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
+		      SRP_MAX_IU_LEN);
+	iu_pool_free(&adapter->iu_queue);
 	scsi_remove_host(shost);
 	scsi_host_put(shost);
 	return 0;
@@ -1261,20 +1339,12 @@
 static int ibmvstgt_init(void)
 {
 	int err = -ENOMEM;
-	size_t size = sizeof(struct iu_entry) + sizeof(union viosrp_iu);
 
 	printk("IBM eServer i/pSeries Virtual SCSI Target Driver\n");
 
-	iu_cache = kmem_cache_create("ibmvstgt_iu",
-				     size, 0,
-				     SLAB_HWCACHE_ALIGN | SLAB_NO_REAP,
-				     NULL, NULL);
-	if (!iu_cache)
-		return err;
-
 	vtgtd = create_workqueue("ibmvtgtd");
 	if (!vtgtd)
-		goto free_iu_cache;
+		return err;
 
 	err = get_system_info();
 	if (err < 0)
@@ -1288,9 +1358,6 @@
 
 destroy_wq:
 	destroy_workqueue(vtgtd);
-free_iu_cache:
-	kmem_cache_destroy(iu_cache);
-
 	return err;
 }
 
@@ -1300,7 +1367,6 @@
 
 	destroy_workqueue(vtgtd);
 	vio_unregister_driver(&ibmvstgt_driver);
-	kmem_cache_destroy(iu_cache);
 }
 
 module_init(ibmvstgt_init);



From tomo at berlios.de  Sat Apr 15 07:14:19 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 07:14:19 +0200
Subject: [Stgt-svn] r414 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604150514.k3F5EJ3n028304@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 07:14:15 +0200 (Sat, 15 Apr 2006)
New Revision: 414

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Fix ring buffer.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 03:24:39 UTC (rev 413)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 05:14:15 UTC (rev 414)
@@ -104,7 +104,7 @@
 	struct list_head cmd_queue;
 
 	struct srp_queue iu_queue;
-	struct srp_buf *rx_ring[INITIAL_SRP_LIMIT];
+	struct srp_buf **rx_ring;
 
 	unsigned long liobn;
 	unsigned long riobn;
@@ -176,11 +176,16 @@
 	kfree(q->pool);
 }
 
-static int srp_ring_alloc(struct device *dev, struct srp_buf **ring,
-			  size_t max, size_t size)
+static struct srp_buf ** srp_ring_alloc(struct device *dev,
+					size_t max, size_t size)
 {
 	int i;
+	struct srp_buf **ring;
 
+	ring = kcalloc(max, sizeof(struct srp_buf *), GFP_KERNEL);
+	if (!ring)
+		return NULL;
+
 	for (i = 0; i < max; i++) {
 		ring[i] = kzalloc(sizeof(struct srp_buf), GFP_KERNEL);
 		if (!ring[i])
@@ -198,7 +203,9 @@
 			dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
 		kfree(ring[i]);
 	}
-	return -ENOMEM;
+	kfree(ring);
+
+	return NULL;
 }
 
 static void srp_ring_free(struct device *dev, struct srp_buf **ring, size_t max,
@@ -1248,9 +1255,9 @@
 	INIT_WORK(&adapter->crq_work, handle_crq, adapter);
 	INIT_LIST_HEAD(&adapter->cmd_queue);
 
-	err = srp_ring_alloc(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
-			     SRP_MAX_IU_LEN);
-	if (err)
+	adapter->rx_ring = srp_ring_alloc(adapter->dev, INITIAL_SRP_LIMIT,
+					  SRP_MAX_IU_LEN);
+	if (!adapter->rx_ring)
 		goto put_host;
 	err = iu_pool_alloc(&adapter->iu_queue, INITIAL_SRP_LIMIT,
 			    adapter->rx_ring);



From tomo at berlios.de  Sat Apr 15 09:26:15 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 15 Apr 2006 09:26:15 +0200
Subject: [Stgt-svn] r415 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604150726.k3F7QF60005184@sheep.berlios.de>

Author: tomo
Date: 2006-04-15 09:25:34 +0200 (Sat, 15 Apr 2006)
New Revision: 415

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Split SRP common code from VIO stuff.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 05:14:15 UTC (rev 414)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 07:25:34 UTC (rev 415)
@@ -93,27 +93,31 @@
 	spinlock_t lock;
 };
 
-struct server_adapter {
+struct srp_target {
+	struct Scsi_Host *shost;
 	struct device *dev;
-	struct vio_dev *dma_dev;
 
-	struct crq_queue crq_queue;
-	struct work_struct crq_work;
-
 	spinlock_t lock; /* cmd_queue */
 	struct list_head cmd_queue;
 
 	struct srp_queue iu_queue;
 	struct srp_buf **rx_ring;
 
+	void *ldata;
+};
+
+struct vio_port {
+	struct vio_dev *dma_dev;
+
+	struct crq_queue crq_queue;
+	struct work_struct crq_work;
+
 	unsigned long liobn;
 	unsigned long riobn;
-
-	struct Scsi_Host *shost;
 };
 
 struct iu_entry {
-	struct server_adapter *adapter;
+	struct srp_target *target;
 	struct scsi_cmnd *scmd;
 
 	struct list_head ilist;
@@ -133,6 +137,16 @@
 static char partition_name[97] = "UNKNOWN";
 static unsigned int partition_number = -1;
 
+static struct srp_target *host_to_target(struct Scsi_Host *host)
+{
+	return (struct srp_target *) host->hostdata;
+}
+
+static struct vio_port *target_to_port(struct srp_target *target)
+{
+	return (struct vio_port *) target->ldata;
+}
+
 static union viosrp_iu *vio_iu(struct iu_entry *iue)
 {
 	return (union viosrp_iu *) (iue->sbuf->buf);
@@ -195,7 +209,7 @@
 		if (!ring[i]->buf)
 			goto out;
 	}
-	return 0;
+	return ring;
 
 out:
 	for (i = 0; i < max && ring[i]; i++) {
@@ -221,6 +235,8 @@
 
 static int send_iu(struct iu_entry *iue, uint64_t length, uint8_t format)
 {
+	struct srp_target *target = iue->target;
+	struct vio_port *vport = target_to_port(target);
 	long rc, rc1;
 	union {
 		struct viosrp_crq cooked;
@@ -228,8 +244,8 @@
 	} crq;
 
 	/* First copy the SRP */
-	rc = h_copy_rdma(length, iue->adapter->liobn, iue->sbuf->dma,
-			 iue->adapter->riobn, iue->remote_token);
+	rc = h_copy_rdma(length, vport->liobn, iue->sbuf->dma,
+			 vport->riobn, iue->remote_token);
 
 	if (rc)
 		eprintk("Error %ld transferring data\n", rc);
@@ -246,8 +262,7 @@
 	else
 		crq.cooked.status = 0x00;
 
-	rc1 = h_send_crq(iue->adapter->dma_dev->unit_address,
-			 crq.raw[0], crq.raw[1]);
+	rc1 = h_send_crq(vport->dma_dev->unit_address, crq.raw[0], crq.raw[1]);
 
 	if (rc1) {
 		eprintk("%ld sending response\n", rc1);
@@ -262,6 +277,7 @@
 static int send_rsp(struct iu_entry *iue, unsigned char status,
 		    unsigned char asc)
 {
+	struct srp_target *target = iue->target;
 	union viosrp_iu *iu = vio_iu(iue);
 	uint64_t tag = iu->srp.rsp.tag;
 	unsigned long flags;
@@ -272,9 +288,9 @@
 
 	memset(iu, 0, sizeof(struct srp_rsp));
 	iu->srp.rsp.opcode = SRP_RSP;
-	spin_lock_irqsave(&iue->adapter->lock, flags);
+	spin_lock_irqsave(&target->lock, flags);
 	iu->srp.rsp.req_lim_delta = 1;
-	spin_unlock_irqrestore(&iue->adapter->lock, flags);
+	spin_unlock_irqrestore(&target->lock, flags);
 	iu->srp.rsp.tag = tag;
 
 	if (test_bit(V_DIOVER, &iue->flags))
@@ -383,13 +399,13 @@
 
 static int process_cmd(struct iu_entry *iue)
 {
-	struct Scsi_host *shost = iue->adapter->shost;
+	struct Scsi_host *shost = iue->target->shost;
 	union viosrp_iu *iu = vio_iu(iue);
 	enum dma_data_direction data_dir;
 	struct scsi_cmnd *scmd;
 	int tag, len;
 
-	dprintk("%p %p\n", iue->adapter, iue);
+	dprintk("%p %p\n", iue->target, iue);
 
 	if (getlink(iue))
 		__set_bit(V_LINKED, &iue->flags);
@@ -448,30 +464,31 @@
 	return 0;
 }
 
-static void handle_cmd_queue(struct server_adapter *adapter)
+static void handle_cmd_queue(struct srp_target *target)
 {
 	struct iu_entry *iue;
 	unsigned long flags;
 
 retry:
-	spin_lock_irqsave(&adapter->lock, flags);
+	spin_lock_irqsave(&target->lock, flags);
 
-	list_for_each_entry(iue, &adapter->cmd_queue, ilist) {
+	list_for_each_entry(iue, &target->cmd_queue, ilist) {
 		if (!test_and_set_bit(V_FLYING, &iue->flags)) {
-			spin_unlock_irqrestore(&adapter->lock, flags);
+			spin_unlock_irqrestore(&target->lock, flags);
 			process_cmd(iue);
 			goto retry;
 		}
 	}
 
-	spin_unlock_irqrestore(&adapter->lock, flags);
+	spin_unlock_irqrestore(&target->lock, flags);
 }
 
 static int direct_data(struct scsi_cmnd *scmd, struct srp_direct_buf *md,
 		       enum dma_data_direction dir)
 {
 	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct server_adapter *adapter = iue->adapter;
+	struct srp_target *target = iue->target;
+	struct vio_port *vport = target_to_port(target);
 	struct scatterlist *sg = scmd->request_buffer;
 	unsigned int rest, len;
 	int i, done, nsg;
@@ -481,7 +498,7 @@
 	dprintk("%p %u %u %u %d\n", iue, scmd->request_bufflen, scmd->bufflen,
 		md->len, scmd->use_sg);
 
-	nsg = dma_map_sg(adapter->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
+	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
 	if (!nsg) {
 		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
 		return 0;
@@ -494,15 +511,11 @@
 		len = min(sg_dma_len(sg + i), rest);
 
 		if (dir == DMA_TO_DEVICE)
-			err = h_copy_rdma(len, adapter->riobn,
-					  md->va + done,
-					  adapter->liobn,
-					  token);
+			err = h_copy_rdma(len, vport->riobn, md->va + done,
+					  vport->liobn, token);
 		else
-			err = h_copy_rdma(len, adapter->liobn,
-					  token,
-					  adapter->riobn,
-					  md->va + done);
+			err = h_copy_rdma(len, vport->liobn, token,
+					  vport->riobn, md->va + done);
 
 		if (err != H_Success) {
 			eprintk("rdma error %d %d %ld\n", dir, i, err);
@@ -513,7 +526,7 @@
 		done += len;
 	}
 
-	dma_unmap_sg(adapter->dev, sg, nsg, DMA_BIDIRECTIONAL);
+	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
 
 	return done;
 }
@@ -522,7 +535,8 @@
 			 enum dma_data_direction dir)
 {
 	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct server_adapter *adapter = iue->adapter;
+	struct srp_target *target = iue->target;
+	struct vio_port *vport = target_to_port(target);
 	struct srp_cmd *cmd = &vio_iu(iue)->srp.cmd;
 	struct srp_direct_buf *mds;
 	struct scatterlist *sg = scmd->request_buffer;
@@ -544,22 +558,22 @@
 		goto rdma;
 	}
 
-	mds = dma_alloc_coherent(adapter->dev, id->table_desc.len,
+	mds = dma_alloc_coherent(target->dev, id->table_desc.len,
 				 &itoken, GFP_KERNEL);
 	if (!mds) {
 		eprintk("Can't get dma memory %u\n", id->table_desc.len);
 		return 0;
 	}
 
-	err = h_copy_rdma(id->table_desc.len, adapter->riobn,
-			  id->table_desc.va, adapter->liobn, itoken);
+	err = h_copy_rdma(id->table_desc.len, vport->riobn,
+			  id->table_desc.va, vport->liobn, itoken);
 	if (err != H_Success) {
 		eprintk("Error copying indirect table %ld\n", err);
 		goto free_mem;
 	}
 
 rdma:
-	nsg = dma_map_sg(adapter->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
+	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
 	if (!nsg) {
 		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
 		goto free_mem;
@@ -577,15 +591,15 @@
 
 			if (dir == DMA_TO_DEVICE)
 				err = h_copy_rdma(slen,
-						  adapter->riobn,
+						  vport->riobn,
 						  mds[i].va + mdone,
-						  adapter->liobn,
+						  vport->liobn,
 						  token + soff);
 			else
 				err = h_copy_rdma(slen,
-						  adapter->liobn,
+						  vport->liobn,
 						  token + soff,
-						  adapter->riobn,
+						  vport->riobn,
 						  mds[i].va + mdone);
 
 			if (err != H_Success) {
@@ -615,11 +629,11 @@
 	}
 
 unmap_sg:
-	dma_unmap_sg(adapter->dev, sg, nsg, DMA_BIDIRECTIONAL);
+	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
 
 free_mem:
 	if (itoken)
-		dma_free_coherent(adapter->dev, id->table_desc.len, mds, itoken);
+		dma_free_coherent(target->dev, id->table_desc.len, mds, itoken);
 
 	return done;
 }
@@ -679,14 +693,14 @@
 	return 0;
 }
 
-static struct iu_entry *get_iu(struct server_adapter *adapter)
+static struct iu_entry *get_iu(struct srp_target *target)
 {
 	struct iu_entry *iue = NULL;
 
-	kfifo_get(adapter->iu_queue.queue, (void *) &iue, sizeof(void *));
+	kfifo_get(target->iu_queue.queue, (void *) &iue, sizeof(void *));
 	BUG_ON(!iue);
 
-	iue->adapter = adapter;
+	iue->target = target;
 	iue->scmd = NULL;
 	INIT_LIST_HEAD(&iue->ilist);
 	iue->flags = 0;
@@ -696,7 +710,7 @@
 
 static void put_iu(struct iu_entry *iue)
 {
-	kfifo_put(iue->adapter->iu_queue.queue, (void *) &iue, sizeof(void *));
+	kfifo_put(iue->target->iu_queue.queue, (void *) &iue, sizeof(void *));
 }
 
 static int ibmvstgt_cmd_done(struct scsi_cmnd *scmd,
@@ -704,13 +718,13 @@
 {
 	unsigned long flags;
 	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct server_adapter *adapter = iue->adapter;
+	struct srp_target *target = iue->target;
 
-	dprintk("%p %p %x\n", iue, adapter, vio_iu(iue)->srp.cmd.cdb[0]);
+	dprintk("%p %p %x\n", iue, target, vio_iu(iue)->srp.cmd.cdb[0]);
 
-	spin_lock_irqsave(&adapter->lock, flags);
+	spin_lock_irqsave(&target->lock, flags);
 	list_del(&iue->ilist);
-	spin_unlock_irqrestore(&adapter->lock, flags);
+	spin_unlock_irqrestore(&target->lock, flags);
 
 	if (scmd->result != SAM_STAT_GOOD) {
 		eprintk("operation failed %p %d %x\n",
@@ -727,23 +741,23 @@
 int send_adapter_info(struct iu_entry *iue,
 		      dma_addr_t remote_buffer, uint16_t length)
 {
-	struct server_adapter *adapter = iue->adapter;
-	struct Scsi_Host *shost = adapter->shost;
+	struct srp_target *target = iue->target;
+	struct vio_port *vport = target_to_port(target);
+	struct Scsi_Host *shost = target->shost;
 	dma_addr_t data_token;
 	struct mad_adapter_info_data *info;
 	int err;
 
-	info = dma_alloc_coherent(adapter->dev, sizeof(*info),
-				  &data_token, GFP_KERNEL);
-
+	info = dma_alloc_coherent(target->dev, sizeof(*info), &data_token,
+				  GFP_KERNEL);
 	if (!info) {
-		eprintk("bad dma_alloc_coherent %p\n", adapter);
+		eprintk("bad dma_alloc_coherent %p\n", target);
 		return 1;
 	}
 
 	/* Get remote info */
-	err = h_copy_rdma(sizeof(*info), adapter->riobn, remote_buffer,
-			  adapter->liobn, data_token);
+	err = h_copy_rdma(sizeof(*info), vport->riobn, remote_buffer,
+			  vport->liobn, data_token);
 	if (err == H_Success) {
 		eprintk("Client connect: %s (%d)\n",
 			info->partition_name, info->partition_number);
@@ -760,11 +774,10 @@
 	info->port_max_txu[0] = shost->hostt->max_sectors << 9;
 
 	/* Send our info to remote */
-	err = h_copy_rdma(sizeof(*info), adapter->liobn, data_token,
-			  adapter->riobn, remote_buffer);
+	err = h_copy_rdma(sizeof(*info), vport->liobn, data_token,
+			  vport->riobn, remote_buffer);
 
-	dma_free_coherent(adapter->dev, sizeof(*info), info,
-			  data_token);
+	dma_free_coherent(target->dev, sizeof(*info), info, data_token);
 
 	if (err != H_Success) {
 		eprintk("Error sending adapter info %d\n", err);
@@ -798,13 +811,13 @@
 
 static inline void queue_cmd(struct iu_entry *iue)
 {
-	struct server_adapter *adapter = iue->adapter;
+	struct srp_target *target = iue->target;
 	unsigned long flags;
 
-	spin_lock_irqsave(&adapter->lock, flags);
-	list_add_tail(&iue->ilist, &iue->adapter->cmd_queue);
-	spin_unlock_irqrestore(&adapter->lock, flags);
-	handle_cmd_queue(adapter);
+	spin_lock_irqsave(&target->lock, flags);
+	list_add_tail(&iue->ilist, &target->cmd_queue);
+	spin_unlock_irqrestore(&target->lock, flags);
+	handle_cmd_queue(target);
 }
 
 static int process_tsk_mgmt(struct iu_entry *iue)
@@ -834,7 +847,7 @@
 		fn = 0;
 	}
 	if (fn)
-		scsi_tgt_tsk_mgmt_request(iue->adapter->shost, fn,
+		scsi_tgt_tsk_mgmt_request(iue->target->shost, fn,
 					  iu->srp.tsk_mgmt.task_tag,
 					  (struct scsi_lun *) &iu->srp.tsk_mgmt.lun,
 					  iue);
@@ -917,23 +930,24 @@
 	return done;
 }
 
-static void process_iu(struct viosrp_crq *crq, struct server_adapter *adapter)
+static void process_iu(struct viosrp_crq *crq, struct srp_target *target)
 {
+	struct vio_port *vport = target_to_port(target);
 	struct iu_entry *iue;
 	long err, done;
 
-	iue = get_iu(adapter);
+	iue = get_iu(target);
 	if (!iue) {
-		eprintk("Error getting IU from pool, %p\n", adapter);
+		eprintk("Error getting IU from pool, %p\n", target);
 		return;
 	}
 
-	dprintk("%p %p\n", adapter, iue);
+	dprintk("%p %p\n", target, iue);
 
 	iue->remote_token = crq->IU_data_ptr;
 
-	err = h_copy_rdma(crq->IU_length, iue->adapter->riobn,
-			  iue->remote_token, adapter->liobn, iue->sbuf->dma);
+	err = h_copy_rdma(crq->IU_length, vport->riobn,
+			  iue->remote_token, vport->liobn, iue->sbuf->dma);
 
 	if (err != H_Success)
 		eprintk("%ld transferring data error %p\n", err, iue);
@@ -947,35 +961,35 @@
 		put_iu(iue);
 }
 
-static irqreturn_t ibmvstgt_interrupt(int irq, void *dev_instance,
-				      struct pt_regs *regs)
+static irqreturn_t ibmvstgt_interrupt(int irq, void *data, struct pt_regs *regs)
 {
-	struct server_adapter *adapter = (struct server_adapter *)dev_instance;
+	struct srp_target *target = (struct srp_target *) data;
+	struct vio_port *vport = target_to_port(target);
 
-	vio_disable_interrupts(adapter->dma_dev);
-	queue_work(vtgtd, &adapter->crq_work);
+	vio_disable_interrupts(vport->dma_dev);
+	queue_work(vtgtd, &vport->crq_work);
 
 	return IRQ_HANDLED;
 }
 
-static int crq_queue_create(struct crq_queue *queue,
-			    struct server_adapter *adapter)
+static int crq_queue_create(struct crq_queue *queue, struct srp_target *target)
 {
 	int err;
+	struct vio_port *vport = target_to_port(target);
 
 	queue->msgs = (struct viosrp_crq *) get_zeroed_page(GFP_KERNEL);
 	if (!queue->msgs)
 		goto malloc_failed;
 	queue->size = PAGE_SIZE / sizeof(*queue->msgs);
 
-	queue->msg_token = dma_map_single(adapter->dev, queue->msgs,
+	queue->msg_token = dma_map_single(target->dev, queue->msgs,
 					  queue->size * sizeof(*queue->msgs),
 					  DMA_BIDIRECTIONAL);
 
 	if (dma_mapping_error(queue->msg_token))
 		goto map_failed;
 
-	err = h_reg_crq(adapter->dma_dev->unit_address, queue->msg_token,
+	err = h_reg_crq(vport->dma_dev->unit_address, queue->msg_token,
 			PAGE_SIZE);
 
 	/* If the adapter was left active for some reason (like kexec)
@@ -983,10 +997,10 @@
 	 */
 	if (err == H_Resource) {
 	    do {
-		err = h_free_crq(adapter->dma_dev->unit_address);
+		err = h_free_crq(vport->dma_dev->unit_address);
 	    } while (err == H_Busy || H_isLongBusy(err));
 
-	    err = h_reg_crq(adapter->dma_dev->unit_address, queue->msg_token,
+	    err = h_reg_crq(vport->dma_dev->unit_address, queue->msg_token,
 			    PAGE_SIZE);
 	}
 
@@ -995,14 +1009,14 @@
 		goto reg_crq_failed;
 	}
 
-	err = request_irq(adapter->dma_dev->irq, &ibmvstgt_interrupt,
-			  SA_INTERRUPT, "ibmvstgt", adapter);
+	err = request_irq(vport->dma_dev->irq, &ibmvstgt_interrupt,
+			  SA_INTERRUPT, "ibmvstgt", target);
 	if (err)
 		goto req_irq_failed;
 
-	vio_enable_interrupts(adapter->dma_dev);
+	vio_enable_interrupts(vport->dma_dev);
 
-	h_send_crq(adapter->dma_dev->unit_address, 0xC001000000000000, 0);
+	h_send_crq(vport->dma_dev->unit_address, 0xC001000000000000, 0);
 
 	queue->cur = 0;
 	spin_lock_init(&queue->lock);
@@ -1011,11 +1025,11 @@
 
 req_irq_failed:
 	do {
-		err = h_free_crq(adapter->dma_dev->unit_address);
+		err = h_free_crq(vport->dma_dev->unit_address);
 	} while (err == H_Busy || H_isLongBusy(err));
 
 reg_crq_failed:
-	dma_unmap_single(adapter->dev, queue->msg_token,
+	dma_unmap_single(target->dev, queue->msg_token,
 			 queue->size * sizeof(*queue->msgs), DMA_BIDIRECTIONAL);
 map_failed:
 	free_page((unsigned long) queue->msgs);
@@ -1024,25 +1038,26 @@
 	return -ENOMEM;
 }
 
-static void crq_queue_destroy(struct server_adapter *adapter)
+static void crq_queue_destroy(struct srp_target *target)
 {
-	struct crq_queue *queue = &adapter->crq_queue;
+	struct vio_port *vport = target_to_port(target);
+	struct crq_queue *queue = &vport->crq_queue;
 	int err;
 
-	free_irq(adapter->dma_dev->irq, adapter);
+	free_irq(vport->dma_dev->irq, target);
 	do {
-		err = h_free_crq(adapter->dma_dev->unit_address);
+		err = h_free_crq(vport->dma_dev->unit_address);
 	} while (err == H_Busy || H_isLongBusy(err));
 
-	dma_unmap_single(adapter->dev, queue->msg_token,
+	dma_unmap_single(target->dev, queue->msg_token,
 			 queue->size * sizeof(*queue->msgs), DMA_BIDIRECTIONAL);
 
 	free_page((unsigned long) queue->msgs);
 }
 
-static void process_crq(struct viosrp_crq *crq,
-			struct server_adapter *adapter)
+static void process_crq(struct viosrp_crq *crq,	struct srp_target *target)
 {
+	struct vio_port *vport = target_to_port(target);
 	dprintk("%x %x\n", crq->valid, crq->format);
 
 	switch (crq->valid) {
@@ -1050,7 +1065,7 @@
 		/* initialization */
 		switch (crq->format) {
 		case 0x01:
-			h_send_crq(adapter->dma_dev->unit_address,
+			h_send_crq(vport->dma_dev->unit_address,
 				   0xC002000000000000, 0);
 			break;
 		case 0x02:
@@ -1067,7 +1082,7 @@
 		switch (crq->format) {
 		case VIOSRP_SRP_FORMAT:
 		case VIOSRP_MAD_FORMAT:
-			process_iu(crq, adapter);
+			process_iu(crq, target);
 			break;
 		case VIOSRP_OS400_FORMAT:
 		case VIOSRP_AIX_FORMAT:
@@ -1103,41 +1118,42 @@
 
 static void handle_crq(void *data)
 {
-	struct server_adapter *adapter = (struct server_adapter *) data;
+	struct srp_target *target = (struct srp_target *) data;
+	struct vio_port *vport = target_to_port(target);
 	struct viosrp_crq *crq;
 	int done = 0;
 
 	while (!done) {
-		while ((crq = next_crq(&adapter->crq_queue)) != NULL) {
-			process_crq(crq, adapter);
+		while ((crq = next_crq(&vport->crq_queue)) != NULL) {
+			process_crq(crq, target);
 			crq->valid = 0x00;
 		}
 
-		vio_enable_interrupts(adapter->dma_dev);
+		vio_enable_interrupts(vport->dma_dev);
 
-		crq = next_crq(&adapter->crq_queue);
+		crq = next_crq(&vport->crq_queue);
 		if (crq) {
-			vio_disable_interrupts(adapter->dma_dev);
-			process_crq(crq, adapter);
+			vio_disable_interrupts(vport->dma_dev);
+			process_crq(crq, target);
 			crq->valid = 0x00;
 		} else
 			done = 1;
 	}
 
-	handle_cmd_queue(adapter);
+	handle_cmd_queue(target);
 }
 
 static int ibmvstgt_eh_abort_handler(struct scsi_cmnd *scmd)
 {
 	unsigned long flags;
 	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct server_adapter *adapter = iue->adapter;
+	struct srp_target *target = iue->target;
 
-	dprintk("%p %p %x\n", iue, adapter, vio_iu(iue)->srp.cmd.cdb[0]);
+	dprintk("%p %p %x\n", iue, target, vio_iu(iue)->srp.cmd.cdb[0]);
 
-	spin_lock_irqsave(&adapter->lock, flags);
+	spin_lock_irqsave(&target->lock, flags);
 	list_del(&iue->ilist);
-	spin_unlock_irqrestore(&adapter->lock, flags);
+	spin_unlock_irqrestore(&target->lock, flags);
 
 	put_iu(iue);
 
@@ -1170,8 +1186,6 @@
 	return 0;
 }
 
-#define	host_to_adapter(x)	(((struct server_adapter *) x->hostdata))
-
 static ssize_t
 system_id_show(struct class_device *cdev, char *buf)
 {
@@ -1188,8 +1202,9 @@
 unit_address_show(struct class_device *cdev, char *buf)
 {
 	struct Scsi_Host *shost = class_to_shost(cdev);
-	struct server_adapter *adapter = host_to_adapter(shost);
-	return snprintf(buf, PAGE_SIZE, "%x\n", adapter->dma_dev->unit_address);
+	struct srp_target *target = host_to_target(shost);
+	struct vio_port *vport = target_to_port(target);
+	return snprintf(buf, PAGE_SIZE, "%x\n", vport->dma_dev->unit_address);
 }
 
 static CLASS_DEVICE_ATTR(system_id, S_IRUGO, system_id_show, NULL);
@@ -1221,25 +1236,31 @@
 static int ibmvstgt_probe(struct vio_dev *dev, const struct vio_device_id *id)
 {
 	struct Scsi_Host *shost;
-	struct server_adapter *adapter;
+	struct srp_target *target;
+	struct vio_port *vport;
 	unsigned int *dma, dma_size;
 	int err = -ENOMEM;
 
 	dprintk("%s %s %x %u\n", dev->name, dev->type,
 		dev->unit_address, dev->irq);
 
-	shost = scsi_host_alloc(&ibmvstgt_sht, sizeof(struct server_adapter));
+	vport = kzalloc(sizeof(struct vio_port), GFP_KERNEL);
+	if (!vport)
+		return err;
+	shost = scsi_host_alloc(&ibmvstgt_sht, sizeof(struct srp_target));
 	if (!shost)
-		return err;
+		goto free_vport;
 	if (scsi_tgt_alloc_queue(shost))
 		goto put_host;
 
-	adapter = (struct server_adapter *) shost->hostdata;
-	adapter->shost = shost;
-	adapter->dma_dev = dev;
-	adapter->dev = &dev->dev;
-	adapter->dev->driver_data = adapter;
-	spin_lock_init(&adapter->lock);
+	target = host_to_target(shost);
+	target->shost = shost;
+	vport->dma_dev = dev;
+	target->dev = &dev->dev;
+	target->dev->driver_data = target;
+	spin_lock_init(&target->lock);
+	INIT_LIST_HEAD(&target->cmd_queue);
+	target->ldata = vport;
 
 	dma = (unsigned int *)
 		vio_get_attribute(dev, "ibm,my-dma-window", &dma_size);
@@ -1248,53 +1269,51 @@
 		err = -EIO;
 		goto put_host;
 	}
+	vport->liobn = dma[0];
+	vport->riobn = dma[5];
 
-	adapter->liobn = dma[0];
-	adapter->riobn = dma[5];
+	INIT_WORK(&vport->crq_work, handle_crq, target);
 
-	INIT_WORK(&adapter->crq_work, handle_crq, adapter);
-	INIT_LIST_HEAD(&adapter->cmd_queue);
-
-	adapter->rx_ring = srp_ring_alloc(adapter->dev, INITIAL_SRP_LIMIT,
+	target->rx_ring = srp_ring_alloc(target->dev, INITIAL_SRP_LIMIT,
 					  SRP_MAX_IU_LEN);
-	if (!adapter->rx_ring)
+	if (!target->rx_ring)
 		goto put_host;
-	err = iu_pool_alloc(&adapter->iu_queue, INITIAL_SRP_LIMIT,
-			    adapter->rx_ring);
+	err = iu_pool_alloc(&target->iu_queue, INITIAL_SRP_LIMIT,
+			    target->rx_ring);
 	if (err)
 		goto free_ring;
 
-	err = crq_queue_create(&adapter->crq_queue, adapter);
+	err = crq_queue_create(&vport->crq_queue, target);
 	if (err)
 		goto free_pool;
 
-	if (scsi_add_host(shost, adapter->dev))
+	if (scsi_add_host(shost, target->dev))
 		goto destroy_queue;
 	return 0;
 
 destroy_queue:
-	crq_queue_destroy(adapter);
+	crq_queue_destroy(target);
 free_pool:
-	iu_pool_free(&adapter->iu_queue);
+	iu_pool_free(&target->iu_queue);
 free_ring:
-	srp_ring_free(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
+	srp_ring_free(target->dev, target->rx_ring, INITIAL_SRP_LIMIT,
 		      SRP_MAX_IU_LEN);
 put_host:
 	scsi_host_put(shost);
-
+free_vport:
+	kfree(vport);
 	return err;
 }
 
 static int ibmvstgt_remove(struct vio_dev *dev)
 {
-	struct server_adapter *adapter =
-		(struct server_adapter *) dev->dev.driver_data;
-	struct Scsi_Host *shost = adapter->shost;
+	struct srp_target *target = (struct srp_target *) dev->dev.driver_data;
+	struct Scsi_Host *shost = target->shost;
 
-	crq_queue_destroy(adapter);
-	srp_ring_free(adapter->dev, adapter->rx_ring, INITIAL_SRP_LIMIT,
+	crq_queue_destroy(target);
+	srp_ring_free(target->dev, target->rx_ring, INITIAL_SRP_LIMIT,
 		      SRP_MAX_IU_LEN);
-	iu_pool_free(&adapter->iu_queue);
+	iu_pool_free(&target->iu_queue);
 	scsi_remove_host(shost);
 	scsi_host_put(shost);
 	return 0;



From tomo at berlios.de  Sun Apr 16 02:16:34 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 02:16:34 +0200
Subject: [Stgt-svn] r416 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160016.k3G0GY7J009649@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 02:16:11 +0200 (Sun, 16 Apr 2006)
New Revision: 416

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Just cleanups.

Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-15 07:25:34 UTC (rev 415)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 00:16:11 UTC (rev 416)
@@ -443,13 +443,12 @@
 		data_dir = DMA_FROM_DEVICE;
 	len = vscsis_data_length(&iu->srp.cmd, data_dir);
 
-	dprintk("%p %x %lx %d %d %d %llx\n",
-		iue, iu->srp.cmd.cdb[0], iu->srp.cmd.lun, data_dir, len, tag,
+	dprintk("%p %x %lx %d %d %d %llx\n", iue, iu->srp.cmd.cdb[0],
+		iu->srp.cmd.lun, data_dir, len, tag,
 		(unsigned long long) iu->srp.cmd.tag);
 
 	scmd = scsi_host_get_command(shost, data_dir, GFP_KERNEL);
 	BUG_ON(!scmd);
-
 	scmd->SCp.ptr = (char *) iue;
 	memcpy(scmd->data_cmnd, iu->srp.cmd.cdb, MAX_COMMAND_SIZE);
 	scmd->request_bufflen = len;
@@ -458,8 +457,8 @@
 	scsi_tgt_queue_command(scmd, (struct scsi_lun *) &iu->srp.cmd.lun,
 			       iu->srp.cmd.tag);
 
-	dprintk("%p %p %x %lx %d %d %d\n",
-		iue, scmd, iu->srp.cmd.cdb[0], iu->srp.cmd.lun, data_dir, len, tag);
+	dprintk("%p %p %x %lx %d %d %d\n", iue, scmd, iu->srp.cmd.cdb[0],
+		iu->srp.cmd.lun, data_dir, len, tag);
 
 	return 0;
 }
@@ -704,7 +703,6 @@
 	iue->scmd = NULL;
 	INIT_LIST_HEAD(&iue->ilist);
 	iue->flags = 0;
-
 	return iue;
 }
 
@@ -791,7 +789,6 @@
 {
 	union viosrp_iu *iu = vio_iu(iue);
 	struct srp_login_rsp *rsp = &iu->srp.login_rsp;
-
 	uint64_t tag = iu->srp.rsp.tag;
 
 	/* TODO handle case that requested size is wrong and
@@ -876,14 +873,12 @@
 		break;
 	case VIOSRP_ADAPTER_INFO_TYPE:
 		info = &iu->mad.adapter_info;
-
 		info->common.status = send_adapter_info(iue, info->buffer,
 							info->common.length);
 		send_iu(iue, sizeof(*info), VIOSRP_MAD_FORMAT);
 		break;
 	case VIOSRP_HOST_CONFIG_TYPE:
 		conf = &iu->mad.host_config;
-
 		conf->common.status = 1;
 		send_iu(iue, sizeof(*conf), VIOSRP_MAD_FORMAT);
 		break;
@@ -1186,20 +1181,17 @@
 	return 0;
 }
 
-static ssize_t
-system_id_show(struct class_device *cdev, char *buf)
+static ssize_t system_id_show(struct class_device *cdev, char *buf)
 {
 	return snprintf(buf, PAGE_SIZE, "%s\n", system_id);
 }
 
-static ssize_t
-partition_number_show(struct class_device *cdev, char *buf)
+static ssize_t partition_number_show(struct class_device *cdev, char *buf)
 {
 	return snprintf(buf, PAGE_SIZE, "%x\n", partition_number);
 }
 
-static ssize_t
-unit_address_show(struct class_device *cdev, char *buf)
+static ssize_t unit_address_show(struct class_device *cdev, char *buf)
 {
 	struct Scsi_Host *shost = class_to_shost(cdev);
 	struct srp_target *target = host_to_target(shost);
@@ -1250,7 +1242,8 @@
 	shost = scsi_host_alloc(&ibmvstgt_sht, sizeof(struct srp_target));
 	if (!shost)
 		goto free_vport;
-	if (scsi_tgt_alloc_queue(shost))
+	err = scsi_tgt_alloc_queue(shost);
+	if (err)
 		goto put_host;
 
 	target = host_to_target(shost);
@@ -1262,8 +1255,8 @@
 	INIT_LIST_HEAD(&target->cmd_queue);
 	target->ldata = vport;
 
-	dma = (unsigned int *)
-		vio_get_attribute(dev, "ibm,my-dma-window", &dma_size);
+	dma = (unsigned int *) vio_get_attribute(dev, "ibm,my-dma-window",
+						 &dma_size);
 	if (!dma || dma_size != 40) {
 		eprintk("Couldn't get window property %d\n", dma_size);
 		err = -EIO;
@@ -1287,7 +1280,8 @@
 	if (err)
 		goto free_pool;
 
-	if (scsi_add_host(shost, target->dev))
+	err = scsi_add_host(shost, target->dev);
+	if (err)
 		goto destroy_queue;
 	return 0;
 
@@ -1373,7 +1367,7 @@
 		return err;
 
 	err = get_system_info();
-	if (err < 0)
+	if (err)
 		goto destroy_wq;
 
 	err = vio_register_driver(&ibmvstgt_driver);



From tomo at berlios.de  Sun Apr 16 03:23:02 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 03:23:02 +0200
Subject: [Stgt-svn] r417 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160123.k3G1N2GF022989@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 03:22:56 +0200 (Sun, 16 Apr 2006)
New Revision: 417

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Stop calling handle_cmd_queue in queue_cmd for simplicity.


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 00:16:11 UTC (rev 416)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 01:22:56 UTC (rev 417)
@@ -814,7 +814,6 @@
 	spin_lock_irqsave(&target->lock, flags);
 	list_add_tail(&iue->ilist, &target->cmd_queue);
 	spin_unlock_irqrestore(&target->lock, flags);
-	handle_cmd_queue(target);
 }
 
 static int process_tsk_mgmt(struct iu_entry *iue)



From tomo at berlios.de  Sun Apr 16 04:33:14 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 04:33:14 +0200
Subject: [Stgt-svn] r418 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160233.k3G2XEC1011341@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 04:33:07 +0200 (Sun, 16 Apr 2006)
New Revision: 418

Added:
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/Makefile
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Initial try for libsrp


Modified: branches/use-scsi-ml/ibmvstgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/Makefile	2006-04-16 01:22:56 UTC (rev 417)
+++ branches/use-scsi-ml/ibmvstgt/kernel/Makefile	2006-04-16 02:33:07 UTC (rev 418)
@@ -1,8 +1,7 @@
-EXTRA_CFLAGS += -I$(KERNELSRC)/drivers/scsi/ibmvscsi/
+EXTRA_CFLAGS += -I$(obj) -I$(KERNELSRC)/drivers/scsi/ibmvscsi/
 
 ifneq ($(KERNELRELEASE),)
-obj-m		+= ibmvstgt.o
-
+obj-m		+= ibmvstgt.o libsrp.o
 else
 
 ifeq ($(KERNELSRC),)

Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 01:22:56 UTC (rev 417)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 02:33:07 UTC (rev 418)
@@ -24,7 +24,6 @@
 
 #include <linux/interrupt.h>
 #include <linux/module.h>
-#include <linux/kfifo.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_host.h>
 #include <scsi/scsi_tcq.h>
@@ -35,6 +34,7 @@
 #include <asm/prom.h>
 #include <asm/vio.h>
 
+#include "libsrp.h"
 #include "ibmvscsi.h"
 
 #define	INITIAL_SRP_LIMIT	16
@@ -81,31 +81,6 @@
 	SRP_ACA_TASK = 4
 };
 
-struct srp_buf {
-	dma_addr_t dma;
-	void *buf;
-};
-
-struct srp_queue {
-	void *pool;
-	void *items;
-	struct kfifo *queue;
-	spinlock_t lock;
-};
-
-struct srp_target {
-	struct Scsi_Host *shost;
-	struct device *dev;
-
-	spinlock_t lock; /* cmd_queue */
-	struct list_head cmd_queue;
-
-	struct srp_queue iu_queue;
-	struct srp_buf **rx_ring;
-
-	void *ldata;
-};
-
 struct vio_port {
 	struct vio_dev *dma_dev;
 
@@ -116,17 +91,6 @@
 	unsigned long riobn;
 };
 
-struct iu_entry {
-	struct srp_target *target;
-	struct scsi_cmnd *scmd;
-
-	struct list_head ilist;
-	dma_addr_t remote_token;
-	unsigned long flags;
-
-	struct srp_buf *sbuf;
-};
-
 static struct workqueue_struct *vtgtd;
 
 /*
@@ -137,102 +101,11 @@
 static char partition_name[97] = "UNKNOWN";
 static unsigned int partition_number = -1;
 
-static struct srp_target *host_to_target(struct Scsi_Host *host)
-{
-	return (struct srp_target *) host->hostdata;
-}
-
 static struct vio_port *target_to_port(struct srp_target *target)
 {
 	return (struct vio_port *) target->ldata;
 }
 
-static union viosrp_iu *vio_iu(struct iu_entry *iue)
-{
-	return (union viosrp_iu *) (iue->sbuf->buf);
-}
-
-static int iu_pool_alloc(struct srp_queue *q, size_t max, struct srp_buf **ring)
-{
-	int i;
-	struct iu_entry *iue;
-
-	q->pool = kcalloc(max, sizeof(struct iu_entry *), GFP_KERNEL);
-	if (!q->pool)
-		return -ENOMEM;
-	q->items = kcalloc(max, sizeof(struct iu_entry), GFP_KERNEL);
-	if (!q->items)
-		goto free_pool;
-
-	spin_lock_init(&q->lock);
-	q->queue = kfifo_init((void *) q->pool, max * sizeof(void *),
-			      GFP_KERNEL, &q->lock);
-	if (IS_ERR(q->queue))
-		goto free_item;
-
-	for (i = 0, iue = q->items; i < max; i++) {
-		__kfifo_put(q->queue, (void *) &iue, sizeof(void *));
-		iue->sbuf = ring[i];
-		iue++;
-	}
-	return 0;
-
-free_item:
-	kfree(q->items);
-free_pool:
-	kfree(q->pool);
-	return -ENOMEM;
-}
-
-static void iu_pool_free(struct srp_queue *q)
-{
-	kfree(q->items);
-	kfree(q->pool);
-}
-
-static struct srp_buf ** srp_ring_alloc(struct device *dev,
-					size_t max, size_t size)
-{
-	int i;
-	struct srp_buf **ring;
-
-	ring = kcalloc(max, sizeof(struct srp_buf *), GFP_KERNEL);
-	if (!ring)
-		return NULL;
-
-	for (i = 0; i < max; i++) {
-		ring[i] = kzalloc(sizeof(struct srp_buf), GFP_KERNEL);
-		if (!ring[i])
-			goto out;
-		ring[i]->buf = dma_alloc_coherent(dev, size, &ring[i]->dma,
-						  GFP_KERNEL);
-		if (!ring[i]->buf)
-			goto out;
-	}
-	return ring;
-
-out:
-	for (i = 0; i < max && ring[i]; i++) {
-		if (ring[i]->buf)
-			dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
-		kfree(ring[i]);
-	}
-	kfree(ring);
-
-	return NULL;
-}
-
-static void srp_ring_free(struct device *dev, struct srp_buf **ring, size_t max,
-			  size_t size)
-{
-	int i;
-
-	for (i = 0; i < max; i++) {
-		dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
-		kfree(ring[i]);
-	}
-}
-
 static int send_iu(struct iu_entry *iue, uint64_t length, uint8_t format)
 {
 	struct srp_target *target = iue->target;
@@ -692,25 +565,6 @@
 	return 0;
 }
 
-static struct iu_entry *get_iu(struct srp_target *target)
-{
-	struct iu_entry *iue = NULL;
-
-	kfifo_get(target->iu_queue.queue, (void *) &iue, sizeof(void *));
-	BUG_ON(!iue);
-
-	iue->target = target;
-	iue->scmd = NULL;
-	INIT_LIST_HEAD(&iue->ilist);
-	iue->flags = 0;
-	return iue;
-}
-
-static void put_iu(struct iu_entry *iue)
-{
-	kfifo_put(iue->target->iu_queue.queue, (void *) &iue, sizeof(void *));
-}
-
 static int ibmvstgt_cmd_done(struct scsi_cmnd *scmd,
 			     void (*done)(struct scsi_cmnd *))
 {
@@ -732,7 +586,7 @@
 		send_rsp(iue, NO_SENSE, 0x00);
 
 	done(scmd);
-	put_iu(iue);
+	srp_iu_put(iue);
 	return 0;
 }
 
@@ -930,7 +784,7 @@
 	struct iu_entry *iue;
 	long err, done;
 
-	iue = get_iu(target);
+	iue = srp_iu_get(target);
 	if (!iue) {
 		eprintk("Error getting IU from pool, %p\n", target);
 		return;
@@ -952,7 +806,7 @@
 		done = process_srp_iu(iue);
 
 	if (done)
-		put_iu(iue);
+		srp_iu_put(iue);
 }
 
 static irqreturn_t ibmvstgt_interrupt(int irq, void *data, struct pt_regs *regs)
@@ -1149,7 +1003,7 @@
 	list_del(&iue->ilist);
 	spin_unlock_irqrestore(&target->lock, flags);
 
-	put_iu(iue);
+	srp_iu_put(iue);
 
 	return 0;
 }
@@ -1175,7 +1029,7 @@
 	}
 
 	send_rsp(iue, status, asc);
-	put_iu(iue);
+	srp_iu_put(iue);
 
 	return 0;
 }
@@ -1248,36 +1102,27 @@
 	target = host_to_target(shost);
 	target->shost = shost;
 	vport->dma_dev = dev;
-	target->dev = &dev->dev;
-	target->dev->driver_data = target;
-	spin_lock_init(&target->lock);
-	INIT_LIST_HEAD(&target->cmd_queue);
 	target->ldata = vport;
+	err = srp_target_alloc(target, &dev->dev, INITIAL_SRP_LIMIT,
+			       SRP_MAX_IU_LEN);
+	if (err)
+		goto put_host;
 
 	dma = (unsigned int *) vio_get_attribute(dev, "ibm,my-dma-window",
 						 &dma_size);
 	if (!dma || dma_size != 40) {
 		eprintk("Couldn't get window property %d\n", dma_size);
 		err = -EIO;
-		goto put_host;
+		goto free_srp_target;
 	}
 	vport->liobn = dma[0];
 	vport->riobn = dma[5];
 
 	INIT_WORK(&vport->crq_work, handle_crq, target);
 
-	target->rx_ring = srp_ring_alloc(target->dev, INITIAL_SRP_LIMIT,
-					  SRP_MAX_IU_LEN);
-	if (!target->rx_ring)
-		goto put_host;
-	err = iu_pool_alloc(&target->iu_queue, INITIAL_SRP_LIMIT,
-			    target->rx_ring);
-	if (err)
-		goto free_ring;
-
 	err = crq_queue_create(&vport->crq_queue, target);
 	if (err)
-		goto free_pool;
+		goto free_srp_target;
 
 	err = scsi_add_host(shost, target->dev);
 	if (err)
@@ -1286,11 +1131,8 @@
 
 destroy_queue:
 	crq_queue_destroy(target);
-free_pool:
-	iu_pool_free(&target->iu_queue);
-free_ring:
-	srp_ring_free(target->dev, target->rx_ring, INITIAL_SRP_LIMIT,
-		      SRP_MAX_IU_LEN);
+free_srp_target:
+	srp_target_free(target);
 put_host:
 	scsi_host_put(shost);
 free_vport:
@@ -1303,10 +1145,8 @@
 	struct srp_target *target = (struct srp_target *) dev->dev.driver_data;
 	struct Scsi_Host *shost = target->shost;
 
+	srp_target_free(target);
 	crq_queue_destroy(target);
-	srp_ring_free(target->dev, target->rx_ring, INITIAL_SRP_LIMIT,
-		      SRP_MAX_IU_LEN);
-	iu_pool_free(&target->iu_queue);
 	scsi_remove_host(shost);
 	scsi_host_put(shost);
 	return 0;

Added: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 01:22:56 UTC (rev 417)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 02:33:07 UTC (rev 418)
@@ -0,0 +1,163 @@
+/*
+ * SCSI RDAM Protocol lib functions
+ *
+ * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+#include <linux/err.h>
+#include <linux/kfifo.h>
+#include <linux/dma-mapping.h>
+#include <libsrp.h>
+
+static int srp_iu_pool_alloc(struct srp_queue *q, size_t max,
+			     struct srp_buf **ring)
+{
+	int i;
+	struct iu_entry *iue;
+
+	q->pool = kcalloc(max, sizeof(struct iu_entry *), GFP_KERNEL);
+	if (!q->pool)
+		return -ENOMEM;
+	q->items = kcalloc(max, sizeof(struct iu_entry), GFP_KERNEL);
+	if (!q->items)
+		goto free_pool;
+
+	spin_lock_init(&q->lock);
+	q->queue = kfifo_init((void *) q->pool, max * sizeof(void *),
+			      GFP_KERNEL, &q->lock);
+	if (IS_ERR(q->queue))
+		goto free_item;
+
+	for (i = 0, iue = q->items; i < max; i++) {
+		__kfifo_put(q->queue, (void *) &iue, sizeof(void *));
+		iue->sbuf = ring[i];
+		iue++;
+	}
+	return 0;
+
+free_item:
+	kfree(q->items);
+free_pool:
+	kfree(q->pool);
+	return -ENOMEM;
+}
+
+static void srp_iu_pool_free(struct srp_queue *q)
+{
+	kfree(q->items);
+	kfree(q->pool);
+}
+
+static struct srp_buf ** srp_ring_alloc(struct device *dev,
+					size_t max, size_t size)
+{
+	int i;
+	struct srp_buf **ring;
+
+	ring = kcalloc(max, sizeof(struct srp_buf *), GFP_KERNEL);
+	if (!ring)
+		return NULL;
+
+	for (i = 0; i < max; i++) {
+		ring[i] = kzalloc(sizeof(struct srp_buf), GFP_KERNEL);
+		if (!ring[i])
+			goto out;
+		ring[i]->buf = dma_alloc_coherent(dev, size, &ring[i]->dma,
+						  GFP_KERNEL);
+		if (!ring[i]->buf)
+			goto out;
+	}
+	return ring;
+
+out:
+	for (i = 0; i < max && ring[i]; i++) {
+		if (ring[i]->buf)
+			dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
+		kfree(ring[i]);
+	}
+	kfree(ring);
+
+	return NULL;
+}
+
+static void srp_ring_free(struct device *dev, struct srp_buf **ring, size_t max,
+			  size_t size)
+{
+	int i;
+
+	for (i = 0; i < max; i++) {
+		dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
+		kfree(ring[i]);
+	}
+}
+
+int srp_target_alloc(struct srp_target *target, struct device *dev,
+		     size_t nr, size_t iu_size)
+{
+	int err;
+
+	spin_lock_init(&target->lock);
+	INIT_LIST_HEAD(&target->cmd_queue);
+
+	target->dev = dev;
+	target->dev->driver_data = target;
+
+	target->srp_iu_size = iu_size;
+	target->rx_ring_size = nr;
+	target->rx_ring = srp_ring_alloc(target->dev, nr, iu_size);
+	if (!target->rx_ring)
+		return -ENOMEM;
+	err = srp_iu_pool_alloc(&target->iu_queue, nr, target->rx_ring);
+	if (err)
+		goto free_ring;
+
+	return 0;
+
+free_ring:
+	srp_ring_free(target->dev, target->rx_ring, nr, iu_size);
+	return -ENOMEM;
+}
+EXPORT_SYMBOL_GPL(srp_target_alloc);
+
+void srp_target_free(struct srp_target *target)
+{
+	srp_ring_free(target->dev, target->rx_ring, target->rx_ring_size,
+		      target->srp_iu_size);
+	srp_iu_pool_free(&target->iu_queue);
+}
+EXPORT_SYMBOL_GPL(srp_target_free);
+
+struct iu_entry *srp_iu_get(struct srp_target *target)
+{
+	struct iu_entry *iue = NULL;
+
+	kfifo_get(target->iu_queue.queue, (void *) &iue, sizeof(void *));
+	BUG_ON(!iue);
+
+	iue->target = target;
+	iue->scmd = NULL;
+	INIT_LIST_HEAD(&iue->ilist);
+	iue->flags = 0;
+	return iue;
+}
+EXPORT_SYMBOL_GPL(srp_iu_get);
+
+void srp_iu_put(struct iu_entry *iue)
+{
+	kfifo_put(iue->target->iu_queue.queue, (void *) &iue, sizeof(void *));
+}
+EXPORT_SYMBOL_GPL(srp_iu_put);

Added: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 01:22:56 UTC (rev 417)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 02:33:07 UTC (rev 418)
@@ -0,0 +1,63 @@
+#ifndef __LIBSRP_H__
+#define __LIBSRP_H__
+
+#include <linux/list.h>
+#include <scsi/scsi_host.h>
+
+struct srp_buf {
+	dma_addr_t dma;
+	void *buf;
+};
+
+struct srp_queue {
+	void *pool;
+	void *items;
+	struct kfifo *queue;
+	spinlock_t lock;
+};
+
+struct srp_target {
+	struct Scsi_Host *shost;
+	struct device *dev;
+
+	spinlock_t lock;
+	struct list_head cmd_queue;
+
+	size_t srp_iu_size;
+	struct srp_queue iu_queue;
+	size_t rx_ring_size;
+	struct srp_buf **rx_ring;
+
+	/* IB needs tx_ring too */
+
+	void *ldata;
+};
+
+struct iu_entry {
+	struct srp_target *target;
+	struct scsi_cmnd *scmd;
+
+	struct list_head ilist;
+	dma_addr_t remote_token;
+	unsigned long flags;
+
+	struct srp_buf *sbuf;
+};
+
+static inline struct srp_target *host_to_target(struct Scsi_Host *host)
+{
+	return (struct srp_target *) host->hostdata;
+}
+
+static inline union viosrp_iu *vio_iu(struct iu_entry *iue)
+{
+	return (union viosrp_iu *) (iue->sbuf->buf);
+}
+
+extern int srp_target_alloc(struct srp_target *, struct device *, size_t, size_t);
+extern void srp_target_free(struct srp_target *);
+
+extern struct iu_entry *srp_iu_get(struct srp_target *);
+extern void srp_iu_put(struct iu_entry *);
+
+#endif



From tomo at berlios.de  Sun Apr 16 04:34:17 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 04:34:17 +0200
Subject: [Stgt-svn] r419 - branches/use-scsi-ml
Message-ID: <200604160234.k3G2YHaW011545@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 04:34:07 +0200 (Sun, 16 Apr 2006)
New Revision: 419

Modified:
   branches/use-scsi-ml/initd
Log:
init script changes for libsrp.

Modified: branches/use-scsi-ml/initd
===================================================================
--- branches/use-scsi-ml/initd	2006-04-16 02:33:07 UTC (rev 418)
+++ branches/use-scsi-ml/initd	2006-04-16 02:34:07 UTC (rev 419)
@@ -19,6 +19,7 @@
 		modprobe -q crc32c
 		insmod ${PWD}/istgt/kernel/istgt.ko
 	else
+		insmod ${PWD}/ibmvstgt/kernel/libsrp.ko
 		insmod ${PWD}/ibmvstgt/kernel/ibmvstgt.ko
 	fi
 
@@ -49,6 +50,7 @@
 	if [ "$TARGET" = "istgt" ] ; then
 		rmmod istgt
 	else
+		rmmod libsrp
 		rmmod ibmvstgt
 	fi
 



From tomo at berlios.de  Sun Apr 16 09:14:29 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 09:14:29 +0200
Subject: [Stgt-svn] r420 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160714.k3G7ETWk028926@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 09:14:24 +0200 (Sun, 16 Apr 2006)
New Revision: 420

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
Log:
Move viosrp_iu to ibmvstgt.

Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 02:34:07 UTC (rev 419)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 07:14:24 UTC (rev 420)
@@ -106,6 +106,11 @@
 	return (struct vio_port *) target->ldata;
 }
 
+static inline union viosrp_iu *vio_iu(struct iu_entry *iue)
+{
+	return (union viosrp_iu *) (iue->sbuf->buf);
+}
+
 static int send_iu(struct iu_entry *iue, uint64_t length, uint8_t format)
 {
 	struct srp_target *target = iue->target;

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 02:34:07 UTC (rev 419)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 07:14:24 UTC (rev 420)
@@ -49,11 +49,6 @@
 	return (struct srp_target *) host->hostdata;
 }
 
-static inline union viosrp_iu *vio_iu(struct iu_entry *iue)
-{
-	return (union viosrp_iu *) (iue->sbuf->buf);
-}
-
 extern int srp_target_alloc(struct srp_target *, struct device *, size_t, size_t);
 extern void srp_target_free(struct srp_target *);
 



From tomo at berlios.de  Sun Apr 16 10:42:58 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 10:42:58 +0200
Subject: [Stgt-svn] r421 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160842.k3G8gw5J021079@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 10:42:57 +0200 (Sun, 16 Apr 2006)
New Revision: 421

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
Log:
Move data buffer code to libsrp


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 07:14:24 UTC (rev 420)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 08:42:57 UTC (rev 421)
@@ -67,13 +67,6 @@
 #define dprintk eprintk
 /* #define dprintk(fmt, args...) */
 
-enum iue_flags {
-	V_DIOVER,
-	V_WRITE,
-	V_LINKED,
-	V_FLYING,
-};
-
 enum srp_task_attributes {
 	SRP_SIMPLE_TASK = 0,
 	SRP_HEAD_TASK = 1,
@@ -360,116 +353,31 @@
 	spin_unlock_irqrestore(&target->lock, flags);
 }
 
-static int direct_data(struct scsi_cmnd *scmd, struct srp_direct_buf *md,
-		       enum dma_data_direction dir)
+int ibmvstgt_rdma(struct iu_entry *iue, struct scatterlist *sg, int nsg,
+		  struct srp_direct_buf *md, int nmd,
+		  enum dma_data_direction dir, unsigned int rest)
 {
-	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
 	struct srp_target *target = iue->target;
 	struct vio_port *vport = target_to_port(target);
-	struct scatterlist *sg = scmd->request_buffer;
-	unsigned int rest, len;
-	int i, done, nsg;
-	long err;
 	dma_addr_t token;
-
-	dprintk("%p %u %u %u %d\n", iue, scmd->request_bufflen, scmd->bufflen,
-		md->len, scmd->use_sg);
-
-	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
-	if (!nsg) {
-		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
-		return 0;
-	}
-
-	rest = min(scmd->request_bufflen, md->len);
-
-	for (i = 0, done = 0; i < nsg && rest; i++) {
-		token = sg_dma_address(sg + i);
-		len = min(sg_dma_len(sg + i), rest);
-
-		if (dir == DMA_TO_DEVICE)
-			err = h_copy_rdma(len, vport->riobn, md->va + done,
-					  vport->liobn, token);
-		else
-			err = h_copy_rdma(len, vport->liobn, token,
-					  vport->riobn, md->va + done);
-
-		if (err != H_Success) {
-			eprintk("rdma error %d %d %ld\n", dir, i, err);
-			break;
-		}
-
-		rest -= len;
-		done += len;
-	}
-
-	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
-
-	return done;
-}
-
-static int indirect_data(struct scsi_cmnd *scmd, struct srp_indirect_buf *id,
-			 enum dma_data_direction dir)
-{
-	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct srp_target *target = iue->target;
-	struct vio_port *vport = target_to_port(target);
-	struct srp_cmd *cmd = &vio_iu(iue)->srp.cmd;
-	struct srp_direct_buf *mds;
-	struct scatterlist *sg = scmd->request_buffer;
-	dma_addr_t token, itoken = 0;
 	long err;
-	unsigned int rest, done = 0;
-	int i, nmd, nsg, sidx, soff;
+	unsigned int done = 0;
+	int i, sidx, soff;
 
-	nmd = id->table_desc.len / sizeof(struct srp_direct_buf);
-
-	dprintk("%p %u %u %u %u %d %d %d\n",
-		iue, scmd->request_bufflen, scmd->bufflen,
-		id->len, scmd->offset, nmd,
-		cmd->data_in_desc_cnt, cmd->data_out_desc_cnt);
-
-	if ((dir == DMA_FROM_DEVICE && nmd == cmd->data_in_desc_cnt) ||
-	    (dir == DMA_TO_DEVICE && nmd == cmd->data_out_desc_cnt)) {
-		mds = &id->desc_list[0];
-		goto rdma;
-	}
-
-	mds = dma_alloc_coherent(target->dev, id->table_desc.len,
-				 &itoken, GFP_KERNEL);
-	if (!mds) {
-		eprintk("Can't get dma memory %u\n", id->table_desc.len);
-		return 0;
-	}
-
-	err = h_copy_rdma(id->table_desc.len, vport->riobn,
-			  id->table_desc.va, vport->liobn, itoken);
-	if (err != H_Success) {
-		eprintk("Error copying indirect table %ld\n", err);
-		goto free_mem;
-	}
-
-rdma:
-	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
-	if (!nsg) {
-		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
-		goto free_mem;
-	}
-
 	sidx = soff = 0;
 	token = sg_dma_address(sg + sidx);
-	rest = min(scmd->request_bufflen, id->len);
+
 	for (i = 0; i < nmd && rest; i++) {
 		unsigned int mdone, mlen;
 
-		mlen = min(rest, mds[i].len);
+		mlen = min(rest, md[i].len);
 		for (mdone = 0; mlen;) {
 			int slen = min(sg_dma_len(sg + sidx) - soff, mlen);
 
 			if (dir == DMA_TO_DEVICE)
 				err = h_copy_rdma(slen,
 						  vport->riobn,
-						  mds[i].va + mdone,
+						  md[i].va + mdone,
 						  vport->liobn,
 						  token + soff);
 			else
@@ -477,11 +385,11 @@
 						  vport->liobn,
 						  token + soff,
 						  vport->riobn,
-						  mds[i].va + mdone);
+						  md[i].va + mdone);
 
 			if (err != H_Success) {
 				eprintk("rdma error %d %d\n", dir, slen);
-				goto unmap_sg;
+				goto out;
 			}
 
 			mlen -= slen;
@@ -495,81 +403,32 @@
 				token = sg_dma_address(sg + sidx);
 
 				if (sidx > nsg) {
-					eprintk("out of sg %p %d %d %d\n",
-						iue, sidx, nsg, scmd->use_sg);
-					goto unmap_sg;
+					eprintk("out of sg %p %d %d\n",
+						iue, sidx, nsg);
+					goto out;
 				}
 			}
 		};
 
 		rest -= mlen;
 	}
+out:
 
-unmap_sg:
-	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
-
-free_mem:
-	if (itoken)
-		dma_free_coherent(target->dev, id->table_desc.len, mds, itoken);
-
-	return done;
+	return 0;
 }
 
-static int handle_cmd_data(struct scsi_cmnd *scmd, enum dma_data_direction dir)
+static int ibmvstgt_transfer_data(struct scsi_cmnd *scmd,
+				  void (*done)(struct scsi_cmnd *))
 {
-	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
-	struct srp_cmd *cmd = &vio_iu(iue)->srp.cmd;
-	struct srp_direct_buf *md;
-	struct srp_indirect_buf *id;
-	int offset, err = 0;
-	u8 format;
+	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
+	int err;
 
-	offset = cmd->add_cdb_len * 4;
-	if (dir == DMA_FROM_DEVICE)
-		offset += data_out_desc_size(cmd);
+	err = srp_transfer_data(scmd, &vio_iu(iue)->srp.cmd, ibmvstgt_rdma);
+	done(scmd);
 
-	if (dir == DMA_TO_DEVICE)
-		format = cmd->buf_fmt >> 4;
-	else
-		format = cmd->buf_fmt & ((1U << 4) - 1);
-
-	switch (format) {
-	case SRP_NO_DATA_DESC:
-		break;
-	case SRP_DATA_DESC_DIRECT:
-		md = (struct srp_direct_buf *)
-			(cmd->add_data + offset);
-		err = direct_data(scmd, md, dir);
-		break;
-	case SRP_DATA_DESC_INDIRECT:
-		id = (struct srp_indirect_buf *)
-			(cmd->add_data + offset);
-		err = indirect_data(scmd, id, dir);
-		break;
-	default:
-		eprintk("Unknown format %d %x\n", dir, format);
-		break;
-	}
-
 	return err;
 }
 
-/* TODO: this can be called multiple times for a single command. */
-static int recv_cmd_data(struct scsi_cmnd *scmd,
-			 void (*done)(struct scsi_cmnd *))
-{
-	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
-	enum dma_data_direction dir;
-
-	if (test_bit(V_WRITE, &iue->flags))
-		dir = DMA_TO_DEVICE;
-	else
-		dir = DMA_FROM_DEVICE;
-	handle_cmd_data(scmd, dir);
-	done(scmd);
-	return 0;
-}
-
 static int ibmvstgt_cmd_done(struct scsi_cmnd *scmd,
 			     void (*done)(struct scsi_cmnd *))
 {
@@ -1076,7 +935,7 @@
 	.use_clustering		= DISABLE_CLUSTERING,
 	.max_sectors		= DEFAULT_MAX_SECTORS,
 	.transfer_response	= ibmvstgt_cmd_done,
-	.transfer_data		= recv_cmd_data,
+	.transfer_data		= ibmvstgt_transfer_data,
 	.eh_abort_handler	= ibmvstgt_eh_abort_handler,
 	.tsk_mgmt_response	= ibmvstgt_tsk_mgmt_response,
 	.shost_attrs		= ibmvstgt_attrs,

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 07:14:24 UTC (rev 420)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 08:42:57 UTC (rev 421)
@@ -20,9 +20,21 @@
  */
 #include <linux/err.h>
 #include <linux/kfifo.h>
+#include <linux/scatterlist.h>
 #include <linux/dma-mapping.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/srp.h>
 #include <libsrp.h>
 
+/* tmp - will replace with SCSI logging stuff */
+#define eprintk(fmt, args...)					\
+do {								\
+	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
+} while (0)
+
+#define dprintk eprintk
+/* #define dprintk(fmt, args...) */
+
 static int srp_iu_pool_alloc(struct srp_queue *q, size_t max,
 			     struct srp_buf **ring)
 {
@@ -161,3 +173,163 @@
 	kfifo_put(iue->target->iu_queue.queue, (void *) &iue, sizeof(void *));
 }
 EXPORT_SYMBOL_GPL(srp_iu_put);
+
+static int direct_data(struct scsi_cmnd *scmd, struct srp_direct_buf *md,
+		       enum dma_data_direction dir, rdma_io_t rdma_io)
+{
+	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
+	struct srp_target *target = iue->target;
+	struct scatterlist *sg = scmd->request_buffer;
+	int nsg, err;
+
+	dprintk("%p %u %u %u %d\n", iue, scmd->request_bufflen, scmd->bufflen,
+		md->len, scmd->use_sg);
+
+	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
+	if (!nsg) {
+		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
+		return 0;
+	}
+	err = rdma_io(iue, sg, nsg, md, 1, dir,
+		      min(scmd->request_bufflen, md->len));
+
+	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
+
+	return err;
+}
+
+static int indirect_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
+			 struct srp_indirect_buf *id,
+			 enum dma_data_direction dir, rdma_io_t rdma_io)
+{
+	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
+	struct srp_target *target = iue->target;
+	struct srp_direct_buf *md;
+	struct scatterlist dummy, *sg = scmd->request_buffer;
+	dma_addr_t token = 0;
+	long err;
+	unsigned int done = 0;
+	int nmd, nsg;
+
+	nmd = id->table_desc.len / sizeof(struct srp_direct_buf);
+
+	dprintk("%p %u %u %u %u %d %d %d\n",
+		iue, scmd->request_bufflen, scmd->bufflen,
+		id->len, scmd->offset, nmd,
+		cmd->data_in_desc_cnt, cmd->data_out_desc_cnt);
+
+	if ((dir == DMA_FROM_DEVICE && nmd == cmd->data_in_desc_cnt) ||
+	    (dir == DMA_TO_DEVICE && nmd == cmd->data_out_desc_cnt)) {
+		md = &id->desc_list[0];
+		goto rdma;
+	}
+
+	md = dma_alloc_coherent(target->dev, id->table_desc.len,
+				 &token, GFP_KERNEL);
+	if (!md) {
+		eprintk("Can't get dma memory %u\n", id->table_desc.len);
+		return 0;
+	}
+
+	sg_init_one(&dummy, md, id->table_desc.len);
+	sg_dma_address(&dummy) = token;
+	err = rdma_io(iue, &dummy, 1, &id->table_desc, 1, DMA_TO_DEVICE,
+		      id->table_desc.len);
+	if (err < 0) {
+		eprintk("Error copying indirect table %ld\n", err);
+		goto free_mem;
+	}
+
+rdma:
+	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
+	if (!nsg) {
+		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
+		goto free_mem;
+	}
+
+	err = rdma_io(iue, sg, nsg, md, nmd, dir,
+		      min(scmd->request_bufflen, id->len));
+	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
+
+free_mem:
+	if (token)
+		dma_free_coherent(target->dev, id->table_desc.len, md, token);
+
+	return done;
+}
+
+static int data_out_desc_size(struct srp_cmd *cmd)
+{
+	int size = 0;
+	u8 fmt = cmd->buf_fmt >> 4;
+
+	switch (fmt) {
+	case SRP_NO_DATA_DESC:
+		break;
+	case SRP_DATA_DESC_DIRECT:
+		size = sizeof(struct srp_direct_buf);
+		break;
+	case SRP_DATA_DESC_INDIRECT:
+		size = sizeof(struct srp_indirect_buf) +
+			sizeof(struct srp_direct_buf) * cmd->data_out_desc_cnt;
+		break;
+	default:
+		eprintk("client error. Invalid data_out_format %x\n", fmt);
+		break;
+	}
+	return size;
+}
+
+static int __srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
+			       enum dma_data_direction dir, rdma_io_t rdma_io)
+{
+	struct srp_direct_buf *md;
+	struct srp_indirect_buf *id;
+	int offset, err = 0;
+	u8 format;
+
+	offset = cmd->add_cdb_len * 4;
+	if (dir == DMA_FROM_DEVICE)
+		offset += data_out_desc_size(cmd);
+
+	if (dir == DMA_TO_DEVICE)
+		format = cmd->buf_fmt >> 4;
+	else
+		format = cmd->buf_fmt & ((1U << 4) - 1);
+
+	switch (format) {
+	case SRP_NO_DATA_DESC:
+		break;
+	case SRP_DATA_DESC_DIRECT:
+		md = (struct srp_direct_buf *)
+			(cmd->add_data + offset);
+		err = direct_data(scmd, md, dir, rdma_io);
+		break;
+	case SRP_DATA_DESC_INDIRECT:
+		id = (struct srp_indirect_buf *)
+			(cmd->add_data + offset);
+		err = indirect_data(scmd, cmd, id, dir, rdma_io);
+		break;
+	default:
+		eprintk("Unknown format %d %x\n", dir, format);
+		break;
+	}
+
+	return err;
+}
+
+/* TODO: this can be called multiple times for a single command. */
+int srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
+		      rdma_io_t rdma_io)
+{
+	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
+	enum dma_data_direction dir;
+
+	if (test_bit(V_WRITE, &iue->flags))
+		dir = DMA_TO_DEVICE;
+	else
+		dir = DMA_FROM_DEVICE;
+	__srp_transfer_data(scmd, cmd, dir, rdma_io);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(srp_transfer_data);

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 07:14:24 UTC (rev 420)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 08:42:57 UTC (rev 421)
@@ -2,8 +2,17 @@
 #define __LIBSRP_H__
 
 #include <linux/list.h>
+#include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_host.h>
+#include <scsi/srp.h>
 
+enum iue_flags {
+	V_DIOVER,
+	V_WRITE,
+	V_LINKED,
+	V_FLYING,
+};
+
 struct srp_buf {
 	dma_addr_t dma;
 	void *buf;
@@ -44,6 +53,10 @@
 	struct srp_buf *sbuf;
 };
 
+typedef int (rdma_io_t) (struct iu_entry *, struct scatterlist *, int,
+			 struct srp_direct_buf *, int,
+			 enum dma_data_direction, unsigned int);
+
 static inline struct srp_target *host_to_target(struct Scsi_Host *host)
 {
 	return (struct srp_target *) host->hostdata;
@@ -55,4 +68,7 @@
 extern struct iu_entry *srp_iu_get(struct srp_target *);
 extern void srp_iu_put(struct iu_entry *);
 
+extern int srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
+			     rdma_io_t rdma_io);
+
 #endif



From tomo at berlios.de  Sun Apr 16 10:53:05 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 10:53:05 +0200
Subject: [Stgt-svn] r422 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160853.k3G8r5Lh021910@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 10:53:04 +0200 (Sun, 16 Apr 2006)
New Revision: 422

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
Log:
Kill unnecessary lock


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 08:42:57 UTC (rev 421)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 08:53:04 UTC (rev 422)
@@ -159,9 +159,7 @@
 
 	memset(iu, 0, sizeof(struct srp_rsp));
 	iu->srp.rsp.opcode = SRP_RSP;
-	spin_lock_irqsave(&target->lock, flags);
 	iu->srp.rsp.req_lim_delta = 1;
-	spin_unlock_irqrestore(&target->lock, flags);
 	iu->srp.rsp.tag = tag;
 
 	if (test_bit(V_DIOVER, &iue->flags))



From tomo at berlios.de  Sun Apr 16 11:25:52 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 11:25:52 +0200
Subject: [Stgt-svn] r423 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160925.k3G9PqI1028009@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 11:25:52 +0200 (Sun, 16 Apr 2006)
New Revision: 423

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
Log:
Move SCSI command performing code to libsrp


Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 08:53:04 UTC (rev 422)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 09:25:52 UTC (rev 423)
@@ -26,9 +26,7 @@
 #include <linux/module.h>
 #include <scsi/scsi.h>
 #include <scsi/scsi_host.h>
-#include <scsi/scsi_tcq.h>
 #include <scsi/scsi_tgt.h>
-
 #include <asm/hvcall.h>
 #include <asm/iommu.h>
 #include <asm/prom.h>
@@ -67,13 +65,6 @@
 #define dprintk eprintk
 /* #define dprintk(fmt, args...) */
 
-enum srp_task_attributes {
-	SRP_SIMPLE_TASK = 0,
-	SRP_HEAD_TASK = 1,
-	SRP_ORDERED_TASK = 2,
-	SRP_ACA_TASK = 4
-};
-
 struct vio_port {
 	struct vio_dev *dma_dev;
 
@@ -148,10 +139,8 @@
 static int send_rsp(struct iu_entry *iue, unsigned char status,
 		    unsigned char asc)
 {
-	struct srp_target *target = iue->target;
 	union viosrp_iu *iu = vio_iu(iue);
 	uint64_t tag = iu->srp.rsp.tag;
-	unsigned long flags;
 
 	/* If the linked bit is on and status is good */
 	if (test_bit(V_LINKED, &iue->flags) && (status == NO_SENSE))
@@ -202,136 +191,6 @@
 	return 0;
 }
 
-static int data_out_desc_size(struct srp_cmd *cmd)
-{
-	int size = 0;
-	u8 fmt = cmd->buf_fmt >> 4;
-
-	switch (fmt) {
-	case SRP_NO_DATA_DESC:
-		break;
-	case SRP_DATA_DESC_DIRECT:
-		size = sizeof(struct srp_direct_buf);
-		break;
-	case SRP_DATA_DESC_INDIRECT:
-		size = sizeof(struct srp_indirect_buf) +
-			sizeof(struct srp_direct_buf) * cmd->data_out_desc_cnt;
-		break;
-	default:
-		eprintk("client error. Invalid data_out_format %x\n", fmt);
-		break;
-	}
-	return size;
-}
-
-static int vscsis_data_length(struct srp_cmd *cmd, enum dma_data_direction dir)
-{
-	struct srp_direct_buf *md;
-	struct srp_indirect_buf *id;
-	int len = 0, offset = cmd->add_cdb_len * 4;
-	u8 fmt;
-
-	if (dir == DMA_TO_DEVICE)
-		fmt = cmd->buf_fmt >> 4;
-	else {
-		fmt = cmd->buf_fmt & ((1U << 4) - 1);
-		offset += data_out_desc_size(cmd);
-	}
-
-	switch (fmt) {
-	case SRP_NO_DATA_DESC:
-		break;
-	case SRP_DATA_DESC_DIRECT:
-		md = (struct srp_direct_buf *) (cmd->add_data + offset);
-		len = md->len;
-		break;
-	case SRP_DATA_DESC_INDIRECT:
-		id = (struct srp_indirect_buf *) (cmd->add_data + offset);
-		len = id->len;
-		break;
-	default:
-		eprintk("invalid data format %x\n", fmt);
-		break;
-	}
-	return len;
-}
-
-static uint8_t getcontrolbyte(uint8_t *cdb)
-{
-	return cdb[COMMAND_SIZE(cdb[0]) - 1];
-}
-
-static inline uint8_t getlink(struct iu_entry *iue)
-{
-	return (getcontrolbyte(vio_iu(iue)->srp.cmd.cdb) & 0x01);
-}
-
-static int process_cmd(struct iu_entry *iue)
-{
-	struct Scsi_host *shost = iue->target->shost;
-	union viosrp_iu *iu = vio_iu(iue);
-	enum dma_data_direction data_dir;
-	struct scsi_cmnd *scmd;
-	int tag, len;
-
-	dprintk("%p %p\n", iue->target, iue);
-
-	if (getlink(iue))
-		__set_bit(V_LINKED, &iue->flags);
-
-	tag = MSG_SIMPLE_TAG;
-
-	switch (iu->srp.cmd.task_attr) {
-	case SRP_SIMPLE_TASK:
-		tag = MSG_SIMPLE_TAG;
-		break;
-	case SRP_ORDERED_TASK:
-		tag = MSG_ORDERED_TAG;
-		break;
-	case SRP_HEAD_TASK:
-		tag = MSG_HEAD_TAG;
-		break;
-	default:
-		eprintk("Task attribute %d not supported, assuming barrier\n",
-			iu->srp.cmd.task_attr);
-		tag = MSG_ORDERED_TAG;
-	}
-
-	switch (iu->srp.cmd.cdb[0]) {
-	case WRITE_6:
-	case WRITE_10:
-	case WRITE_VERIFY:
-	case WRITE_12:
-	case WRITE_VERIFY_12:
-		__set_bit(V_WRITE, &iue->flags);
-	}
-
-	if (iu->srp.cmd.buf_fmt >> 4)
-		data_dir = DMA_TO_DEVICE;
-	else
-		data_dir = DMA_FROM_DEVICE;
-	len = vscsis_data_length(&iu->srp.cmd, data_dir);
-
-	dprintk("%p %x %lx %d %d %d %llx\n", iue, iu->srp.cmd.cdb[0],
-		iu->srp.cmd.lun, data_dir, len, tag,
-		(unsigned long long) iu->srp.cmd.tag);
-
-	scmd = scsi_host_get_command(shost, data_dir, GFP_KERNEL);
-	BUG_ON(!scmd);
-	scmd->SCp.ptr = (char *) iue;
-	memcpy(scmd->data_cmnd, iu->srp.cmd.cdb, MAX_COMMAND_SIZE);
-	scmd->request_bufflen = len;
-	scmd->tag= tag;
-	iue->scmd = scmd;
-	scsi_tgt_queue_command(scmd, (struct scsi_lun *) &iu->srp.cmd.lun,
-			       iu->srp.cmd.tag);
-
-	dprintk("%p %p %x %lx %d %d %d\n", iue, scmd, iu->srp.cmd.cdb[0],
-		iu->srp.cmd.lun, data_dir, len, tag);
-
-	return 0;
-}
-
 static void handle_cmd_queue(struct srp_target *target)
 {
 	struct iu_entry *iue;
@@ -343,7 +202,7 @@
 	list_for_each_entry(iue, &target->cmd_queue, ilist) {
 		if (!test_and_set_bit(V_FLYING, &iue->flags)) {
 			spin_unlock_irqrestore(&target->lock, flags);
-			process_cmd(iue);
+			srp_cmd_perform(iue, (struct srp_cmd *) iue->sbuf->buf);
 			goto retry;
 		}
 	}
@@ -853,6 +712,7 @@
 	handle_cmd_queue(target);
 }
 
+
 static int ibmvstgt_eh_abort_handler(struct scsi_cmnd *scmd)
 {
 	unsigned long flags;

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 08:53:04 UTC (rev 422)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 09:25:52 UTC (rev 423)
@@ -22,10 +22,20 @@
 #include <linux/kfifo.h>
 #include <linux/scatterlist.h>
 #include <linux/dma-mapping.h>
+#include <scsi/scsi.h>
 #include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_tcq.h>
+#include <scsi/scsi_tgt.h>
 #include <scsi/srp.h>
 #include <libsrp.h>
 
+enum srp_task_attributes {
+	SRP_SIMPLE_TASK = 0,
+	SRP_HEAD_TASK = 1,
+	SRP_ORDERED_TASK = 2,
+	SRP_ACA_TASK = 4
+};
+
 /* tmp - will replace with SCSI logging stuff */
 #define eprintk(fmt, args...)					\
 do {								\
@@ -333,3 +343,112 @@
 	return 0;
 }
 EXPORT_SYMBOL_GPL(srp_transfer_data);
+
+static int vscsis_data_length(struct srp_cmd *cmd, enum dma_data_direction dir)
+{
+	struct srp_direct_buf *md;
+	struct srp_indirect_buf *id;
+	int len = 0, offset = cmd->add_cdb_len * 4;
+	u8 fmt;
+
+	if (dir == DMA_TO_DEVICE)
+		fmt = cmd->buf_fmt >> 4;
+	else {
+		fmt = cmd->buf_fmt & ((1U << 4) - 1);
+		offset += data_out_desc_size(cmd);
+	}
+
+	switch (fmt) {
+	case SRP_NO_DATA_DESC:
+		break;
+	case SRP_DATA_DESC_DIRECT:
+		md = (struct srp_direct_buf *) (cmd->add_data + offset);
+		len = md->len;
+		break;
+	case SRP_DATA_DESC_INDIRECT:
+		id = (struct srp_indirect_buf *) (cmd->add_data + offset);
+		len = id->len;
+		break;
+	default:
+		eprintk("invalid data format %x\n", fmt);
+		break;
+	}
+	return len;
+}
+
+static uint8_t getcontrolbyte(u8 *cdb)
+{
+	return cdb[COMMAND_SIZE(cdb[0]) - 1];
+}
+
+static inline uint8_t getlink(struct srp_cmd *cmd)
+{
+	return (getcontrolbyte(cmd->cdb) & 0x01);
+}
+
+int srp_cmd_perform(struct iu_entry *iue, struct srp_cmd *cmd)
+{
+	struct Scsi_host *shost = iue->target->shost;
+	enum dma_data_direction data_dir;
+	struct scsi_cmnd *scmd;
+	int tag, len;
+
+	dprintk("%p %p\n", iue->target, iue);
+
+	if (getlink(cmd))
+		__set_bit(V_LINKED, &iue->flags);
+
+	tag = MSG_SIMPLE_TAG;
+
+	switch (cmd->task_attr) {
+	case SRP_SIMPLE_TASK:
+		tag = MSG_SIMPLE_TAG;
+		break;
+	case SRP_ORDERED_TASK:
+		tag = MSG_ORDERED_TAG;
+		break;
+	case SRP_HEAD_TASK:
+		tag = MSG_HEAD_TAG;
+		break;
+	default:
+		eprintk("Task attribute %d not supported\n", cmd->task_attr);
+		tag = MSG_ORDERED_TAG;
+	}
+
+	switch (cmd->cdb[0]) {
+	case WRITE_6:
+	case WRITE_10:
+	case WRITE_VERIFY:
+	case WRITE_12:
+	case WRITE_VERIFY_12:
+		__set_bit(V_WRITE, &iue->flags);
+	}
+
+	if (cmd->buf_fmt >> 4)
+		data_dir = DMA_TO_DEVICE;
+	else
+		data_dir = DMA_FROM_DEVICE;
+	len = vscsis_data_length(cmd, data_dir);
+
+	dprintk("%p %x %lx %d %d %d %llx\n", iue, cmd->cdb[0],
+		cmd->lun, data_dir, len, tag, (unsigned long long) cmd->tag);
+
+	scmd = scsi_host_get_command(shost, data_dir, GFP_KERNEL);
+	BUG_ON(!scmd);
+	scmd->SCp.ptr = (char *) iue;
+	memcpy(scmd->data_cmnd, cmd->cdb, MAX_COMMAND_SIZE);
+	scmd->request_bufflen = len;
+	scmd->tag = tag;
+	iue->scmd = scmd;
+	scsi_tgt_queue_command(scmd, (struct scsi_lun *) &cmd->lun, cmd->tag);
+
+	dprintk("%p %p %x %lx %d %d %d\n", iue, scmd, cmd->cdb[0],
+		cmd->lun, data_dir, len, tag);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(srp_cmd_perform);
+
+MODULE_DESCRIPTION("SCSI RDAM Protocol lib functions");
+MODULE_AUTHOR("FUJITA Tomonori");
+MODULE_LICENSE("GPL");

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 08:53:04 UTC (rev 422)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.h	2006-04-16 09:25:52 UTC (rev 423)
@@ -68,6 +68,7 @@
 extern struct iu_entry *srp_iu_get(struct srp_target *);
 extern void srp_iu_put(struct iu_entry *);
 
+extern int srp_cmd_perform(struct iu_entry *iue, struct srp_cmd *cmd);
 extern int srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
 			     rdma_io_t rdma_io);
 



From tomo at berlios.de  Sun Apr 16 11:38:03 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sun, 16 Apr 2006 11:38:03 +0200
Subject: [Stgt-svn] r424 - branches/use-scsi-ml/ibmvstgt/kernel
Message-ID: <200604160938.k3G9c3nt028756@sheep.berlios.de>

Author: tomo
Date: 2006-04-16 11:38:03 +0200 (Sun, 16 Apr 2006)
New Revision: 424

Modified:
   branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
   branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
Log:
Just cleanups.

Modified: branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 09:25:52 UTC (rev 423)
+++ branches/use-scsi-ml/ibmvstgt/kernel/ibmvstgt.c	2006-04-16 09:38:03 UTC (rev 424)
@@ -21,7 +21,6 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307
  * USA
  */
-
 #include <linux/interrupt.h>
 #include <linux/module.h>
 #include <scsi/scsi.h>
@@ -52,19 +51,14 @@
 #define h_free_crq(ua) \
 			plpar_hcall_norets(H_FREE_CRQ, ua);
 
-MODULE_DESCRIPTION("IBM Virtual SCSI Target");
-MODULE_AUTHOR("Dave Boutcher");
-MODULE_LICENSE("GPL");
-
 /* tmp - will replace with SCSI logging stuff */
 #define eprintk(fmt, args...)					\
 do {								\
 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
 } while (0)
+/* #define dprintk eprintk */
+#define dprintk(fmt, args...)
 
-#define dprintk eprintk
-/* #define dprintk(fmt, args...) */
-
 struct vio_port {
 	struct vio_dev *dma_dev;
 
@@ -210,9 +204,9 @@
 	spin_unlock_irqrestore(&target->lock, flags);
 }
 
-int ibmvstgt_rdma(struct iu_entry *iue, struct scatterlist *sg, int nsg,
-		  struct srp_direct_buf *md, int nmd,
-		  enum dma_data_direction dir, unsigned int rest)
+static int ibmvstgt_rdma(struct iu_entry *iue, struct scatterlist *sg, int nsg,
+			 struct srp_direct_buf *md, int nmd,
+			 enum dma_data_direction dir, unsigned int rest)
 {
 	struct srp_target *target = iue->target;
 	struct vio_port *vport = target_to_port(target);
@@ -332,7 +326,7 @@
 	err = h_copy_rdma(sizeof(*info), vport->riobn, remote_buffer,
 			  vport->liobn, data_token);
 	if (err == H_Success) {
-		eprintk("Client connect: %s (%d)\n",
+		dprintk("Client connect: %s (%d)\n",
 			info->partition_name, info->partition_number);
 	}
 
@@ -396,7 +390,7 @@
 	union viosrp_iu *iu = vio_iu(iue);
 	int fn;
 
-	eprintk("%p %u\n", iue, iu->srp.tsk_mgmt.tsk_mgmt_func);
+	dprintk("%p %u\n", iue, iu->srp.tsk_mgmt.tsk_mgmt_func);
 
 	switch (iu->srp.tsk_mgmt.tsk_mgmt_func) {
 	case SRP_TSK_ABORT_TASK:
@@ -434,8 +428,6 @@
 	struct viosrp_adapter_info *info;
 	struct viosrp_host_config *conf;
 
-	dprintk("%p %d\n", iue, iu->mad.empty_iu.common.type);
-
 	switch (iu->mad.empty_iu.common.type) {
 	case VIOSRP_EMPTY_IU_TYPE:
 		eprintk("%s\n", "Unsupported EMPTY MAD IU");
@@ -469,8 +461,6 @@
 	int done = 1;
 	u8 opcode = iu->srp.rsp.opcode;
 
-	dprintk("%p %u\n", iue, opcode);
-
 	switch (opcode) {
 	case SRP_LOGIN_REQ:
 		process_login(iue);
@@ -511,8 +501,6 @@
 		return;
 	}
 
-	dprintk("%p %p\n", target, iue);
-
 	iue->remote_token = crq->IU_data_ptr;
 
 	err = h_copy_rdma(crq->IU_length, vport->riobn,
@@ -808,9 +796,6 @@
 	unsigned int *dma, dma_size;
 	int err = -ENOMEM;
 
-	dprintk("%s %s %x %u\n", dev->name, dev->type,
-		dev->unit_address, dev->irq);
-
 	vport = kzalloc(sizeof(struct vio_port), GFP_KERNEL);
 	if (!vport)
 		return err;
@@ -950,5 +935,9 @@
 	vio_unregister_driver(&ibmvstgt_driver);
 }
 
+MODULE_DESCRIPTION("IBM Virtual SCSI Target");
+MODULE_AUTHOR("Dave Boutcher");
+MODULE_LICENSE("GPL");
+
 module_init(ibmvstgt_init);
 module_exit(ibmvstgt_exit);

Modified: branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c
===================================================================
--- branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 09:25:52 UTC (rev 423)
+++ branches/use-scsi-ml/ibmvstgt/kernel/libsrp.c	2006-04-16 09:38:03 UTC (rev 424)
@@ -41,10 +41,9 @@
 do {								\
 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
 } while (0)
+/* #define dprintk eprintk */
+#define dprintk(fmt, args...)
 
-#define dprintk eprintk
-/* #define dprintk(fmt, args...) */
-
 static int srp_iu_pool_alloc(struct srp_queue *q, size_t max,
 			     struct srp_buf **ring)
 {
@@ -197,7 +196,7 @@
 
 	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
 	if (!nsg) {
-		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
+		printk("fail to map %p %d\n", iue, scmd->use_sg);
 		return 0;
 	}
 	err = rdma_io(iue, sg, nsg, md, 1, dir,
@@ -393,8 +392,6 @@
 	struct scsi_cmnd *scmd;
 	int tag, len;
 
-	dprintk("%p %p\n", iue->target, iue);
-
 	if (getlink(cmd))
 		__set_bit(V_LINKED, &iue->flags);
 
@@ -442,9 +439,6 @@
 	iue->scmd = scmd;
 	scsi_tgt_queue_command(scmd, (struct scsi_lun *) &cmd->lun, cmd->tag);
 
-	dprintk("%p %p %x %lx %d %d %d\n", iue, scmd, cmd->cdb[0],
-		cmd->lun, data_dir, len, tag);
-
 	return 0;
 }
 EXPORT_SYMBOL_GPL(srp_cmd_perform);



From tomo at berlios.de  Wed Apr 19 10:40:42 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Wed, 19 Apr 2006 10:40:42 +0200
Subject: [Stgt-svn] r425 - branches/use-scsi-ml/patchset/broken-out
Message-ID: <200604190840.k3J8eg9g006522@sheep.berlios.de>

Author: tomo
Date: 2006-04-19 10:40:02 +0200 (Wed, 19 Apr 2006)
New Revision: 425

Removed:
   branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt
   branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt
Log:
Somehow, I forgot to remove some old patches.


Deleted: branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt	2006-04-16 09:38:03 UTC (rev 424)
+++ branches/use-scsi-ml/patchset/broken-out/0009-scsi-tgt-add-task-management-function-support.txt	2006-04-19 08:40:02 UTC (rev 425)
@@ -1,463 +0,0 @@
-Subject: [PATCH 09/10] scsi tgt: add task management function support
-From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Date: 1144370959 +0900
-
-This patch addes task management function support to tgt. This
-assumes that all the previous patchsets are applied.
-
-- add callback to task management function to scsi_host_template
-structure. It is used notify LLDs of the completion of a TMF request.
-
-- this patch doesn't use a single queue for TMF requests and SCSI
-commands yet. We'll work on it later on.
-
-- when LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
-need to specify unique 'tag' for each command for ABORT_TASK.
-
-- when tgt aborts a command, it calls eh_abort_handler in
-scsi_host_template structure. Would be better to add
-tgt_eh_abort_handler for LLDs support target and initiator modes at
-the same time?
-
-tgt TMF works in the followings:
-
-- When LLDs queue scsi commands to tgt (scsi_tgt_queue_command), they
-need to specify unique 'tag' for each command.
-
-- LLDs call 'int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *host, int,
-u64 tag, struct scsi_lun *lun, void *data)'.
-
-- int (* tsk_mgmt_response)(u64 data, int result) is added to
-scsi_host_template.
-
-When an initiator sends a task management request, the LLD calls
-scsi_tgt_tsk_mgmt_request. the LLD can use whatever it wants for the
-data arg. The data arg is used later as the arg in the
-tsk_mgmt_response callback.
-
-tgt core just sends the task management request to user space
-(by using TGT_KEVENT_TSK_MGMT_REQ).
-
-In the case of ABORT_TASK, tgtd finds a single command to abort and
-sends TGT_UEVENT_CMD_RSP and TGT_UEVENT_TSK_MGMT_RSP events.
-
-tgt core calls eh_abort_handler for TGT_UEVENT_CMD_RSP and then
-tsk_mgmt_response for TGT_UEVENT_TSK_MGMT_RSP.
-
-If tgtd fails to find a command to abort, it sends only
-TGT_UEVENT_TSK_MGMT_RSP event (no TGT_UEVENT_CMD_RSP event).
-
-In the case of the rests task management function (like
-ABORT_TASK_SET), tgt needs to abort multiple commands. Thus, tgtd
-finds multiple commands to abort and sends multiple TGT_UEVENT_CMD_RSP
-events and a single TGT_UEVENT_TSK_MGMT_RSP event. tgt core calls
-eh_abort_handler multiple times and tsk_mgmt_response once.
-
-eh_abort_handler enables LLDs to safely free resource related with a
-command to abort.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/scsi_tgt_if.c   |   43 +++++++++++++++---
- drivers/scsi/scsi_tgt_lib.c  |  103 +++++++++++++++++++++++++++++-------------
- drivers/scsi/scsi_tgt_priv.h |   11 +++-
- include/scsi/scsi_host.h     |    3 +
- include/scsi/scsi_tgt.h      |    6 ++
- include/scsi/scsi_tgt_if.h   |    7 ++-
- 6 files changed, 125 insertions(+), 48 deletions(-)
-
-b9579b62f8d6309815a60da2e6f9a7638df074aa
-diff --git a/drivers/scsi/scsi_tgt_if.c b/drivers/scsi/scsi_tgt_if.c
-index a31c8d5..ba1b75b 100644
---- a/drivers/scsi/scsi_tgt_if.c
-+++ b/drivers/scsi/scsi_tgt_if.c
-@@ -56,7 +56,8 @@ static int send_event_rsp(uint16_t type,
- 	return netlink_unicast(nl_sk, skb, pid, 0);
- }
- 
--int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t gfp_mask)
-+int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, u64 tag,
-+			 gfp_t flags)
- {
- 	struct Scsi_Host *shost = scsi_tgt_cmd_to_host(cmd);
- 	struct sk_buff *skb;
-@@ -71,7 +72,7 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	/*
- 	 * TODO: add MAX_COMMAND_SIZE to ev and add mempool
- 	 */
--	skb = alloc_skb(NLMSG_SPACE(len), gfp_mask);
-+	skb = alloc_skb(NLMSG_SPACE(len), flags);
- 	if (!skb)
- 		return -ENOMEM;
- 
-@@ -85,9 +86,11 @@ int scsi_tgt_uspace_send(struct scsi_cmn
- 	memcpy(ev->k.cmd_req.scb, cmd->cmnd, sizeof(ev->k.cmd_req.scb));
- 	memcpy(ev->k.cmd_req.lun, lun, sizeof(ev->k.cmd_req.lun));
- 	ev->k.cmd_req.attribute = cmd->tag;
-+	ev->k.cmd_req.tag = tag;
- 
--	dprintk("%d %u %u\n", ev->k.cmd_req.host_no, ev->k.cmd_req.cid,
--		ev->k.cmd_req.data_len);
-+	dprintk("%p %d %u %u %x %llx\n", cmd, shost->host_no, ev->k.cmd_req.cid,
-+		ev->k.cmd_req.data_len, cmd->tag,
-+		(unsigned long long) ev->k.cmd_req.tag);
- 
- 	err = netlink_unicast(nl_sk, skb, tgtd_pid, 0);
- 	if (err < 0)
-@@ -109,6 +112,24 @@ int scsi_tgt_uspace_send_status(struct s
- 	return send_event_rsp(TGT_KEVENT_CMD_DONE, &ev, gfp_mask, tgtd_pid);
- }
- 
-+int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+				  struct scsi_lun *scsilun, void *data)
-+{
-+	struct tgt_event ev;
-+
-+	memset(&ev, 0, sizeof(ev));
-+	ev.k.tsk_mgmt_req.host_no = host_no;
-+	ev.k.tsk_mgmt_req.function = function;
-+	ev.k.tsk_mgmt_req.tag = tag;
-+	memcpy(ev.k.tsk_mgmt_req.lun, scsilun, sizeof(ev.k.tsk_mgmt_req.lun));
-+	ev.k.tsk_mgmt_req.mid = (u64) data;
-+
-+	dprintk("%d %x %llx %llx\n", host_no, function, (unsigned long long) tag,
-+		(unsigned long long) ev.k.tsk_mgmt_req.mid);
-+
-+	return send_event_rsp(TGT_KEVENT_TSK_MGMT_REQ, &ev, GFP_KERNEL, tgtd_pid);
-+}
-+
- static int event_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
- {
- 	struct tgt_event *ev = NLMSG_DATA(nlh);
-@@ -130,6 +151,11 @@ static int event_recv_msg(struct sk_buff
- 					   ev->u.cmd_rsp.uaddr,
- 					   ev->u.cmd_rsp.rw);
- 		break;
-+	case TGT_UEVENT_TSK_MGMT_RSP:
-+		err = scsi_tgt_kspace_tsk_mgmt(ev->u.tsk_mgmt_rsp.host_no,
-+					       ev->u.tsk_mgmt_rsp.mid,
-+					       ev->u.tsk_mgmt_rsp.result);
-+		break;
- 	default:
- 		eprintk("unknown type %d\n", nlh->nlmsg_type);
- 		err = -EINVAL;
-@@ -143,6 +169,7 @@ static int event_recv_skb(struct sk_buff
- 	int err;
- 	uint32_t rlen;
- 	struct nlmsghdr	*nlh;
-+	struct tgt_event ev;
- 
- 	while (skb->len >= NLMSG_SPACE(0)) {
- 		nlh = (struct nlmsghdr *) skb->data;
-@@ -158,9 +185,11 @@ static int event_recv_skb(struct sk_buff
- 		 * TODO for passthru commands the lower level should
- 		 * probably handle the result or we should modify this
- 		 */
--		if (nlh->nlmsg_type != TGT_UEVENT_CMD_RSP) {
--			struct tgt_event ev;
--
-+		switch (nlh->nlmsg_type) {
-+		case TGT_UEVENT_CMD_RSP:
-+		case TGT_UEVENT_TSK_MGMT_RSP:
-+			break;
-+		default:
- 			memset(&ev, 0, sizeof(ev));
- 			ev.k.event_rsp.err = err;
- 			send_event_rsp(TGT_KEVENT_RSP, &ev,
-diff --git a/drivers/scsi/scsi_tgt_lib.c b/drivers/scsi/scsi_tgt_lib.c
-index 2cbc749..5a98fc4 100644
---- a/drivers/scsi/scsi_tgt_lib.c
-+++ b/drivers/scsi/scsi_tgt_lib.c
-@@ -49,6 +49,7 @@ struct scsi_tgt_cmd {
- 
- 	struct list_head hash_list;
- 	struct request *rq;
-+	u64 tag;
- };
- 
- #define TGT_HASH_ORDER	4
-@@ -106,7 +107,6 @@ static void scsi_tgt_cmd_destroy(void *d
- 		cmd->request->flags &= ~1UL;
- 
- 	scsi_unmap_user_pages(tcmd);
--	scsi_tgt_uspace_send_status(cmd, GFP_KERNEL);
- 	kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
- 	scsi_host_put_command(scsi_tgt_cmd_to_host(cmd), cmd);
- }
-@@ -118,19 +118,11 @@ static void init_scsi_tgt_cmd(struct req
- 	struct list_head *head;
- 	static u32 tag = 0;
- 
--	tcmd->lun = rq->end_io_data;
--	bio_list_init(&tcmd->xfer_list);
--	bio_list_init(&tcmd->xfer_done_list);
--
- 	spin_lock_irqsave(&qdata->cmd_hash_lock, flags);
- 	rq->tag = tag++;
- 	head = &qdata->cmd_hash[cmd_hashfn(rq->tag)];
- 	list_add(&tcmd->hash_list, head);
- 	spin_unlock_irqrestore(&qdata->cmd_hash_lock, flags);
--
--	tcmd->rq = rq;
--	rq->end_io_data = tcmd;
--	rq->flags |= REQ_DONTPREP;
- }
- 
- static void scsi_tgt_uspace_send_fn(void *data)
-@@ -148,33 +140,22 @@ retry:
- 	if (list_empty(&qdata->cmd_req))
- 		return;
- 
--	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
--	if (!tcmd) {
--		err = -ENOMEM;
--		goto out;
--	}
--
- 	mutex_lock(&qdata->cmd_req_mutex);
- 
- 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
- 	if (list_empty(&qdata->cmd_req)) {
- 		spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 		mutex_unlock(&qdata->cmd_req_mutex);
--		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
- 		goto out;
- 	}
- 	rq = list_entry_rq(qdata->cmd_req.next);
- 	list_del_init(&rq->queuelist);
- 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 
--	if ((rq->flags & REQ_DONTPREP)) {
--		kmem_cache_free(scsi_tgt_cmd_cache, tcmd);
--		tcmd = rq->end_io_data;
--	} else
--		init_scsi_tgt_cmd(rq, tcmd);
--
-+	tcmd = rq->end_io_data;
-+	init_scsi_tgt_cmd(rq, tcmd);
- 	cmd = rq->special;
--	err = scsi_tgt_uspace_send(cmd, tcmd->lun, GFP_ATOMIC);
-+	err = scsi_tgt_uspace_send(cmd, tcmd->lun, tcmd->tag, GFP_ATOMIC);
- 	if (err < 0) {
- 		eprintk("failed to send: %p %d\n", cmd, err);
- 
-@@ -266,20 +247,35 @@ EXPORT_SYMBOL_GPL(scsi_tgt_cmd_to_host);
-  * @scsilun:	scsi lun
-  * @noblock:	set to nonzero if the command should be queued
-  **/
--void scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
--			    int noblock)
-+int scsi_tgt_queue_command(struct scsi_cmnd *cmd, struct scsi_lun *scsilun,
-+			   u64 tag)
- {
- 	struct request_queue *q = cmd->request->q;
- 	struct scsi_tgt_queuedata *qdata = q->queuedata;
- 	unsigned long flags;
-+	struct scsi_tgt_cmd *tcmd;
-+
-+	/*
-+	 * It would be better to allocate scsi_tgt_cmd structure in
-+	 * scsi_host_get_command and not to fail due to OOM.
-+	 */
-+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
-+	if (!tcmd)
-+		return -ENOMEM;
-+	cmd->request->end_io_data = tcmd;
- 
--	cmd->request->end_io_data = scsilun;
-+	bio_list_init(&tcmd->xfer_list);
-+	bio_list_init(&tcmd->xfer_done_list);
-+	tcmd->lun = scsilun;
-+	tcmd->tag = tag;
-+	tcmd->rq = cmd->request;
- 
- 	spin_lock_irqsave(&qdata->cmd_req_lock, flags);
- 	list_add_tail(&cmd->request->queuelist, &qdata->cmd_req);
- 	spin_unlock_irqrestore(&qdata->cmd_req_lock, flags);
- 
- 	queue_work(scsi_tgtd, &qdata->uspace_send_work);
-+	return 0;
- }
- EXPORT_SYMBOL_GPL(scsi_tgt_queue_command);
- 
-@@ -293,12 +289,7 @@ static void scsi_tgt_cmd_done(struct scs
- 
- 	dprintk("cmd %p %lu\n", cmd, rq_data_dir(cmd->request));
- 
--	/* don't we have to call this if result is set or not */
--	if (cmd->result) {
--		scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
--		return;
--	}
--
-+	scsi_tgt_uspace_send_status(cmd, GFP_ATOMIC);
- 	INIT_WORK(&tcmd->work, scsi_tgt_cmd_destroy, cmd);
- 	queue_work(scsi_tgtd, &tcmd->work);
- }
-@@ -495,6 +486,18 @@ static int scsi_tgt_copy_sense(struct sc
- 	return 0;
- }
- 
-+static int scsi_tgt_abort_cmd(struct Scsi_Host *host, struct scsi_cmnd *cmd)
-+{
-+	int err;
-+
-+	err = host->hostt->eh_abort_handler(cmd);
-+	if (err)
-+		eprintk("fail to abort %p\n", cmd);
-+
-+	scsi_tgt_cmd_destroy(cmd);
-+	return err;
-+}
-+
- static struct request *tgt_cmd_hash_lookup(struct request_queue *q, u32 cid)
- {
- 	struct scsi_tgt_queuedata *qdata = q->queuedata;
-@@ -545,6 +548,10 @@ int scsi_tgt_kspace_exec(int host_no, u3
- 	dprintk("cmd %p result %d len %d bufflen %u %lu %x\n", cmd,
- 		result, len, cmd->request_bufflen, rq_data_dir(rq), cmd->cmnd[0]);
- 
-+	if (result == TASK_ABORTED) {
-+		scsi_tgt_abort_cmd(shost, cmd);
-+		goto done;
-+	}
- 	/*
- 	 * store the userspace values here, the working values are
- 	 * in the request_* values
-@@ -585,6 +592,38 @@ done:
- 	return err;
- }
- 
-+int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *shost, int function, u64 tag,
-+			      struct scsi_lun *scsilun, void *data)
-+{
-+	int err;
-+
-+	/* TODO: need to retry if this fails. */
-+	err = scsi_tgt_uspace_send_tsk_mgmt(shost->host_no, function,
-+					    tag, scsilun, data);
-+	if (err < 0)
-+		eprintk("The task management request lost!\n");
-+	return err;
-+}
-+EXPORT_SYMBOL_GPL(scsi_tgt_tsk_mgmt_request);
-+
-+int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result)
-+{
-+	struct Scsi_Host *shost;
-+	int err;
-+
-+	dprintk("%d %d %llx\n", host_no, result, (unsigned long long) mid);
-+
-+	shost = scsi_host_lookup(host_no);
-+	if (IS_ERR(shost)) {
-+		printk(KERN_ERR "Could not find host no %d\n", host_no);
-+		return -EINVAL;
-+	}
-+	err = shost->hostt->tsk_mgmt_response(mid, result);
-+	scsi_host_put(shost);
-+
-+	return err;
-+}
-+
- static int __init scsi_tgt_init(void)
- {
- 	int err;
-diff --git a/drivers/scsi/scsi_tgt_priv.h b/drivers/scsi/scsi_tgt_priv.h
-index 6fedcec..77a1d06 100644
---- a/drivers/scsi/scsi_tgt_priv.h
-+++ b/drivers/scsi/scsi_tgt_priv.h
-@@ -4,18 +4,21 @@ struct Scsi_Host;
- struct task_struct;
- 
- /* tmp - will replace with SCSI logging stuff */
--#define dprintk(fmt, args...)					\
-+#define eprintk(fmt, args...)					\
- do {								\
- 	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
- } while (0)
- 
--#define eprintk dprintk
-+#define dprintk eprintk
- 
- extern void scsi_tgt_if_exit(void);
- extern int scsi_tgt_if_init(void);
- 
--extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun, gfp_t flags);
-+extern int scsi_tgt_uspace_send(struct scsi_cmnd *cmd, struct scsi_lun *lun,
-+				u64 tag, gfp_t flags);
- extern int scsi_tgt_uspace_send_status(struct scsi_cmnd *cmd, gfp_t flags);
- extern int scsi_tgt_kspace_exec(int host_no, u32 cid, int result, u32 len,
- 				unsigned long uaddr, u8 rw);
--
-+extern int scsi_tgt_uspace_send_tsk_mgmt(int host_no, int function, u64 tag,
-+					 struct scsi_lun *scsilun, void *data);
-+extern int scsi_tgt_kspace_tsk_mgmt(int host_no, u64 mid, int result);
-diff --git a/include/scsi/scsi_host.h b/include/scsi/scsi_host.h
-index 8b799db..eca5721 100644
---- a/include/scsi/scsi_host.h
-+++ b/include/scsi/scsi_host.h
-@@ -153,6 +153,9 @@ struct scsi_host_template {
- 	int (* transfer_data)(struct scsi_cmnd *,
- 			      void (*done)(struct scsi_cmnd *));
- 
-+	/* Used as callback for the completion of task management request. */
-+	int (* tsk_mgmt_response)(u64 mid, int result);
-+
- 	/*
- 	 * This is an error handling strategy routine.  You don't need to
- 	 * define one of these if you don't want to - there is a default
-diff --git a/include/scsi/scsi_tgt.h b/include/scsi/scsi_tgt.h
-index 91ad6bc..2d65be7 100644
---- a/include/scsi/scsi_tgt.h
-+++ b/include/scsi/scsi_tgt.h
-@@ -6,6 +6,8 @@ struct Scsi_Host;
- struct scsi_cmnd;
- struct scsi_lun;
- 
--extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *cmd);
-+extern struct Scsi_Host *scsi_tgt_cmd_to_host(struct scsi_cmnd *);
- extern int scsi_tgt_alloc_queue(struct Scsi_Host *);
--extern void scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, int);
-+extern int scsi_tgt_queue_command(struct scsi_cmnd *, struct scsi_lun *, u64);
-+extern int scsi_tgt_tsk_mgmt_request(struct Scsi_Host *, int, u64, struct scsi_lun *,
-+				     void *);
-diff --git a/include/scsi/scsi_tgt_if.h b/include/scsi/scsi_tgt_if.h
-index ebca452..63b2e3a 100644
---- a/include/scsi/scsi_tgt_if.h
-+++ b/include/scsi/scsi_tgt_if.h
-@@ -52,7 +52,7 @@ struct tgt_event {
- 		} cmd_rsp;
- 		struct {
- 			int host_no;
--			int mid;
-+			uint64_t mid;
- 			int result;
- 		} tsk_mgmt_rsp;
- 	} u;
-@@ -69,6 +69,7 @@ struct tgt_event {
- 			uint8_t scb[16];
- 			uint8_t lun[8];
- 			int attribute;
-+			uint64_t tag;
- 		} cmd_req;
- 		struct {
- 			int host_no;
-@@ -77,10 +78,10 @@ struct tgt_event {
- 		} cmd_done;
- 		struct {
- 			int host_no;
--			int mid;
-+			int function;
- 			uint64_t tag;
- 			uint8_t lun[8];
--			int function;
-+			uint64_t mid;
- 		} tsk_mgmt_req;
- 	} k;
- 
--- 
-1.1.5

Deleted: branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt
===================================================================
--- branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt	2006-04-16 09:38:03 UTC (rev 424)
+++ branches/use-scsi-ml/patchset/broken-out/0010-scsi-tgt-add-NET-dependence-to-Kconfig.txt	2006-04-19 08:40:02 UTC (rev 425)
@@ -1,32 +0,0 @@
-Subject: [PATCH 10/10] scsi tgt: add NET dependence to Kconfig
-From: FUJITA <fujita.tomonori at lab.ntt.co.jp>
-
-> From: "Jun'ichi Nomura" <j-nomura at ce.jp.nec.com>:
-
-scsi_tgt_if.c depends on CONFIG_NET for using netlink.
-So it would be nice if the Kconfig entry checks it.
-
-Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
-Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
-
----
-
- drivers/scsi/Kconfig |    2 +-
- 1 files changed, 1 insertions(+), 1 deletions(-)
-
-731f4924dd33579ffa5ff45ad03b7b7e933f728b
-diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
-index d09c792..5b5eeb4 100644
---- a/drivers/scsi/Kconfig
-+++ b/drivers/scsi/Kconfig
-@@ -29,7 +29,7 @@ config SCSI
- 
- config SCSI_TGT
- 	tristate "SCSI target support"
--	depends on SCSI && EXPERIMENTAL
-+	depends on SCSI && NET && EXPERIMENTAL
- 	---help---
- 	  If you want to use SCSI target mode drivers enable this option.
- 	  If you choose M, the module will be called scsi_tgt.
--- 
-1.1.5



From tomo at berlios.de  Wed Apr 19 10:43:49 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Wed, 19 Apr 2006 10:43:49 +0200
Subject: [Stgt-svn] r426 - branches/use-scsi-ml/patchset
Message-ID: <200604190843.k3J8hnIB008248@sheep.berlios.de>

Author: tomo
Date: 2006-04-19 10:43:40 +0200 (Wed, 19 Apr 2006)
New Revision: 426

Added:
   branches/use-scsi-ml/patchset/0001-scsi-tgt-add-libsrp.txt
   branches/use-scsi-ml/patchset/0002-scsi-tgt-ibmvstgt-driver.txt
Log:
Add libsrp and ibmvstgt patchset to submit to scsi-ml.


Added: branches/use-scsi-ml/patchset/0001-scsi-tgt-add-libsrp.txt
===================================================================
--- branches/use-scsi-ml/patchset/0001-scsi-tgt-add-libsrp.txt	2006-04-19 08:40:02 UTC (rev 425)
+++ branches/use-scsi-ml/patchset/0001-scsi-tgt-add-libsrp.txt	2006-04-19 08:43:40 UTC (rev 426)
@@ -0,0 +1,593 @@
+Subject: [PATCH 1/2] scsi tgt: add libsrp
+
+There's a fair chance that we'll get several SRP target drivers (for
+IBM iSeries and OpenIB at least). They will have lots of duplicated
+code. libsrp tries to provide helper functions for them to avoid the
+duplicated code.
+
+The next step would be to add initiator support to merge the two SRP
+initiator drivers in mainline.
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/Kconfig  |    9 +
+ drivers/scsi/Makefile |    1 
+ drivers/scsi/libsrp.c |  448 +++++++++++++++++++++++++++++++++++++++++++++++++
+ include/scsi/libsrp.h |   75 ++++++++
+ 4 files changed, 533 insertions(+), 0 deletions(-)
+ create mode 100644 drivers/scsi/libsrp.c
+ create mode 100644 include/scsi/libsrp.h
+
+04bec8adfeeee4a0b0a04627d5f8b7d6261f0c4a
+diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
+index 5b5eeb4..cf3558b 100644
+--- a/drivers/scsi/Kconfig
++++ b/drivers/scsi/Kconfig
+@@ -1834,6 +1834,15 @@ config ZFCP
+           called zfcp. If you want to compile it as a module, say M here
+           and read <file:Documentation/modules.txt>.
+ 
++config SCSI_SRP
++	tristate "SCSI RDMA Protocol helper library"
++	depends on SCSI
++	help
++	  If you wish to use SRP target drivers, say Y.
++
++	  To compile this driver as a module, choose M here: the
++	  module will be called libsrp.
++
+ endmenu
+ 
+ source "drivers/scsi/pcmcia/Kconfig"
+diff --git a/drivers/scsi/Makefile b/drivers/scsi/Makefile
+index 3d81b8d..0779523 100644
+--- a/drivers/scsi/Makefile
++++ b/drivers/scsi/Makefile
+@@ -123,6 +123,7 @@ obj-$(CONFIG_SCSI_FCAL)		+= fcal.o
+ obj-$(CONFIG_SCSI_LASI700)	+= 53c700.o lasi700.o
+ obj-$(CONFIG_SCSI_NSP32)	+= nsp32.o
+ obj-$(CONFIG_SCSI_IPR)		+= ipr.o
++obj-$(CONFIG_SCSI_SRP)		+= libsrp.o
+ obj-$(CONFIG_SCSI_IBMVSCSI)	+= ibmvscsi/
+ obj-$(CONFIG_SCSI_SATA_AHCI)	+= libata.o ahci.o
+ obj-$(CONFIG_SCSI_SATA_SVW)	+= libata.o sata_svw.o
+diff --git a/drivers/scsi/libsrp.c b/drivers/scsi/libsrp.c
+new file mode 100644
+index 0000000..2a2cfd6
+--- /dev/null
++++ b/drivers/scsi/libsrp.c
+@@ -0,0 +1,448 @@
++/*
++ * SCSI RDAM Protocol lib functions
++ *
++ * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
++ *
++ * This program is free software; you can redistribute it and/or
++ * modify it under the terms of the GNU General Public License as
++ * published by the Free Software Foundation; either version 2 of the
++ * License, or (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful, but
++ * WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
++ * General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
++ * 02110-1301 USA
++ */
++#include <linux/err.h>
++#include <linux/kfifo.h>
++#include <linux/scatterlist.h>
++#include <linux/dma-mapping.h>
++#include <scsi/scsi.h>
++#include <scsi/scsi_cmnd.h>
++#include <scsi/scsi_tcq.h>
++#include <scsi/scsi_tgt.h>
++#include <scsi/srp.h>
++#include <scsi/libsrp.h>
++
++enum srp_task_attributes {
++	SRP_SIMPLE_TASK = 0,
++	SRP_HEAD_TASK = 1,
++	SRP_ORDERED_TASK = 2,
++	SRP_ACA_TASK = 4
++};
++
++/* tmp - will replace with SCSI logging stuff */
++#define eprintk(fmt, args...)					\
++do {								\
++	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
++} while (0)
++/* #define dprintk eprintk */
++#define dprintk(fmt, args...)
++
++static int srp_iu_pool_alloc(struct srp_queue *q, size_t max,
++			     struct srp_buf **ring)
++{
++	int i;
++	struct iu_entry *iue;
++
++	q->pool = kcalloc(max, sizeof(struct iu_entry *), GFP_KERNEL);
++	if (!q->pool)
++		return -ENOMEM;
++	q->items = kcalloc(max, sizeof(struct iu_entry), GFP_KERNEL);
++	if (!q->items)
++		goto free_pool;
++
++	spin_lock_init(&q->lock);
++	q->queue = kfifo_init((void *) q->pool, max * sizeof(void *),
++			      GFP_KERNEL, &q->lock);
++	if (IS_ERR(q->queue))
++		goto free_item;
++
++	for (i = 0, iue = q->items; i < max; i++) {
++		__kfifo_put(q->queue, (void *) &iue, sizeof(void *));
++		iue->sbuf = ring[i];
++		iue++;
++	}
++	return 0;
++
++free_item:
++	kfree(q->items);
++free_pool:
++	kfree(q->pool);
++	return -ENOMEM;
++}
++
++static void srp_iu_pool_free(struct srp_queue *q)
++{
++	kfree(q->items);
++	kfree(q->pool);
++}
++
++static struct srp_buf ** srp_ring_alloc(struct device *dev,
++					size_t max, size_t size)
++{
++	int i;
++	struct srp_buf **ring;
++
++	ring = kcalloc(max, sizeof(struct srp_buf *), GFP_KERNEL);
++	if (!ring)
++		return NULL;
++
++	for (i = 0; i < max; i++) {
++		ring[i] = kzalloc(sizeof(struct srp_buf), GFP_KERNEL);
++		if (!ring[i])
++			goto out;
++		ring[i]->buf = dma_alloc_coherent(dev, size, &ring[i]->dma,
++						  GFP_KERNEL);
++		if (!ring[i]->buf)
++			goto out;
++	}
++	return ring;
++
++out:
++	for (i = 0; i < max && ring[i]; i++) {
++		if (ring[i]->buf)
++			dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
++		kfree(ring[i]);
++	}
++	kfree(ring);
++
++	return NULL;
++}
++
++static void srp_ring_free(struct device *dev, struct srp_buf **ring, size_t max,
++			  size_t size)
++{
++	int i;
++
++	for (i = 0; i < max; i++) {
++		dma_free_coherent(dev, size, ring[i]->buf, ring[i]->dma);
++		kfree(ring[i]);
++	}
++}
++
++int srp_target_alloc(struct srp_target *target, struct device *dev,
++		     size_t nr, size_t iu_size)
++{
++	int err;
++
++	spin_lock_init(&target->lock);
++	INIT_LIST_HEAD(&target->cmd_queue);
++
++	target->dev = dev;
++	target->dev->driver_data = target;
++
++	target->srp_iu_size = iu_size;
++	target->rx_ring_size = nr;
++	target->rx_ring = srp_ring_alloc(target->dev, nr, iu_size);
++	if (!target->rx_ring)
++		return -ENOMEM;
++	err = srp_iu_pool_alloc(&target->iu_queue, nr, target->rx_ring);
++	if (err)
++		goto free_ring;
++
++	return 0;
++
++free_ring:
++	srp_ring_free(target->dev, target->rx_ring, nr, iu_size);
++	return -ENOMEM;
++}
++EXPORT_SYMBOL_GPL(srp_target_alloc);
++
++void srp_target_free(struct srp_target *target)
++{
++	srp_ring_free(target->dev, target->rx_ring, target->rx_ring_size,
++		      target->srp_iu_size);
++	srp_iu_pool_free(&target->iu_queue);
++}
++EXPORT_SYMBOL_GPL(srp_target_free);
++
++struct iu_entry *srp_iu_get(struct srp_target *target)
++{
++	struct iu_entry *iue = NULL;
++
++	kfifo_get(target->iu_queue.queue, (void *) &iue, sizeof(void *));
++	BUG_ON(!iue);
++
++	iue->target = target;
++	iue->scmd = NULL;
++	INIT_LIST_HEAD(&iue->ilist);
++	iue->flags = 0;
++	return iue;
++}
++EXPORT_SYMBOL_GPL(srp_iu_get);
++
++void srp_iu_put(struct iu_entry *iue)
++{
++	kfifo_put(iue->target->iu_queue.queue, (void *) &iue, sizeof(void *));
++}
++EXPORT_SYMBOL_GPL(srp_iu_put);
++
++static int direct_data(struct scsi_cmnd *scmd, struct srp_direct_buf *md,
++		       enum dma_data_direction dir, rdma_io_t rdma_io)
++{
++	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
++	struct srp_target *target = iue->target;
++	struct scatterlist *sg = scmd->request_buffer;
++	int nsg, err;
++
++	dprintk("%p %u %u %u %d\n", iue, scmd->request_bufflen, scmd->bufflen,
++		md->len, scmd->use_sg);
++
++	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
++	if (!nsg) {
++		printk("fail to map %p %d\n", iue, scmd->use_sg);
++		return 0;
++	}
++	err = rdma_io(iue, sg, nsg, md, 1, dir,
++		      min(scmd->request_bufflen, md->len));
++
++	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
++
++	return err;
++}
++
++static int indirect_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
++			 struct srp_indirect_buf *id,
++			 enum dma_data_direction dir, rdma_io_t rdma_io)
++{
++	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
++	struct srp_target *target = iue->target;
++	struct srp_direct_buf *md;
++	struct scatterlist dummy, *sg = scmd->request_buffer;
++	dma_addr_t token = 0;
++	long err;
++	unsigned int done = 0;
++	int nmd, nsg;
++
++	nmd = id->table_desc.len / sizeof(struct srp_direct_buf);
++
++	dprintk("%p %u %u %u %u %d %d %d\n",
++		iue, scmd->request_bufflen, scmd->bufflen,
++		id->len, scmd->offset, nmd,
++		cmd->data_in_desc_cnt, cmd->data_out_desc_cnt);
++
++	if ((dir == DMA_FROM_DEVICE && nmd == cmd->data_in_desc_cnt) ||
++	    (dir == DMA_TO_DEVICE && nmd == cmd->data_out_desc_cnt)) {
++		md = &id->desc_list[0];
++		goto rdma;
++	}
++
++	md = dma_alloc_coherent(target->dev, id->table_desc.len,
++				 &token, GFP_KERNEL);
++	if (!md) {
++		eprintk("Can't get dma memory %u\n", id->table_desc.len);
++		return 0;
++	}
++
++	sg_init_one(&dummy, md, id->table_desc.len);
++	sg_dma_address(&dummy) = token;
++	err = rdma_io(iue, &dummy, 1, &id->table_desc, 1, DMA_TO_DEVICE,
++		      id->table_desc.len);
++	if (err < 0) {
++		eprintk("Error copying indirect table %ld\n", err);
++		goto free_mem;
++	}
++
++rdma:
++	nsg = dma_map_sg(target->dev, sg, scmd->use_sg, DMA_BIDIRECTIONAL);
++	if (!nsg) {
++		eprintk("fail to map %p %d\n", iue, scmd->use_sg);
++		goto free_mem;
++	}
++
++	err = rdma_io(iue, sg, nsg, md, nmd, dir,
++		      min(scmd->request_bufflen, id->len));
++	dma_unmap_sg(target->dev, sg, nsg, DMA_BIDIRECTIONAL);
++
++free_mem:
++	if (token)
++		dma_free_coherent(target->dev, id->table_desc.len, md, token);
++
++	return done;
++}
++
++static int data_out_desc_size(struct srp_cmd *cmd)
++{
++	int size = 0;
++	u8 fmt = cmd->buf_fmt >> 4;
++
++	switch (fmt) {
++	case SRP_NO_DATA_DESC:
++		break;
++	case SRP_DATA_DESC_DIRECT:
++		size = sizeof(struct srp_direct_buf);
++		break;
++	case SRP_DATA_DESC_INDIRECT:
++		size = sizeof(struct srp_indirect_buf) +
++			sizeof(struct srp_direct_buf) * cmd->data_out_desc_cnt;
++		break;
++	default:
++		eprintk("client error. Invalid data_out_format %x\n", fmt);
++		break;
++	}
++	return size;
++}
++
++static int __srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
++			       enum dma_data_direction dir, rdma_io_t rdma_io)
++{
++	struct srp_direct_buf *md;
++	struct srp_indirect_buf *id;
++	int offset, err = 0;
++	u8 format;
++
++	offset = cmd->add_cdb_len * 4;
++	if (dir == DMA_FROM_DEVICE)
++		offset += data_out_desc_size(cmd);
++
++	if (dir == DMA_TO_DEVICE)
++		format = cmd->buf_fmt >> 4;
++	else
++		format = cmd->buf_fmt & ((1U << 4) - 1);
++
++	switch (format) {
++	case SRP_NO_DATA_DESC:
++		break;
++	case SRP_DATA_DESC_DIRECT:
++		md = (struct srp_direct_buf *)
++			(cmd->add_data + offset);
++		err = direct_data(scmd, md, dir, rdma_io);
++		break;
++	case SRP_DATA_DESC_INDIRECT:
++		id = (struct srp_indirect_buf *)
++			(cmd->add_data + offset);
++		err = indirect_data(scmd, cmd, id, dir, rdma_io);
++		break;
++	default:
++		eprintk("Unknown format %d %x\n", dir, format);
++		break;
++	}
++
++	return err;
++}
++
++/* TODO: this can be called multiple times for a single command. */
++int srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
++		      rdma_io_t rdma_io)
++{
++	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
++	enum dma_data_direction dir;
++
++	if (test_bit(V_WRITE, &iue->flags))
++		dir = DMA_TO_DEVICE;
++	else
++		dir = DMA_FROM_DEVICE;
++	__srp_transfer_data(scmd, cmd, dir, rdma_io);
++	return 0;
++}
++EXPORT_SYMBOL_GPL(srp_transfer_data);
++
++static int vscsis_data_length(struct srp_cmd *cmd, enum dma_data_direction dir)
++{
++	struct srp_direct_buf *md;
++	struct srp_indirect_buf *id;
++	int len = 0, offset = cmd->add_cdb_len * 4;
++	u8 fmt;
++
++	if (dir == DMA_TO_DEVICE)
++		fmt = cmd->buf_fmt >> 4;
++	else {
++		fmt = cmd->buf_fmt & ((1U << 4) - 1);
++		offset += data_out_desc_size(cmd);
++	}
++
++	switch (fmt) {
++	case SRP_NO_DATA_DESC:
++		break;
++	case SRP_DATA_DESC_DIRECT:
++		md = (struct srp_direct_buf *) (cmd->add_data + offset);
++		len = md->len;
++		break;
++	case SRP_DATA_DESC_INDIRECT:
++		id = (struct srp_indirect_buf *) (cmd->add_data + offset);
++		len = id->len;
++		break;
++	default:
++		eprintk("invalid data format %x\n", fmt);
++		break;
++	}
++	return len;
++}
++
++static uint8_t getcontrolbyte(u8 *cdb)
++{
++	return cdb[COMMAND_SIZE(cdb[0]) - 1];
++}
++
++static inline uint8_t getlink(struct srp_cmd *cmd)
++{
++	return (getcontrolbyte(cmd->cdb) & 0x01);
++}
++
++int srp_cmd_perform(struct iu_entry *iue, struct srp_cmd *cmd)
++{
++	struct Scsi_host *shost = iue->target->shost;
++	enum dma_data_direction data_dir;
++	struct scsi_cmnd *scmd;
++	int tag, len;
++
++	if (getlink(cmd))
++		__set_bit(V_LINKED, &iue->flags);
++
++	tag = MSG_SIMPLE_TAG;
++
++	switch (cmd->task_attr) {
++	case SRP_SIMPLE_TASK:
++		tag = MSG_SIMPLE_TAG;
++		break;
++	case SRP_ORDERED_TASK:
++		tag = MSG_ORDERED_TAG;
++		break;
++	case SRP_HEAD_TASK:
++		tag = MSG_HEAD_TAG;
++		break;
++	default:
++		eprintk("Task attribute %d not supported\n", cmd->task_attr);
++		tag = MSG_ORDERED_TAG;
++	}
++
++	switch (cmd->cdb[0]) {
++	case WRITE_6:
++	case WRITE_10:
++	case WRITE_VERIFY:
++	case WRITE_12:
++	case WRITE_VERIFY_12:
++		__set_bit(V_WRITE, &iue->flags);
++	}
++
++	if (cmd->buf_fmt >> 4)
++		data_dir = DMA_TO_DEVICE;
++	else
++		data_dir = DMA_FROM_DEVICE;
++	len = vscsis_data_length(cmd, data_dir);
++
++	dprintk("%p %x %lx %d %d %d %llx\n", iue, cmd->cdb[0],
++		cmd->lun, data_dir, len, tag, (unsigned long long) cmd->tag);
++
++	scmd = scsi_host_get_command(shost, data_dir, GFP_KERNEL);
++	BUG_ON(!scmd);
++	scmd->SCp.ptr = (char *) iue;
++	memcpy(scmd->data_cmnd, cmd->cdb, MAX_COMMAND_SIZE);
++	scmd->request_bufflen = len;
++	scmd->tag = tag;
++	iue->scmd = scmd;
++	scsi_tgt_queue_command(scmd, (struct scsi_lun *) &cmd->lun, cmd->tag);
++
++	return 0;
++}
++EXPORT_SYMBOL_GPL(srp_cmd_perform);
++
++MODULE_DESCRIPTION("SCSI RDAM Protocol lib functions");
++MODULE_AUTHOR("FUJITA Tomonori");
++MODULE_LICENSE("GPL");
+diff --git a/include/scsi/libsrp.h b/include/scsi/libsrp.h
+new file mode 100644
+index 0000000..9dd10ff
+--- /dev/null
++++ b/include/scsi/libsrp.h
+@@ -0,0 +1,75 @@
++#ifndef __LIBSRP_H__
++#define __LIBSRP_H__
++
++#include <linux/list.h>
++#include <scsi/scsi_cmnd.h>
++#include <scsi/scsi_host.h>
++#include <scsi/srp.h>
++
++enum iue_flags {
++	V_DIOVER,
++	V_WRITE,
++	V_LINKED,
++	V_FLYING,
++};
++
++struct srp_buf {
++	dma_addr_t dma;
++	void *buf;
++};
++
++struct srp_queue {
++	void *pool;
++	void *items;
++	struct kfifo *queue;
++	spinlock_t lock;
++};
++
++struct srp_target {
++	struct Scsi_Host *shost;
++	struct device *dev;
++
++	spinlock_t lock;
++	struct list_head cmd_queue;
++
++	size_t srp_iu_size;
++	struct srp_queue iu_queue;
++	size_t rx_ring_size;
++	struct srp_buf **rx_ring;
++
++	/* IB needs tx_ring too */
++
++	void *ldata;
++};
++
++struct iu_entry {
++	struct srp_target *target;
++	struct scsi_cmnd *scmd;
++
++	struct list_head ilist;
++	dma_addr_t remote_token;
++	unsigned long flags;
++
++	struct srp_buf *sbuf;
++};
++
++typedef int (rdma_io_t) (struct iu_entry *, struct scatterlist *, int,
++			 struct srp_direct_buf *, int,
++			 enum dma_data_direction, unsigned int);
++
++static inline struct srp_target *host_to_target(struct Scsi_Host *host)
++{
++	return (struct srp_target *) host->hostdata;
++}
++
++extern int srp_target_alloc(struct srp_target *, struct device *, size_t, size_t);
++extern void srp_target_free(struct srp_target *);
++
++extern struct iu_entry *srp_iu_get(struct srp_target *);
++extern void srp_iu_put(struct iu_entry *);
++
++extern int srp_cmd_perform(struct iu_entry *iue, struct srp_cmd *cmd);
++extern int srp_transfer_data(struct scsi_cmnd *scmd, struct srp_cmd *cmd,
++			     rdma_io_t rdma_io);
++
++#endif
+-- 
+1.1.3

Added: branches/use-scsi-ml/patchset/0002-scsi-tgt-ibmvstgt-driver.txt
===================================================================
--- branches/use-scsi-ml/patchset/0002-scsi-tgt-ibmvstgt-driver.txt	2006-04-19 08:40:02 UTC (rev 425)
+++ branches/use-scsi-ml/patchset/0002-scsi-tgt-ibmvstgt-driver.txt	2006-04-19 08:43:40 UTC (rev 426)
@@ -0,0 +1,1021 @@
+Subject: [PATCH 2/2] scsi tgt: ibmvstgt driver
+
+This tgt driver provides SCSI RDMA target support for IBM Power5
+systems.
+
+tgt and libsrp allow large simplifications in the original ibmvscsis
+driver:
+
+http://lkml.org/lkml/2005/10/17/99
+
+Signed-off-by: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
+Signed-off-by: Mike Christie <michaelc at cs.wisc.edu>
+
+---
+
+ drivers/scsi/Kconfig             |   14 +
+ drivers/scsi/Makefile            |    1 
+ drivers/scsi/ibmvscsi/Makefile   |    2 
+ drivers/scsi/ibmvscsi/ibmvstgt.c |  943 ++++++++++++++++++++++++++++++++++++++
+ 4 files changed, 960 insertions(+), 0 deletions(-)
+ create mode 100644 drivers/scsi/ibmvscsi/ibmvstgt.c
+
+756cba9c44e2cccbabfa9abc2e96bdbcea92e25a
+diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
+index 5b5eeb4..0ad0a5b 100644
+--- a/drivers/scsi/Kconfig
++++ b/drivers/scsi/Kconfig
+@@ -897,6 +897,20 @@ config SCSI_IBMVSCSI
+ 	  To compile this driver as a module, choose M here: the
+ 	  module will be called ibmvscsic.
+ 
++config SCSI_IBMVSCSIS
++	tristate "IBM Virtual SCSI Server support"
++	depends on PPC_PSERIES && SCSI_TGT && SCSI_SRP
++	help
++	  This is the SRP target driver for IBM pSeries virtual environments.
++
++	  The userspace component needed to initialize the driver and
++	  documentation can be found:
++
++	  http://stgt.berlios.de/
++
++	  To compile this driver as a module, choose M here: the
++	  module will be called ibmvstgt.
++
+ config SCSI_INITIO
+ 	tristate "Initio 9100U(W) support"
+ 	depends on PCI && SCSI
+diff --git a/drivers/scsi/Makefile b/drivers/scsi/Makefile
+index 3d81b8d..c951da1 100644
+--- a/drivers/scsi/Makefile
++++ b/drivers/scsi/Makefile
+@@ -124,6 +124,7 @@ obj-$(CONFIG_SCSI_LASI700)	+= 53c700.o l
+ obj-$(CONFIG_SCSI_NSP32)	+= nsp32.o
+ obj-$(CONFIG_SCSI_IPR)		+= ipr.o
+ obj-$(CONFIG_SCSI_IBMVSCSI)	+= ibmvscsi/
++obj-$(CONFIG_SCSI_IBMVSCSIS)	+= ibmvscsi/
+ obj-$(CONFIG_SCSI_SATA_AHCI)	+= libata.o ahci.o
+ obj-$(CONFIG_SCSI_SATA_SVW)	+= libata.o sata_svw.o
+ obj-$(CONFIG_SCSI_ATA_PIIX)	+= libata.o ata_piix.o
+diff --git a/drivers/scsi/ibmvscsi/Makefile b/drivers/scsi/ibmvscsi/Makefile
+index 4e247b6..6ac0633 100644
+--- a/drivers/scsi/ibmvscsi/Makefile
++++ b/drivers/scsi/ibmvscsi/Makefile
+@@ -3,3 +3,5 @@ obj-$(CONFIG_SCSI_IBMVSCSI)	+= ibmvscsic
+ ibmvscsic-y			+= ibmvscsi.o
+ ibmvscsic-$(CONFIG_PPC_ISERIES)	+= iseries_vscsi.o 
+ ibmvscsic-$(CONFIG_PPC_PSERIES)	+= rpa_vscsi.o 
++
++obj-$(CONFIG_SCSI_IBMVSCSIS)	+= ibmvstgt.o
+diff --git a/drivers/scsi/ibmvscsi/ibmvstgt.c b/drivers/scsi/ibmvscsi/ibmvstgt.c
+new file mode 100644
+index 0000000..a4891f6
+--- /dev/null
++++ b/drivers/scsi/ibmvscsi/ibmvstgt.c
+@@ -0,0 +1,943 @@
++/*
++ * IBM eServer i/pSeries Virtual SCSI Target Driver
++ * Copyright (C) 2003-2005 Dave Boutcher (boutcher at us.ibm.com) IBM Corp.
++ *			   Santiago Leon (santil at us.ibm.com) IBM Corp.
++ *			   Linda Xie (lxie at us.ibm.com) IBM Corp.
++ *
++ * Copyright (C) 2005 FUJITA Tomonori <tomof at acm.org>
++ *
++ * This program is free software; you can redistribute it and/or modify
++ * it under the terms of the GNU General Public License as published by
++ * the Free Software Foundation; either version 2 of the License, or
++ * (at your option) any later version.
++ *
++ * This program is distributed in the hope that it will be useful,
++ * but WITHOUT ANY WARRANTY; without even the implied warranty of
++ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
++ * GNU General Public License for more details.
++ *
++ * You should have received a copy of the GNU General Public License
++ * along with this program; if not, write to the Free Software
++ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307
++ * USA
++ */
++#include <linux/interrupt.h>
++#include <linux/module.h>
++#include <scsi/scsi.h>
++#include <scsi/scsi_host.h>
++#include <scsi/scsi_tgt.h>
++#include <scsi/libsrp.h>
++#include <asm/hvcall.h>
++#include <asm/iommu.h>
++#include <asm/prom.h>
++#include <asm/vio.h>
++
++#include "ibmvscsi.h"
++
++#define	INITIAL_SRP_LIMIT	16
++#define	DEFAULT_MAX_SECTORS	512
++
++#define	TGT_NAME	"ibmvstgt"
++
++/*
++ * Hypervisor calls.
++ */
++#define h_copy_rdma(l, sa, sb, da, db) \
++			plpar_hcall_norets(H_COPY_RDMA, l, sa, sb, da, db)
++#define h_send_crq(ua, l, h) \
++			plpar_hcall_norets(H_SEND_CRQ, ua, l, h)
++#define h_reg_crq(ua, tok, sz)\
++			plpar_hcall_norets(H_REG_CRQ, ua, tok, sz);
++#define h_free_crq(ua) \
++			plpar_hcall_norets(H_FREE_CRQ, ua);
++
++/* tmp - will replace with SCSI logging stuff */
++#define eprintk(fmt, args...)					\
++do {								\
++	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
++} while (0)
++/* #define dprintk eprintk */
++#define dprintk(fmt, args...)
++
++struct vio_port {
++	struct vio_dev *dma_dev;
++
++	struct crq_queue crq_queue;
++	struct work_struct crq_work;
++
++	unsigned long liobn;
++	unsigned long riobn;
++};
++
++static struct workqueue_struct *vtgtd;
++
++/*
++ * These are fixed for the system and come from the Open Firmware device tree.
++ * We just store them here to save getting them every time.
++ */
++static char system_id[64] = "";
++static char partition_name[97] = "UNKNOWN";
++static unsigned int partition_number = -1;
++
++static struct vio_port *target_to_port(struct srp_target *target)
++{
++	return (struct vio_port *) target->ldata;
++}
++
++static inline union viosrp_iu *vio_iu(struct iu_entry *iue)
++{
++	return (union viosrp_iu *) (iue->sbuf->buf);
++}
++
++static int send_iu(struct iu_entry *iue, uint64_t length, uint8_t format)
++{
++	struct srp_target *target = iue->target;
++	struct vio_port *vport = target_to_port(target);
++	long rc, rc1;
++	union {
++		struct viosrp_crq cooked;
++		uint64_t raw[2];
++	} crq;
++
++	/* First copy the SRP */
++	rc = h_copy_rdma(length, vport->liobn, iue->sbuf->dma,
++			 vport->riobn, iue->remote_token);
++
++	if (rc)
++		eprintk("Error %ld transferring data\n", rc);
++
++	crq.cooked.valid = 0x80;
++	crq.cooked.format = format;
++	crq.cooked.reserved = 0x00;
++	crq.cooked.timeout = 0x00;
++	crq.cooked.IU_length = length;
++	crq.cooked.IU_data_ptr = vio_iu(iue)->srp.rsp.tag;
++
++	if (rc == 0)
++		crq.cooked.status = 0x99;	/* Just needs to be non-zero */
++	else
++		crq.cooked.status = 0x00;
++
++	rc1 = h_send_crq(vport->dma_dev->unit_address, crq.raw[0], crq.raw[1]);
++
++	if (rc1) {
++		eprintk("%ld sending response\n", rc1);
++		return rc1;
++	}
++
++	return rc;
++}
++
++#define SRP_RSP_SENSE_DATA_LEN	18
++
++static int send_rsp(struct iu_entry *iue, unsigned char status,
++		    unsigned char asc)
++{
++	union viosrp_iu *iu = vio_iu(iue);
++	uint64_t tag = iu->srp.rsp.tag;
++
++	/* If the linked bit is on and status is good */
++	if (test_bit(V_LINKED, &iue->flags) && (status == NO_SENSE))
++		status = 0x10;
++
++	memset(iu, 0, sizeof(struct srp_rsp));
++	iu->srp.rsp.opcode = SRP_RSP;
++	iu->srp.rsp.req_lim_delta = 1;
++	iu->srp.rsp.tag = tag;
++
++	if (test_bit(V_DIOVER, &iue->flags))
++		iu->srp.rsp.flags |= SRP_RSP_FLAG_DIOVER;
++
++	iu->srp.rsp.data_in_res_cnt = 0;
++	iu->srp.rsp.data_out_res_cnt = 0;
++
++	iu->srp.rsp.flags &= ~SRP_RSP_FLAG_RSPVALID;
++
++	iu->srp.rsp.resp_data_len = 0;
++	iu->srp.rsp.status = status;
++	if (status) {
++		uint8_t *sense = iu->srp.rsp.data;
++
++		if (iue->scmd) {
++			iu->srp.rsp.flags |= SRP_RSP_FLAG_SNSVALID;
++			iu->srp.rsp.sense_data_len = SCSI_SENSE_BUFFERSIZE;
++			memcpy(sense, iue->scmd->sense_buffer,
++			       SCSI_SENSE_BUFFERSIZE);
++		} else {
++			iu->srp.rsp.status = SAM_STAT_CHECK_CONDITION;
++			iu->srp.rsp.flags |= SRP_RSP_FLAG_SNSVALID;
++			iu->srp.rsp.sense_data_len = SRP_RSP_SENSE_DATA_LEN;
++
++			/* Valid bit and 'current errors' */
++			sense[0] = (0x1 << 7 | 0x70);
++			/* Sense key */
++			sense[2] = status;
++			/* Additional sense length */
++			sense[7] = 0xa;	/* 10 bytes */
++			/* Additional sense code */
++			sense[12] = asc;
++		}
++	}
++
++	send_iu(iue, sizeof(iu->srp.rsp) + SRP_RSP_SENSE_DATA_LEN,
++		VIOSRP_SRP_FORMAT);
++
++	return 0;
++}
++
++static void handle_cmd_queue(struct srp_target *target)
++{
++	struct iu_entry *iue;
++	unsigned long flags;
++
++retry:
++	spin_lock_irqsave(&target->lock, flags);
++
++	list_for_each_entry(iue, &target->cmd_queue, ilist) {
++		if (!test_and_set_bit(V_FLYING, &iue->flags)) {
++			spin_unlock_irqrestore(&target->lock, flags);
++			srp_cmd_perform(iue, (struct srp_cmd *) iue->sbuf->buf);
++			goto retry;
++		}
++	}
++
++	spin_unlock_irqrestore(&target->lock, flags);
++}
++
++static int ibmvstgt_rdma(struct iu_entry *iue, struct scatterlist *sg, int nsg,
++			 struct srp_direct_buf *md, int nmd,
++			 enum dma_data_direction dir, unsigned int rest)
++{
++	struct srp_target *target = iue->target;
++	struct vio_port *vport = target_to_port(target);
++	dma_addr_t token;
++	long err;
++	unsigned int done = 0;
++	int i, sidx, soff;
++
++	sidx = soff = 0;
++	token = sg_dma_address(sg + sidx);
++
++	for (i = 0; i < nmd && rest; i++) {
++		unsigned int mdone, mlen;
++
++		mlen = min(rest, md[i].len);
++		for (mdone = 0; mlen;) {
++			int slen = min(sg_dma_len(sg + sidx) - soff, mlen);
++
++			if (dir == DMA_TO_DEVICE)
++				err = h_copy_rdma(slen,
++						  vport->riobn,
++						  md[i].va + mdone,
++						  vport->liobn,
++						  token + soff);
++			else
++				err = h_copy_rdma(slen,
++						  vport->liobn,
++						  token + soff,
++						  vport->riobn,
++						  md[i].va + mdone);
++
++			if (err != H_Success) {
++				eprintk("rdma error %d %d\n", dir, slen);
++				goto out;
++			}
++
++			mlen -= slen;
++			mdone += slen;
++			soff += slen;
++			done += slen;
++
++			if (soff == sg_dma_len(sg + sidx)) {
++				sidx++;
++				soff = 0;
++				token = sg_dma_address(sg + sidx);
++
++				if (sidx > nsg) {
++					eprintk("out of sg %p %d %d\n",
++						iue, sidx, nsg);
++					goto out;
++				}
++			}
++		};
++
++		rest -= mlen;
++	}
++out:
++
++	return 0;
++}
++
++static int ibmvstgt_transfer_data(struct scsi_cmnd *scmd,
++				  void (*done)(struct scsi_cmnd *))
++{
++	struct iu_entry	*iue = (struct iu_entry *) scmd->SCp.ptr;
++	int err;
++
++	err = srp_transfer_data(scmd, &vio_iu(iue)->srp.cmd, ibmvstgt_rdma);
++	done(scmd);
++
++	return err;
++}
++
++static int ibmvstgt_cmd_done(struct scsi_cmnd *scmd,
++			     void (*done)(struct scsi_cmnd *))
++{
++	unsigned long flags;
++	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
++	struct srp_target *target = iue->target;
++
++	dprintk("%p %p %x\n", iue, target, vio_iu(iue)->srp.cmd.cdb[0]);
++
++	spin_lock_irqsave(&target->lock, flags);
++	list_del(&iue->ilist);
++	spin_unlock_irqrestore(&target->lock, flags);
++
++	if (scmd->result != SAM_STAT_GOOD) {
++		eprintk("operation failed %p %d %x\n",
++			iue, scmd->result, vio_iu(iue)->srp.cmd.cdb[0]);
++		send_rsp(iue, HARDWARE_ERROR, 0x00);
++	} else
++		send_rsp(iue, NO_SENSE, 0x00);
++
++	done(scmd);
++	srp_iu_put(iue);
++	return 0;
++}
++
++int send_adapter_info(struct iu_entry *iue,
++		      dma_addr_t remote_buffer, uint16_t length)
++{
++	struct srp_target *target = iue->target;
++	struct vio_port *vport = target_to_port(target);
++	struct Scsi_Host *shost = target->shost;
++	dma_addr_t data_token;
++	struct mad_adapter_info_data *info;
++	int err;
++
++	info = dma_alloc_coherent(target->dev, sizeof(*info), &data_token,
++				  GFP_KERNEL);
++	if (!info) {
++		eprintk("bad dma_alloc_coherent %p\n", target);
++		return 1;
++	}
++
++	/* Get remote info */
++	err = h_copy_rdma(sizeof(*info), vport->riobn, remote_buffer,
++			  vport->liobn, data_token);
++	if (err == H_Success) {
++		dprintk("Client connect: %s (%d)\n",
++			info->partition_name, info->partition_number);
++	}
++
++	memset(info, 0, sizeof(*info));
++
++	strcpy(info->srp_version, "16.a");
++	strncpy(info->partition_name, partition_name,
++		sizeof(info->partition_name));
++	info->partition_number = partition_number;
++	info->mad_version = 1;
++	info->os_type = 2;
++	info->port_max_txu[0] = shost->hostt->max_sectors << 9;
++
++	/* Send our info to remote */
++	err = h_copy_rdma(sizeof(*info), vport->liobn, data_token,
++			  vport->riobn, remote_buffer);
++
++	dma_free_coherent(target->dev, sizeof(*info), info, data_token);
++
++	if (err != H_Success) {
++		eprintk("Error sending adapter info %d\n", err);
++		return 1;
++	}
++
++	return 0;
++}
++
++static void process_login(struct iu_entry *iue)
++{
++	union viosrp_iu *iu = vio_iu(iue);
++	struct srp_login_rsp *rsp = &iu->srp.login_rsp;
++	uint64_t tag = iu->srp.rsp.tag;
++
++	/* TODO handle case that requested size is wrong and
++	 * buffer format is wrong
++	 */
++	memset(iu, 0, sizeof(struct srp_login_rsp));
++	rsp->opcode = SRP_LOGIN_RSP;
++	rsp->req_lim_delta = INITIAL_SRP_LIMIT;
++	rsp->tag = tag;
++	rsp->max_it_iu_len = sizeof(union srp_iu);
++	rsp->max_ti_iu_len = sizeof(union srp_iu);
++	/* direct and indirect */
++	rsp->buf_fmt = SRP_BUF_FORMAT_DIRECT | SRP_BUF_FORMAT_INDIRECT;
++
++	send_iu(iue, sizeof(*rsp), VIOSRP_SRP_FORMAT);
++}
++
++static inline void queue_cmd(struct iu_entry *iue)
++{
++	struct srp_target *target = iue->target;
++	unsigned long flags;
++
++	spin_lock_irqsave(&target->lock, flags);
++	list_add_tail(&iue->ilist, &target->cmd_queue);
++	spin_unlock_irqrestore(&target->lock, flags);
++}
++
++static int process_tsk_mgmt(struct iu_entry *iue)
++{
++	union viosrp_iu *iu = vio_iu(iue);
++	int fn;
++
++	dprintk("%p %u\n", iue, iu->srp.tsk_mgmt.tsk_mgmt_func);
++
++	switch (iu->srp.tsk_mgmt.tsk_mgmt_func) {
++	case SRP_TSK_ABORT_TASK:
++		fn = ABORT_TASK;
++		break;
++	case SRP_TSK_ABORT_TASK_SET:
++		fn = ABORT_TASK_SET;
++		break;
++	case SRP_TSK_CLEAR_TASK_SET:
++		fn = CLEAR_TASK_SET;
++		break;
++	case SRP_TSK_LUN_RESET:
++		fn = LOGICAL_UNIT_RESET;
++		break;
++	case SRP_TSK_CLEAR_ACA:
++		fn = CLEAR_ACA;
++		break;
++	default:
++		fn = 0;
++	}
++	if (fn)
++		scsi_tgt_tsk_mgmt_request(iue->target->shost, fn,
++					  iu->srp.tsk_mgmt.task_tag,
++					  (struct scsi_lun *) &iu->srp.tsk_mgmt.lun,
++					  iue);
++	else
++		send_rsp(iue, ILLEGAL_REQUEST, 0x20);
++
++	return !fn;
++}
++
++static int process_mad_iu(struct iu_entry *iue)
++{
++	union viosrp_iu *iu = vio_iu(iue);
++	struct viosrp_adapter_info *info;
++	struct viosrp_host_config *conf;
++
++	switch (iu->mad.empty_iu.common.type) {
++	case VIOSRP_EMPTY_IU_TYPE:
++		eprintk("%s\n", "Unsupported EMPTY MAD IU");
++		break;
++	case VIOSRP_ERROR_LOG_TYPE:
++		eprintk("%s\n", "Unsupported ERROR LOG MAD IU");
++		iu->mad.error_log.common.status = 1;
++		send_iu(iue, sizeof(iu->mad.error_log),	VIOSRP_MAD_FORMAT);
++		break;
++	case VIOSRP_ADAPTER_INFO_TYPE:
++		info = &iu->mad.adapter_info;
++		info->common.status = send_adapter_info(iue, info->buffer,
++							info->common.length);
++		send_iu(iue, sizeof(*info), VIOSRP_MAD_FORMAT);
++		break;
++	case VIOSRP_HOST_CONFIG_TYPE:
++		conf = &iu->mad.host_config;
++		conf->common.status = 1;
++		send_iu(iue, sizeof(*conf), VIOSRP_MAD_FORMAT);
++		break;
++	default:
++		eprintk("Unknown type %u\n", iu->srp.rsp.opcode);
++	}
++
++	return 1;
++}
++
++static int process_srp_iu(struct iu_entry *iue)
++{
++	union viosrp_iu *iu = vio_iu(iue);
++	int done = 1;
++	u8 opcode = iu->srp.rsp.opcode;
++
++	switch (opcode) {
++	case SRP_LOGIN_REQ:
++		process_login(iue);
++		break;
++	case SRP_TSK_MGMT:
++		done = process_tsk_mgmt(iue);
++		break;
++	case SRP_CMD:
++		queue_cmd(iue);
++		done = 0;
++		break;
++	case SRP_LOGIN_RSP:
++	case SRP_I_LOGOUT:
++	case SRP_T_LOGOUT:
++	case SRP_RSP:
++	case SRP_CRED_REQ:
++	case SRP_CRED_RSP:
++	case SRP_AER_REQ:
++	case SRP_AER_RSP:
++		eprintk("Unsupported type %u\n", opcode);
++		break;
++	default:
++		eprintk("Unknown type %u\n", opcode);
++	}
++
++	return done;
++}
++
++static void process_iu(struct viosrp_crq *crq, struct srp_target *target)
++{
++	struct vio_port *vport = target_to_port(target);
++	struct iu_entry *iue;
++	long err, done;
++
++	iue = srp_iu_get(target);
++	if (!iue) {
++		eprintk("Error getting IU from pool, %p\n", target);
++		return;
++	}
++
++	iue->remote_token = crq->IU_data_ptr;
++
++	err = h_copy_rdma(crq->IU_length, vport->riobn,
++			  iue->remote_token, vport->liobn, iue->sbuf->dma);
++
++	if (err != H_Success)
++		eprintk("%ld transferring data error %p\n", err, iue);
++
++	if (crq->format == VIOSRP_MAD_FORMAT)
++		done = process_mad_iu(iue);
++	else
++		done = process_srp_iu(iue);
++
++	if (done)
++		srp_iu_put(iue);
++}
++
++static irqreturn_t ibmvstgt_interrupt(int irq, void *data, struct pt_regs *regs)
++{
++	struct srp_target *target = (struct srp_target *) data;
++	struct vio_port *vport = target_to_port(target);
++
++	vio_disable_interrupts(vport->dma_dev);
++	queue_work(vtgtd, &vport->crq_work);
++
++	return IRQ_HANDLED;
++}
++
++static int crq_queue_create(struct crq_queue *queue, struct srp_target *target)
++{
++	int err;
++	struct vio_port *vport = target_to_port(target);
++
++	queue->msgs = (struct viosrp_crq *) get_zeroed_page(GFP_KERNEL);
++	if (!queue->msgs)
++		goto malloc_failed;
++	queue->size = PAGE_SIZE / sizeof(*queue->msgs);
++
++	queue->msg_token = dma_map_single(target->dev, queue->msgs,
++					  queue->size * sizeof(*queue->msgs),
++					  DMA_BIDIRECTIONAL);
++
++	if (dma_mapping_error(queue->msg_token))
++		goto map_failed;
++
++	err = h_reg_crq(vport->dma_dev->unit_address, queue->msg_token,
++			PAGE_SIZE);
++
++	/* If the adapter was left active for some reason (like kexec)
++	 * try freeing and re-registering
++	 */
++	if (err == H_Resource) {
++	    do {
++		err = h_free_crq(vport->dma_dev->unit_address);
++	    } while (err == H_Busy || H_isLongBusy(err));
++
++	    err = h_reg_crq(vport->dma_dev->unit_address, queue->msg_token,
++			    PAGE_SIZE);
++	}
++
++	if (err != H_Success && err != 2) {
++		eprintk("Error 0x%x opening virtual adapter\n", err);
++		goto reg_crq_failed;
++	}
++
++	err = request_irq(vport->dma_dev->irq, &ibmvstgt_interrupt,
++			  SA_INTERRUPT, "ibmvstgt", target);
++	if (err)
++		goto req_irq_failed;
++
++	vio_enable_interrupts(vport->dma_dev);
++
++	h_send_crq(vport->dma_dev->unit_address, 0xC001000000000000, 0);
++
++	queue->cur = 0;
++	spin_lock_init(&queue->lock);
++
++	return 0;
++
++req_irq_failed:
++	do {
++		err = h_free_crq(vport->dma_dev->unit_address);
++	} while (err == H_Busy || H_isLongBusy(err));
++
++reg_crq_failed:
++	dma_unmap_single(target->dev, queue->msg_token,
++			 queue->size * sizeof(*queue->msgs), DMA_BIDIRECTIONAL);
++map_failed:
++	free_page((unsigned long) queue->msgs);
++
++malloc_failed:
++	return -ENOMEM;
++}
++
++static void crq_queue_destroy(struct srp_target *target)
++{
++	struct vio_port *vport = target_to_port(target);
++	struct crq_queue *queue = &vport->crq_queue;
++	int err;
++
++	free_irq(vport->dma_dev->irq, target);
++	do {
++		err = h_free_crq(vport->dma_dev->unit_address);
++	} while (err == H_Busy || H_isLongBusy(err));
++
++	dma_unmap_single(target->dev, queue->msg_token,
++			 queue->size * sizeof(*queue->msgs), DMA_BIDIRECTIONAL);
++
++	free_page((unsigned long) queue->msgs);
++}
++
++static void process_crq(struct viosrp_crq *crq,	struct srp_target *target)
++{
++	struct vio_port *vport = target_to_port(target);
++	dprintk("%x %x\n", crq->valid, crq->format);
++
++	switch (crq->valid) {
++	case 0xC0:
++		/* initialization */
++		switch (crq->format) {
++		case 0x01:
++			h_send_crq(vport->dma_dev->unit_address,
++				   0xC002000000000000, 0);
++			break;
++		case 0x02:
++			break;
++		default:
++			eprintk("Unknown format %u\n", crq->format);
++		}
++		break;
++	case 0xFF:
++		/* transport event */
++		break;
++	case 0x80:
++		/* real payload */
++		switch (crq->format) {
++		case VIOSRP_SRP_FORMAT:
++		case VIOSRP_MAD_FORMAT:
++			process_iu(crq, target);
++			break;
++		case VIOSRP_OS400_FORMAT:
++		case VIOSRP_AIX_FORMAT:
++		case VIOSRP_LINUX_FORMAT:
++		case VIOSRP_INLINE_FORMAT:
++			eprintk("Unsupported format %u\n", crq->format);
++			break;
++		default:
++			eprintk("Unknown format %u\n", crq->format);
++		}
++		break;
++	default:
++		eprintk("unknown message type 0x%02x!?\n", crq->valid);
++	}
++}
++
++static inline struct viosrp_crq *next_crq(struct crq_queue *queue)
++{
++	struct viosrp_crq *crq;
++	unsigned long flags;
++
++	spin_lock_irqsave(&queue->lock, flags);
++	crq = &queue->msgs[queue->cur];
++	if (crq->valid & 0x80) {
++		if (++queue->cur == queue->size)
++			queue->cur = 0;
++	} else
++		crq = NULL;
++	spin_unlock_irqrestore(&queue->lock, flags);
++
++	return crq;
++}
++
++static void handle_crq(void *data)
++{
++	struct srp_target *target = (struct srp_target *) data;
++	struct vio_port *vport = target_to_port(target);
++	struct viosrp_crq *crq;
++	int done = 0;
++
++	while (!done) {
++		while ((crq = next_crq(&vport->crq_queue)) != NULL) {
++			process_crq(crq, target);
++			crq->valid = 0x00;
++		}
++
++		vio_enable_interrupts(vport->dma_dev);
++
++		crq = next_crq(&vport->crq_queue);
++		if (crq) {
++			vio_disable_interrupts(vport->dma_dev);
++			process_crq(crq, target);
++			crq->valid = 0x00;
++		} else
++			done = 1;
++	}
++
++	handle_cmd_queue(target);
++}
++
++
++static int ibmvstgt_eh_abort_handler(struct scsi_cmnd *scmd)
++{
++	unsigned long flags;
++	struct iu_entry *iue = (struct iu_entry *) scmd->SCp.ptr;
++	struct srp_target *target = iue->target;
++
++	dprintk("%p %p %x\n", iue, target, vio_iu(iue)->srp.cmd.cdb[0]);
++
++	spin_lock_irqsave(&target->lock, flags);
++	list_del(&iue->ilist);
++	spin_unlock_irqrestore(&target->lock, flags);
++
++	srp_iu_put(iue);
++
++	return 0;
++}
++
++static int ibmvstgt_tsk_mgmt_response(u64 mid, int result)
++{
++	struct iu_entry *iue = (struct iu_entry *) ((void *) mid);
++	union viosrp_iu *iu = vio_iu(iue);
++	unsigned char status, asc;
++
++	eprintk("%p %d\n", iue, result);
++	status = NO_SENSE;
++	asc = 0;
++
++	switch (iu->srp.tsk_mgmt.tsk_mgmt_func) {
++	case SRP_TSK_ABORT_TASK:
++		asc = 0x14;
++		if (result)
++			status = ABORTED_COMMAND;
++		break;
++	default:
++		break;
++	}
++
++	send_rsp(iue, status, asc);
++	srp_iu_put(iue);
++
++	return 0;
++}
++
++static ssize_t system_id_show(struct class_device *cdev, char *buf)
++{
++	return snprintf(buf, PAGE_SIZE, "%s\n", system_id);
++}
++
++static ssize_t partition_number_show(struct class_device *cdev, char *buf)
++{
++	return snprintf(buf, PAGE_SIZE, "%x\n", partition_number);
++}
++
++static ssize_t unit_address_show(struct class_device *cdev, char *buf)
++{
++	struct Scsi_Host *shost = class_to_shost(cdev);
++	struct srp_target *target = host_to_target(shost);
++	struct vio_port *vport = target_to_port(target);
++	return snprintf(buf, PAGE_SIZE, "%x\n", vport->dma_dev->unit_address);
++}
++
++static CLASS_DEVICE_ATTR(system_id, S_IRUGO, system_id_show, NULL);
++static CLASS_DEVICE_ATTR(partition_number, S_IRUGO, partition_number_show, NULL);
++static CLASS_DEVICE_ATTR(unit_address, S_IRUGO, unit_address_show, NULL);
++
++static struct class_device_attribute *ibmvstgt_attrs[] = {
++	&class_device_attr_system_id,
++	&class_device_attr_partition_number,
++	&class_device_attr_unit_address,
++	NULL,
++};
++
++static struct scsi_host_template ibmvstgt_sht = {
++	.name			= TGT_NAME,
++	.module			= THIS_MODULE,
++	.can_queue		= INITIAL_SRP_LIMIT,
++	.sg_tablesize		= SG_ALL,
++	.use_clustering		= DISABLE_CLUSTERING,
++	.max_sectors		= DEFAULT_MAX_SECTORS,
++	.transfer_response	= ibmvstgt_cmd_done,
++	.transfer_data		= ibmvstgt_transfer_data,
++	.eh_abort_handler	= ibmvstgt_eh_abort_handler,
++	.tsk_mgmt_response	= ibmvstgt_tsk_mgmt_response,
++	.shost_attrs		= ibmvstgt_attrs,
++	.proc_name		= TGT_NAME,
++};
++
++static int ibmvstgt_probe(struct vio_dev *dev, const struct vio_device_id *id)
++{
++	struct Scsi_Host *shost;
++	struct srp_target *target;
++	struct vio_port *vport;
++	unsigned int *dma, dma_size;
++	int err = -ENOMEM;
++
++	vport = kzalloc(sizeof(struct vio_port), GFP_KERNEL);
++	if (!vport)
++		return err;
++	shost = scsi_host_alloc(&ibmvstgt_sht, sizeof(struct srp_target));
++	if (!shost)
++		goto free_vport;
++	err = scsi_tgt_alloc_queue(shost);
++	if (err)
++		goto put_host;
++
++	target = host_to_target(shost);
++	target->shost = shost;
++	vport->dma_dev = dev;
++	target->ldata = vport;
++	err = srp_target_alloc(target, &dev->dev, INITIAL_SRP_LIMIT,
++			       SRP_MAX_IU_LEN);
++	if (err)
++		goto put_host;
++
++	dma = (unsigned int *) vio_get_attribute(dev, "ibm,my-dma-window",
++						 &dma_size);
++	if (!dma || dma_size != 40) {
++		eprintk("Couldn't get window property %d\n", dma_size);
++		err = -EIO;
++		goto free_srp_target;
++	}
++	vport->liobn = dma[0];
++	vport->riobn = dma[5];
++
++	INIT_WORK(&vport->crq_work, handle_crq, target);
++
++	err = crq_queue_create(&vport->crq_queue, target);
++	if (err)
++		goto free_srp_target;
++
++	err = scsi_add_host(shost, target->dev);
++	if (err)
++		goto destroy_queue;
++	return 0;
++
++destroy_queue:
++	crq_queue_destroy(target);
++free_srp_target:
++	srp_target_free(target);
++put_host:
++	scsi_host_put(shost);
++free_vport:
++	kfree(vport);
++	return err;
++}
++
++static int ibmvstgt_remove(struct vio_dev *dev)
++{
++	struct srp_target *target = (struct srp_target *) dev->dev.driver_data;
++	struct Scsi_Host *shost = target->shost;
++
++	srp_target_free(target);
++	crq_queue_destroy(target);
++	scsi_remove_host(shost);
++	scsi_host_put(shost);
++	return 0;
++}
++
++static struct vio_device_id ibmvstgt_device_table[] __devinitdata = {
++	{"v-scsi-host", "IBM,v-scsi-host"},
++	{"",""}
++};
++
++MODULE_DEVICE_TABLE(vio, ibmvstgt_device_table);
++
++static struct vio_driver ibmvstgt_driver = {
++	.id_table = ibmvstgt_device_table,
++	.probe = ibmvstgt_probe,
++	.remove = ibmvstgt_remove,
++	.driver = {
++		.name = "ibmvscsi",
++		.owner = THIS_MODULE,
++	}
++};
++
++static int get_system_info(void)
++{
++	struct device_node *rootdn;
++	char *id, *model, *name;
++	unsigned int *num;
++
++	rootdn = find_path_device("/");
++	if (!rootdn)
++		return -ENOENT;
++
++	model = get_property(rootdn, "model", NULL);
++	id = get_property(rootdn, "system-id", NULL);
++	if (model && id)
++		snprintf(system_id, sizeof(system_id), "%s-%s", model, id);
++
++	name = get_property(rootdn, "ibm,partition-name", NULL);
++	if (name)
++		strncpy(partition_name, name, sizeof(partition_name));
++
++	num = (unsigned int *) get_property(rootdn, "ibm,partition-no", NULL);
++	if (num)
++		partition_number = *num;
++
++	return 0;
++}
++
++static int ibmvstgt_init(void)
++{
++	int err = -ENOMEM;
++
++	printk("IBM eServer i/pSeries Virtual SCSI Target Driver\n");
++
++	vtgtd = create_workqueue("ibmvtgtd");
++	if (!vtgtd)
++		return err;
++
++	err = get_system_info();
++	if (err)
++		goto destroy_wq;
++
++	err = vio_register_driver(&ibmvstgt_driver);
++	if (err)
++		goto destroy_wq;
++
++	return 0;
++
++destroy_wq:
++	destroy_workqueue(vtgtd);
++	return err;
++}
++
++static void ibmvstgt_exit(void)
++{
++	printk("Unregister IBM virtual SCSI driver\n");
++
++	destroy_workqueue(vtgtd);
++	vio_unregister_driver(&ibmvstgt_driver);
++}
++
++MODULE_DESCRIPTION("IBM Virtual SCSI Target");
++MODULE_AUTHOR("Dave Boutcher");
++MODULE_LICENSE("GPL");
++
++module_init(ibmvstgt_init);
++module_exit(ibmvstgt_exit);
+-- 
+1.1.3



From tomo at berlios.de  Fri Apr 28 13:46:11 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Fri, 28 Apr 2006 13:46:11 +0200
Subject: [Stgt-svn] r427 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604281146.k3SBkBTm026946@sheep.berlios.de>

Author: tomo
Date: 2006-04-28 13:46:09 +0200 (Fri, 28 Apr 2006)
New Revision: 427

Added:
   branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
Modified:
   branches/use-scsi-ml/istgt/kernel/Makefile
Log:
Just started to implement istgt_tcp. Currently, the code is completely
broken. It will work nicely with scsi_transport_iscsi and
libiscsi. Integrating istgt_tcp with iscsi_tcp would be nice because
istgt_tcp takes lots of code from iscsi_tcp.


Modified: branches/use-scsi-ml/istgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-19 08:43:40 UTC (rev 426)
+++ branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-28 11:46:09 UTC (rev 427)
@@ -7,12 +7,11 @@
 #
 # Note 2! The CFLAGS definitions are now in the main makefile.
 
-EXTRA_CFLAGS += -I$(obj) -I$(obj)/../include -I$(obj)/../../kernel
+EXTRA_CFLAGS += -I$(obj) -I$(KERNELSRC)/drivers/scsi/
 
 ifneq ($(KERNELRELEASE),)
-obj-m		+= istgt.o
-istgt-objs	:= iscsi_tcp_tgt.o nthread.o digest.o \
-			conn.o
+obj-m		+= istgt_tcp.o
+#obj-m		+= libistgt.o
 else
 
 ifeq ($(KERNELSRC),)

Added: branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-19 08:43:40 UTC (rev 426)
+++ branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-28 11:46:09 UTC (rev 427)
@@ -0,0 +1,1073 @@
+/*
+ * iSCSI Target over TCP/IP
+ *
+ * Copyright (C) 2004 Dmitry Yusupov
+ * Copyright (C) 2004 Alex Aizman
+ * Copyright (C) 2005 - 2006 Mike Christie
+ * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
+ * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published
+ * by the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * See the file COPYING included with this distribution for more details.
+ */
+
+/*
+ * Most part is taken from iscsi_tcp. Integrating with iscsi_tcp would
+ * be nice...
+ */
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/inet.h>
+#include <linux/blkdev.h>
+#include <linux/crypto.h>
+#include <linux/delay.h>
+#include <linux/kfifo.h>
+#include <linux/scatterlist.h>
+#include <linux/mutex.h>
+#include <net/tcp.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi.h>
+#include <iscsi_tcp.h>
+#include <scsi/libiscsi.h>
+#include <scsi/scsi_transport_iscsi.h>
+#include <scsi/scsi_tgt.h>
+#include <scsi/scsi_tcq.h>
+
+/* tmp - will replace with SCSI logging stuff */
+#define eprintk(fmt, args...)					\
+do {								\
+	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
+} while (0)
+
+#define dprintk eprintk
+
+struct istgt_session {
+	struct list_head pending_list;
+};
+
+static kmem_cache_t *taskcache;
+
+static void build_r2t(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_r2t_rsp *hdr;
+	struct iscsi_data_task *dtask;
+	struct iscsi_r2t_info *r2t;
+	struct iscsi_session *session = ctask->conn->session;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data;
+	int rc;
+
+/* 	length = req->r2t_length; */
+/* 	burst = req->conn->session->param.max_burst_length; */
+/* 	offset = be32_to_cpu(cmd_hdr(req)->data_length) - length; */
+more:
+	rc = __kfifo_get(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
+	BUG_ON(!rc);
+
+	dtask = mempool_alloc(tcp_ctask->datapool, GFP_ATOMIC);
+	BUG_ON(!dtask);
+
+	INIT_LIST_HEAD(&dtask->item);
+	r2t->dtask = dtask;
+	hdr = (struct iscsi_r2t_rsp *) &dtask->hdr;
+
+/* 	rsp->pdu.bhs.ttt = req->target_task_tag; */
+
+	hdr->opcode = ISCSI_OP_R2T;
+	hdr->flags = ISCSI_FLAG_CMD_FINAL;
+	memcpy(hdr->lun, ctask->hdr->lun, 8);
+	hdr->itt = ctask->hdr->itt;
+	hdr->r2tsn = cpu_to_be32(tcp_ctask->exp_r2tsn++);
+/* 	hdr->data_offset = cpu_to_be32(offset); */
+/* 	if (length > burst) { */
+/* 		rsp_hdr->data_length = cpu_to_be32(burst); */
+/* 		length -= burst; */
+/* 		offset += burst; */
+/* 	} else { */
+/* 		rsp_hdr->data_length = cpu_to_be32(length); */
+/* 		length = 0; */
+/* 	} */
+
+	dprintk("%x %u %u %u\n", ctask->hdr->itt,
+		be32_to_cpu(hdr->data_length),
+		be32_to_cpu(hdr->data_offset),
+		be32_to_cpu(hdr->r2tsn));
+
+/* 	if (++req->outstanding_r2t >= req->conn->session->param.max_outstanding_r2t) */
+/* 		break; */
+
+	__kfifo_put(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
+
+/* 	if (length) */
+/* 		goto more; */
+}
+
+static void istgt_scsi_tgt_queue_command(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_session *session = ctask->conn->session;
+	struct iscsi_cls_session *cls_session;
+	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
+	struct iscsi_cmd *hdr = ctask->hdr;
+	struct scsi_cmnd *scmd;
+	enum dma_data_direction dir;
+
+	if (hdr->flags & ISCSI_FLAG_CMD_WRITE)
+		dir = DMA_TO_DEVICE;
+	else if (hdr->flags & ISCSI_FLAG_CMD_READ)
+		dir = DMA_FROM_DEVICE;
+	else
+		dir = DMA_NONE;
+
+	scmd = scsi_host_get_command(shost, dir, GFP_KERNEL);
+	BUG_ON(!scmd);
+	ctask->sc = scmd;
+
+	memcpy(scmd->data_cmnd, hdr->cdb, MAX_COMMAND_SIZE);
+	scmd->request_bufflen = be32_to_cpu(hdr->data_length);
+	scmd->SCp.ptr = (void *) ctask;
+
+	switch (hdr->flags & ISCSI_FLAG_CMD_ATTR_MASK) {
+	case ISCSI_ATTR_UNTAGGED:
+	case ISCSI_ATTR_SIMPLE:
+		scmd->tag = MSG_SIMPLE_TAG;
+		break;
+	case ISCSI_ATTR_ORDERED:
+		scmd->tag = MSG_ORDERED_TAG;
+		break;
+	case ISCSI_ATTR_HEAD_OF_QUEUE:
+		scmd->tag = MSG_HEAD_TAG;
+		break;
+	case ISCSI_ATTR_ACA:
+		scmd->tag = MSG_SIMPLE_TAG;
+		break;
+	default:
+		scmd->tag = MSG_SIMPLE_TAG;
+	}
+
+	if (scmd->sc_data_direction == DMA_TO_DEVICE &&
+	    be32_to_cpu(hdr->data_length)) {
+		switch (hdr->cdb[0]) {
+		case WRITE_6:
+		case WRITE_10:
+		case WRITE_16:
+		case WRITE_VERIFY:
+			break;
+		default:
+			eprintk("%x\n", hdr->cdb[0]);
+			break;
+		}
+	}
+
+	scsi_tgt_queue_command(scmd, (struct scsi_lun *) hdr->lun, hdr->itt);
+}
+
+static void istgt_scsi_cmnd_exec(struct iscsi_cmd_task *ctask)
+{
+	struct scsi_cmnd *scmd = ctask->sc;
+
+	if (ctask->data_count) {
+		if (!ctask->unsol_count)
+			;
+/* 			send_r2t(ctask); */
+	} else {
+/* 		set_cmd_waitio(cmnd); */
+		if (scmd) {
+/* 			BUG_ON(!ctask->done); */
+/* 			cmnd->done(scmd); */
+		} else
+			istgt_scsi_tgt_queue_command(ctask);
+	}
+}
+
+static void istgt_cmd_exec(struct iscsi_cmd_task *ctask)
+{
+	u8 opcode;
+
+	opcode = ctask->hdr->opcode & ISCSI_OPCODE_MASK;
+
+	dprintk("%p,%x,%u\n", ctask, opcode, ctask->hdr->cmdsn);
+
+	switch (opcode) {
+	case ISCSI_OP_NOOP_OUT:
+/* 		noop_out_exec(cmnd); */
+		break;
+	case ISCSI_OP_SCSI_CMD:
+		istgt_scsi_cmnd_exec(ctask);
+		break;
+	case ISCSI_OP_SCSI_TMFUNC:
+/* 		execute_task_management(cmnd); */
+		break;
+	case ISCSI_OP_LOGOUT:
+/* 		logout_exec(cmnd); */
+		break;
+/* 	case ISCSI_OP_SCSI_REJECT: */
+/* 		iscsi_cmnd_init_write(get_rsp_cmnd(cmnd)); */
+/* 		break; */
+	case ISCSI_OP_TEXT:
+	case ISCSI_OP_SNACK:
+		break;
+	default:
+		eprintk("unexpected cmnd op %x\n", ctask->hdr->opcode);
+		break;
+	}
+}
+
+static void istgt_ctask_add(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_session *session = ctask->conn->session;
+	struct iscsi_cls_session *cls_session;
+	struct istgt_session *sess;
+	struct iscsi_cmd *hdr = ctask->hdr;
+	struct list_head *entry;
+	uint32_t cmdsn;
+
+	sess = (struct istgt_session *) cls_session->dd_data;
+
+	if (hdr->opcode & ISCSI_OP_IMMEDIATE) {
+		istgt_cmd_exec(ctask);
+		return;
+	}
+
+	cmdsn = hdr->cmdsn;
+	if (cmdsn == session->exp_cmdsn) {
+		session->exp_cmdsn = ++cmdsn;
+		istgt_cmd_exec(ctask);
+
+		if (list_empty(&sess->pending_list))
+			return;
+		ctask = list_entry(sess->pending_list.next,
+				   struct iscsi_cmd_task, running);
+		if (ctask->hdr->cmdsn != cmdsn)
+			return;
+		list_del_init(&ctask->running);
+	} else {
+/* 		set_cmd_pending(cmnd); */
+		if (before(cmdsn, session->exp_cmdsn)) /* close the conn */
+			eprintk("unexpected cmd_sn (%u,%u)\n", cmdsn, session->exp_cmdsn);
+
+/* 		if (after(cmdsn, session->exp_cmdsn + session->max_queued_cmnds)) */
+/* 			eprintk("too large cmd_sn (%u,%u)\n", cmd_sn, session->exp_cmd_sn); */
+
+		list_for_each(entry, &sess->pending_list) {
+			struct iscsi_cmd_task *tmp;
+			tmp = list_entry(entry, struct iscsi_cmd_task, running);
+			if (before(cmdsn, tmp->hdr->cmdsn))
+				break;
+		}
+
+		BUG_ON(!list_empty(&ctask->running));
+
+		list_add_tail(&ctask->running, entry);
+	}
+}
+
+
+/*
+ * the followings are taken from iscsi_tcp.
+ */
+
+int iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
+{
+	int rc = 0, opcode, ahslen;
+	struct iscsi_hdr *hdr;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	uint32_t cdgst, rdgst = 0;
+	struct iscsi_cmd_task *ctask = NULL;
+
+	hdr = tcp_conn->in.hdr;
+
+	/* verify PDU length */
+	tcp_conn->in.datalen = ntoh24(hdr->dlength);
+	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
+		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
+		       tcp_conn->in.datalen, conn->max_recv_dlength);
+		return ISCSI_ERR_DATALEN;
+	}
+	tcp_conn->data_copied = 0;
+
+	/* read AHS */
+	ahslen = hdr->hlength << 2;
+	tcp_conn->in.offset += ahslen;
+	tcp_conn->in.copy -= ahslen;
+	if (tcp_conn->in.copy < 0) {
+		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
+		       "%d bytes\n", ahslen);
+		return ISCSI_ERR_AHSLEN;
+	}
+
+	/* calculate read padding */
+	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
+	if (tcp_conn->in.padding) {
+		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
+		dprintk("read padding %d bytes\n", tcp_conn->in.padding);
+	}
+
+	if (conn->hdrdgst_en) {
+		struct scatterlist sg;
+
+		sg_init_one(&sg, (u8 *)hdr,
+			    sizeof(struct iscsi_hdr) + ahslen);
+		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
+		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
+				     ahslen);
+		if (cdgst != rdgst) {
+			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
+			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
+			return ISCSI_ERR_HDR_DGST;
+		}
+	}
+
+	__kfifo_get(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
+	ctask->conn = conn;
+	INIT_LIST_HEAD(&ctask->running);
+	memcpy(ctask->hdr, hdr, sizeof(*hdr));
+
+	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
+
+	dprintk("opcode 0x%x offset %d copy %d ahslen %d datalen %d\n",
+		opcode, tcp_conn->in.offset, tcp_conn->in.copy,
+		ahslen, tcp_conn->in.datalen);
+
+	switch(opcode) {
+	case ISCSI_OP_NOOP_OUT:
+		/* TODO */
+		BUG();
+		break;
+	case ISCSI_OP_SCSI_CMD:
+/* 		if (!(err = cmnd_insert_hash(cmnd))) */
+/* 			scsi_cmnd_start(conn, cmnd); */
+		break;
+	case ISCSI_OP_SCSI_TMFUNC:
+		/* TODO */
+		BUG();
+		break;
+	case ISCSI_OP_SCSI_DATA_OUT:
+/* 		data_out_start(conn, cmnd); */
+		break;
+	case ISCSI_OP_LOGOUT:
+/* 		err = cmnd_insert_hash(cmnd); */
+		break;
+	case ISCSI_OP_TEXT:
+	case ISCSI_OP_SNACK:
+		rc = -ISCSI_REASON_CMD_NOT_SUPPORTED;
+		break;
+	default:
+		rc = -ISCSI_REASON_CMD_NOT_SUPPORTED;
+		break;
+	}
+
+	return rc;
+}
+
+static int
+iscsi_data_recv(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int rc = 0, opcode;
+
+	opcode = tcp_conn->in.hdr->opcode & ISCSI_OPCODE_MASK;
+	switch (opcode) {
+	case ISCSI_OP_SCSI_CMD:
+		break;
+	case ISCSI_OP_SCSI_DATA_OUT:
+		/* READ DATAT */
+		break;
+	case ISCSI_OP_TEXT:
+	case ISCSI_OP_LOGOUT:
+	case ISCSI_OP_NOOP_OUT:
+	case ISCSI_OP_ASYNC_EVENT:
+		/*
+		 * Collect data segment to the connection's data
+		 * placeholder
+		 */
+		if (iscsi_tcp_copy(tcp_conn)) {
+			rc = -EAGAIN;
+			goto exit;
+		}
+
+/* 		rc = iscsi_complete_pdu(conn, tcp_conn->in.hdr, tcp_conn->data, */
+/* 					tcp_conn->in.datalen); */
+/* 		if (!rc && conn->datadgst_en && opcode != ISCSI_OP_LOGIN_RSP) */
+/* 			iscsi_recv_digest_update(tcp_conn, tcp_conn->data, */
+/* 			  			tcp_conn->in.datalen); */
+		break;
+	default:
+		BUG_ON(1);
+	}
+exit:
+	return rc;
+}
+
+static inline int
+iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn)
+{
+	struct sk_buff *skb = tcp_conn->in.skb;
+
+	tcp_conn->in.zero_copy_hdr = 0;
+
+	if (tcp_conn->in.copy >= tcp_conn->hdr_size &&
+	    tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER) {
+		/*
+		 * Zero-copy PDU Header: using connection context
+		 * to store header pointer.
+		 */
+		if (skb_shinfo(skb)->frag_list == NULL &&
+		    !skb_shinfo(skb)->nr_frags) {
+			tcp_conn->in.hdr = (struct iscsi_hdr *)
+				((char*)skb->data + tcp_conn->in.offset);
+			tcp_conn->in.zero_copy_hdr = 1;
+		} else {
+			/* ignoring return code since we checked
+			 * in.copy before */
+			skb_copy_bits(skb, tcp_conn->in.offset,
+				&tcp_conn->hdr, tcp_conn->hdr_size);
+			tcp_conn->in.hdr = &tcp_conn->hdr;
+		}
+		tcp_conn->in.offset += tcp_conn->hdr_size;
+		tcp_conn->in.copy -= tcp_conn->hdr_size;
+	} else {
+		int hdr_remains;
+		int copylen;
+
+		/*
+		 * PDU header scattered across SKB's,
+		 * copying it... This'll happen quite rarely.
+		 */
+
+		if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
+			tcp_conn->in.hdr_offset = 0;
+
+		hdr_remains = tcp_conn->hdr_size - tcp_conn->in.hdr_offset;
+		BUG_ON(hdr_remains <= 0);
+
+		copylen = min(tcp_conn->in.copy, hdr_remains);
+		skb_copy_bits(skb, tcp_conn->in.offset,
+			(char*)&tcp_conn->hdr + tcp_conn->in.hdr_offset,
+			copylen);
+
+		dprintk("PDU gather offset %d bytes %d in.offset %d "
+			"in.copy %d\n", tcp_conn->in.hdr_offset, copylen,
+			tcp_conn->in.offset, tcp_conn->in.copy);
+
+		tcp_conn->in.offset += copylen;
+		tcp_conn->in.copy -= copylen;
+		if (copylen < hdr_remains)  {
+			tcp_conn->in_progress = IN_PROGRESS_HEADER_GATHER;
+			tcp_conn->in.hdr_offset += copylen;
+		        return -EAGAIN;
+		}
+		tcp_conn->in.hdr = &tcp_conn->hdr;
+		tcp_conn->discontiguous_hdr_cnt++;
+	        tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	return 0;
+}
+
+static int
+iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
+		unsigned int offset, size_t len)
+{
+	int rc;
+	struct iscsi_conn *conn = rd_desc->arg.data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int processed;
+	char pad[ISCSI_PAD_LEN];
+	struct scatterlist sg;
+
+	/*
+	 * Save current SKB and its offset in the corresponding
+	 * connection context.
+	 */
+	tcp_conn->in.copy = skb->len - offset;
+	tcp_conn->in.offset = offset;
+	tcp_conn->in.skb = skb;
+	tcp_conn->in.len = tcp_conn->in.copy;
+	BUG_ON(tcp_conn->in.copy <= 0);
+	dprintk("in %d bytes\n", tcp_conn->in.copy);
+
+more:
+	tcp_conn->in.copied = 0;
+	rc = 0;
+
+	if (unlikely(conn->suspend_rx)) {
+		dprintk("conn %d Rx suspended!\n", conn->id);
+		return 0;
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER ||
+	    tcp_conn->in_progress == IN_PROGRESS_HEADER_GATHER) {
+		rc = iscsi_hdr_extract(tcp_conn);
+		if (rc) {
+		       if (rc == -EAGAIN)
+				goto nomore;
+		       else {
+				iscsi_conn_failure(conn, rc);
+				return 0;
+		       }
+		}
+
+		/*
+		 * Verify and process incoming PDU header.
+		 */
+		rc = iscsi_tcp_hdr_recv(conn);
+		if (!rc && tcp_conn->in.datalen) {
+			if (conn->datadgst_en) {
+				BUG_ON(!tcp_conn->data_rx_tfm);
+				crypto_digest_init(tcp_conn->data_rx_tfm);
+			}
+			tcp_conn->in_progress = IN_PROGRESS_DATA_RECV;
+		} else if (rc) {
+			iscsi_conn_failure(conn, rc);
+			return 0;
+		}
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
+		uint32_t recv_digest;
+
+		dprintk("extra data_recv offset %d copy %d\n",
+			  tcp_conn->in.offset, tcp_conn->in.copy);
+		skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+				&recv_digest, 4);
+		tcp_conn->in.offset += 4;
+		tcp_conn->in.copy -= 4;
+		if (recv_digest != tcp_conn->in.datadgst) {
+			dprintk("iscsi_tcp: data digest error!"
+				  "0x%x != 0x%x\n", recv_digest,
+				  tcp_conn->in.datadgst);
+			iscsi_conn_failure(conn, ISCSI_ERR_DATA_DGST);
+			return 0;
+		} else {
+			dprintk("iscsi_tcp: data digest match!"
+				  "0x%x == 0x%x\n", recv_digest,
+				  tcp_conn->in.datadgst);
+			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+		}
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_DATA_RECV &&
+	   tcp_conn->in.copy) {
+
+		dprintk("data_recv offset %d copy %d\n",
+		       tcp_conn->in.offset, tcp_conn->in.copy);
+
+		rc = iscsi_data_recv(conn);
+		if (rc) {
+			if (rc == -EAGAIN)
+				goto again;
+			iscsi_conn_failure(conn, rc);
+			return 0;
+		}
+		tcp_conn->in.copy -= tcp_conn->in.padding;
+		tcp_conn->in.offset += tcp_conn->in.padding;
+		if (conn->datadgst_en) {
+			if (tcp_conn->in.padding) {
+				dprintk("padding -> %d\n",
+					  tcp_conn->in.padding);
+				memset(pad, 0, tcp_conn->in.padding);
+				sg_init_one(&sg, pad, tcp_conn->in.padding);
+				crypto_digest_update(tcp_conn->data_rx_tfm,
+						     &sg, 1);
+			}
+			crypto_digest_final(tcp_conn->data_rx_tfm,
+					    (u8 *) & tcp_conn->in.datadgst);
+			dprintk("rx digest 0x%x\n", tcp_conn->in.datadgst);
+			tcp_conn->in_progress = IN_PROGRESS_DDIGEST_RECV;
+		} else
+			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	dprintk("f, processed %d from out of %d padding %d\n",
+	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
+	BUG_ON(tcp_conn->in.offset - offset > len);
+
+	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
+		;
+
+	if (tcp_conn->in.offset - offset != len) {
+		dprintk("continue to process %d bytes\n",
+		       (int)len - (tcp_conn->in.offset - offset));
+		goto more;
+	}
+
+nomore:
+	processed = tcp_conn->in.offset - offset;
+	BUG_ON(processed == 0);
+	return processed;
+
+again:
+	processed = tcp_conn->in.offset - offset;
+	dprintk("c, processed %d from out of %d rd_desc_cnt %d\n",
+	          processed, (int)len, (int)rd_desc->count);
+	BUG_ON(processed == 0);
+	BUG_ON(processed > len);
+
+	conn->rxdata_octets += processed;
+	return processed;
+}
+
+static void
+iscsi_tcp_data_ready(struct sock *sk, int flag)
+{
+	struct iscsi_conn *conn = sk->sk_user_data;
+	read_descriptor_t rd_desc;
+
+	read_lock(&sk->sk_callback_lock);
+
+	/* use rd_desc to pass 'conn' to iscsi_tcp_data_recv */
+	rd_desc.arg.data = conn;
+	rd_desc.count = 1;
+	tcp_read_sock(sk, &rd_desc, iscsi_tcp_data_recv);
+
+	read_unlock(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_tcp_state_change(struct sock *sk)
+{
+	struct iscsi_tcp_conn *tcp_conn;
+	struct iscsi_conn *conn;
+	struct iscsi_session *session;
+	void (*old_state_change)(struct sock *);
+
+	read_lock(&sk->sk_callback_lock);
+
+	conn = (struct iscsi_conn*)sk->sk_user_data;
+	session = conn->session;
+
+	if ((sk->sk_state == TCP_CLOSE_WAIT ||
+	     sk->sk_state == TCP_CLOSE) &&
+	    !atomic_read(&sk->sk_rmem_alloc)) {
+		dprintk("iscsi_tcp_state_change: TCP_CLOSE|TCP_CLOSE_WAIT\n");
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+	}
+
+	tcp_conn = conn->dd_data;
+	old_state_change = tcp_conn->old_state_change;
+
+	read_unlock(&sk->sk_callback_lock);
+
+	old_state_change(sk);
+}
+
+static void
+iscsi_write_space(struct sock *sk)
+{
+	struct iscsi_conn *conn = (struct iscsi_conn*)sk->sk_user_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	tcp_conn->old_write_space(sk);
+	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	scsi_queue_work(conn->session->host, &conn->xmitwork);
+}
+
+static void
+iscsi_conn_set_callbacks(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk = tcp_conn->sock->sk;
+
+	/* assign new callbacks */
+	write_lock_bh(&sk->sk_callback_lock);
+	sk->sk_user_data = conn;
+	tcp_conn->old_data_ready = sk->sk_data_ready;
+	tcp_conn->old_state_change = sk->sk_state_change;
+	tcp_conn->old_write_space = sk->sk_write_space;
+	sk->sk_data_ready = iscsi_tcp_data_ready;
+	sk->sk_state_change = iscsi_tcp_state_change;
+	sk->sk_write_space = iscsi_write_space;
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_conn_restore_callbacks(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk = tcp_conn->sock->sk;
+
+	/* restore socket callbacks, see also: iscsi_conn_set_callbacks() */
+	write_lock_bh(&sk->sk_callback_lock);
+	sk->sk_user_data    = NULL;
+	sk->sk_data_ready   = tcp_conn->old_data_ready;
+	sk->sk_state_change = tcp_conn->old_state_change;
+	sk->sk_write_space  = tcp_conn->old_write_space;
+	sk->sk_no_check	 = 0;
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_tcp_terminate_conn(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	if (!tcp_conn->sock)
+		return;
+
+	sock_hold(tcp_conn->sock->sk);
+	iscsi_conn_restore_callbacks(conn);
+	sock_put(tcp_conn->sock->sk);
+
+	sock_release(tcp_conn->sock);
+	tcp_conn->sock = NULL;
+	conn->recv_lock = NULL;
+}
+
+static int
+iscsi_r2tpool_alloc(struct iscsi_session *session)
+{
+	int i;
+	int cmd_i;
+
+	/*
+	 * initialize per-task: R2T pool and xmit queue
+	 */
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+	        struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		/*
+		 * pre-allocated x4 as much r2ts to handle race when
+		 * target acks DataOut faster than we data_xmit() queues
+		 * could replenish r2tqueue.
+		 */
+
+		/* R2T pool */
+		if (iscsi_pool_init(&tcp_ctask->r2tpool, session->max_r2t * 4,
+				    (void***)&tcp_ctask->r2ts,
+				    sizeof(struct iscsi_r2t_info))) {
+			goto r2t_alloc_fail;
+		}
+
+		/* R2T xmit queue */
+		tcp_ctask->r2tqueue = kfifo_alloc(
+		      session->max_r2t * 4 * sizeof(void*), GFP_KERNEL, NULL);
+		if (tcp_ctask->r2tqueue == ERR_PTR(-ENOMEM)) {
+			iscsi_pool_free(&tcp_ctask->r2tpool,
+					(void**)tcp_ctask->r2ts);
+			goto r2t_alloc_fail;
+		}
+
+		/*
+		 * number of
+		 * Data-Out PDU's within R2T-sequence can be quite big;
+		 * using mempool
+		 */
+		tcp_ctask->datapool = mempool_create(ISCSI_DTASK_DEFAULT_MAX,
+						     mempool_alloc_slab,
+						     mempool_free_slab,
+						     taskcache);
+		if (tcp_ctask->datapool == NULL) {
+			kfifo_free(tcp_ctask->r2tqueue);
+			iscsi_pool_free(&tcp_ctask->r2tpool,
+					(void**)tcp_ctask->r2ts);
+			goto r2t_alloc_fail;
+		}
+		INIT_LIST_HEAD(&tcp_ctask->dataqueue);
+	}
+
+	return 0;
+
+r2t_alloc_fail:
+	for (i = 0; i < cmd_i; i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		mempool_destroy(tcp_ctask->datapool);
+		kfifo_free(tcp_ctask->r2tqueue);
+		iscsi_pool_free(&tcp_ctask->r2tpool,
+				(void**)tcp_ctask->r2ts);
+	}
+	return -ENOMEM;
+}
+
+static void
+iscsi_r2tpool_free(struct iscsi_session *session)
+{
+	int i;
+
+	for (i = 0; i < session->cmds_max; i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		mempool_destroy(tcp_ctask->datapool);
+		kfifo_free(tcp_ctask->r2tqueue);
+		iscsi_pool_free(&tcp_ctask->r2tpool,
+				(void**)tcp_ctask->r2ts);
+	}
+}
+
+static struct iscsi_cls_session *
+istgt_tcp_session_create(struct iscsi_transport *iscsit,
+			 struct scsi_transport_template *scsit,
+			 uint32_t initial_cmdsn, uint32_t *hostno)
+{
+	struct Scsi_Host *shost;
+	struct iscsi_cls_session *cls_session;
+	struct iscsi_session *session;
+	uint32_t hn;
+	int err, i;
+
+	cls_session = iscsi_session_setup(iscsit, scsit,
+					 sizeof(struct iscsi_tcp_cmd_task),
+					 sizeof(struct iscsi_tcp_mgmt_task),
+					 initial_cmdsn, &hn);
+	if (!cls_session)
+		return NULL;
+	shost = iscsi_session_to_shost(cls_session);
+	err = scsi_tgt_alloc_queue(shost);
+	if (err)
+		goto session_free;
+	*hostno = hn;
+
+	session = class_to_transport_session(cls_session);
+	for (i = 0; i < initial_cmdsn; i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		ctask->hdr = &tcp_ctask->hdr;
+	}
+
+	for (i = 0; i < session->mgmtpool_max; i++) {
+		struct iscsi_mgmt_task *mtask = session->mgmt_cmds[i];
+		struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
+
+		mtask->hdr = &tcp_mtask->hdr;
+	}
+
+	if (iscsi_r2tpool_alloc(class_to_transport_session(cls_session)))
+		goto session_free;
+
+	return cls_session;
+session_free:
+	iscsi_session_teardown(cls_session);
+	return NULL;
+}
+
+static void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
+{
+	struct iscsi_session *session = class_to_transport_session(cls_session);
+	struct iscsi_data_task *dtask, *n;
+	int cmd_i;
+
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		list_for_each_entry_safe(dtask, n, &tcp_ctask->dataqueue,
+					 item) {
+			list_del(&dtask->item);
+			mempool_free(dtask, tcp_ctask->datapool);
+		}
+	}
+
+	iscsi_r2tpool_free(class_to_transport_session(cls_session));
+	iscsi_session_teardown(cls_session);
+}
+
+static struct iscsi_cls_conn *
+iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
+{
+	struct iscsi_conn *conn;
+	struct iscsi_cls_conn *cls_conn;
+	struct iscsi_tcp_conn *tcp_conn;
+
+	cls_conn = iscsi_conn_setup(cls_session, conn_idx);
+	if (!cls_conn)
+		return NULL;
+	conn = cls_conn->dd_data;
+	/*
+	 * due to strange issues with iser these are not set
+	 * in iscsi_conn_setup
+	 */
+	conn->max_recv_dlength = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+
+	tcp_conn = kzalloc(sizeof(*tcp_conn), GFP_KERNEL);
+	if (!tcp_conn)
+		goto tcp_conn_alloc_fail;
+
+	conn->dd_data = tcp_conn;
+	tcp_conn->iscsi_conn = conn;
+	tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	/* initial operational parameters */
+	tcp_conn->hdr_size = sizeof(struct iscsi_hdr);
+	tcp_conn->data_size = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+
+	/* allocate initial PDU receive place holder */
+	if (tcp_conn->data_size <= PAGE_SIZE)
+		tcp_conn->data = kmalloc(tcp_conn->data_size, GFP_KERNEL);
+	else
+		tcp_conn->data = (void*)__get_free_pages(GFP_KERNEL,
+					get_order(tcp_conn->data_size));
+	if (!tcp_conn->data)
+		goto max_recv_dlenght_alloc_fail;
+
+	return cls_conn;
+
+max_recv_dlenght_alloc_fail:
+	kfree(tcp_conn);
+tcp_conn_alloc_fail:
+	iscsi_conn_teardown(cls_conn);
+	return NULL;
+}
+
+static void
+iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int digest = 0;
+
+	if (conn->hdrdgst_en || conn->datadgst_en)
+		digest = 1;
+
+	iscsi_conn_teardown(cls_conn);
+
+	/* now free tcp_conn */
+	if (digest) {
+		if (tcp_conn->tx_tfm)
+			crypto_free_tfm(tcp_conn->tx_tfm);
+		if (tcp_conn->rx_tfm)
+			crypto_free_tfm(tcp_conn->rx_tfm);
+		if (tcp_conn->data_tx_tfm)
+			crypto_free_tfm(tcp_conn->data_tx_tfm);
+		if (tcp_conn->data_rx_tfm)
+			crypto_free_tfm(tcp_conn->data_rx_tfm);
+	}
+
+	/* free conn->data, size = MaxRecvDataSegmentLength */
+	if (tcp_conn->data_size <= PAGE_SIZE)
+		kfree(tcp_conn->data);
+	else
+		free_pages((unsigned long)tcp_conn->data,
+			   get_order(tcp_conn->data_size));
+	kfree(tcp_conn);
+}
+
+static int
+iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
+		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
+		    int is_leading)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk;
+	struct socket *sock;
+	int err;
+
+	/* lookup for existing socket */
+	sock = sockfd_lookup((int)transport_eph, &err);
+	if (!sock) {
+		printk(KERN_ERR "iscsi_tcp: sockfd_lookup failed %d\n", err);
+		return -EEXIST;
+	}
+
+	err = iscsi_conn_bind(cls_session, cls_conn, is_leading);
+	if (err)
+		return err;
+
+	if (conn->stop_stage != STOP_CONN_SUSPEND) {
+		/* bind iSCSI connection and socket */
+		tcp_conn->sock = sock;
+
+		/* setup Socket parameters */
+		sk = sock->sk;
+		sk->sk_reuse = 1;
+		sk->sk_sndtimeo = 15 * HZ; /* FIXME: make it configurable */
+		sk->sk_allocation = GFP_ATOMIC;
+
+		/* FIXME: disable Nagle's algorithm */
+
+		/*
+		 * Intercept TCP callbacks for sendfile like receive
+		 * processing.
+		 */
+		conn->recv_lock = &sk->sk_callback_lock;
+		iscsi_conn_set_callbacks(conn);
+		tcp_conn->sendpage = tcp_conn->sock->ops->sendpage;
+		/*
+		 * set receive state machine into initial state
+		 */
+		tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	return 0;
+}
+
+static int istgt_tcp_eh_abort_handler(struct scsi_cmnd *scmd)
+{
+	BUG();
+	return 0;
+}
+
+#define	DEFAULT_NR_QUEUED_CMNDS	32
+#define TGT_NAME "istgt_tcp"
+
+static struct scsi_host_template istgt_tcp_sht = {
+	.name			= TGT_NAME,
+	.module			= THIS_MODULE,
+	.can_queue		= DEFAULT_NR_QUEUED_CMNDS,
+	.sg_tablesize		= SG_ALL,
+	.max_sectors		= 65535,
+	.use_clustering		= DISABLE_CLUSTERING,
+/* 	.transfer_response	= scsi_cmnd_done, */
+/* 	.transfer_data		= buffer_ready, */
+	.eh_abort_handler	= istgt_tcp_eh_abort_handler,
+};
+
+static struct iscsi_transport istgt_tcp_transport = {
+	.owner			= THIS_MODULE,
+	.name			= TGT_NAME,
+	.host_template		= &istgt_tcp_sht,
+	.conndata_size		= sizeof(struct iscsi_conn),
+	.max_conn		= 1,
+	.max_cmd_len		= ISCSI_TCP_MAX_CMD_LEN,
+	.create_session		= istgt_tcp_session_create,
+	.destroy_session	= iscsi_tcp_session_destroy,
+	.create_conn		= iscsi_tcp_conn_create,
+	.destroy_conn		= iscsi_tcp_conn_destroy,
+	.bind_conn		= iscsi_tcp_conn_bind,
+	.start_conn		= iscsi_conn_start,
+	.terminate_conn		= iscsi_tcp_terminate_conn,
+};
+
+static int __init istgt_tcp_init(void)
+{
+	printk("iSCSI Target over TCP\n");
+
+	taskcache = kmem_cache_create("istgt_taskcache",
+				      sizeof(struct iscsi_data_task), 0,
+				      SLAB_HWCACHE_ALIGN, NULL, NULL);
+	if (!taskcache)
+		return -ENOMEM;
+
+	if (!iscsi_register_transport(&istgt_tcp_transport))
+		goto free_taskcache;
+	return 0;
+free_taskcache:
+	kmem_cache_destroy(taskcache);
+	return -ENOMEM;
+}
+
+static void __exit istgt_tcp_exit(void)
+{
+	iscsi_unregister_transport(&istgt_tcp_transport);
+	kmem_cache_destroy(taskcache);
+}
+
+module_init(istgt_tcp_init);
+module_exit(istgt_tcp_exit);
+
+MODULE_DESCRIPTION("iSCSI target over TCP");
+MODULE_LICENSE("GPL");



From tomo at berlios.de  Sat Apr 29 15:19:06 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 15:19:06 +0200
Subject: [Stgt-svn] r428 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291319.k3TDJ6s6000386@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 15:19:04 +0200 (Sat, 29 Apr 2006)
New Revision: 428

Modified:
   branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
Log:
Updated istgt_tcp, though it's still completely broken.


Modified: branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-28 11:46:09 UTC (rev 427)
+++ branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-29 13:19:04 UTC (rev 428)
@@ -52,25 +52,46 @@
 #define dprintk eprintk
 
 struct istgt_session {
-	struct list_head pending_list;
+	struct list_head recvlist;
+	/* replace with array later on */
+	struct list_head cmd_hash;
+	spinlock_t slock;
+	struct work_struct recvwork;
 };
 
+struct istgt_task {
+	struct list_head hash;
+	struct list_head tlist;
+};
+
 static kmem_cache_t *taskcache;
 
+static inline struct istgt_task *ctask_to_ttask(struct iscsi_cmd_task *ctask)
+{
+	return (struct istgt_task *) ((void *) ctask->dd_data +
+				      sizeof(struct iscsi_tcp_cmd_task));
+}
+
+static inline struct iscsi_cmd_task *ttask_to_ctask(struct istgt_task *ttask)
+{
+	return (struct iscsi_cmd_task *)
+		((void *) ttask - sizeof(struct iscsi_tcp_cmd_task));
+}
+
 static void build_r2t(struct iscsi_cmd_task *ctask)
 {
 	struct iscsi_r2t_rsp *hdr;
 	struct iscsi_data_task *dtask;
 	struct iscsi_r2t_info *r2t;
-	struct iscsi_session *session = ctask->conn->session;
+/* 	struct iscsi_session *session = ctask->conn->session; */
 	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-	struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data;
+/* 	struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data; */
 	int rc;
 
 /* 	length = req->r2t_length; */
 /* 	burst = req->conn->session->param.max_burst_length; */
 /* 	offset = be32_to_cpu(cmd_hdr(req)->data_length) - length; */
-more:
+/* more: */
 	rc = __kfifo_get(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
 	BUG_ON(!rc);
 
@@ -115,7 +136,7 @@
 static void istgt_scsi_tgt_queue_command(struct iscsi_cmd_task *ctask)
 {
 	struct iscsi_session *session = ctask->conn->session;
-	struct iscsi_cls_session *cls_session;
+	struct iscsi_cls_session *cls_session = session_to_cls(session);
 	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
 	struct iscsi_cmd *hdr = ctask->hdr;
 	struct scsi_cmnd *scmd;
@@ -222,56 +243,78 @@
 	}
 }
 
-static void istgt_ctask_add(struct iscsi_cmd_task *ctask)
+static void istgt_recvworker(void *data)
 {
-	struct iscsi_session *session = ctask->conn->session;
-	struct iscsi_cls_session *cls_session;
-	struct istgt_session *sess;
-	struct iscsi_cmd *hdr = ctask->hdr;
-	struct list_head *entry;
-	uint32_t cmdsn;
+	struct iscsi_cls_session *cls_session = data;
+	struct iscsi_session *session =
+		class_to_transport_session(cls_session);
+	struct istgt_session *istgt_session =
+		(struct istgt_session *) cls_session->dd_data;
+	struct iscsi_cmd_task *ctask;
+	struct istgt_task *pos;
 
-	sess = (struct istgt_session *) cls_session->dd_data;
+retry:
+	spin_lock_bh(&istgt_session->slock);
 
-	if (hdr->opcode & ISCSI_OP_IMMEDIATE) {
+	while (istgt_session->recvlist.next) {
+		pos = list_entry(istgt_session->recvlist.next,
+				 struct istgt_task, tlist);
+		ctask = ttask_to_ctask(pos);
+		if (ctask->hdr->cmdsn != session->exp_cmdsn)
+			break;
+
+		list_del(&pos->tlist);
+		session->exp_cmdsn++;
+
+		spin_unlock_bh(&istgt_session->slock);
 		istgt_cmd_exec(ctask);
-		return;
+		goto retry;
 	}
 
-	cmdsn = hdr->cmdsn;
-	if (cmdsn == session->exp_cmdsn) {
-		session->exp_cmdsn = ++cmdsn;
-		istgt_cmd_exec(ctask);
+	spin_unlock_bh(&istgt_session->slock);
+}
 
-		if (list_empty(&sess->pending_list))
-			return;
-		ctask = list_entry(sess->pending_list.next,
-				   struct iscsi_cmd_task, running);
-		if (ctask->hdr->cmdsn != cmdsn)
-			return;
-		list_del_init(&ctask->running);
-	} else {
-/* 		set_cmd_pending(cmnd); */
-		if (before(cmdsn, session->exp_cmdsn)) /* close the conn */
-			eprintk("unexpected cmd_sn (%u,%u)\n", cmdsn, session->exp_cmdsn);
+static void istgt_ctask_recvlist_add(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_session *session = ctask->conn->session;
+	struct iscsi_cls_session *cls_session = session_to_cls(session);
+	struct istgt_session *istgt_session;
+	struct istgt_task *pos;
 
-/* 		if (after(cmdsn, session->exp_cmdsn + session->max_queued_cmnds)) */
-/* 			eprintk("too large cmd_sn (%u,%u)\n", cmd_sn, session->exp_cmd_sn); */
+	istgt_session = (struct istgt_session *) cls_session->dd_data;
 
-		list_for_each(entry, &sess->pending_list) {
-			struct iscsi_cmd_task *tmp;
-			tmp = list_entry(entry, struct iscsi_cmd_task, running);
-			if (before(cmdsn, tmp->hdr->cmdsn))
-				break;
-		}
+	spin_lock_bh(&istgt_session->slock);
 
-		BUG_ON(!list_empty(&ctask->running));
+	if (ctask->hdr->opcode & ISCSI_OP_IMMEDIATE) {
+		list_add(&ctask_to_ttask(ctask)->tlist,
+			 &istgt_session->recvlist);
+		goto out;
+	}
 
-		list_add_tail(&ctask->running, entry);
-	}
+	list_for_each_entry(pos, &istgt_session->recvlist, tlist)
+		if (before(ctask->hdr->cmdsn, ttask_to_ctask(pos)->hdr->cmdsn))
+			break;
+
+	list_add_tail(&ctask_to_ttask(ctask)->tlist, &pos->tlist);
+out:
+	spin_unlock_bh(&istgt_session->slock);
 }
 
+static int
+istgt_tcp_ctask_xmit(struct iscsi_conn *conn, struct iscsi_mgmt_task *mtask)
+{
+	return 0;
+}
 
+static void istgt_unsolicited_data(struct iscsi_cmd_task *ctask)
+{
+/* 	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data; */
+
+	istgt_scsi_tgt_queue_command(ctask);
+/* 	tcp_ctask->r2t_data_count; */
+/* 	ctask->r2t_data_count; */
+}
+
 /*
  * the followings are taken from iscsi_tcp.
  */
@@ -281,10 +324,13 @@
 	int rc = 0, opcode, ahslen;
 	struct iscsi_hdr *hdr;
 	struct iscsi_session *session = conn->session;
+	struct iscsi_cls_session *cls_session = session_to_cls(session);
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct Scsi_Host *shost;
 	uint32_t cdgst, rdgst = 0;
 	struct iscsi_cmd_task *ctask = NULL;
 
+	shost = iscsi_session_to_shost(cls_session);
 	hdr = tcp_conn->in.hdr;
 
 	/* verify PDU length */
@@ -328,48 +374,196 @@
 		}
 	}
 
-	__kfifo_get(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
-	ctask->conn = conn;
-	INIT_LIST_HEAD(&ctask->running);
-	memcpy(ctask->hdr, hdr, sizeof(*hdr));
-
 	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
-
 	dprintk("opcode 0x%x offset %d copy %d ahslen %d datalen %d\n",
 		opcode, tcp_conn->in.offset, tcp_conn->in.copy,
 		ahslen, tcp_conn->in.datalen);
 
-	switch(opcode) {
+	switch (opcode) {
 	case ISCSI_OP_NOOP_OUT:
-		/* TODO */
-		BUG();
-		break;
 	case ISCSI_OP_SCSI_CMD:
-/* 		if (!(err = cmnd_insert_hash(cmnd))) */
-/* 			scsi_cmnd_start(conn, cmnd); */
-		break;
 	case ISCSI_OP_SCSI_TMFUNC:
-		/* TODO */
-		BUG();
+	case ISCSI_OP_LOGOUT:
+		__kfifo_get(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
+		ctask->conn = conn;
+		memcpy(ctask->hdr, hdr, sizeof(*hdr));
+		if (opcode == ISCSI_OP_SCSI_CMD)
+			switch (ctask->hdr->cdb[0]) {
+			case WRITE_6:
+			case WRITE_10:
+			case WRITE_16:
+			case WRITE_VERIFY:
+				istgt_unsolicited_data(ctask);
+				set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
+			}
 		break;
 	case ISCSI_OP_SCSI_DATA_OUT:
-/* 		data_out_start(conn, cmnd); */
+		/* Find a command in the hash list */
+		/* data_out_start(conn, cmnd); */
 		break;
-	case ISCSI_OP_LOGOUT:
-/* 		err = cmnd_insert_hash(cmnd); */
-		break;
 	case ISCSI_OP_TEXT:
 	case ISCSI_OP_SNACK:
-		rc = -ISCSI_REASON_CMD_NOT_SUPPORTED;
-		break;
 	default:
-		rc = -ISCSI_REASON_CMD_NOT_SUPPORTED;
-		break;
+		rc = ISCSI_ERR_BAD_OPCODE;
 	}
 
+	if (ctask)
+		tcp_conn->in.ctask = ctask;
 	return rc;
 }
 
+static inline int
+iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn)
+{
+	void *buf = tcp_conn->data;
+	int buf_size = tcp_conn->in.datalen;
+	int buf_left = buf_size - tcp_conn->data_copied;
+	int size = min(tcp_conn->in.copy, buf_left);
+	int rc;
+
+	dprintk("tcp_copy %d bytes at offset %d copied %d\n",
+		size, tcp_conn->in.offset, tcp_conn->data_copied);
+	BUG_ON(size <= 0);
+
+	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+			   (char*)buf + tcp_conn->data_copied, size);
+	BUG_ON(rc);
+
+	tcp_conn->in.offset += size;
+	tcp_conn->in.copy -= size;
+	tcp_conn->in.copied += size;
+	tcp_conn->data_copied += size;
+
+	if (buf_size != tcp_conn->data_copied)
+		return -EAGAIN;
+
+	return 0;
+}
+
+static inline void
+partial_sg_digest_update(struct iscsi_tcp_conn *tcp_conn,
+			 struct scatterlist *sg, int offset, int length)
+{
+	struct scatterlist temp;
+
+	memcpy(&temp, sg, sizeof(struct scatterlist));
+	temp.offset = offset;
+	temp.length = length;
+	crypto_digest_update(tcp_conn->data_rx_tfm, &temp, 1);
+}
+
+static inline int
+iscsi_ctask_copy(struct iscsi_tcp_conn *tcp_conn, struct iscsi_cmd_task *ctask,
+		 void *buf, int buf_size, int offset)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	int buf_left = buf_size - (tcp_conn->data_copied + offset);
+	int size = min(tcp_conn->in.copy, buf_left);
+	int rc;
+
+	size = min(size, ctask->data_count);
+
+	dprintk("ctask_copy %d bytes at offset %d copied %d\n",
+		size, tcp_conn->in.offset, tcp_conn->in.copied);
+
+	BUG_ON(size <= 0);
+	BUG_ON(tcp_ctask->sent + size > ctask->total_length);
+
+	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+			   (char*)buf + (offset + tcp_conn->data_copied), size);
+	/* must fit into skb->len */
+	BUG_ON(rc);
+
+	tcp_conn->in.offset += size;
+	tcp_conn->in.copy -= size;
+	tcp_conn->in.copied += size;
+	tcp_conn->data_copied += size;
+	tcp_ctask->sent += size;
+	ctask->data_count -= size;
+
+	BUG_ON(tcp_conn->in.copy < 0);
+	BUG_ON(ctask->data_count < 0);
+
+	if (buf_size != (tcp_conn->data_copied + offset)) {
+		if (!ctask->data_count) {
+			BUG_ON(buf_size - tcp_conn->data_copied < 0);
+			/* done with this PDU */
+			return buf_size - tcp_conn->data_copied;
+		}
+		return -EAGAIN;
+	}
+
+	/* done with this buffer or with both - PDU and buffer */
+	tcp_conn->data_copied = 0;
+	return 0;
+}
+
+static int iscsi_scsi_data_in(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_cmd_task *ctask = tcp_conn->in.ctask;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct scsi_cmnd *sc = ctask->sc;
+	struct scatterlist *sg;
+	int i, offset, rc = 0;
+
+	BUG_ON((void*)ctask != sc->SCp.ptr);
+
+	offset = tcp_ctask->data_offset;
+	sg = sc->request_buffer;
+
+	if (tcp_ctask->data_offset)
+		for (i = 0; i < tcp_ctask->sg_count; i++)
+			offset -= sg[i].length;
+	/* we've passed through partial sg*/
+	if (offset < 0)
+		offset = 0;
+
+	for (i = tcp_ctask->sg_count; i < sc->use_sg; i++) {
+		char *dest;
+
+		dest = kmap_atomic(sg[i].page, KM_SOFTIRQ0);
+		rc = iscsi_ctask_copy(tcp_conn, ctask, dest + sg[i].offset,
+				      sg[i].length, offset);
+		kunmap_atomic(dest, KM_SOFTIRQ0);
+		if (rc == -EAGAIN)
+			/* continue with the next SKB/PDU */
+			return rc;
+		if (!rc) {
+			if (conn->datadgst_en) {
+				if (!offset)
+					crypto_digest_update(
+							tcp_conn->data_rx_tfm,
+							&sg[i], 1);
+				else
+					partial_sg_digest_update(tcp_conn,
+							&sg[i],
+							sg[i].offset + offset,
+							sg[i].length - offset);
+			}
+			offset = 0;
+			tcp_ctask->sg_count++;
+		}
+
+		if (!ctask->data_count) {
+			if (rc && conn->datadgst_en)
+				/*
+				 * data-in is complete, but buffer not...
+				 */
+				partial_sg_digest_update(tcp_conn, &sg[i],
+						sg[i].offset, sg[i].length-rc);
+			rc = 0;
+			break;
+		}
+
+		if (!tcp_conn->in.copy)
+			return -EAGAIN;
+	}
+	BUG_ON(ctask->data_count);
+
+	return rc;
+}
+
 static int
 iscsi_data_recv(struct iscsi_conn *conn)
 {
@@ -379,9 +573,8 @@
 	opcode = tcp_conn->in.hdr->opcode & ISCSI_OPCODE_MASK;
 	switch (opcode) {
 	case ISCSI_OP_SCSI_CMD:
-		break;
 	case ISCSI_OP_SCSI_DATA_OUT:
-		/* READ DATAT */
+		iscsi_scsi_data_in(conn);
 		break;
 	case ISCSI_OP_TEXT:
 	case ISCSI_OP_LOGOUT:
@@ -534,6 +727,9 @@
 		}
 	}
 
+	if (unlikely(conn->suspend_rx))
+		goto nomore;
+
 	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
 		uint32_t recv_digest;
 
@@ -594,8 +790,17 @@
 	BUG_ON(tcp_conn->in.offset - offset > len);
 
 	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
-		;
+		if (tcp_conn->in.ctask) {
+			struct iscsi_cls_session *cls_session =
+				session_to_cls(conn->session);
+			struct istgt_session *istgt_session =
+				cls_session->dd_data;
 
+			istgt_ctask_recvlist_add(tcp_conn->in.ctask);
+			tcp_conn->in.ctask = NULL;
+			schedule_work(&istgt_session->recvwork);
+		}
+
 	if (tcp_conn->in.offset - offset != len) {
 		dprintk("continue to process %d bytes\n",
 		       (int)len - (tcp_conn->in.offset - offset));
@@ -808,6 +1013,18 @@
 	}
 }
 
+void istgt_session_init(struct iscsi_cls_session *cls_session)
+{
+	struct istgt_session *istgt_session =
+		(struct istgt_session *) cls_session->dd_data;
+
+	INIT_LIST_HEAD(&istgt_session->recvlist);
+	INIT_LIST_HEAD(&istgt_session->cmd_hash);
+	spin_lock_init(&istgt_session->slock);
+
+	INIT_WORK(&istgt_session->recvwork, istgt_recvworker, cls_session);
+}
+
 static struct iscsi_cls_session *
 istgt_tcp_session_create(struct iscsi_transport *iscsit,
 			 struct scsi_transport_template *scsit,
@@ -818,11 +1035,15 @@
 	struct iscsi_session *session;
 	uint32_t hn;
 	int err, i;
+	int cmd_task_size;
 
+	cmd_task_size = sizeof(struct iscsi_tcp_cmd_task) +
+		sizeof(struct istgt_task);
+
 	cls_session = iscsi_session_setup(iscsit, scsit,
-					 sizeof(struct iscsi_tcp_cmd_task),
-					 sizeof(struct iscsi_tcp_mgmt_task),
-					 initial_cmdsn, &hn);
+					  cmd_task_size,
+					  sizeof(struct iscsi_tcp_mgmt_task),
+					  initial_cmdsn, &hn);
 	if (!cls_session)
 		return NULL;
 	shost = iscsi_session_to_shost(cls_session);
@@ -837,6 +1058,9 @@
 		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
 
 		ctask->hdr = &tcp_ctask->hdr;
+
+		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->hash);
+		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->tlist);
 	}
 
 	for (i = 0; i < session->mgmtpool_max; i++) {
@@ -1005,6 +1229,44 @@
 	return 0;
 }
 
+static int istgt_transfer_response(struct scsi_cmnd *scmd,
+				   void (*done)(struct scsi_cmnd *))
+{
+	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *) scmd->SCp.ptr;
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_cls_session *cls_session = session_to_cls(conn->session);
+	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
+
+	__kfifo_put(conn->xmitqueue, (void*)&ctask, sizeof(void*));
+	scsi_queue_work(shost, &conn->xmitwork);
+
+	return 0;
+}
+
+static int istgt_transfer_data(struct scsi_cmnd *scmd,
+				  void (*done)(struct scsi_cmnd *))
+{
+	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *) scmd->SCp.ptr;
+
+	if (scmd->sc_data_direction == DMA_TO_DEVICE) {
+		struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data;
+		struct sock *sk = tcp_conn->sock->sk;
+
+		/* FIXME: too hacky */
+		bh_lock_sock(sk);
+
+		if (tcp_conn->in.ctask == ctask) {
+			clear_bit(ISCSI_SUSPEND_BIT, &ctask->conn->suspend_rx);
+			sk->sk_data_ready(sk, 0);
+		}
+
+		bh_unlock_sock(sk);
+	}
+	done(scmd);
+
+	return 0;
+}
+
 static int istgt_tcp_eh_abort_handler(struct scsi_cmnd *scmd)
 {
 	BUG();
@@ -1021,8 +1283,8 @@
 	.sg_tablesize		= SG_ALL,
 	.max_sectors		= 65535,
 	.use_clustering		= DISABLE_CLUSTERING,
-/* 	.transfer_response	= scsi_cmnd_done, */
-/* 	.transfer_data		= buffer_ready, */
+	.transfer_response	= istgt_transfer_response,
+	.transfer_data		= istgt_transfer_data,
 	.eh_abort_handler	= istgt_tcp_eh_abort_handler,
 };
 
@@ -1031,6 +1293,7 @@
 	.name			= TGT_NAME,
 	.host_template		= &istgt_tcp_sht,
 	.conndata_size		= sizeof(struct iscsi_conn),
+	.sessiondata_size	= sizeof(struct istgt_session),
 	.max_conn		= 1,
 	.max_cmd_len		= ISCSI_TCP_MAX_CMD_LEN,
 	.create_session		= istgt_tcp_session_create,
@@ -1040,6 +1303,7 @@
 	.bind_conn		= iscsi_tcp_conn_bind,
 	.start_conn		= iscsi_conn_start,
 	.terminate_conn		= iscsi_tcp_terminate_conn,
+	.xmit_cmd_task		= istgt_tcp_ctask_xmit,
 };
 
 static int __init istgt_tcp_init(void)



From tomo at berlios.de  Sat Apr 29 15:47:26 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 15:47:26 +0200
Subject: [Stgt-svn] r429 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291347.k3TDlQXL016983@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 15:47:13 +0200 (Sat, 29 Apr 2006)
New Revision: 429

Removed:
   branches/use-scsi-ml/istgt/kernel/conn.c
   branches/use-scsi-ml/istgt/kernel/digest.c
   branches/use-scsi-ml/istgt/kernel/digest.h
   branches/use-scsi-ml/istgt/kernel/iscsi.h
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
   branches/use-scsi-ml/istgt/kernel/nthread.c
Log:
Remove old files

Deleted: branches/use-scsi-ml/istgt/kernel/conn.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/conn.c	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/conn.c	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,167 +0,0 @@
-/*
- * Copyright (C) 2002-2003 Ardis Technolgies <roman at ardistech.com>
- *
- * Released under the terms of the GNU GPL v2.0.
- */
-#include <linux/file.h>
-#include <linux/ip.h>
-#include <net/tcp.h>
-#include <scsi/scsi_host.h>
-#include <scsi/scsi_transport_iscsi.h>
-
-#include <iscsi.h>
-#include <digest.h>
-
-int conn_close(struct iscsi_conn *conn)
-{
-	/* TODO: pass in error */
-	iscsi_conn_error(conn->cls_conn, ISCSI_ERR_CONN_FAILED);
-	return 0;
-}
-
-static void state_change(struct sock *sk)
-{
-	struct iscsi_conn *conn = sk->sk_user_data;
-	struct iscsi_session *session = conn->session;
-
-	if (sk->sk_state != TCP_ESTABLISHED)
-		conn_close(conn);
-	else
-		nthread_wakeup(session);
-
-	session->nthread_info.old_state_change(sk);
-}
-
-static void data_ready(struct sock *sk, int len)
-{
-	struct iscsi_conn *conn = sk->sk_user_data;
-	struct iscsi_session *session = conn->session;
-
-	nthread_wakeup(session);
-	session->nthread_info.old_data_ready(sk, len);
-}
-
-int
-istgt_conn_bind(struct iscsi_cls_session *cls_session,
-		struct iscsi_cls_conn *cls_conn, uint32_t transport_fd,
-		int is_leading)
-{
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	int opt = 1, err;
-	mm_segment_t oldfs;
-
-	dprintk("%llu\n", (unsigned long long) session->sid);
-
-	conn->file = fget(transport_fd);
-
-	conn->sock = sockfd_lookup(transport_fd, &err);
-	conn->sock->sk->sk_user_data = conn;
-
-	write_lock(&conn->sock->sk->sk_callback_lock);
-	session->nthread_info.old_state_change = conn->sock->sk->sk_state_change;
-	conn->sock->sk->sk_state_change = state_change;
-
-	session->nthread_info.old_data_ready = conn->sock->sk->sk_data_ready;
-	conn->sock->sk->sk_data_ready = data_ready;
-	write_unlock(&conn->sock->sk->sk_callback_lock);
-
-	oldfs = get_fs();
-	set_fs(get_ds());
-	conn->sock->ops->setsockopt(conn->sock, SOL_TCP, TCP_NODELAY,
-				    (void *)&opt, sizeof(opt));
-	set_fs(oldfs);
-	return 0;
-}
-
-int conn_free(struct iscsi_conn *conn)
-{
-	struct completion *wait = conn->free_done;
-
-	dprintk("%p %#Lx %u\n", conn->session,
-		(unsigned long long) conn->session->sid, conn->cid);
-
-	BUG_ON(atomic_read(&conn->nr_cmnds));
-	BUG_ON(!list_empty(&conn->pdu_list));
-	BUG_ON(!list_empty(&conn->write_list));
-
-	list_del(&conn->list);
-	list_del(&conn->poll_list);
-
-	digest_cleanup(conn);
-
-	sock_release(conn->sock);
-
-	if (wait)
-		complete(wait);
-
-	return 0;
-}
-
-void istgt_conn_destroy(struct iscsi_cls_conn *cls_conn)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_session *session = conn->session;
-	DECLARE_COMPLETION(wait);
-
-	conn->free_done = &wait;
-
-	if (test_and_clear_bit(CONN_ACTIVE, &conn->state))
-		set_bit(CONN_CLOSING, &conn->state);
-
-	nthread_wakeup(session);
-	wait_for_completion(&wait);
-}
-
-struct iscsi_cls_conn *istgt_conn_create(struct iscsi_cls_session *cls_session,
-					 uint32_t cid)
-{
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
-	struct iscsi_cls_conn *cls_conn;
-	struct iscsi_conn *conn;
-
-	dprintk("%#Lx:%u\n", (unsigned long long) session->sid, cid);
-
-        cls_conn = iscsi_create_conn(cls_session, cid);
-	if (!cls_conn)
-		return NULL;
-
-	conn = cls_conn->dd_data;
-	memset(conn, 0, sizeof(*conn));
-
-	conn->cls_conn = cls_conn;
-	conn->session = session;
-	conn->cid = cid;
-//	conn->stat_sn = info->stat_sn;
-// mnc	conn->exp_stat_sn = info->exp_stat_sn;
-
-//	conn->hdigest_type = info->header_digest;
-//	conn->ddigest_type = info->data_digest;
-//	if (digest_init(conn) < 0) {
-//		iscsi_destroy_conn(cls_conn);
-//		return NULL;
-//	}
-
-	spin_lock_init(&conn->list_lock);
-	atomic_set(&conn->nr_cmnds, 0);
-	atomic_set(&conn->nr_busy_cmnds, 0);
-	INIT_LIST_HEAD(&conn->pdu_list);
-	INIT_LIST_HEAD(&conn->write_list);
-	INIT_LIST_HEAD(&conn->poll_list);
-
-	list_add(&conn->list, &session->conn_list);
-	return cls_conn;
-}
-
-int istgt_conn_start(struct iscsi_cls_conn *cls_conn)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_session *session = conn->session;
-
-	set_bit(CONN_ACTIVE, &conn->state);
-	list_add(&conn->poll_list, &session->nthread_info.active_conns);
-	nthread_wakeup(conn->session);
-	return 0;
-}

Deleted: branches/use-scsi-ml/istgt/kernel/digest.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/digest.c	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/digest.c	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,168 +0,0 @@
-/*
- * iSCSI digest handling.
- * (C) 2004 Xiranet Communications GmbH <arne.redlich at xiranet.com>
- * This code is licensed under the GPL.
- */
-
-#include <linux/mm.h>
-#include <asm/types.h>
-#include <asm/scatterlist.h>
-#include <linux/scatterlist.h>
-
-#include <iscsi.h>
-#include <digest.h>
-
-void digest_alg_available(unsigned int *val)
-{
-	if (*val & DIGEST_CRC32C && !crypto_alg_available("crc32c", 0)) {
-		printk("CRC32C digest algorithm not available in kernel\n");
-		*val |= ~DIGEST_CRC32C;
-	}
-}
-
-int digest_init(struct iscsi_conn *conn)
-{
-	int err = 0;
-
-	if (!(conn->hdigest_type & DIGEST_ALL))
-		conn->hdigest_type = DIGEST_NONE;
-
-	if (!(conn->ddigest_type & DIGEST_ALL))
-		conn->ddigest_type = DIGEST_NONE;
-
-	if (conn->hdigest_type & DIGEST_CRC32C || conn->ddigest_type & DIGEST_CRC32C) {
-		conn->rx_digest_tfm = crypto_alloc_tfm("crc32c", 0);
-		if (!conn->rx_digest_tfm) {
-			err = -ENOMEM;
-			goto out;
-		}
-
-		conn->tx_digest_tfm = crypto_alloc_tfm("crc32c", 0);
-		if (!conn->tx_digest_tfm) {
-			err = -ENOMEM;
-			goto out;
-		}
-	}
-
-out:
-	if (err)
-		digest_cleanup(conn);
-
-	return err;
-}
-
-void digest_cleanup(struct iscsi_conn *conn)
-{
-	if (conn->tx_digest_tfm)
-		crypto_free_tfm(conn->tx_digest_tfm);
-	if (conn->rx_digest_tfm)
-		crypto_free_tfm(conn->rx_digest_tfm);
-}
-
-static void digest_header(struct crypto_tfm *tfm, struct iscsi_pdu *pdu,
-			  uint8_t *crc)
-{
-	struct scatterlist sg[2];
-	int i = 0;
-
-	sg_init_one(&sg[i], (uint8_t *) &pdu->bhs, sizeof(struct iscsi_hdr));
-	i++;
-	if (pdu->ahssize) {
-		sg_init_one(&sg[i], pdu->ahs, pdu->ahssize);
-		i++;
-	}
-
-	crypto_digest_init(tfm);
-	crypto_digest_update(tfm, sg, i);
-	crypto_digest_final(tfm, crc);
-}
-
-int digest_rx_header(struct istgt_cmd *cmnd)
-{
-	uint32_t crc;
-
-	digest_header(cmnd->conn->rx_digest_tfm, &cmnd->pdu, (uint8_t *) &crc);
-	if (crc != cmnd->hdigest)
-		return -EIO;
-
-	return 0;
-}
-
-void digest_tx_header(struct istgt_cmd *cmnd)
-{
-	digest_header(cmnd->conn->tx_digest_tfm, &cmnd->pdu,
-		      (uint8_t *) &cmnd->hdigest);
-}
-
-static void digest_data(struct crypto_tfm *tfm, struct istgt_cmd *cmnd,
-			struct scatterlist *sgv, uint32_t offset, uint8_t *crc)
-{
-	struct scatterlist sg[ISCSI_CONN_IOV_MAX];
-	uint32_t size, length;
-	int i, idx, count;
-
-	size = cmnd->pdu.datasize;
-	size = (size + 3) & ~3;
-
-	offset += sgv->offset;
-	idx = offset >> PAGE_CACHE_SHIFT;
-	offset &= ~PAGE_CACHE_MASK;
-	count = get_pgcnt(size, offset);
-	BUG_ON(count > ISCSI_CONN_IOV_MAX);
-/* 	assert(idx + count <= tio->pg_cnt); */
-
-	crypto_digest_init(tfm);
-
-	for (i = 0; size; i++) {
-		if (offset + size > PAGE_CACHE_SIZE)
-			length = PAGE_CACHE_SIZE - offset;
-		else
-			length = size;
-
-		sg[i].page = sgv[idx + i].page;
-		sg[i].offset = offset;
-		sg[i].length = length;
-		size -= length;
-		offset = 0;
-	}
-
-	crypto_digest_update(tfm, sg, count);
-	crypto_digest_final(tfm, crc);
-}
-
-int digest_rx_data(struct istgt_cmd *cmnd)
-{
-	struct scatterlist *sg;
-	uint32_t offset, crc;
-
-	if (cmd_opcode(cmnd) == ISCSI_OP_SCSI_DATA_OUT) {
-		struct istgt_cmd *scsi_cmnd = cmnd->req;
-		struct iscsi_data *req = (struct iscsi_data *) &cmnd->pdu.bhs;
-
-		sg = scsi_cmnd->scmd->request_buffer;
-		offset = be32_to_cpu(req->offset);
-	} else {
-		sg = cmnd->scmd->request_buffer;
-		offset = 0;
-	}
-
-	BUG_ON(!sg);
-	digest_data(cmnd->conn->rx_digest_tfm, cmnd, sg, offset,
-		    (uint8_t *) &crc);
-
-	if (!cmnd->conn->read_overflow && (cmd_opcode(cmnd) != ISCSI_OP_PDU_REJECT)) {
-		if (crc != cmnd->ddigest)
-			return -EIO;
-	}
-
-	return 0;
-}
-
-void digest_tx_data(struct istgt_cmd *cmnd)
-{
-	struct iscsi_data *req = (struct iscsi_data *) &cmnd->pdu.bhs;
-
-	BUG_ON(!cmnd->sg);
-	digest_data(cmnd->conn->tx_digest_tfm, cmnd, cmnd->sg,
-		    be32_to_cpu(req->offset), (uint8_t *) &cmnd->ddigest);
-}

Deleted: branches/use-scsi-ml/istgt/kernel/digest.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/digest.h	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/digest.h	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,20 +0,0 @@
-/*
- * iSCSI digest handling.
- * (C) 2004 Xiranet Communications GmbH <arne.redlich at xiranet.com>
- * This code is licensed under the GPL.
- */
-
-#ifndef __IET_DIGEST_H__
-#define __IET_DIGEST_H__
-
-extern void digest_alg_available(unsigned int *val);
-extern int digest_init(struct iscsi_conn *conn);
-extern void digest_cleanup(struct iscsi_conn *conn);
-
-extern int digest_rx_header(struct istgt_cmd *cmnd);
-extern int digest_rx_data(struct istgt_cmd *cmnd);
-
-extern void digest_tx_header(struct istgt_cmd *cmnd);
-extern void digest_tx_data(struct istgt_cmd *cmnd);
-
-#endif /* __IET_DIGEST_H__ */

Deleted: branches/use-scsi-ml/istgt/kernel/iscsi.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi.h	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/iscsi.h	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,309 +0,0 @@
-/*
- * Copyright (C) 2002-2003 Ardis Technolgies <roman at ardistech.com>
- *
- * Released under the terms of the GNU GPL v2.0.
- */
-
-#ifndef __ISCSI_H__
-#define __ISCSI_H__
-
-#include <linux/pagemap.h>
-#include <linux/mm.h>
-#include <linux/crypto.h>
-#include <net/sock.h>
-#include <asm/scatterlist.h>
-#include <linux/blkdev.h>
-
-#include <scsi/iscsi_proto.h>
-#include <scsi/scsi_cmnd.h>
-#include <istgt_u.h>
-
-#include <tgt.h>
-#include <tgt_target.h>
-#include <tgt_scsi.h>
-#include <tgt_protocol.h>
-
-struct iscsi_sess_param {
-	int initial_r2t;
-	int immediate_data;
-	int max_connections;
-	int max_recv_data_length;
-	int max_xmit_data_length;
-	int max_burst_length;
-	int first_burst_length;
-	int default_wait_time;
-	int default_retain_time;
-	int max_outstanding_r2t;
-	int data_pdu_inorder;
-	int data_sequence_inorder;
-	int error_recovery_level;
-	int header_digest;
-	int data_digest;
-	int ofmarker;
-	int ifmarker;
-	int ofmarkint;
-	int ifmarkint;
-};
-
-struct iscsi_trgt_param {
-	int queued_cmnds;
-};
-
-struct network_thread_info {
-	struct task_struct *task;
-	unsigned long flags;
-	struct list_head active_conns;
-
-	spinlock_t nthread_lock;
-
-	void (*old_state_change)(struct sock *);
-	void (*old_data_ready)(struct sock *, int);
-};
-
-struct istgt_cmd;
-
-#define IET_HASH_ORDER		8
-#define	cmnd_hashfn(itt)	hash_long((itt), IET_HASH_ORDER)
-
-struct iscsi_session {
-	struct list_head list;
-
-	uint64_t sid;
-
-	uint32_t exp_cmd_sn;
-	uint32_t max_cmd_sn;
-
-	struct iscsi_sess_param param;
-	uint32_t max_queued_cmnds;
-
-	struct list_head conn_list;
-	struct list_head pending_list;
-
-	spinlock_t cmnd_hash_lock;
-	struct list_head cmnd_hash[1 << IET_HASH_ORDER];
-
-	uint32_t next_ttt;
-
-	struct iscsi_trgt_param trgt_param;
-
-	struct list_head session_list;
-	struct network_thread_info nthread_info;
-	struct semaphore target_sem;
-
-	struct Scsi_Host *shost;
-};
-
-enum connection_state_bit {
-	CONN_ACTIVE,
-	CONN_CLOSING,
-};
-
-#define ISCSI_CONN_IOV_MAX	(((256 << 10) >> PAGE_SHIFT) + 1)
-
-struct iscsi_cls_session;
-struct iscsi_cls_conn;
-struct completion;
-
-struct iscsi_conn {
-	struct list_head list;			/* list entry in session list */
-	struct iscsi_session *session;		/* owning session */
-	struct iscsi_cls_conn *cls_conn;
-	struct completion *free_done;
-
-	uint16_t cid;
-	unsigned long state;
-
-	uint32_t stat_sn;
-	uint32_t exp_stat_sn;
-
-	int hdigest_type;
-	int ddigest_type;
-
-	struct list_head poll_list;
-
-	struct file *file;
-	struct socket *sock;
-	spinlock_t list_lock;
-	atomic_t nr_cmnds;
-	atomic_t nr_busy_cmnds;
-	struct list_head pdu_list;		/* in/outcoming pdus */
-	struct list_head write_list;		/* list of data pdus to be sent */
-
-	struct istgt_cmd *read_cmnd;
-	struct msghdr read_msg;
-	struct iovec read_iov[ISCSI_CONN_IOV_MAX];
-	uint32_t read_size;
-	uint32_t read_overflow;
-	int read_state;
-
-	struct istgt_cmd *write_cmnd;
-	struct iovec write_iov[ISCSI_CONN_IOV_MAX];
-	struct iovec *write_iop;
-
-	struct scatterlist *write_sg;
-
-	uint32_t write_size;
-	uint32_t write_offset;
-	int write_state;
-
-	struct crypto_tfm *rx_digest_tfm;
-	struct crypto_tfm *tx_digest_tfm;
-};
-
-struct iscsi_pdu {
-	struct iscsi_hdr bhs;
-	void *ahs;
-	unsigned int ahssize;
-	unsigned int datasize;
-};
-
-struct iscsi_sense_data {
-	uint16_t length;
-	uint8_t sense_buff[SCSI_SENSE_BUFFERSIZE];
-} __attribute__((packed));
-
-struct istgt_cmd {
-	struct list_head list;
-	struct list_head conn_list;
-	unsigned long flags;
-	struct iscsi_conn *conn;
-
-	struct iscsi_pdu pdu;
-	struct list_head pdu_list;
-
-	struct list_head hash_list;
-
-	struct scatterlist *sg, sense_sg;
-
-	uint32_t r2t_sn;
-	uint32_t r2t_length;
-	uint32_t is_unsolicited_data;
-	uint32_t target_task_tag;
-	uint32_t outstanding_r2t;
-
-	uint32_t hdigest;
-	uint32_t ddigest;
-
-	struct work_struct work;
-	struct completion event;
-
-	struct iscsi_sense_data sense;
-
-	struct istgt_cmd *req;
-
-	struct scsi_cmnd *scmd;
-	void (*done)(struct scsi_cmnd *);
-};
-
-#define ISCSI_OP_SCSI_REJECT	ISCSI_OP_VENDOR1_CMD
-#define ISCSI_OP_PDU_REJECT	ISCSI_OP_VENDOR2_CMD
-#define ISCSI_OP_DATA_REJECT	ISCSI_OP_VENDOR3_CMD
-#define ISCSI_OP_SCSI_ABORT	ISCSI_OP_VENDOR4_CMD
-
-/* iscsi.c */
-extern struct istgt_cmd *cmnd_alloc(struct iscsi_conn *, int);
-extern void cmnd_rx_start(struct istgt_cmd *);
-extern void cmnd_rx_end(struct istgt_cmd *);
-extern void cmnd_tx_start(struct istgt_cmd *);
-extern void cmnd_tx_end(struct istgt_cmd *);
-extern void cmnd_release(struct istgt_cmd *, int);
-
-/* conn.c */
-extern struct iscsi_cls_conn *istgt_conn_create(struct iscsi_cls_session *,
-						uint32_t cid);
-extern void istgt_conn_destroy(struct iscsi_cls_conn *);
-extern int istgt_conn_bind(struct iscsi_cls_session *, struct iscsi_cls_conn *,
-			   uint32_t, int);
-extern int istgt_conn_start(struct iscsi_cls_conn *);
-extern int conn_free(struct iscsi_conn *);
-extern int conn_close(struct iscsi_conn *conn);
-
-/* nthread.c */
-extern int nthread_init(struct iscsi_session *);
-extern int nthread_start(struct iscsi_session *);
-extern int nthread_stop(struct iscsi_session *);
-extern void nthread_wakeup(struct iscsi_session *);
-
-#define get_pgcnt(size, offset)	((((size) + ((offset) & ~PAGE_CACHE_MASK)) + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT)
-
-static inline void iscsi_cmnd_get_length(struct iscsi_pdu *pdu)
-{
-	pdu->ahssize = pdu->bhs.hlength * 4;
-	pdu->datasize = ntoh24(pdu->bhs.dlength);
-}
-
-static inline void iscsi_cmnd_set_length(struct iscsi_pdu *pdu)
-{
-	pdu->bhs.hlength = pdu->ahssize / 4;
-	hton24(pdu->bhs.dlength, pdu->datasize);
-}
-
-#define cmd_hdr(cmd)		((struct iscsi_cmd *) (&((cmd)->pdu.bhs)))
-#define cmd_ttt(cmd)		cpu_to_be32((cmd)->pdu.bhs.ttt)
-#define cmd_itt(cmd)		cpu_to_be32((cmd)->pdu.bhs.itt)
-#define cmd_opcode(cmd)		((cmd)->pdu.bhs.opcode & ISCSI_OPCODE_MASK)
-#define cmd_scsicode(cmd)	cmd_hdr(cmd)->cdb[0]
-
-#define	SECTOR_SIZE_BITS	9
-
-enum istgt_cmd_flags {
-	CMD_hashed,
-	CMD_final,
-	CMD_waitio,
-	CMD_close,
-	CMD_pending,
-};
-
-#define set_cmd_hashed(cmd)	set_bit(CMD_hashed, &(cmd)->flags)
-#define cmd_hashed(cmd)		test_bit(CMD_hashed, &(cmd)->flags)
-
-#define set_cmd_final(cmd)	set_bit(CMD_final, &(cmd)->flags)
-#define cmd_final(cmd)		test_bit(CMD_final, &(cmd)->flags)
-
-#define set_cmd_waitio(cmd)	set_bit(CMD_waitio, &(cmd)->flags)
-#define cmd_waitio(cmd)		test_bit(CMD_waitio, &(cmd)->flags)
-
-#define set_cmd_close(cmd)	set_bit(CMD_close, &(cmd)->flags)
-#define cmd_close(cmd)		test_bit(CMD_close, &(cmd)->flags)
-
-#define set_cmd_pending(cmd)	set_bit(CMD_pending, &(cmd)->flags)
-#define clear_cmd_pending(cmd)	clear_bit(CMD_pending, &(cmd)->flags)
-#define cmd_pending(cmd)	test_bit(CMD_pending, &(cmd)->flags)
-
-/* We still use 'IET' id. Maybe someday, we get own id. */
-
-#define VENDOR_ID	"IET"
-#define PRODUCT_ID	"VIRTUAL-DISK"
-#define PRODUCT_REV	"0"
-
-#define show_param(param)\
-{\
-	eprintk("%d %d %d %d %d %d %d %d %d %d %d %d %d %d %d\n",\
-		(param)->initial_r2t,\
-		(param)->immediate_data,\
-		(param)->max_connections,\
-		(param)->max_recv_data_length,\
-		(param)->max_xmit_data_length,\
-		(param)->max_burst_length,\
-		(param)->first_burst_length,\
-		(param)->default_wait_time,\
-		(param)->default_retain_time,\
-		(param)->max_outstanding_r2t,\
-		(param)->data_pdu_inorder,\
-		(param)->data_sequence_inorder,\
-		(param)->error_recovery_level,\
-		(param)->header_digest,\
-		(param)->data_digest);\
-}
-
-#undef dprintk
-
-#undef DEBUG_ISTGT
-
-#ifdef DEBUG_ISTGT
-#define dprintk eprintk
-#else
-#define dprintk(fmt, args...)
-#endif
-
-#endif	/* __ISCSI_H__ */

Deleted: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,1935 +0,0 @@
-/*
- * (C) 2004 - 2005 FUJITA Tomonori <tomof at acm.org>
- * Copyright (C) 2002 - 2003 Ardis Technolgies <roman at ardistech.com>
- * Copyright (C) 2005 - 2006 Mike Christie
- *
- * Released under the terms of the GNU GPL v2.0.
- */
-
-#include <linux/module.h>
-#include <linux/hash.h>
-#include <linux/mempool.h>
-#include <net/tcp.h>
-#include <scsi/scsi.h>
-#include <scsi/scsi_tgt.h>
-#include <scsi/scsi_tcq.h>
-#include <scsi/scsi_transport.h>
-#include <scsi/scsi_transport_iscsi.h>
-#include <iscsi.h>
-
-static kmem_cache_t *istgt_cmd_cache;
-static char dummy_data[1024];
-
-static uint32_t cmnd_write_size(struct istgt_cmd *cmnd)
-{
-	struct iscsi_cmd *hdr = cmd_hdr(cmnd);
-
-	if (hdr->flags & ISCSI_FLAG_CMD_WRITE)
-		return be32_to_cpu(hdr->data_length);
-	return 0;
-}
-
-static uint32_t cmnd_read_size(struct istgt_cmd *cmnd)
-{
-	struct iscsi_cmd *hdr = cmd_hdr(cmnd);
-
-	if (hdr->flags & ISCSI_FLAG_CMD_READ) {
-		if (!(hdr->flags & ISCSI_FLAG_CMD_WRITE))
-			return be32_to_cpu(hdr->data_length);
-		if (hdr->flags & ISCSI_FLAG_CMD_READ) {
-			struct iscsi_rlength_ahdr *ahdr =
-				(struct iscsi_rlength_ahdr *)cmnd->pdu.ahs;
-			if (ahdr && ahdr->ahstype == ISCSI_AHSTYPE_RLENGTH)
-				return be32_to_cpu(ahdr->read_length);
-		}
-	}
-	return 0;
-}
-
-/*
- * create a new command.
- *
- * iscsi_cmnd_create - 
- * @conn: ptr to connection (for i/o)
- *
- * @return    ptr to command or NULL
- */
-
-struct istgt_cmd *cmnd_alloc(struct iscsi_conn *conn, int req)
-{
-	struct istgt_cmd *cmnd;
-
-	/* TODO: async interface is necessary ? */
-	cmnd = kmem_cache_alloc(istgt_cmd_cache, GFP_KERNEL | __GFP_NOFAIL);
-
-	memset(cmnd, 0, sizeof(*cmnd));
-	INIT_LIST_HEAD(&cmnd->list);
-	INIT_LIST_HEAD(&cmnd->pdu_list);
-	INIT_LIST_HEAD(&cmnd->conn_list);
-	INIT_LIST_HEAD(&cmnd->hash_list);
-	cmnd->conn = conn;
-	spin_lock(&conn->list_lock);
-	atomic_inc(&conn->nr_cmnds);
-	init_completion(&cmnd->event);
-	if (req)
-		list_add_tail(&cmnd->conn_list, &conn->pdu_list);
-	spin_unlock(&conn->list_lock);
-	cmnd->sg = NULL;
-
-	if (req)
-		BUG_ON(!conn->session);
-
-	dprintk("%p:%p\n", conn, cmnd);
-
-	return cmnd;
-}
-
-/**
- * create a new command used as response.
- *
- * iscsi_cmnd_create_rsp_cmnd - 
- * @cmnd: ptr to request command
- *
- * @return    ptr to response command or NULL
- */
-
-static struct istgt_cmd *iscsi_cmnd_create_rsp_cmnd(struct istgt_cmd *cmnd, int final)
-{
-	struct istgt_cmd *rsp = cmnd_alloc(cmnd->conn, 0);
-
-	if (final)
-		set_cmd_final(rsp);
-	list_add_tail(&rsp->pdu_list, &cmnd->pdu_list);
-	rsp->req = cmnd;
-	return rsp;
-}
-
-static struct istgt_cmd *get_rsp_cmnd(struct istgt_cmd *req)
-{
-	return list_entry(req->pdu_list.prev, struct istgt_cmd, pdu_list);
-}
-
-static void iscsi_cmnds_init_write(struct list_head *send)
-{
-	struct istgt_cmd *cmnd = list_entry(send->next, struct istgt_cmd, list);
-	struct iscsi_conn *conn = cmnd->conn;
-	struct list_head *pos, *next;
-
-	spin_lock(&conn->list_lock);
-
-	list_for_each_safe(pos, next, send) {
-		cmnd = list_entry(pos, struct istgt_cmd, list);
-
-		dprintk("%p:%x\n", cmnd, cmd_opcode(cmnd));
-
-		list_del_init(&cmnd->list);
-		BUG_ON(conn != cmnd->conn);
-		list_add_tail(&cmnd->list, &conn->write_list);
-	}
-
-	spin_unlock(&conn->list_lock);
-
-	nthread_wakeup(conn->session);
-}
-
-static void iscsi_cmnd_init_write(struct istgt_cmd *cmnd)
-{
-	LIST_HEAD(head);
-
-	if (!list_empty(&cmnd->list)) {
-		eprintk("%x %x %x %x %lx %u %u %u %u %u %u %u %d %d\n",
-			cmd_itt(cmnd), cmd_ttt(cmnd), cmd_opcode(cmnd),
-			cmd_scsicode(cmnd), cmnd->flags,
-			cmnd->r2t_sn, cmnd->r2t_length, cmnd->is_unsolicited_data,
-			cmnd->target_task_tag, cmnd->outstanding_r2t,
-			cmnd->hdigest, cmnd->ddigest,
-			list_empty(&cmnd->pdu_list), list_empty(&cmnd->hash_list));
-
-		BUG_ON(!list_empty(&cmnd->list));
-	}
-	list_add(&cmnd->list, &head);
-	iscsi_cmnds_init_write(&head);
-}
-
-static void do_send_data_rsp(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	struct istgt_cmd *data_cmnd;
-	struct scatterlist *sg = cmnd->scmd->request_buffer;
-	struct iscsi_cmd *req = cmd_hdr(cmnd);
-	struct iscsi_data_rsp *rsp;
-	uint32_t pdusize, expsize, scsisize, size, offset, sn;
-	LIST_HEAD(send);
-
-	dprintk("%p\n", cmnd);
-	pdusize = conn->session->param.max_xmit_data_length;
-	expsize = cmnd_read_size(cmnd);
-	size = min(expsize, cmnd->scmd->request_bufflen);
-	dprintk("%u %u\n", expsize, cmnd->scmd->request_bufflen);
-	offset = 0;
-	sn = 0;
-
-	BUG_ON(!sg);
-
-	while (1) {
-		data_cmnd = iscsi_cmnd_create_rsp_cmnd(cmnd, size <= pdusize);
-		data_cmnd->sg = sg;
-		rsp = (struct iscsi_data_rsp *)&data_cmnd->pdu.bhs;
-
-		rsp->opcode = ISCSI_OP_SCSI_DATA_IN;
-		rsp->itt = req->itt;
-		rsp->ttt = cpu_to_be32(ISCSI_RESERVED_TAG);
-		rsp->offset = offset;
-		rsp->datasn = cpu_to_be32(sn);
-
-		if (size <= pdusize) {
-			data_cmnd->pdu.datasize = size;
-			rsp->flags = ISCSI_FLAG_CMD_FINAL |
-				     ISCSI_FLAG_DATA_STATUS;
-
-			scsisize = cmnd->scmd->request_bufflen;
-			if (scsisize < expsize) {
-				rsp->flags |= ISCSI_FLAG_CMD_UNDERFLOW;
-				size = expsize - scsisize;
-			} else if (scsisize > expsize) {
-				rsp->flags |= ISCSI_FLAG_CMD_OVERFLOW;
-				size = scsisize - expsize;
-			} else
-				size = 0;
-			rsp->residual_count = cpu_to_be32(size);
-			list_add_tail(&data_cmnd->list, &send);
-
-			break;
-		}
-
-		data_cmnd->pdu.datasize = pdusize;
-
-		size -= pdusize;
-		offset += pdusize;
-		sn++;
-
-		list_add_tail(&data_cmnd->list, &send);
-	}
-
-	iscsi_cmnds_init_write(&send);
-}
-
-static struct istgt_cmd *create_scsi_rsp(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_cmd *req_hdr = cmd_hdr(req);
-	struct iscsi_cmd_rsp *rsp_hdr;
-
-	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-
-	rsp_hdr = (struct iscsi_cmd_rsp *)&rsp->pdu.bhs;
-	rsp_hdr->opcode = ISCSI_OP_SCSI_CMD_RSP;
-	rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	rsp_hdr->response = ISCSI_STATUS_CMD_COMPLETED;
-	rsp_hdr->cmd_status = SAM_STAT_GOOD;
-	rsp_hdr->itt = req_hdr->itt;
-
-	return rsp;
-}
-
-static void send_scsi_rsp(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_cmd_rsp *rsp_hdr;
-	uint32_t size;
-
-	rsp = create_scsi_rsp(req);
-	rsp_hdr = (struct iscsi_cmd_rsp *) &rsp->pdu.bhs;
-	if ((size = cmnd_read_size(req)) != 0) {
-		rsp_hdr->flags |= ISCSI_FLAG_CMD_UNDERFLOW;
-		rsp_hdr->residual_count = cpu_to_be32(size);
-	}
-
-	iscsi_cmnd_init_write(rsp);
-}
-
-static struct istgt_cmd *do_create_sense_rsp(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_cmd_rsp *rsp_hdr;
-	struct iscsi_sense_data *sense = &req->sense;
-	struct scatterlist *sg = &req->sense_sg;
-	struct scatterlist *sg_data = req->scmd->request_buffer;
-	struct page *page;
-
-	page = sg_data[0].page;
-	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-
-	rsp_hdr = (struct iscsi_cmd_rsp *)&rsp->pdu.bhs;
-	rsp_hdr->opcode = ISCSI_OP_SCSI_CMD_RSP;
-	rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	rsp_hdr->response = ISCSI_STATUS_CMD_COMPLETED;
-	rsp_hdr->cmd_status = SAM_STAT_CHECK_CONDITION;
-	rsp_hdr->itt = cmd_hdr(req)->itt;
-
-	memcpy(sense->sense_buff, req->scmd->sense_buffer,
-		sizeof(sense->sense_buff));
-	/*
-	 * this looks broken for ppc
-	 */
-	sense->length = cpu_to_be16(req->scmd->request_bufflen);
-
-	sg->page = virt_to_page(sense);
-	sg->offset = offset_in_page(sense);
-	sg->length = req->scmd->request_bufflen + sizeof(uint16_t);
-	rsp->pdu.datasize = sg->length;
-	rsp->sg = sg;
-
-	return rsp;
-}
-
-static struct istgt_cmd *create_sense_rsp(struct istgt_cmd *req,
-					   uint8_t sense_key, uint8_t asc, uint8_t ascq)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_cmd_rsp *rsp_hdr;
-	struct scatterlist *sg = &req->sense_sg;
-	struct iscsi_sense_data *sense = &req->sense;
-	uint8_t *data = sense->sense_buff;
-
-	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-
-	rsp_hdr = (struct iscsi_cmd_rsp *)&rsp->pdu.bhs;
-	rsp_hdr->opcode = ISCSI_OP_SCSI_CMD_RSP;
-	rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	rsp_hdr->response = ISCSI_STATUS_CMD_COMPLETED;
-	rsp_hdr->cmd_status = SAM_STAT_CHECK_CONDITION;
-	rsp_hdr->itt = cmd_hdr(req)->itt;
-
-	sg->page = virt_to_page(sense);
-	sg->offset = offset_in_page(sense);
-
-	sense->length = cpu_to_be16(14);
-	data[0] = 0xf0;
-	data[2] = sense_key;
-	data[7] = 6;	// Additional sense length
-	data[12] = asc;
-	data[13] = ascq;
-
-	rsp->pdu.datasize = sizeof(uint16_t) + 14;
-	rsp->sg = sg;
-
-	sg->length = (rsp->pdu.datasize + 3) & -4;
-
-	return rsp;
-}
-
-/**
- * Free a command.
- * Also frees the additional header.
- *
- * iscsi_cmnd_remove - 
- * @cmnd: ptr to command
- */
-
-void iscsi_cmnd_remove(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn;
-
-	if (!cmnd)
-		return;
-	dprintk("%p\n", cmnd);
-	conn = cmnd->conn;
-	kfree(cmnd->pdu.ahs);
-
-	if (!list_empty(&cmnd->list)) {
-		struct iscsi_cmd *req = cmd_hdr(cmnd);
-
-		eprintk("cmnd %p still on some list?, %x %x %x %x %x %x %x %lx\n",
-			cmnd, req->opcode, req->cdb[0], req->flags, req->itt,
-			be32_to_cpu(req->data_length), req->cmdsn,
-			be32_to_cpu(cmnd->pdu.datasize), conn->state);
-
-		if (cmnd->req) {
-			struct iscsi_cmd *req = cmd_hdr(cmnd->req);
-			eprintk("%p %x %u\n", req, req->opcode, req->cdb[0]);
-		}
-		BUG();
-	}
-	list_del(&cmnd->list);
-	spin_lock(&conn->list_lock);
-	atomic_dec(&conn->nr_cmnds);
-	list_del(&cmnd->conn_list);
-	spin_unlock(&conn->list_lock);
-
-	if (cmnd->scmd)
-		cmnd->done(cmnd->scmd);
-	kmem_cache_free(istgt_cmd_cache, cmnd);
-}
-
-static void cmnd_skip_pdu(struct istgt_cmd *cmnd)
-{
-/* 	struct iscsi_conn *conn = cmnd->conn; */
-/* 	struct tio *tio = cmnd->tio; */
-/* 	char *addr; */
-/* 	u32 size; */
-/* 	int i; */
-
-	BUG_ON(1);
-
-/* 	eprintk("%x %x %x %u\n", cmd_itt(cmnd), cmd_opcode(cmnd), */
-/* 		cmd_hdr(cmnd)->cdb[0], cmnd->pdu.datasize); */
-
-/* 	if (!(size = cmnd->pdu.datasize)) */
-/* 		return; */
-
-/* 	if (tio) */
-/* 		assert(tio->pg_cnt > 0); */
-/* 	else */
-/* 		tio = cmnd->tio = tio_alloc(1); */
-
-/* 	addr = page_address(tio->pvec[0]); */
-/* 	assert(addr); */
-/* 	size = (size + 3) & -4; */
-/* 	conn->read_size = size; */
-/* 	for (i = 0; size > PAGE_CACHE_SIZE; i++, size -= PAGE_CACHE_SIZE) { */
-/* 		assert(i < ISCSI_CONN_IOV_MAX); */
-/* 		conn->read_iov[i].iov_base = addr; */
-/* 		conn->read_iov[i].iov_len = PAGE_CACHE_SIZE; */
-/* 	} */
-/* 	conn->read_iov[i].iov_base = addr; */
-/* 	conn->read_iov[i].iov_len = size; */
-/* 	conn->read_msg.msg_iov = conn->read_iov; */
-/* 	conn->read_msg.msg_iovlen = ++i; */
-}
-
-static void iscsi_cmnd_reject(struct istgt_cmd *req, int reason)
-{
-/* 	struct istgt_cmd *rsp; */
-/* 	struct iscsi_reject_hdr *rsp_hdr; */
-/* 	struct tio *tio; */
-/* 	char *addr; */
-
-	BUG_ON(1);
-
-/* 	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1); */
-/* 	rsp_hdr = (struct iscsi_reject_hdr *)&rsp->pdu.bhs; */
-
-/* 	rsp_hdr->opcode = ISCSI_OP_REJECT; */
-/* 	rsp_hdr->ffffffff = ISCSI_RESERVED_TAG; */
-/* 	rsp_hdr->reason = reason; */
-
-/* 	rsp->tio = tio = tio_alloc(1); */
-/* 	addr = page_address(tio->pvec[0]); */
-/* 	clear_page(addr); */
-/* 	memcpy(addr, &req->pdu.bhs, sizeof(struct iscsi_hdr)); */
-/* 	tio->size = rsp->pdu.datasize = sizeof(struct iscsi_hdr); */
-/* 	cmnd_skip_pdu(req); */
-
-/* 	req->pdu.bhs.opcode = ISCSI_OP_PDU_REJECT; */
-}
-
-static void cmnd_set_sn(struct istgt_cmd *cmnd, int set_stat_sn)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	struct iscsi_session *sess = conn->session;
-
-	if (set_stat_sn)
-		cmnd->pdu.bhs.statsn = cpu_to_be32(conn->stat_sn++);
-	cmnd->pdu.bhs.exp_statsn = cpu_to_be32(sess->exp_cmd_sn);
-	cmnd->pdu.bhs.max_statsn = cpu_to_be32(sess->exp_cmd_sn +
-						sess->max_queued_cmnds);
-}
-
-static void update_stat_sn(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	uint32_t exp_stat_sn;
-
-	cmnd->pdu.bhs.exp_statsn = exp_stat_sn = be32_to_cpu(cmnd->pdu.bhs.exp_statsn);
-	dprintk("%x,%x\n", cmd_opcode(cmnd), exp_stat_sn);
-	if ((int32_t) (exp_stat_sn - conn->exp_stat_sn) > 0 &&
-	    (int32_t) (exp_stat_sn - conn->stat_sn) <= 0) {
-		// free pdu resources
-		cmnd->conn->exp_stat_sn = exp_stat_sn;
-	}
-}
-
-static int check_cmd_sn(struct istgt_cmd *cmnd)
-{
-	struct iscsi_session *session = cmnd->conn->session;
-	uint32_t cmd_sn;
-
-	cmnd->pdu.bhs.statsn = cmd_sn = be32_to_cpu(cmnd->pdu.bhs.statsn);
-	dprintk("%d(%d)\n", cmd_sn, session->exp_cmd_sn);
-	if ((int32_t) (cmd_sn - session->exp_cmd_sn) >= 0)
-		return 0;
-	eprintk("sequence error (%x,%x)\n", cmd_sn, session->exp_cmd_sn);
-	return -ISCSI_REASON_PROTOCOL_ERROR;
-}
-
-static struct istgt_cmd *__cmnd_find_hash(struct iscsi_session *session,
-					   uint32_t itt, uint32_t ttt)
-{
-	struct list_head *head;
-	struct istgt_cmd *cmnd;
-
-	head = &session->cmnd_hash[cmnd_hashfn(itt)];
-
-	list_for_each_entry(cmnd, head, hash_list) {
-		if (cmnd->pdu.bhs.itt == itt) {
-			if ((ttt != ISCSI_RESERVED_TAG) && (ttt != cmnd->target_task_tag))
-				continue;
-			return cmnd;
-		}
-	}
-
-	return NULL;
-}
-
-static struct istgt_cmd *cmnd_find_hash(struct iscsi_session *session,
-					 uint32_t itt, uint32_t ttt)
-{
-	struct istgt_cmd *cmnd;
-
-	spin_lock(&session->cmnd_hash_lock);
-
-	cmnd = __cmnd_find_hash(session, itt, ttt);
-
-	spin_unlock(&session->cmnd_hash_lock);
-
-	return cmnd;
-}
-
-static int cmnd_insert_hash(struct istgt_cmd *cmnd)
-{
-	struct iscsi_session *session = cmnd->conn->session;
-	struct istgt_cmd *tmp;
-	struct list_head *head;
-	int err = 0;
-	uint32_t itt = cmnd->pdu.bhs.itt;
-
-	dprintk("%p:%x\n", cmnd, itt);
-	if (itt == ISCSI_RESERVED_TAG) {
-		err = -ISCSI_REASON_PROTOCOL_ERROR;
-		goto out;
-	}
-
-	head = &session->cmnd_hash[cmnd_hashfn(cmnd->pdu.bhs.itt)];
-
-	spin_lock(&session->cmnd_hash_lock);
-
-	tmp = __cmnd_find_hash(session, itt, ISCSI_RESERVED_TAG);
-	if (!tmp) {
-		list_add_tail(&cmnd->hash_list, head);
-		set_cmd_hashed(cmnd);
-	} else
-		err = -ISCSI_REASON_TASK_IN_PROGRESS;
-
-	spin_unlock(&session->cmnd_hash_lock);
-
-	if (!err) {
-		update_stat_sn(cmnd);
-		err = check_cmd_sn(cmnd);
-	}
-
-out:
-	return err;
-}
-
-static void __cmnd_remove_hash(struct istgt_cmd *cmnd)
-{
-	list_del(&cmnd->hash_list);
-}
-
-static void cmnd_remove_hash(struct istgt_cmd *cmnd)
-{
-	struct iscsi_session *session = cmnd->conn->session;
-	struct istgt_cmd *tmp;
-
-	spin_lock(&session->cmnd_hash_lock);
-
-	tmp = __cmnd_find_hash(session, cmnd->pdu.bhs.itt, ISCSI_RESERVED_TAG);
-
-	if (tmp && tmp == cmnd)
-		__cmnd_remove_hash(tmp);
-	else
-		eprintk("%p:%x not found\n", cmnd, cmd_itt(cmnd));
-
-	spin_unlock(&session->cmnd_hash_lock);
-}
-
-static void cmnd_skip_data(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_cmd_rsp *rsp_hdr;
-	uint32_t size;
-
-	rsp = get_rsp_cmnd(req);
-	rsp_hdr = (struct iscsi_cmd_rsp *)&rsp->pdu.bhs;
-	if (cmd_opcode(rsp) != ISCSI_OP_SCSI_CMD_RSP) {
-		eprintk("unexpected response command %u\n", cmd_opcode(rsp));
-		return;
-	}
-
-	size = cmnd_write_size(req);
-	if (size) {
-		rsp_hdr->flags |= ISCSI_FLAG_CMD_UNDERFLOW;
-		rsp_hdr->residual_count = cpu_to_be32(size);
-	}
-	size = cmnd_read_size(req);
-	if (size) {
-		if (cmd_hdr(req)->flags & ISCSI_FLAG_CMD_WRITE) {
-			rsp_hdr->flags |= ISCSI_FLAG_CMD_BIDI_UNDERFLOW;
-			rsp_hdr->bi_residual_count = cpu_to_be32(size);
-		} else {
-			rsp_hdr->flags |= ISCSI_FLAG_CMD_BIDI_OVERFLOW;
-			rsp_hdr->residual_count = cpu_to_be32(size);
-		}
-	}
-	req->pdu.bhs.opcode =
-		(req->pdu.bhs.opcode & ~ISCSI_OPCODE_MASK) | ISCSI_OP_SCSI_REJECT;
-
-	cmnd_skip_pdu(req);
-}
-
-static int cmnd_recv_pdu(struct iscsi_conn *conn, struct scsi_cmnd *scmd,
-			 uint32_t offset, uint32_t size)
-{
-	int idx, i;
-	char *addr;
-	struct scatterlist *sg;
-
-	dprintk("%u,%u\n", offset, size);
-
-	BUG_ON(!scmd);
-	BUG_ON(!scmd->request_buffer);
-	sg = scmd->request_buffer;
-	offset += sg->offset;
-
-	if (!(offset < sg->offset + scmd->request_bufflen) ||
-	    !(offset + size <= sg->offset + scmd->request_bufflen)) {
-		eprintk("%u %u %u %u", offset, size, sg->offset,
-			scmd->request_bufflen);
-		return -EIO;
-	}
-	BUG_ON(!(offset < sg->offset + scmd->request_bufflen));
-	BUG_ON(!(offset + size <= sg->offset + scmd->request_bufflen));
-
-	idx = offset >> PAGE_CACHE_SHIFT;
-	offset &= ~PAGE_CACHE_MASK;
-
-	conn->read_msg.msg_iov = conn->read_iov;
-	conn->read_size = (size + 3) & -4;
-	conn->read_overflow = 0;
-
-	i = 0;
-	while (1) {
-		sg = scmd->request_buffer + idx;
-		BUG_ON(!sg);
-		BUG_ON(!sg->page);
-		addr = page_address(sg->page);
-		BUG_ON(!addr);
-
-		conn->read_iov[i].iov_base =  addr + offset;
-		if (offset + size <= PAGE_CACHE_SIZE) {
-			conn->read_iov[i].iov_len = size;
-			conn->read_msg.msg_iovlen = ++i;
-			break;
-		}
-		conn->read_iov[i].iov_len = PAGE_CACHE_SIZE - offset;
-		size -= conn->read_iov[i].iov_len;
-		offset = 0;
-		if (++i >= ISCSI_CONN_IOV_MAX) {
-			conn->read_msg.msg_iovlen = i;
-			conn->read_overflow = size;
-			conn->read_size -= size;
-			break;
-		}
-
-		idx++;
-	}
-
-	return 0;
-}
-
-static void send_r2t(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_r2t_rsp *rsp_hdr;
-	uint32_t length, offset, burst;
-	LIST_HEAD(send);
-
-	length = req->r2t_length;
-	burst = req->conn->session->param.max_burst_length;
-	offset = be32_to_cpu(cmd_hdr(req)->data_length) - length;
-
-	do {
-		rsp = iscsi_cmnd_create_rsp_cmnd(req, 0);
-		rsp->pdu.bhs.ttt = req->target_task_tag;
-
-		rsp_hdr = (struct iscsi_r2t_rsp *)&rsp->pdu.bhs;
-		rsp_hdr->opcode = ISCSI_OP_R2T;
-		rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-		memcpy(rsp_hdr->lun, cmd_hdr(req)->lun, 8);
-		rsp_hdr->itt = cmd_hdr(req)->itt;
-		rsp_hdr->r2tsn = cpu_to_be32(req->r2t_sn++);
-		rsp_hdr->data_offset = cpu_to_be32(offset);
-		if (length > burst) {
-			rsp_hdr->data_length = cpu_to_be32(burst);
-			length -= burst;
-			offset += burst;
-		} else {
-			rsp_hdr->data_length = cpu_to_be32(length);
-			length = 0;
-		}
-
-		dprintk("%x %u %u %u %u\n", cmd_itt(req),
-			be32_to_cpu(rsp_hdr->data_length),
-			be32_to_cpu(rsp_hdr->data_offset),
-			be32_to_cpu(rsp_hdr->r2tsn), req->outstanding_r2t);
-
-		list_add_tail(&rsp->list, &send);
-
-		if (++req->outstanding_r2t >= req->conn->session->param.max_outstanding_r2t)
-			break;
-
-	} while (length);
-
-	iscsi_cmnds_init_write(&send);
-}
-
-static void __scsi_cmnd_done(void *data)
-{
-	struct scsi_cmnd *scmd = data;
-	struct istgt_cmd *cmnd = (struct istgt_cmd *) scmd->SCp.ptr;
-	struct iscsi_cmd *req = cmd_hdr(cmnd);
-
-	if (scmd->result) {
-		struct istgt_cmd *rsp;
-
-		rsp = do_create_sense_rsp(cmnd);
-		iscsi_cmnd_init_write(rsp);
-		return;
-	}
-
-	switch (req->cdb[0]) {
-	case INQUIRY:
-	case REPORT_LUNS:
-	case READ_CAPACITY:
-	case MODE_SENSE:
-	case REQUEST_SENSE:
-	case SERVICE_ACTION_IN:
-	case READ_6:
-	case READ_10:
-	case READ_16:
-		do_send_data_rsp(cmnd);
-		break;
-	case WRITE_6:
-	case WRITE_10:
-	case WRITE_16:
-	case WRITE_VERIFY:
-	case START_STOP:
-	case TEST_UNIT_READY:
-	case SYNCHRONIZE_CACHE:
-	case VERIFY:
-	case VERIFY_16:
-	case RESERVE:
-	case RELEASE:
-	case RESERVE_10:
-	case RELEASE_10:
-		send_scsi_rsp(cmnd);
-		break;
-	default:
-		BUG_ON(1);
-		break;
-	}
-}
-
-/* TODO : merge this with nthread. */
-static int scsi_cmnd_done(struct scsi_cmnd *scmd,
-			  void (*done)(struct scsi_cmnd *))
-{
-	struct istgt_cmd *cmnd = (struct istgt_cmd *) scmd->SCp.ptr;
-	int err;
-
-	cmnd->done = done;
-	INIT_WORK(&cmnd->work, __scsi_cmnd_done, scmd);
-	err = schedule_work(&cmnd->work);
-	BUG_ON(!err);
-
-	return TGT_CMD_XMIT_OK;
-}
-
-static void tgt_scsi_cmd_create(struct istgt_cmd *req)
-{
-	struct iscsi_cmd *req_hdr = cmd_hdr(req);
-	struct scsi_cmnd *scmd;
-
-	scmd = scsi_host_get_command(req->conn->session->shost, GFP_KERNEL);
-	BUG_ON(!scmd);
-	req->scmd = scmd;
-
-	memcpy(scmd->data_cmnd, req_hdr->cdb, MAX_COMMAND_SIZE);
-	scmd->request_bufflen = be32_to_cpu(req_hdr->data_length);
-	scmd->SCp.ptr = (char *) req;
-
-	/*
-	 * handle bidi later
-	 */
-	if (req_hdr->flags & ISCSI_FLAG_CMD_WRITE)
-		scmd->sc_data_direction = DMA_TO_DEVICE;
-	else if (req_hdr->flags & ISCSI_FLAG_CMD_READ)
-		scmd->sc_data_direction = DMA_FROM_DEVICE;
-	else
-		scmd->sc_data_direction = DMA_NONE;
-
-	switch (req->pdu.bhs.flags & ISCSI_FLAG_CMD_ATTR_MASK) {
-	case ISCSI_ATTR_UNTAGGED:
-	case ISCSI_ATTR_SIMPLE:
-		scmd->tag = MSG_SIMPLE_TAG;
-		break;
-	case ISCSI_ATTR_ORDERED:
-		scmd->tag = MSG_ORDERED_TAG;
-		break;
-	case ISCSI_ATTR_HEAD_OF_QUEUE:
-		scmd->tag = MSG_HEAD_TAG;
-		break;
-	case ISCSI_ATTR_ACA:
-		scmd->tag = MSG_SIMPLE_TAG;
-		break;
-	default:
-		scmd->tag = MSG_SIMPLE_TAG;
-	}
-
-	if (scmd->sc_data_direction == DMA_TO_DEVICE &&
-	    be32_to_cpu(req_hdr->data_length)) {
-		switch (req_hdr->cdb[0]) {
-		case WRITE_6:
-		case WRITE_10:
-		case WRITE_16:
-		case WRITE_VERIFY:
-			break;
-		default:
-			eprintk("%x\n", req_hdr->cdb[0]);
-			break;
-		}
-	}
-
-	scsi_tgt_queue_command(scmd, (struct scsi_lun *)req_hdr->lun, 0);
-}
-
-static void scsi_cmnd_exec(struct istgt_cmd *cmnd)
-{
-	struct scsi_cmnd *scmd = cmnd->scmd;
-
-	if (cmnd->r2t_length) {
-		if (!cmnd->is_unsolicited_data)
-			send_r2t(cmnd);
-	} else {
-		set_cmd_waitio(cmnd);
-		if (scmd) {
-			if (!cmnd->done)
-				BUG();
-			else
-				cmnd->done(scmd);
-		} else
-			tgt_scsi_cmd_create(cmnd);
-	}
-}
-
-static int noop_out_start(struct iscsi_conn *conn, struct istgt_cmd *cmnd)
-{
-	uint32_t size, tmp;
-	int i = 0, err = 0;
-
-	if (cmd_ttt(cmnd) != cpu_to_be32(ISCSI_RESERVED_TAG)) {
-		/*
-		 * We don't request a NOP-Out by sending a NOP-In.
-		 * See 10.18.2 in the draft 20.
-		 */
-		eprintk("initiator bug %x\n", cmd_itt(cmnd));
-		err = -ISCSI_REASON_PROTOCOL_ERROR;
-		goto out;
-	}
-
-	if (cmd_itt(cmnd) == cpu_to_be32(ISCSI_RESERVED_TAG)) {
-		if (!(cmnd->pdu.bhs.opcode & ISCSI_OP_IMMEDIATE))
-			eprintk("%s\n","initiator bug!");
-		update_stat_sn(cmnd);
-		err = check_cmd_sn(cmnd);
-		goto out;
-	} else if ((err = cmnd_insert_hash(cmnd)) < 0) {
-		eprintk("ignore this request %x\n", cmd_itt(cmnd));
-		goto out;
-	}
-
-	if ((size = cmnd->pdu.datasize)) {
-		size = (size + 3) & -4;
-		conn->read_msg.msg_iov = conn->read_iov;
-		if (cmnd->pdu.bhs.itt != cpu_to_be32(ISCSI_RESERVED_TAG)) {
-/* 			struct tio *tio; */
-			int pg_cnt = get_pgcnt(size, 0);
-
-			BUG_ON(pg_cnt >= ISCSI_CONN_IOV_MAX);
-			BUG_ON(1);
-/* 			cmnd->tio = tio = tio_alloc(pg_cnt); */
-/* 			tio_set(tio, size, 0); */
-
-/* 			for (i = 0; i < pg_cnt; i++) { */
-/* 				conn->read_iov[i].iov_base */
-/* 					= page_address(tio->pvec[i]); */
-/* 				tmp = min_t(u32, size, PAGE_CACHE_SIZE); */
-/* 				conn->read_iov[i].iov_len = tmp; */
-/* 				conn->read_size += tmp; */
-/* 				size -= tmp; */
-/* 			} */
-		} else {
-			for (i = 0; i < ISCSI_CONN_IOV_MAX; i++) {
-				conn->read_iov[i].iov_base = dummy_data;
-				tmp = min_t(uint32_t, size, sizeof(dummy_data));
-				conn->read_iov[i].iov_len = tmp;
-				conn->read_size += tmp;
-				size -= tmp;
-			}
-		}
-		BUG_ON(size);
-		conn->read_overflow = size;
-		conn->read_msg.msg_iovlen = i;
-	}
-
-out:
-	return err;
-}
-
-static uint32_t get_next_ttt(struct iscsi_session *session)
-{
-	uint32_t ttt;
-
-	if (session->next_ttt == ISCSI_RESERVED_TAG)
-		session->next_ttt++;
-	ttt = session->next_ttt++;
-
-	return cpu_to_be32(ttt);
-}
-
-static void scsi_cmnd_start(struct iscsi_conn *conn, struct istgt_cmd *req)
-{
-	struct iscsi_cmd *req_hdr = cmd_hdr(req);
-
-	dprintk("scsi command: %02x\n", req_hdr->cdb[0]);
-
-	switch (req_hdr->cdb[0]) {
-	case SERVICE_ACTION_IN:
-		if ((req_hdr->cdb[1] & 0x1f) != 0x10)
-			goto error;
-
-	case INQUIRY:
-	case REPORT_LUNS:
-	case TEST_UNIT_READY:
-	case SYNCHRONIZE_CACHE:
-	case VERIFY:
-	case VERIFY_16:
-	case START_STOP:
-	case READ_CAPACITY:
-	case MODE_SENSE:
-	case REQUEST_SENSE:
-	case RESERVE:
-	case RELEASE:
-	case RESERVE_10:
-	case RELEASE_10:
-	case READ_6:
-	case READ_10:
-	case READ_16:
-	{
-		if (!(req_hdr->flags & ISCSI_FLAG_CMD_FINAL) ||
-		      req->pdu.datasize) {
-			/* unexpected unsolicited data */
-			eprintk("%x %x\n", cmd_itt(req), req_hdr->cdb[0]);
-			create_sense_rsp(req, ABORTED_COMMAND, 0xc, 0xc);
-			cmnd_skip_data(req);
-		}
-		break;
-	}
-	case WRITE_6:
-	case WRITE_10:
-	case WRITE_16:
-	case WRITE_VERIFY:
-	{
-		struct iscsi_sess_param *param = &conn->session->param;
-
-		/*
-		 * We don't know this command arrives in order,
-		 * however we need to allocate buffer for immediate
-		 * and unsolicited data. tgt will not start to perform
-		 * this command until we call cmd->done so we don't
-		 * need to worry about the order of the command.
-		 */
-		tgt_scsi_cmd_create(req);
-		wait_for_completion(&req->event);
-
-		req->r2t_length = be32_to_cpu(req_hdr->data_length) - req->pdu.datasize;
-		req->is_unsolicited_data = !(req_hdr->flags &
-						ISCSI_FLAG_CMD_FINAL);
-		req->target_task_tag = get_next_ttt(conn->session);
-
-		if (!param->immediate_data && req->pdu.datasize)
-			eprintk("%x %x\n", cmd_itt(req), req_hdr->cdb[0]);
-
-		if (param->initial_r2t &&
-		    !(req_hdr->flags & ISCSI_FLAG_CMD_FINAL))
-			eprintk("%x %x\n", cmd_itt(req), req_hdr->cdb[0]);
-
-		if (req_hdr->cdb[0] == WRITE_VERIFY && req_hdr->cdb[1] & 0x02)
-			eprintk("Verification is ignored %x\n", cmd_itt(req));
-
-		if (req->pdu.datasize) {
-			if (cmnd_recv_pdu(conn, req->scmd, 0,
-					  req->pdu.datasize) < 0)
-				BUG_ON(1);
-		}
-		break;
-	}
-	error:
-	default:
-		eprintk("Unsupported %x\n", req_hdr->cdb[0]);
-		create_sense_rsp(req, ILLEGAL_REQUEST, 0x20, 0x0);
-		cmnd_skip_data(req);
-		break;
-	}
-
-	return;
-}
-
-static void data_out_start(struct iscsi_conn *conn, struct istgt_cmd *cmnd)
-{
-	struct iscsi_data *req = (struct iscsi_data *)&cmnd->pdu.bhs;
-	struct istgt_cmd *scsi_cmnd = NULL;
-	uint32_t offset = be32_to_cpu(req->offset);
-
-	update_stat_sn(cmnd);
-
-	cmnd->req = scsi_cmnd = cmnd_find_hash(conn->session, req->itt, req->ttt);
-	if (!scsi_cmnd) {
-		eprintk("unable to find scsi task %x %x\n",
-			cmd_itt(cmnd), cmd_ttt(cmnd));
-		goto skip_data;
-	}
-
-	if (scsi_cmnd->r2t_length < cmnd->pdu.datasize) {
-		eprintk("invalid data len %x %u %u\n",
-			cmd_itt(scsi_cmnd), cmnd->pdu.datasize, scsi_cmnd->r2t_length);
-		goto skip_data;
-	}
-
-	if (scsi_cmnd->r2t_length + offset != cmnd_write_size(scsi_cmnd)) {
-		eprintk("%x %u %u %u\n", cmd_itt(scsi_cmnd), scsi_cmnd->r2t_length,
-			offset,	cmnd_write_size(scsi_cmnd));
-		goto skip_data;
-	}
-
-	scsi_cmnd->r2t_length -= cmnd->pdu.datasize;
-
-	if (req->ttt == cpu_to_be32(ISCSI_RESERVED_TAG)) {
-		/* unsolicited burst data */
-		if (scsi_cmnd->pdu.bhs.flags & ISCSI_FLAG_CMD_FINAL) {
-			eprintk("unexpected data from %x %x\n",
-				cmd_itt(cmnd), cmd_ttt(cmnd));
-			goto skip_data;
-		}
-	}
-
-	dprintk("%u %p %p %u %u\n", req->ttt, cmnd, scsi_cmnd,
-		offset, cmnd->pdu.datasize);
-
-	if (cmnd_recv_pdu(conn, scsi_cmnd->scmd, offset, cmnd->pdu.datasize) < 0)
-		goto skip_data;
-	return;
-
-skip_data:
-	cmnd->pdu.bhs.opcode = ISCSI_OP_DATA_REJECT;
-	cmnd_skip_pdu(cmnd);
-	return;
-}
-
-static void data_out_end(struct iscsi_conn *conn, struct istgt_cmd *cmnd)
-{
-	struct iscsi_data *req = (struct iscsi_data *) &cmnd->pdu.bhs;
-	struct istgt_cmd *scsi_cmnd;
-	uint32_t offset;
-
-	BUG_ON(!cmnd);
-	scsi_cmnd = cmnd->req;
-	BUG_ON(!scsi_cmnd);
-
-	if (conn->read_overflow) {
-		eprintk("%x %u\n", cmd_itt(cmnd), conn->read_overflow);
-		offset = be32_to_cpu(req->offset);
-		offset += cmnd->pdu.datasize - conn->read_overflow;
-		if (cmnd_recv_pdu(conn, scsi_cmnd->scmd, offset,
-				  conn->read_overflow) < 0)
-			BUG_ON(1);
-		return;
-	}
-
-	if (req->ttt == cpu_to_be32(ISCSI_RESERVED_TAG)) {
-		if (req->flags & ISCSI_FLAG_CMD_FINAL) {
-			scsi_cmnd->is_unsolicited_data = 0;
-			if (!cmd_pending(scsi_cmnd))
-				scsi_cmnd_exec(scsi_cmnd);
-		}
-	} else {
-		/* TODO : proper error handling */
-		if (!(req->flags & ISCSI_FLAG_CMD_FINAL) &&
-		    scsi_cmnd->r2t_length == 0)
-			eprintk("initiator error %x\n", cmd_itt(scsi_cmnd));
-
-		if (!(req->flags & ISCSI_FLAG_CMD_FINAL))
-			goto out;
-
-		scsi_cmnd->outstanding_r2t--;
-
-		if (scsi_cmnd->r2t_length == 0)
-			BUG_ON(!list_empty(&scsi_cmnd->pdu_list));
-
-		scsi_cmnd_exec(scsi_cmnd);
-	}
-
-out:
-	iscsi_cmnd_remove(cmnd);
-	return;
-}
-
-/* static int __cmnd_abort(struct istgt_cmd *cmnd) */
-/* { */
-/* 	if (!cmnd_waitio(cmnd)) { */
-/* 		cmnd_release(cmnd, 1); */
-/* 		return 0; */
-/* 	} else */
-/* 		return -ISCSI_RESPONSE_UNKNOWN_TASK; */
-/* } */
-
-/* static int cmnd_abort(struct iscsi_session *session, u32 itt) */
-/* { */
-/* 	struct istgt_cmd *cmnd; */
-/* 	int err =  -ISCSI_RESPONSE_UNKNOWN_TASK; */
-
-/* 	if ((cmnd = cmnd_find_hash(session, itt, ISCSI_RESERVED_TAG))) { */
-/* 		eprintk("%x %x %x %u %u %u %u\n", cmd_itt(cmnd), cmd_opcode(cmnd), */
-/* 			cmnd->r2t_length, cmnd_scsicode(cmnd), */
-/* 			cmnd_write_size(cmnd), cmnd->is_unsolicited_data, */
-/* 			cmnd->outstanding_r2t); */
-/* 		err = __cmnd_abort(cmnd); */
-/* 	} */
-
-/* 	return err; */
-/* } */
-
-/* static int target_reset(struct istgt_cmd *req, u32 lun, int all) */
-/* { */
-/* 	struct iscsi_target *target = req->conn->session->target; */
-/* 	struct iscsi_session *session; */
-/* 	struct iscsi_conn *conn; */
-/* 	struct istgt_cmd *cmnd, *tmp; */
-
-/* 	list_for_each_entry(session, &target->session_list, list) { */
-/* 		list_for_each_entry(conn, &session->conn_list, list) { */
-/* 			list_for_each_entry_safe(cmnd, tmp, &conn->pdu_list, conn_list) { */
-/* 				if (cmnd == req) */
-/* 					continue; */
-
-/* 				if (all) */
-/* 					__cmnd_abort(cmnd); */
-/* 				else if (translate_lun(cmd_hdr(cmnd)->lun) == lun) */
-/* 					__cmnd_abort(cmnd); */
-/* 			} */
-/* 		} */
-/* 	} */
-
-/* 	return 0; */
-/* } */
-
-/* static void task_set_abort(struct istgt_cmd *req) */
-/* { */
-/* 	struct iscsi_session *session = req->conn->session; */
-/* 	struct iscsi_conn *conn; */
-/* 	struct istgt_cmd *cmnd, *tmp; */
-
-/* 	list_for_each_entry(conn, &session->conn_list, list) { */
-/* 		list_for_each_entry_safe(cmnd, tmp, &conn->pdu_list, conn_list) { */
-/* 			if (cmnd != req) */
-/* 				__cmnd_abort(cmnd); */
-/* 		} */
-/* 	} */
-/* } */
-
-static void execute_task_management(struct istgt_cmd *req)
-{
-/* 	struct iscsi_conn *conn = req->conn; */
-/* 	struct iscsi_target *target = conn->session->target; */
-	struct istgt_cmd *rsp;
-	struct iscsi_tm *req_hdr = (struct iscsi_tm *)&req->pdu.bhs;
-	struct iscsi_tm_rsp *rsp_hdr;
-	int function = req_hdr->flags & ISCSI_FLAG_TM_FUNC_MASK;
-
-	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-	rsp_hdr = (struct iscsi_tm_rsp *)&rsp->pdu.bhs;
-
-	rsp_hdr->opcode = ISCSI_OP_SCSI_TMFUNC_RSP;
-	rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	rsp_hdr->itt = req_hdr->itt;
-/* 	rsp_hdr->response = ISCSI_TMF_RSP_COMPLETE; */
-	rsp_hdr->response = ISCSI_TMF_RSP_REJECTED;
-
-	eprintk("%x %d %x\n", cmd_itt(req), function, req_hdr->rtt);
-
-/* 	switch (function) { */
-/* 	case ISCSI_FUNCTION_ABORT_TASK: */
-/* 	case ISCSI_FUNCTION_ABORT_TASK_SET: */
-/* 	case ISCSI_FUNCTION_CLEAR_ACA: */
-/* 	case ISCSI_FUNCTION_CLEAR_TASK_SET: */
-/* 	case ISCSI_FUNCTION_LOGICAL_UNIT_RESET: */
-/* 		lun = translate_lun(req_hdr->lun); */
-/* 		if (!volume_lookup(target, lun)) { */
-/* 			rsp_hdr->response = ISCSI_RESPONSE_UNKNOWN_LUN; */
-/* 			goto out; */
-/* 		} */
-/* 	} */
-
-/* 	switch (function) { */
-/* 	case ISCSI_FUNCTION_ABORT_TASK: */
-/* 		if ((err = cmnd_abort(conn->session, req_hdr->rtt)) < 0) */
-/* 			rsp_hdr->response = -err; */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_ABORT_TASK_SET: */
-/* 		task_set_abort(req); */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_CLEAR_ACA: */
-/* 		rsp_hdr->response = ISCSI_RESPONSE_FUNCTION_UNSUPPORTED; */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_CLEAR_TASK_SET: */
-/* 		rsp_hdr->response = ISCSI_RESPONSE_FUNCTION_UNSUPPORTED; */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_LOGICAL_UNIT_RESET: */
-/* 		target_reset(req, translate_lun(req_hdr->lun), 0); */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_TARGET_WARM_RESET: */
-/* 	case ISCSI_FUNCTION_TARGET_COLD_RESET: */
-/* 		target_reset(req, 0, 1); */
-/* 		if (function == ISCSI_FUNCTION_TARGET_COLD_RESET) */
-/* 			set_cmnd_close(rsp); */
-/* 		break; */
-/* 	case ISCSI_FUNCTION_TASK_REASSIGN: */
-/* 		rsp_hdr->response = ISCSI_RESPONSE_FUNCTION_UNSUPPORTED; */
-/* 		break; */
-/* 	default: */
-/* 		rsp_hdr->response = ISCSI_RESPONSE_FUNCTION_REJECTED; */
-/* 		break; */
-/* 	} */
-/* out: */
-	iscsi_cmnd_init_write(rsp);
-}
-
-static void noop_out_exec(struct istgt_cmd *req)
-{
-	struct istgt_cmd *rsp;
-	struct iscsi_nopin *rsp_hdr;
-
-	if (cmd_itt(req) != cpu_to_be32(ISCSI_RESERVED_TAG)) {
-		rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-
-		rsp_hdr = (struct iscsi_nopin *)&rsp->pdu.bhs;
-		rsp_hdr->opcode = ISCSI_OP_NOOP_IN;
-		rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-		rsp_hdr->itt = req->pdu.bhs.itt;
-		rsp_hdr->ttt = cpu_to_be32(ISCSI_RESERVED_TAG);
-
-/* 		if (req->pdu.datasize) */
-/* 			assert(req->tio); */
-/* 		else */
-/* 			assert(!req->tio); */
-
-/* 		if (req->tio) { */
-/* 			tio_get(req->tio); */
-/* 			rsp->tio = req->tio; */
-/* 		} */
-
-		BUG_ON(get_pgcnt(req->pdu.datasize, 0) >= ISCSI_CONN_IOV_MAX);
-		rsp->pdu.datasize = req->pdu.datasize;
-		iscsi_cmnd_init_write(rsp);
-	} else
-		iscsi_cmnd_remove(req);
-}
-
-static void logout_exec(struct istgt_cmd *req)
-{
-	struct iscsi_logout *req_hdr;
-	struct istgt_cmd *rsp;
-	struct iscsi_logout_rsp *rsp_hdr;
-
-	req_hdr = (struct iscsi_logout *)&req->pdu.bhs;
-	rsp = iscsi_cmnd_create_rsp_cmnd(req, 1);
-	rsp_hdr = (struct iscsi_logout_rsp *)&rsp->pdu.bhs;
-	rsp_hdr->opcode = ISCSI_OP_LOGOUT_RSP;
-	rsp_hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	rsp_hdr->itt = req_hdr->itt;
-	set_cmd_close(rsp);
-	iscsi_cmnd_init_write(rsp);
-}
-
-static void iscsi_cmnd_exec(struct istgt_cmd *cmnd)
-{
-	dprintk("%p,%x,%u\n", cmnd, cmd_opcode(cmnd),
-		cmnd->pdu.bhs.statsn);
-
-	switch (cmd_opcode(cmnd)) {
-	case ISCSI_OP_NOOP_OUT:
-		noop_out_exec(cmnd);
-		break;
-	case ISCSI_OP_SCSI_CMD:
-		scsi_cmnd_exec(cmnd);
-		break;
-	case ISCSI_OP_SCSI_TMFUNC:
-		execute_task_management(cmnd);
-		break;
-	case ISCSI_OP_LOGOUT:
-		logout_exec(cmnd);
-		break;
-	case ISCSI_OP_SCSI_REJECT:
-		iscsi_cmnd_init_write(get_rsp_cmnd(cmnd));
-		break;
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_SNACK:
-		break;
-	default:
-		eprintk("unexpected cmnd op %x\n", cmd_opcode(cmnd));
-		break;
-	}
-}
-
-static void __cmnd_send_pdu(struct iscsi_conn *conn, struct scatterlist *sg,
-			    uint32_t offset, uint32_t size)
-{
-/* 	dprintk(D_GENERIC, "%p %u,%u\n", tio, offset, size); */
-	offset += sg->offset;
-
-/* 	assert(offset <= sg->offset + tio->size); */
-/* 	assert(offset + size <= tio->offset + tio->size); */
-
-	conn->write_sg = sg;
-	conn->write_offset = offset;
-	conn->write_size += size;
-}
-
-static void cmnd_send_pdu(struct iscsi_conn *conn, struct istgt_cmd *cmnd)
-{
-	uint32_t size;
-
-	if (!cmnd->pdu.datasize)
-		return;
-
-	size = (cmnd->pdu.datasize + 3) & -4;
-	BUG_ON(!cmnd->sg);
-	__cmnd_send_pdu(conn, cmnd->sg, 0, size);
-}
-
-static void set_cork(struct socket *sock, int on)
-{
-	int opt = on;
-	mm_segment_t oldfs;
-
-	oldfs = get_fs();
-	set_fs(get_ds());
-	sock->ops->setsockopt(sock, SOL_TCP, TCP_CORK, (void *)&opt, sizeof(opt));
-	set_fs(oldfs);
-}
-
-void cmnd_release(struct istgt_cmd *cmnd, int force)
-{
-	struct istgt_cmd *req, *rsp;
-	int is_last = 0;
-
-	if (!cmnd)
-		return;
-
-	req = cmnd->req;
-	is_last = cmd_final(cmnd);
-
-	if (force) {
-		while (!list_empty(&cmnd->pdu_list)) {
-			rsp = list_entry(cmnd->pdu_list.next, struct istgt_cmd, pdu_list);
-			list_del_init(&rsp->list);
-			list_del(&rsp->pdu_list);
-			iscsi_cmnd_remove(rsp);
-		}
-		list_del_init(&cmnd->list);
-	}
-
-	if (cmd_hashed(cmnd))
-		cmnd_remove_hash(cmnd);
-
-	list_del_init(&cmnd->pdu_list);
-	iscsi_cmnd_remove(cmnd);
-
-	if (is_last) {
-		BUG_ON(force);
-		BUG_ON(!req);
-		cmnd_release(req, 0);
-	}
-
-	return;
-}
-
-void cmnd_tx_start(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	struct iovec *iop;
-
-	dprintk("%p:%x\n", cmnd, cmd_opcode(cmnd));
-	BUG_ON(!cmnd);
-	iscsi_cmnd_set_length(&cmnd->pdu);
-
-	set_cork(conn->sock, 1);
-
-	conn->write_iop = iop = conn->write_iov;
-	iop->iov_base = &cmnd->pdu.bhs;
-	iop->iov_len = sizeof(cmnd->pdu.bhs);
-	iop++;
-	conn->write_size = sizeof(cmnd->pdu.bhs);
-
-	switch (cmd_opcode(cmnd)) {
-	case ISCSI_OP_NOOP_IN:
-		cmnd_set_sn(cmnd, 1);
-		cmnd_send_pdu(conn, cmnd);
-		break;
-	case ISCSI_OP_SCSI_CMD_RSP:
-		cmnd_set_sn(cmnd, 1);
-		cmnd_send_pdu(conn, cmnd);
-		break;
-	case ISCSI_OP_SCSI_TMFUNC_RSP:
-		cmnd_set_sn(cmnd, 1);
-		break;
-	case ISCSI_OP_TEXT_RSP:
-		cmnd_set_sn(cmnd, 1);
-		break;
-	case ISCSI_OP_SCSI_DATA_IN:
-	{
-		struct iscsi_data_rsp *rsp = (struct iscsi_data_rsp *)&cmnd->pdu.bhs;
-		uint32_t offset;
-
-		cmnd_set_sn(cmnd, (rsp->flags & ISCSI_FLAG_CMD_FINAL) ? 1 : 0);
-		offset = rsp->offset;
-		rsp->offset = cpu_to_be32(offset);
-		BUG_ON(!cmnd->sg);
-		__cmnd_send_pdu(conn, cmnd->sg, offset, cmnd->pdu.datasize);
-		break;
-	}
-	case ISCSI_OP_LOGOUT_RSP:
-		cmnd_set_sn(cmnd, 1);
-		break;
-	case ISCSI_OP_R2T:
-		cmnd_set_sn(cmnd, 0);
-		cmnd->pdu.bhs.statsn = cpu_to_be32(conn->stat_sn);
-		break;
-	case ISCSI_OP_ASYNC_EVENT:
-		cmnd_set_sn(cmnd, 1);
-		break;
-	case ISCSI_OP_REJECT:
-		cmnd_set_sn(cmnd, 1);
-		cmnd_send_pdu(conn, cmnd);
-		break;
-	default:
-		eprintk("unexpected cmnd op %x\n", cmd_opcode(cmnd));
-		break;
-	}
-
-	iop->iov_len = 0;
-	// move this?
-	conn->write_size = (conn->write_size + 3) & -4;
-}
-
-void cmnd_tx_end(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-
-	dprintk("%p:%x\n", cmnd, cmd_opcode(cmnd));
-	switch (cmd_opcode(cmnd)) {
-	case ISCSI_OP_NOOP_IN:
-	case ISCSI_OP_SCSI_CMD_RSP:
-	case ISCSI_OP_SCSI_TMFUNC_RSP:
-	case ISCSI_OP_TEXT_RSP:
-	case ISCSI_OP_R2T:
-	case ISCSI_OP_ASYNC_EVENT:
-	case ISCSI_OP_REJECT:
-	case ISCSI_OP_SCSI_DATA_IN:
-	case ISCSI_OP_LOGOUT_RSP:
-		break;
-	default:
-		eprintk("unexpected cmnd op %x\n", cmd_opcode(cmnd));
-		BUG_ON(1);
-		break;
-	}
-
-	if (cmd_close(cmnd))
-		conn_close(conn);
-
-	list_del_init(&cmnd->list);
-	set_cork(cmnd->conn->sock, 0);
-}
-
-/**
- * Push the command for execution.
- * This functions reorders the commands.
- * Called from the read thread.
- *
- * iscsi_session_push_cmnd - 
- * @cmnd: ptr to command
- */
-
-static void iscsi_session_push_cmnd(struct istgt_cmd *cmnd)
-{
-	struct iscsi_session *session = cmnd->conn->session;
-	struct list_head *entry;
-	uint32_t cmd_sn;
-
-	dprintk("%p:%x %u,%u\n",
-		cmnd, cmd_opcode(cmnd), cmnd->pdu.bhs.statsn,
-		session->exp_cmd_sn);
-
-	if (cmnd->pdu.bhs.opcode & ISCSI_OP_IMMEDIATE) {
-		iscsi_cmnd_exec(cmnd);
-		return;
-	}
-
-	cmd_sn = cmnd->pdu.bhs.statsn;
-	if (cmd_sn == session->exp_cmd_sn) {
-		while (1) {
-			session->exp_cmd_sn = ++cmd_sn;
-			iscsi_cmnd_exec(cmnd);
-
-			if (list_empty(&session->pending_list))
-				break;
-			cmnd = list_entry(session->pending_list.next, struct istgt_cmd, list);
-			if (cmnd->pdu.bhs.statsn != cmd_sn)
-				break;
-/* 			eprintk("find out-of-order %x %u %u\n", */
-/* 				cmd_itt(cmnd), cmd_sn, cmnd->pdu.bhs.statsn); */
-			list_del_init(&cmnd->list);
-			clear_cmd_pending(cmnd);
-		}
-	} else {
-/* 		eprintk("out-of-order %x %u %u\n", */
-/* 			cmd_itt(cmnd), cmd_sn, session->exp_cmd_sn); */
-
-		set_cmd_pending(cmnd);
-		if (before(cmd_sn, session->exp_cmd_sn)) /* close the conn */
-			eprintk("unexpected cmd_sn (%u,%u)\n", cmd_sn, session->exp_cmd_sn);
-
-		if (after(cmd_sn, session->exp_cmd_sn + session->max_queued_cmnds))
-			eprintk("too large cmd_sn (%u,%u)\n", cmd_sn, session->exp_cmd_sn);
-
-		list_for_each(entry, &session->pending_list) {
-			struct istgt_cmd *tmp = list_entry(entry, struct istgt_cmd, list);
-			if (before(cmd_sn, tmp->pdu.bhs.statsn))
-				break;
-		}
-
-		BUG_ON(!list_empty(&cmnd->list));
-
-		list_add_tail(&cmnd->list, entry);
-	}
-}
-
-static int check_segment_length(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	struct iscsi_sess_param *param = &conn->session->param;
-
-	if (cmnd->pdu.datasize > param->max_recv_data_length) {
-		eprintk("too lond data %x %u %u\n", cmd_itt(cmnd),
-			cmnd->pdu.datasize, param->max_recv_data_length);
-
-		if (get_pgcnt(cmnd->pdu.datasize, 0) > ISCSI_CONN_IOV_MAX) {
-			conn_close(conn);
-			return -EINVAL;
-		}
-	}
-
-	return 0;
-}
-
-void cmnd_rx_start(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	int err = 0;
-
-	if (check_segment_length(cmnd) < 0)
-		return;
-
-	switch (cmd_opcode(cmnd)) {
-	case ISCSI_OP_NOOP_OUT:
-		err = noop_out_start(conn, cmnd);
-		break;
-	case ISCSI_OP_SCSI_CMD:
-		if (!(err = cmnd_insert_hash(cmnd)))
-			scsi_cmnd_start(conn, cmnd);
-		break;
-	case ISCSI_OP_SCSI_TMFUNC:
-		err = cmnd_insert_hash(cmnd);
-		break;
-	case ISCSI_OP_SCSI_DATA_OUT:
-		data_out_start(conn, cmnd);
-		break;
-	case ISCSI_OP_LOGOUT:
-		err = cmnd_insert_hash(cmnd);
-		break;
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_SNACK:
-		err = -ISCSI_REASON_CMD_NOT_SUPPORTED;
-		break;
-	default:
-		err = -ISCSI_REASON_CMD_NOT_SUPPORTED;
-		break;
-	}
-
-	if (err < 0) {
-		eprintk("%x %x %d\n", cmd_opcode(cmnd), cmd_itt(cmnd), err);
-		iscsi_cmnd_reject(cmnd, -err);
-	}
-}
-
-void cmnd_rx_end(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-
-	dprintk("%p:%x\n", cmnd, cmd_opcode(cmnd));
-	switch (cmd_opcode(cmnd)) {
-	case ISCSI_OP_SCSI_REJECT:
-	case ISCSI_OP_NOOP_OUT:
-	case ISCSI_OP_SCSI_CMD:
-	case ISCSI_OP_SCSI_TMFUNC:
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_LOGOUT:
-		iscsi_session_push_cmnd(cmnd);
-		break;
-	case ISCSI_OP_SCSI_DATA_OUT:
-		data_out_end(conn, cmnd);
-		break;
-	case ISCSI_OP_SNACK:
-		break;
-	case ISCSI_OP_PDU_REJECT:
-		iscsi_cmnd_init_write(get_rsp_cmnd(cmnd));
-		break;
-	case ISCSI_OP_DATA_REJECT:
-		cmnd_release(cmnd, 0);
-		break;
-	default:
-		eprintk("unexpected cmnd op %x\n", cmd_opcode(cmnd));
-		BUG();
-		break;
-	}
-}
-
-static int buffer_ready(struct scsi_cmnd *scmd,
-			void (*done)(struct scsi_cmnd *))
-{
-	struct istgt_cmd *cmnd = (struct istgt_cmd *) scmd->SCp.ptr;
-
-	cmnd->done = done;
-	complete(&cmnd->event);
-	return 0;
-}
-
-
-static struct iscsi_sess_param default_session_param = {
-	.initial_r2t = 1,
-	.immediate_data = 1,
-	.max_connections = 1,
-	.max_recv_data_length = 8192,
-	.max_xmit_data_length = 8192,
-	.max_burst_length = 262144,
-	.first_burst_length = 65536,
-	.default_wait_time = 2,
-	.default_retain_time = 20,
-	.max_outstanding_r2t = 1,
-	.data_pdu_inorder = 1,
-	.data_sequence_inorder = 1,
-	.error_recovery_level = 0,
-	.header_digest = DIGEST_NONE,
-	.data_digest = DIGEST_NONE,
-	.ofmarker = 0,
-	.ifmarker = 0,
-	.ofmarkint = 2048,
-	.ifmarkint = 2048,
-};
-
-static struct iscsi_trgt_param default_target_param = {
-	.queued_cmnds = DEFAULT_NR_QUEUED_CMNDS,
-};
-
-static struct iscsi_transport istgt_transport;
-
-static struct iscsi_cls_session *
-istgt_session_create(struct scsi_transport_template *scsit,
-		     uint32_t initial_cmdsn, uint32_t *sid)
-{
-	struct Scsi_Host *shost;
-	struct iscsi_session *session;
-	nt err, i;
-
-	shost = iscsi_transport_create_session(scsit, &istgt_transport);
-	if (!shost)
-		return NULL;
-
-	session = iscsi_hostdata(shost->hostdata);
-	memset(session, 0, sizeof(*session));
-
-	dprintk("%p %u %" PRIx64 "\n", session, session->shost->host_no);
-
-	session->shost = shost;
-	*sid = session->sid = shost->host_no;
-	memcpy(&session->param, &default_session_param,
-	       sizeof(default_session_param));
-	memcpy(&session->trgt_param, &default_target_param,
-	       sizeof(default_target_param));
-	init_MUTEX(&session->target_sem);
-	INIT_LIST_HEAD(&session->session_list);
-
-	session->max_queued_cmnds = session->trgt_param.queued_cmnds;
-	session->exp_cmd_sn = initial_cmdsn + 1;
-	session->max_cmd_sn = initial_cmdsn + 1;
-
-	INIT_LIST_HEAD(&session->conn_list);
-	INIT_LIST_HEAD(&session->pending_list);
-
-	spin_lock_init(&session->cmnd_hash_lock);
-	for (i = 0; i < ARRAY_SIZE(session->cmnd_hash); i++)
-		INIT_LIST_HEAD(&session->cmnd_hash[i]);
-
-	session->next_ttt = 1;
-
-	nthread_init(session);
-	err = nthread_start(session);
-	if (err)
-		goto destroy_session;
-
-	return hostdata_session(shost->hostdata);
-
-destroy_session:
-	iscsi_transport_destroy_session(shost);
-	return NULL;
-}
-
-static void istgt_session_destroy(struct iscsi_cls_session *cls_session)
-{
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
-	int i;
-
-	dprintk("%" PRIx64 "\n", session->sid);
-
-	if (!list_empty(&session->conn_list)) {
-		eprintk("%" PRIx64 " still have connections\n", session->sid);
-		BUG();
-	}
-
-	BUG_ON(!list_empty(&session->conn_list));
-
-	for (i = 0; i < ARRAY_SIZE(session->cmnd_hash); i++)
-		BUG_ON(!list_empty(&session->cmnd_hash[i]));
-
-	down(&session->target_sem);
-	up(&session->target_sem);
-
-	nthread_stop(session);
-	iscsi_transport_destroy_session(shost);
-}
-
-static int
-istgt_conn_get_param(struct iscsi_cls_conn *cls_conn,
-		     enum iscsi_param key, uint32_t *value)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_sess_param *param = &conn->session->param;
-
-	switch(key) {
-	case ISCSI_PARAM_MAX_RECV_DLENGTH:
-		*value = param->max_recv_data_length;
-		break;
-	case ISCSI_PARAM_MAX_XMIT_DLENGTH:
-		*value = param->max_xmit_data_length;
-		break;
-	case ISCSI_PARAM_HDRDGST_EN:
-		*value = param->header_digest;
-		break;
-	case ISCSI_PARAM_DATADGST_EN:
-		*value = param->data_digest;
-		break;
-	default:
-		return ISCSI_ERR_PARAM_NOT_FOUND;
-	}
-
-	return 0;
-}
-
-static int
-istgt_session_get_param(struct iscsi_cls_session *cls_session,
-			enum iscsi_param key, uint32_t *value)
-{
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
-	struct iscsi_sess_param *param = &session->param;
-
-	switch(key) {
-	case ISCSI_PARAM_INITIAL_R2T_EN:
-		*value = param->initial_r2t;
-		break;
-	case ISCSI_PARAM_MAX_R2T:
-		*value = param->max_outstanding_r2t;
-		break;
-	case ISCSI_PARAM_IMM_DATA_EN:
-		*value = param->immediate_data;
-		break;
-	case ISCSI_PARAM_FIRST_BURST:
-		*value = param->first_burst_length;
-		break;
-	case ISCSI_PARAM_MAX_BURST:
-		*value = param->max_burst_length;
-		break;
-	case ISCSI_PARAM_PDU_INORDER_EN:
-		*value = param->data_pdu_inorder;
-		break;
-	case ISCSI_PARAM_DATASEQ_INORDER_EN:
-		*value = param->data_sequence_inorder;
-		break;
-	case ISCSI_PARAM_ERL:
-		*value = param->error_recovery_level;
-		break;
-	case ISCSI_PARAM_IFMARKER_EN:
-		*value = param->ifmarker;
-		break;
-	case ISCSI_PARAM_OFMARKER_EN:
-		*value = param->ofmarker;
-		break;
-	default:
-		return ISCSI_ERR_PARAM_NOT_FOUND;
-	}
-
-	return 0;
-}
-
-static int
-istgt_set_param(struct iscsi_cls_conn *cls_conn, enum iscsi_param key,
-		uint32_t value)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_session *session = conn->session;
-	struct iscsi_sess_param *param = &session->param;
-
-	switch(key) {
-	case ISCSI_PARAM_MAX_RECV_DLENGTH:
-		param->max_recv_data_length = value;
-		break;
-	case ISCSI_PARAM_MAX_XMIT_DLENGTH:
-		param->max_xmit_data_length = value;
-		break;
-	case ISCSI_PARAM_HDRDGST_EN:
-		param->header_digest = value;
-		break;
-	case ISCSI_PARAM_DATADGST_EN:
-		param->data_digest = value;
-		break;
-	case ISCSI_PARAM_INITIAL_R2T_EN:
-		param->initial_r2t = value;
-		break;
-	case ISCSI_PARAM_MAX_R2T:
-		param->max_outstanding_r2t = value;
-		break;
-	case ISCSI_PARAM_IMM_DATA_EN:
-		param->immediate_data = value;
-		break;
-	case ISCSI_PARAM_FIRST_BURST:
-		param->first_burst_length = value;
-		break;
-	case ISCSI_PARAM_MAX_BURST:
-		param->max_burst_length = value;
-		break;
-	case ISCSI_PARAM_PDU_INORDER_EN:
-		param->data_pdu_inorder = value;
-		break;
-	case ISCSI_PARAM_DATASEQ_INORDER_EN:
-		param->data_sequence_inorder = value;
-		break;
-	case ISCSI_PARAM_ERL:
-		param->error_recovery_level = value;
-		break;
-	case ISCSI_PARAM_IFMARKER_EN:
-		param->ifmarker = value;
-		break;
-	case ISCSI_PARAM_OFMARKER_EN:
-		param->ofmarker = value;
-		break;
-	default:
-		break;
-	}
-
-	return 0;
-}
-
-static struct scsi_host_template istgt_sht = {
-	.name			= THIS_NAME,
-	.module			= THIS_MODULE,
-	.can_queue		= DEFAULT_NR_QUEUED_CMNDS,
-	.sg_tablesize		= SG_ALL,
-	.max_sectors		= 65536,	/* really no limit */
-	.use_clustering		= DISABLE_CLUSTERING, /* do we support this,  ihave to double check */
-	.transfer_response	= scsi_cmnd_done,
-	.transfer_data		= buffer_ready,
-};
-
-static struct iscsi_transport istgt_transport = {
-	.owner			= THIS_MODULE,
-	.name			= "tcp_tgt",
-	.host_template		= &istgt_sht,
-	.hostdata_size		= sizeof(struct iscsi_session),
-	.max_conn		= 1,
-	.max_cmd_len		= 16,
-	.create_session		= istgt_session_create,
-	.destroy_session	= istgt_session_destroy, 
-	.create_conn		= istgt_conn_create,
-	.destroy_conn		= istgt_conn_destroy,
-	.bind_conn		= istgt_conn_bind,
-	.start_conn		= istgt_conn_start,
-	.set_param		= istgt_set_param,
-	.get_session_param	= istgt_session_get_param,
-	.get_conn_param		= istgt_conn_get_param,
-
-};
-
-static void istgt_exit(void)
-{
-	kmem_cache_destroy(istgt_cmd_cache);
-	iscsi_unregister_transport(&istgt_transport);
-}
-
-static int istgt_init(void)
-{
-	printk("iSCSI Target Software for Linux Target Framework %s\n",
-	       VERSION_STRING);
-
-	istgt_cmd_cache = kmem_cache_create("istgt_cmd",
-					    sizeof(struct istgt_cmd),
-					    0, 0, NULL, NULL);
-	if (!istgt_cmd_cache)
-		return -ENOMEM;
-
-	if (!iscsi_register_transport(&istgt_transport))
-		goto free_cmd_cache;
-
-	return 0;
-
-free_cmd_cache:
-	kmem_cache_destroy(istgt_cmd_cache);
-	return -ENOMEM;
-
-}
-
-module_init(istgt_init);
-module_exit(istgt_exit);
-
-MODULE_LICENSE("GPL");

Deleted: branches/use-scsi-ml/istgt/kernel/nthread.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/nthread.c	2006-04-29 13:19:04 UTC (rev 428)
+++ branches/use-scsi-ml/istgt/kernel/nthread.c	2006-04-29 13:47:13 UTC (rev 429)
@@ -1,697 +0,0 @@
-/*
- * Network thread.
- * (C) 2004 - 2005 FUJITA Tomonori <tomof at acm.org>
- * This code is licenced under the GPL.
- */
-
-#include <linux/sched.h>
-#include <linux/file.h>
-#include <linux/kthread.h>
-#include <asm/ioctls.h>
-#include <asm/scatterlist.h>
-
-#include <iscsi.h>
-#include <digest.h>
-
-DECLARE_WAIT_QUEUE_HEAD(iscsi_ctl_wait);
-
-enum daemon_state_bit {
-	D_ACTIVE,
-	D_DATA_READY,
-};
-
-void nthread_wakeup(struct iscsi_session *session)
-{
-	struct network_thread_info *info = &session->nthread_info;
-
-	spin_lock_bh(&info->nthread_lock);
-	set_bit(D_DATA_READY, &info->flags);
-	wake_up_process(info->task);
-	spin_unlock_bh(&info->nthread_lock);
-}
-
-static inline void iscsi_conn_init_read(struct iscsi_conn *conn, void *data, size_t len)
-{
-	len = (len + 3) & -4; // XXX ???
-	conn->read_iov[0].iov_base = data;
-	conn->read_iov[0].iov_len = len;
-	conn->read_msg.msg_iov = conn->read_iov;
-	conn->read_msg.msg_iovlen = 1;
-	conn->read_size = (len + 3) & -4;
-}
-
-static void iscsi_conn_read_ahs(struct iscsi_conn *conn, struct istgt_cmd *cmnd)
-{
-	cmnd->pdu.ahs = kmalloc(cmnd->pdu.ahssize, __GFP_NOFAIL|GFP_KERNEL);
-	BUG_ON(!cmnd->pdu.ahs);
-	iscsi_conn_init_read(conn, cmnd->pdu.ahs, cmnd->pdu.ahssize);
-}
-
-static struct istgt_cmd * iscsi_get_send_cmnd(struct iscsi_conn *conn)
-{
-	struct istgt_cmd *cmnd = NULL;
-
-	spin_lock(&conn->list_lock);
-	if (!list_empty(&conn->write_list)) {
-		cmnd = list_entry(conn->write_list.next, struct istgt_cmd, list);
-		list_del_init(&cmnd->list);
-	}
-	spin_unlock(&conn->list_lock);
-
-	return cmnd;
-}
-
-static int is_data_available(struct iscsi_conn *conn)
-{
-	int avail, res;
-	mm_segment_t oldfs;
-	struct socket *sock = conn->sock;
-
-	oldfs = get_fs();
-	set_fs(get_ds());
-	res = sock->ops->ioctl(sock, SIOCINQ, (unsigned long) &avail);
-	set_fs(oldfs);
-	return (res >= 0) ? avail : res;
-}
-
-static void forward_iov(struct msghdr *msg, int len)
-{
-	while (msg->msg_iov->iov_len <= len) {
-		len -= msg->msg_iov->iov_len;
-		msg->msg_iov++;
-		msg->msg_iovlen--;
-	}
-
-	msg->msg_iov->iov_base = (char *) msg->msg_iov->iov_base + len;
-	msg->msg_iov->iov_len -= len;
-}
-
-static int do_recv(struct iscsi_conn *conn, int state)
-{
-	mm_segment_t oldfs;
-	struct msghdr msg;
-	struct iovec iov[ISCSI_CONN_IOV_MAX];
-	int i, len, res;
-
-	if (!test_bit(CONN_ACTIVE, &conn->state)) {
-		res = -EIO;
-		goto out;
-	}
-
-	if (is_data_available(conn) <= 0) {
-		res = -EAGAIN;
-		goto out;
-	}
-
-	msg.msg_iov = iov;
-	msg.msg_iovlen = min_t(size_t, conn->read_msg.msg_iovlen, ISCSI_CONN_IOV_MAX);
-	for (i = 0, len = 0; i < msg.msg_iovlen; i++) {
-		iov[i] = conn->read_msg.msg_iov[i];
-		len += iov[i].iov_len;
-	}
-
-	oldfs = get_fs();
-	set_fs(get_ds());
-	res = sock_recvmsg(conn->sock, &msg, len, MSG_DONTWAIT | MSG_NOSIGNAL);
-	set_fs(oldfs);
-
-	if (res <= 0) {
-		switch (res) {
-		case -EAGAIN:
-		case -ERESTARTSYS:
-			break;
-		default:
-			eprintk("%d\n", res);
-			conn_close(conn);
-			break;
-		}
-	} else {
-		conn->read_size -= res;
-		if (conn->read_size)
-			forward_iov(&conn->read_msg, res);
-		else
-			conn->read_state = state;
-	}
-
-out:
-	dprintk("%d\n", res);
-
-	return res;
-}
-
-enum rx_state {
-	RX_INIT_BHS, /* Must be zero. */
-	RX_BHS,
-
-	RX_INIT_AHS,
-	RX_AHS,
-
-	RX_INIT_HDIGEST,
-	RX_HDIGEST,
-	RX_CHECK_HDIGEST,
-
-	RX_INIT_DATA,
-	RX_DATA,
-
-	RX_INIT_DDIGEST,
-	RX_DDIGEST,
-	RX_CHECK_DDIGEST,
-
-	RX_END,
-};
-
-static void rx_ddigest(struct iscsi_conn *conn, int state)
-{
-	struct istgt_cmd *cmnd = conn->read_cmnd;
-	int res = digest_rx_data(cmnd);
-
-	if (!res)
-		conn->read_state = state;
-	else
-		conn_close(conn);
-}
-
-static void rx_hdigest(struct iscsi_conn *conn, int state)
-{
-	struct istgt_cmd *cmnd = conn->read_cmnd;
-	int res = digest_rx_header(cmnd);
-
-	if (!res)
-		conn->read_state = state;
-	else
-		conn_close(conn);
-}
-
-static struct istgt_cmd *create_cmnd(struct iscsi_conn *conn)
-{
-	struct istgt_cmd *cmnd;
-
-	cmnd = cmnd_alloc(conn, 1);
-	iscsi_conn_init_read(cmnd->conn, &cmnd->pdu.bhs, sizeof(cmnd->pdu.bhs));
-	conn->read_state = RX_BHS;
-
-	return cmnd;
-}
-
-static int recv(struct iscsi_conn *conn)
-{
-	struct istgt_cmd *cmnd = conn->read_cmnd;
-	int hdigest, ddigest, res = 1;
-
-	if (!test_bit(CONN_ACTIVE, &conn->state))
-		return -EIO;
-
-	hdigest = conn->hdigest_type & DIGEST_NONE ? 0 : 1;
-	ddigest = conn->ddigest_type & DIGEST_NONE ? 0 : 1;
-
-	switch (conn->read_state) {
-	case RX_INIT_BHS:
-		BUG_ON(cmnd);
-		cmnd = conn->read_cmnd = create_cmnd(conn);
-	case RX_BHS:
-		res = do_recv(conn, RX_INIT_AHS);
-		if (res <= 0 || conn->read_state != RX_INIT_AHS)
-			break;
-	case RX_INIT_AHS:
-		iscsi_cmnd_get_length(&cmnd->pdu);
-		if (cmnd->pdu.ahssize) {
-			iscsi_conn_read_ahs(conn, cmnd);
-			conn->read_state = RX_AHS;
-		} else
-			conn->read_state = hdigest ? RX_INIT_HDIGEST : RX_INIT_DATA;
-
-		if (conn->read_state != RX_AHS)
-			break;
-	case RX_AHS:
-		res = do_recv(conn, hdigest ? RX_INIT_HDIGEST : RX_INIT_DATA);
-		if (res <= 0 || conn->read_state != RX_INIT_HDIGEST)
-			break;
-	case RX_INIT_HDIGEST:
-		iscsi_conn_init_read(conn, &cmnd->hdigest, sizeof(uint32_t));
-		conn->read_state = RX_HDIGEST;
-	case RX_HDIGEST:
-		res = do_recv(conn, RX_CHECK_HDIGEST);
-		if (res <= 0 || conn->read_state != RX_CHECK_HDIGEST)
-			break;
-	case RX_CHECK_HDIGEST:
-		rx_hdigest(conn, RX_INIT_DATA);
-		if (conn->read_state != RX_INIT_DATA)
-			break;
-	case RX_INIT_DATA:
-		cmnd_rx_start(cmnd);
-		conn->read_state = cmnd->pdu.datasize ? RX_DATA : RX_END;
-		if (conn->read_state != RX_DATA)
-			break;
-	case RX_DATA:
-		res = do_recv(conn, ddigest ? RX_INIT_DDIGEST : RX_END);
-		if (res <= 0 || conn->read_state != RX_INIT_DDIGEST)
-			break;
-	case RX_INIT_DDIGEST:
-		iscsi_conn_init_read(conn, &cmnd->ddigest, sizeof(uint32_t));
-		conn->read_state = RX_DDIGEST;
-	case RX_DDIGEST:
-		res = do_recv(conn, RX_CHECK_DDIGEST);
-		if (res <= 0 || conn->read_state != RX_CHECK_DDIGEST)
-			break;
-	case RX_CHECK_DDIGEST:
-		rx_ddigest(conn, RX_END);
-		break;
-	default:
-		eprintk("%d %d %x\n", res, conn->read_state, cmd_opcode(cmnd));
-		BUG_ON(1);
-	}
-
-	if (res <= 0)
-		return res;
-
-	if (conn->read_state != RX_END)
-		return res;
-
-	if (conn->read_size) {
-		eprintk("%d %x %d\n", res, cmd_opcode(cmnd), conn->read_size);
-		BUG_ON(1);
-	}
-
-	cmnd_rx_end(cmnd);
-	if (conn->read_size) {
-		eprintk("%x %d\n", cmd_opcode(cmnd), conn->read_size);
-		conn->read_state = RX_DATA;
-		return 1;
-	}
-
-	conn->read_cmnd = NULL;
-	conn->read_state = RX_INIT_BHS;
-
-	return 0;
-}
-
-/* This is taken from the Ardis code. */
-static int write_data(struct iscsi_conn *conn)
-{
-	mm_segment_t oldfs;
-	struct file *file;
-	struct socket *sock;
-	ssize_t (*sendpage)(struct socket *, struct page *, int, size_t, int);
-	struct scatterlist *sg;
-	struct iovec *iop;
-	int saved_size, size, sendsize;
-	int offset, idx;
-	int flags, res;
-
-	file = conn->file;
-	saved_size = size = conn->write_size;
-	iop = conn->write_iop;
-
-	if (iop) while (1) {
-		loff_t off = 0;
-		unsigned long count;
-		struct iovec *vec;
-		int rest;
-
-		vec = iop;
-		for (count = 0; vec->iov_len; count++, vec++)
-			;
-		oldfs = get_fs();
-		set_fs(KERNEL_DS);
-		res = vfs_writev(file, (struct iovec __user *) iop, count, &off);
-		set_fs(oldfs);
-		dprintk("%#Lx:%u: %d(%ld)\n",
-			(unsigned long long) conn->session->sid, conn->cid,
-			res, (long) iop->iov_len);
-		if (unlikely(res <= 0)) {
-			if (res == -EAGAIN || res == -EINTR) {
-				conn->write_iop = iop;
-				goto out_iov;
-			}
-			goto err;
-		}
-
-		rest = res;
-		size -= res;
-		while (iop->iov_len <= rest && rest) {
-			rest -= iop->iov_len;
-			iop++;
-		}
-		iop->iov_base += rest;
-		iop->iov_len -= rest;
-
-		if (!iop->iov_len) {
-			conn->write_iop = NULL;
-			if (size)
-				break;
-			goto out_iov;
-		}
-	}
-
-	sg = conn->write_sg;
-	if (!sg) {
-		eprintk("warning data missing!\n");
-		return 0;
-	}
-	offset = conn->write_offset;
-	idx = offset >> PAGE_CACHE_SHIFT;
-	offset &= ~PAGE_CACHE_MASK;
-
-	sock = conn->sock;
-	sendpage = sock->ops->sendpage ? : sock_no_sendpage;
-	flags = MSG_DONTWAIT;
-
-	while (1) {
-		sendsize = PAGE_CACHE_SIZE - offset;
-		if (size <= sendsize) {
-			res = sendpage(sock, sg[idx].page, offset, size, flags);
-			dprintk("%s %#Lx:%u: %d(%lu,%u,%u)\n",
-				sock->ops->sendpage ? "sendpage" : "writepage",
-				(unsigned long long ) conn->session->sid, conn->cid,
-				res, sg[idx].page->index, offset, size);
-			if (unlikely(res <= 0)) {
-				if (res == -EAGAIN || res == -EINTR) {
-					goto out;
-				}
-				goto err;
-			}
-			if (res == size) {
-				conn->write_sg = NULL;
-				conn->write_size = 0;
-				return saved_size;
-			}
-			offset += res;
-			size -= res;
-			continue;
-		}
-
-		res = sendpage(sock, sg[idx].page, offset, sendsize, flags | MSG_MORE);
-		dprintk("%s %#Lx:%u: %d(%lu,%u,%u)\n",
-			sock->ops->sendpage ? "sendpage" : "writepage",
-			(unsigned long long ) conn->session->sid, conn->cid,
-			res, sg[idx].page->index, offset, sendsize);
-		if (unlikely(res <= 0)) {
-			if (res == -EAGAIN || res == -EINTR) {
-				goto out;
-			}
-			goto err;
-		}
-		if (res == sendsize) {
-			idx++;
-			offset = 0;
-		} else
-			offset += res;
-		size -= res;
-	}
- out:
-	conn->write_offset = (idx << PAGE_CACHE_SHIFT) + offset;
- out_iov:
-	conn->write_size = size;
-	if ((saved_size == size) && res == -EAGAIN)
-		return res;
-
-	return saved_size - size;
-
- err:
-	eprintk("error %d at %#Lx:%u\n", res,
-		(unsigned long long) conn->session->sid, conn->cid);
-	return res;
-}
-
-static void exit_tx(struct iscsi_conn *conn, int res)
-{
-	if (res > 0)
-		return;
-
-	switch (res) {
-	case -EAGAIN:
-	case -ERESTARTSYS:
-		break;
-	default:
-		eprintk("%d %d %d\n", conn->write_size, conn->write_state, res);
-		conn_close(conn);
-		break;
-	}
-}
-
-static int tx_ddigest(struct istgt_cmd *cmnd, int state)
-{
-	int res, rest = cmnd->conn->write_size;
-	struct msghdr msg = {.msg_flags = MSG_NOSIGNAL | MSG_DONTWAIT};
-	struct kvec iov;
-
-	iov.iov_base = (char *) (&cmnd->ddigest) + (sizeof(uint32_t) - rest);
-	iov.iov_len = rest;
-
-	res = kernel_sendmsg(cmnd->conn->sock, &msg, &iov, 1, rest);
-
-	if (res > 0) {
-		cmnd->conn->write_size -= res;
-		if (!cmnd->conn->write_size)
-			cmnd->conn->write_state = state;
-	} else
-		exit_tx(cmnd->conn, res);
-
-	return res;
-}
-
-static void init_tx_hdigest(struct istgt_cmd *cmnd)
-{
-	struct iscsi_conn *conn = cmnd->conn;
-	struct iovec *iop;
-
-	if (conn->hdigest_type & DIGEST_NONE)
-		return;
-
-	digest_tx_header(cmnd);
-
-	for (iop = conn->write_iop; iop->iov_len; iop++)
-		;
-	iop->iov_base = &(cmnd->hdigest);
-	iop->iov_len = sizeof(uint32_t);
-	conn->write_size += sizeof(uint32_t);
-	iop++;
-	iop->iov_len = 0;
-
-	return;
-}
-
-enum tx_state {
-	TX_INIT, /* Must be zero. */
-	TX_BHS_DATA,
-	TX_INIT_DDIGEST,
-	TX_DDIGEST,
-	TX_END,
-};
-
-static int do_send(struct iscsi_conn *conn, int state)
-{
-	int res;
-
-	res = write_data(conn);
-
-	if (res > 0) {
-		if (!conn->write_size)
-			conn->write_state = state;
-	} else
-		exit_tx(conn, res);
-
-	return res;
-}
-
-static int send(struct iscsi_conn *conn)
-{
-	struct istgt_cmd *cmnd = conn->write_cmnd;
-	int ddigest, res = 0;
-
-	ddigest = conn->ddigest_type != DIGEST_NONE ? 1 : 0;
-
-	switch (conn->write_state) {
-	case TX_INIT:
-		BUG_ON(cmnd);
-		cmnd = conn->write_cmnd = iscsi_get_send_cmnd(conn);
-		if (!cmnd)
-			return 0;
-		cmnd_tx_start(cmnd);
-		init_tx_hdigest(cmnd);
-		conn->write_state = TX_BHS_DATA;
-	case TX_BHS_DATA:
-		res = do_send(conn, ddigest && cmnd->pdu.datasize ? TX_INIT_DDIGEST : TX_END);
-		if (res <= 0 || conn->write_state != TX_INIT_DDIGEST)
-			break;
-	case TX_INIT_DDIGEST:
-		digest_tx_data(cmnd);
-		BUG_ON(cmnd->conn->write_size);
-		cmnd->conn->write_size += sizeof(uint32_t);
-		conn->write_state = TX_DDIGEST;
-	case TX_DDIGEST:
-		res = tx_ddigest(cmnd, TX_END);
-		break;
-	default:
-		eprintk("%d %d %x\n", res, conn->write_state, cmd_opcode(cmnd));
-		BUG_ON(1);
-	}
-
-	if (res <= 0)
-		return res;
-
-	if (conn->write_state != TX_END)
-		return res;
-
-	if (conn->write_size) {
-		eprintk("%d %x %u\n", res, cmd_opcode(cmnd), conn->write_size);
-		BUG_ON(conn->write_size);
-	}
-	cmnd_tx_end(cmnd);
-	cmnd_release(cmnd, 0);
-	conn->write_cmnd = NULL;
-	conn->write_state = TX_INIT;
-
-	return 0;
-}
-
-static void process_io(struct iscsi_conn *conn)
-{
-	int res, wakeup = 0;
-
-	res = recv(conn);
-
-	if (is_data_available(conn) > 0 || res > 0)
-		wakeup = 1;
-
-	if (!test_bit(CONN_ACTIVE, &conn->state)) {
-		wakeup = 1;
-		goto out;
-	}
-
-	res = send(conn);
-
-	if (!list_empty(&conn->write_list) || conn->write_cmnd)
-		wakeup = 1;
-
-out:
-	if (wakeup)
-		nthread_wakeup(conn->session);
-
-	return;
-}
-
-static void close_conn(struct iscsi_conn *conn)
-{
-	struct iscsi_session *session = conn->session;
-	struct istgt_cmd *cmnd;
-
-	conn->sock->ops->shutdown(conn->sock, 2);
-
-	write_lock(&conn->sock->sk->sk_callback_lock);
-	conn->sock->sk->sk_state_change = session->nthread_info.old_state_change;
-	conn->sock->sk->sk_data_ready = session->nthread_info.old_data_ready;
-	write_unlock(&conn->sock->sk->sk_callback_lock);
-
-	fput(conn->file);
-	conn->file = NULL;
-	conn->sock = NULL;
-
-	while (atomic_read(&conn->nr_busy_cmnds))
-		yield();
-
-	while (!list_empty(&conn->pdu_list)) {
-		cmnd = list_entry(conn->pdu_list.next, struct istgt_cmd, conn_list);
-
-		list_del_init(&cmnd->list);
-		cmnd_release(cmnd, 1);
-	}
-
-	if (atomic_read(&conn->nr_cmnds)) {
-		eprintk("%u\n", atomic_read(&conn->nr_cmnds));
-		list_for_each_entry(cmnd, &conn->pdu_list, conn_list)
-			eprintk("%x %x\n", cmd_opcode(cmnd), cmd_itt(cmnd));
-		BUG_ON(1);
-	}
-
-	eprintk("%llu %d\n", session->sid, conn->cid);
-	conn_free(conn);
-}
-
-static int istd(void *arg)
-{
-	struct iscsi_session *session = arg;
-	struct network_thread_info *info = &session->nthread_info;
-	struct iscsi_conn *conn, *tmp;
-
-	__set_current_state(TASK_RUNNING);
-	do {
-		spin_lock_bh(&info->nthread_lock);
-		__set_current_state(TASK_INTERRUPTIBLE);
-
-		if (!test_bit(D_DATA_READY, &info->flags)) {
-			spin_unlock_bh(&info->nthread_lock);
-			schedule();
-			spin_lock_bh(&info->nthread_lock);
-		}
-		__set_current_state(TASK_RUNNING);
-		clear_bit(D_DATA_READY, &info->flags);
-		spin_unlock_bh(&info->nthread_lock);
-
-		down(&session->target_sem);
-		list_for_each_entry_safe(conn, tmp, &info->active_conns, poll_list) {
-			if (test_bit(CONN_ACTIVE, &conn->state))
-				process_io(conn);
-			else
-				close_conn(conn);
-		}
-		up(&session->target_sem);
-
-	} while (!kthread_should_stop());
-
-	return 0;
-}
-
-int nthread_init(struct iscsi_session *session)
-{
-	struct network_thread_info *info = &session->nthread_info;
-
-	info->flags = 0;
-	info->task = NULL;
-
-	info->old_state_change = NULL;
-	info->old_data_ready = NULL;
-
-	INIT_LIST_HEAD(&info->active_conns);
-
-	spin_lock_init(&info->nthread_lock);
-
-	return 0;
-}
-
-int nthread_start(struct iscsi_session *session)
-{
-	int err = 0;
-	struct network_thread_info *info = &session->nthread_info;
-	struct task_struct *task;
-
-	if (info->task) {
-		eprintk("Target (%llu) already runs\n", session->sid);
-		return -EALREADY;
-	}
-
-	task = kthread_run(istd, session, "istd%llu", session->sid);
-
-	if (IS_ERR(task))
-		err = PTR_ERR(task);
-	else
-		info->task = task;
-
-	return err;
-}
-
-int nthread_stop(struct iscsi_session *session)
-{
-	int err;
-	struct network_thread_info *info = &session->nthread_info;
-
-	if (!info->task)
-		return -ESRCH;
-
-	err = kthread_stop(info->task);
-
-	if (!err)
-		info->task = NULL;
-
-	return err;
-}



From tomo at berlios.de  Sat Apr 29 15:49:44 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 15:49:44 +0200
Subject: [Stgt-svn] r430 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291349.k3TDnic5018766@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 15:49:25 +0200 (Sat, 29 Apr 2006)
New Revision: 430

Added:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Removed:
   branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
Modified:
   branches/use-scsi-ml/istgt/kernel/Makefile
Log:
Rename istgt_tcp iscsi_tcp_tgt, though I'm not still sure what we call this driver.

Modified: branches/use-scsi-ml/istgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 13:47:13 UTC (rev 429)
+++ branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 13:49:25 UTC (rev 430)
@@ -10,7 +10,7 @@
 EXTRA_CFLAGS += -I$(obj) -I$(KERNELSRC)/drivers/scsi/
 
 ifneq ($(KERNELRELEASE),)
-obj-m		+= istgt_tcp.o
+obj-m		+= iscsi_tcp_tgt.o
 #obj-m		+= libistgt.o
 else
 

Copied: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c (from rev 428, branches/use-scsi-ml/istgt/kernel/istgt_tcp.c)

Deleted: branches/use-scsi-ml/istgt/kernel/istgt_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-29 13:47:13 UTC (rev 429)
+++ branches/use-scsi-ml/istgt/kernel/istgt_tcp.c	2006-04-29 13:49:25 UTC (rev 430)
@@ -1,1337 +0,0 @@
-/*
- * iSCSI Target over TCP/IP
- *
- * Copyright (C) 2004 Dmitry Yusupov
- * Copyright (C) 2004 Alex Aizman
- * Copyright (C) 2005 - 2006 Mike Christie
- * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
- * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published
- * by the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * General Public License for more details.
- *
- * See the file COPYING included with this distribution for more details.
- */
-
-/*
- * Most part is taken from iscsi_tcp. Integrating with iscsi_tcp would
- * be nice...
- */
-#include <linux/types.h>
-#include <linux/list.h>
-#include <linux/inet.h>
-#include <linux/blkdev.h>
-#include <linux/crypto.h>
-#include <linux/delay.h>
-#include <linux/kfifo.h>
-#include <linux/scatterlist.h>
-#include <linux/mutex.h>
-#include <net/tcp.h>
-#include <scsi/scsi_cmnd.h>
-#include <scsi/scsi_host.h>
-#include <scsi/scsi.h>
-#include <iscsi_tcp.h>
-#include <scsi/libiscsi.h>
-#include <scsi/scsi_transport_iscsi.h>
-#include <scsi/scsi_tgt.h>
-#include <scsi/scsi_tcq.h>
-
-/* tmp - will replace with SCSI logging stuff */
-#define eprintk(fmt, args...)					\
-do {								\
-	printk("%s(%d) " fmt, __FUNCTION__, __LINE__, ##args);	\
-} while (0)
-
-#define dprintk eprintk
-
-struct istgt_session {
-	struct list_head recvlist;
-	/* replace with array later on */
-	struct list_head cmd_hash;
-	spinlock_t slock;
-	struct work_struct recvwork;
-};
-
-struct istgt_task {
-	struct list_head hash;
-	struct list_head tlist;
-};
-
-static kmem_cache_t *taskcache;
-
-static inline struct istgt_task *ctask_to_ttask(struct iscsi_cmd_task *ctask)
-{
-	return (struct istgt_task *) ((void *) ctask->dd_data +
-				      sizeof(struct iscsi_tcp_cmd_task));
-}
-
-static inline struct iscsi_cmd_task *ttask_to_ctask(struct istgt_task *ttask)
-{
-	return (struct iscsi_cmd_task *)
-		((void *) ttask - sizeof(struct iscsi_tcp_cmd_task));
-}
-
-static void build_r2t(struct iscsi_cmd_task *ctask)
-{
-	struct iscsi_r2t_rsp *hdr;
-	struct iscsi_data_task *dtask;
-	struct iscsi_r2t_info *r2t;
-/* 	struct iscsi_session *session = ctask->conn->session; */
-	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-/* 	struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data; */
-	int rc;
-
-/* 	length = req->r2t_length; */
-/* 	burst = req->conn->session->param.max_burst_length; */
-/* 	offset = be32_to_cpu(cmd_hdr(req)->data_length) - length; */
-/* more: */
-	rc = __kfifo_get(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
-	BUG_ON(!rc);
-
-	dtask = mempool_alloc(tcp_ctask->datapool, GFP_ATOMIC);
-	BUG_ON(!dtask);
-
-	INIT_LIST_HEAD(&dtask->item);
-	r2t->dtask = dtask;
-	hdr = (struct iscsi_r2t_rsp *) &dtask->hdr;
-
-/* 	rsp->pdu.bhs.ttt = req->target_task_tag; */
-
-	hdr->opcode = ISCSI_OP_R2T;
-	hdr->flags = ISCSI_FLAG_CMD_FINAL;
-	memcpy(hdr->lun, ctask->hdr->lun, 8);
-	hdr->itt = ctask->hdr->itt;
-	hdr->r2tsn = cpu_to_be32(tcp_ctask->exp_r2tsn++);
-/* 	hdr->data_offset = cpu_to_be32(offset); */
-/* 	if (length > burst) { */
-/* 		rsp_hdr->data_length = cpu_to_be32(burst); */
-/* 		length -= burst; */
-/* 		offset += burst; */
-/* 	} else { */
-/* 		rsp_hdr->data_length = cpu_to_be32(length); */
-/* 		length = 0; */
-/* 	} */
-
-	dprintk("%x %u %u %u\n", ctask->hdr->itt,
-		be32_to_cpu(hdr->data_length),
-		be32_to_cpu(hdr->data_offset),
-		be32_to_cpu(hdr->r2tsn));
-
-/* 	if (++req->outstanding_r2t >= req->conn->session->param.max_outstanding_r2t) */
-/* 		break; */
-
-	__kfifo_put(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
-
-/* 	if (length) */
-/* 		goto more; */
-}
-
-static void istgt_scsi_tgt_queue_command(struct iscsi_cmd_task *ctask)
-{
-	struct iscsi_session *session = ctask->conn->session;
-	struct iscsi_cls_session *cls_session = session_to_cls(session);
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-	struct iscsi_cmd *hdr = ctask->hdr;
-	struct scsi_cmnd *scmd;
-	enum dma_data_direction dir;
-
-	if (hdr->flags & ISCSI_FLAG_CMD_WRITE)
-		dir = DMA_TO_DEVICE;
-	else if (hdr->flags & ISCSI_FLAG_CMD_READ)
-		dir = DMA_FROM_DEVICE;
-	else
-		dir = DMA_NONE;
-
-	scmd = scsi_host_get_command(shost, dir, GFP_KERNEL);
-	BUG_ON(!scmd);
-	ctask->sc = scmd;
-
-	memcpy(scmd->data_cmnd, hdr->cdb, MAX_COMMAND_SIZE);
-	scmd->request_bufflen = be32_to_cpu(hdr->data_length);
-	scmd->SCp.ptr = (void *) ctask;
-
-	switch (hdr->flags & ISCSI_FLAG_CMD_ATTR_MASK) {
-	case ISCSI_ATTR_UNTAGGED:
-	case ISCSI_ATTR_SIMPLE:
-		scmd->tag = MSG_SIMPLE_TAG;
-		break;
-	case ISCSI_ATTR_ORDERED:
-		scmd->tag = MSG_ORDERED_TAG;
-		break;
-	case ISCSI_ATTR_HEAD_OF_QUEUE:
-		scmd->tag = MSG_HEAD_TAG;
-		break;
-	case ISCSI_ATTR_ACA:
-		scmd->tag = MSG_SIMPLE_TAG;
-		break;
-	default:
-		scmd->tag = MSG_SIMPLE_TAG;
-	}
-
-	if (scmd->sc_data_direction == DMA_TO_DEVICE &&
-	    be32_to_cpu(hdr->data_length)) {
-		switch (hdr->cdb[0]) {
-		case WRITE_6:
-		case WRITE_10:
-		case WRITE_16:
-		case WRITE_VERIFY:
-			break;
-		default:
-			eprintk("%x\n", hdr->cdb[0]);
-			break;
-		}
-	}
-
-	scsi_tgt_queue_command(scmd, (struct scsi_lun *) hdr->lun, hdr->itt);
-}
-
-static void istgt_scsi_cmnd_exec(struct iscsi_cmd_task *ctask)
-{
-	struct scsi_cmnd *scmd = ctask->sc;
-
-	if (ctask->data_count) {
-		if (!ctask->unsol_count)
-			;
-/* 			send_r2t(ctask); */
-	} else {
-/* 		set_cmd_waitio(cmnd); */
-		if (scmd) {
-/* 			BUG_ON(!ctask->done); */
-/* 			cmnd->done(scmd); */
-		} else
-			istgt_scsi_tgt_queue_command(ctask);
-	}
-}
-
-static void istgt_cmd_exec(struct iscsi_cmd_task *ctask)
-{
-	u8 opcode;
-
-	opcode = ctask->hdr->opcode & ISCSI_OPCODE_MASK;
-
-	dprintk("%p,%x,%u\n", ctask, opcode, ctask->hdr->cmdsn);
-
-	switch (opcode) {
-	case ISCSI_OP_NOOP_OUT:
-/* 		noop_out_exec(cmnd); */
-		break;
-	case ISCSI_OP_SCSI_CMD:
-		istgt_scsi_cmnd_exec(ctask);
-		break;
-	case ISCSI_OP_SCSI_TMFUNC:
-/* 		execute_task_management(cmnd); */
-		break;
-	case ISCSI_OP_LOGOUT:
-/* 		logout_exec(cmnd); */
-		break;
-/* 	case ISCSI_OP_SCSI_REJECT: */
-/* 		iscsi_cmnd_init_write(get_rsp_cmnd(cmnd)); */
-/* 		break; */
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_SNACK:
-		break;
-	default:
-		eprintk("unexpected cmnd op %x\n", ctask->hdr->opcode);
-		break;
-	}
-}
-
-static void istgt_recvworker(void *data)
-{
-	struct iscsi_cls_session *cls_session = data;
-	struct iscsi_session *session =
-		class_to_transport_session(cls_session);
-	struct istgt_session *istgt_session =
-		(struct istgt_session *) cls_session->dd_data;
-	struct iscsi_cmd_task *ctask;
-	struct istgt_task *pos;
-
-retry:
-	spin_lock_bh(&istgt_session->slock);
-
-	while (istgt_session->recvlist.next) {
-		pos = list_entry(istgt_session->recvlist.next,
-				 struct istgt_task, tlist);
-		ctask = ttask_to_ctask(pos);
-		if (ctask->hdr->cmdsn != session->exp_cmdsn)
-			break;
-
-		list_del(&pos->tlist);
-		session->exp_cmdsn++;
-
-		spin_unlock_bh(&istgt_session->slock);
-		istgt_cmd_exec(ctask);
-		goto retry;
-	}
-
-	spin_unlock_bh(&istgt_session->slock);
-}
-
-static void istgt_ctask_recvlist_add(struct iscsi_cmd_task *ctask)
-{
-	struct iscsi_session *session = ctask->conn->session;
-	struct iscsi_cls_session *cls_session = session_to_cls(session);
-	struct istgt_session *istgt_session;
-	struct istgt_task *pos;
-
-	istgt_session = (struct istgt_session *) cls_session->dd_data;
-
-	spin_lock_bh(&istgt_session->slock);
-
-	if (ctask->hdr->opcode & ISCSI_OP_IMMEDIATE) {
-		list_add(&ctask_to_ttask(ctask)->tlist,
-			 &istgt_session->recvlist);
-		goto out;
-	}
-
-	list_for_each_entry(pos, &istgt_session->recvlist, tlist)
-		if (before(ctask->hdr->cmdsn, ttask_to_ctask(pos)->hdr->cmdsn))
-			break;
-
-	list_add_tail(&ctask_to_ttask(ctask)->tlist, &pos->tlist);
-out:
-	spin_unlock_bh(&istgt_session->slock);
-}
-
-static int
-istgt_tcp_ctask_xmit(struct iscsi_conn *conn, struct iscsi_mgmt_task *mtask)
-{
-	return 0;
-}
-
-static void istgt_unsolicited_data(struct iscsi_cmd_task *ctask)
-{
-/* 	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data; */
-
-	istgt_scsi_tgt_queue_command(ctask);
-/* 	tcp_ctask->r2t_data_count; */
-/* 	ctask->r2t_data_count; */
-}
-
-/*
- * the followings are taken from iscsi_tcp.
- */
-
-int iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
-{
-	int rc = 0, opcode, ahslen;
-	struct iscsi_hdr *hdr;
-	struct iscsi_session *session = conn->session;
-	struct iscsi_cls_session *cls_session = session_to_cls(session);
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct Scsi_Host *shost;
-	uint32_t cdgst, rdgst = 0;
-	struct iscsi_cmd_task *ctask = NULL;
-
-	shost = iscsi_session_to_shost(cls_session);
-	hdr = tcp_conn->in.hdr;
-
-	/* verify PDU length */
-	tcp_conn->in.datalen = ntoh24(hdr->dlength);
-	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
-		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
-		       tcp_conn->in.datalen, conn->max_recv_dlength);
-		return ISCSI_ERR_DATALEN;
-	}
-	tcp_conn->data_copied = 0;
-
-	/* read AHS */
-	ahslen = hdr->hlength << 2;
-	tcp_conn->in.offset += ahslen;
-	tcp_conn->in.copy -= ahslen;
-	if (tcp_conn->in.copy < 0) {
-		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
-		       "%d bytes\n", ahslen);
-		return ISCSI_ERR_AHSLEN;
-	}
-
-	/* calculate read padding */
-	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
-	if (tcp_conn->in.padding) {
-		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
-		dprintk("read padding %d bytes\n", tcp_conn->in.padding);
-	}
-
-	if (conn->hdrdgst_en) {
-		struct scatterlist sg;
-
-		sg_init_one(&sg, (u8 *)hdr,
-			    sizeof(struct iscsi_hdr) + ahslen);
-		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
-		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
-				     ahslen);
-		if (cdgst != rdgst) {
-			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
-			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
-			return ISCSI_ERR_HDR_DGST;
-		}
-	}
-
-	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
-	dprintk("opcode 0x%x offset %d copy %d ahslen %d datalen %d\n",
-		opcode, tcp_conn->in.offset, tcp_conn->in.copy,
-		ahslen, tcp_conn->in.datalen);
-
-	switch (opcode) {
-	case ISCSI_OP_NOOP_OUT:
-	case ISCSI_OP_SCSI_CMD:
-	case ISCSI_OP_SCSI_TMFUNC:
-	case ISCSI_OP_LOGOUT:
-		__kfifo_get(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
-		ctask->conn = conn;
-		memcpy(ctask->hdr, hdr, sizeof(*hdr));
-		if (opcode == ISCSI_OP_SCSI_CMD)
-			switch (ctask->hdr->cdb[0]) {
-			case WRITE_6:
-			case WRITE_10:
-			case WRITE_16:
-			case WRITE_VERIFY:
-				istgt_unsolicited_data(ctask);
-				set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
-			}
-		break;
-	case ISCSI_OP_SCSI_DATA_OUT:
-		/* Find a command in the hash list */
-		/* data_out_start(conn, cmnd); */
-		break;
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_SNACK:
-	default:
-		rc = ISCSI_ERR_BAD_OPCODE;
-	}
-
-	if (ctask)
-		tcp_conn->in.ctask = ctask;
-	return rc;
-}
-
-static inline int
-iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn)
-{
-	void *buf = tcp_conn->data;
-	int buf_size = tcp_conn->in.datalen;
-	int buf_left = buf_size - tcp_conn->data_copied;
-	int size = min(tcp_conn->in.copy, buf_left);
-	int rc;
-
-	dprintk("tcp_copy %d bytes at offset %d copied %d\n",
-		size, tcp_conn->in.offset, tcp_conn->data_copied);
-	BUG_ON(size <= 0);
-
-	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-			   (char*)buf + tcp_conn->data_copied, size);
-	BUG_ON(rc);
-
-	tcp_conn->in.offset += size;
-	tcp_conn->in.copy -= size;
-	tcp_conn->in.copied += size;
-	tcp_conn->data_copied += size;
-
-	if (buf_size != tcp_conn->data_copied)
-		return -EAGAIN;
-
-	return 0;
-}
-
-static inline void
-partial_sg_digest_update(struct iscsi_tcp_conn *tcp_conn,
-			 struct scatterlist *sg, int offset, int length)
-{
-	struct scatterlist temp;
-
-	memcpy(&temp, sg, sizeof(struct scatterlist));
-	temp.offset = offset;
-	temp.length = length;
-	crypto_digest_update(tcp_conn->data_rx_tfm, &temp, 1);
-}
-
-static inline int
-iscsi_ctask_copy(struct iscsi_tcp_conn *tcp_conn, struct iscsi_cmd_task *ctask,
-		 void *buf, int buf_size, int offset)
-{
-	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-	int buf_left = buf_size - (tcp_conn->data_copied + offset);
-	int size = min(tcp_conn->in.copy, buf_left);
-	int rc;
-
-	size = min(size, ctask->data_count);
-
-	dprintk("ctask_copy %d bytes at offset %d copied %d\n",
-		size, tcp_conn->in.offset, tcp_conn->in.copied);
-
-	BUG_ON(size <= 0);
-	BUG_ON(tcp_ctask->sent + size > ctask->total_length);
-
-	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-			   (char*)buf + (offset + tcp_conn->data_copied), size);
-	/* must fit into skb->len */
-	BUG_ON(rc);
-
-	tcp_conn->in.offset += size;
-	tcp_conn->in.copy -= size;
-	tcp_conn->in.copied += size;
-	tcp_conn->data_copied += size;
-	tcp_ctask->sent += size;
-	ctask->data_count -= size;
-
-	BUG_ON(tcp_conn->in.copy < 0);
-	BUG_ON(ctask->data_count < 0);
-
-	if (buf_size != (tcp_conn->data_copied + offset)) {
-		if (!ctask->data_count) {
-			BUG_ON(buf_size - tcp_conn->data_copied < 0);
-			/* done with this PDU */
-			return buf_size - tcp_conn->data_copied;
-		}
-		return -EAGAIN;
-	}
-
-	/* done with this buffer or with both - PDU and buffer */
-	tcp_conn->data_copied = 0;
-	return 0;
-}
-
-static int iscsi_scsi_data_in(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct iscsi_cmd_task *ctask = tcp_conn->in.ctask;
-	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-	struct scsi_cmnd *sc = ctask->sc;
-	struct scatterlist *sg;
-	int i, offset, rc = 0;
-
-	BUG_ON((void*)ctask != sc->SCp.ptr);
-
-	offset = tcp_ctask->data_offset;
-	sg = sc->request_buffer;
-
-	if (tcp_ctask->data_offset)
-		for (i = 0; i < tcp_ctask->sg_count; i++)
-			offset -= sg[i].length;
-	/* we've passed through partial sg*/
-	if (offset < 0)
-		offset = 0;
-
-	for (i = tcp_ctask->sg_count; i < sc->use_sg; i++) {
-		char *dest;
-
-		dest = kmap_atomic(sg[i].page, KM_SOFTIRQ0);
-		rc = iscsi_ctask_copy(tcp_conn, ctask, dest + sg[i].offset,
-				      sg[i].length, offset);
-		kunmap_atomic(dest, KM_SOFTIRQ0);
-		if (rc == -EAGAIN)
-			/* continue with the next SKB/PDU */
-			return rc;
-		if (!rc) {
-			if (conn->datadgst_en) {
-				if (!offset)
-					crypto_digest_update(
-							tcp_conn->data_rx_tfm,
-							&sg[i], 1);
-				else
-					partial_sg_digest_update(tcp_conn,
-							&sg[i],
-							sg[i].offset + offset,
-							sg[i].length - offset);
-			}
-			offset = 0;
-			tcp_ctask->sg_count++;
-		}
-
-		if (!ctask->data_count) {
-			if (rc && conn->datadgst_en)
-				/*
-				 * data-in is complete, but buffer not...
-				 */
-				partial_sg_digest_update(tcp_conn, &sg[i],
-						sg[i].offset, sg[i].length-rc);
-			rc = 0;
-			break;
-		}
-
-		if (!tcp_conn->in.copy)
-			return -EAGAIN;
-	}
-	BUG_ON(ctask->data_count);
-
-	return rc;
-}
-
-static int
-iscsi_data_recv(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	int rc = 0, opcode;
-
-	opcode = tcp_conn->in.hdr->opcode & ISCSI_OPCODE_MASK;
-	switch (opcode) {
-	case ISCSI_OP_SCSI_CMD:
-	case ISCSI_OP_SCSI_DATA_OUT:
-		iscsi_scsi_data_in(conn);
-		break;
-	case ISCSI_OP_TEXT:
-	case ISCSI_OP_LOGOUT:
-	case ISCSI_OP_NOOP_OUT:
-	case ISCSI_OP_ASYNC_EVENT:
-		/*
-		 * Collect data segment to the connection's data
-		 * placeholder
-		 */
-		if (iscsi_tcp_copy(tcp_conn)) {
-			rc = -EAGAIN;
-			goto exit;
-		}
-
-/* 		rc = iscsi_complete_pdu(conn, tcp_conn->in.hdr, tcp_conn->data, */
-/* 					tcp_conn->in.datalen); */
-/* 		if (!rc && conn->datadgst_en && opcode != ISCSI_OP_LOGIN_RSP) */
-/* 			iscsi_recv_digest_update(tcp_conn, tcp_conn->data, */
-/* 			  			tcp_conn->in.datalen); */
-		break;
-	default:
-		BUG_ON(1);
-	}
-exit:
-	return rc;
-}
-
-static inline int
-iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn)
-{
-	struct sk_buff *skb = tcp_conn->in.skb;
-
-	tcp_conn->in.zero_copy_hdr = 0;
-
-	if (tcp_conn->in.copy >= tcp_conn->hdr_size &&
-	    tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER) {
-		/*
-		 * Zero-copy PDU Header: using connection context
-		 * to store header pointer.
-		 */
-		if (skb_shinfo(skb)->frag_list == NULL &&
-		    !skb_shinfo(skb)->nr_frags) {
-			tcp_conn->in.hdr = (struct iscsi_hdr *)
-				((char*)skb->data + tcp_conn->in.offset);
-			tcp_conn->in.zero_copy_hdr = 1;
-		} else {
-			/* ignoring return code since we checked
-			 * in.copy before */
-			skb_copy_bits(skb, tcp_conn->in.offset,
-				&tcp_conn->hdr, tcp_conn->hdr_size);
-			tcp_conn->in.hdr = &tcp_conn->hdr;
-		}
-		tcp_conn->in.offset += tcp_conn->hdr_size;
-		tcp_conn->in.copy -= tcp_conn->hdr_size;
-	} else {
-		int hdr_remains;
-		int copylen;
-
-		/*
-		 * PDU header scattered across SKB's,
-		 * copying it... This'll happen quite rarely.
-		 */
-
-		if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
-			tcp_conn->in.hdr_offset = 0;
-
-		hdr_remains = tcp_conn->hdr_size - tcp_conn->in.hdr_offset;
-		BUG_ON(hdr_remains <= 0);
-
-		copylen = min(tcp_conn->in.copy, hdr_remains);
-		skb_copy_bits(skb, tcp_conn->in.offset,
-			(char*)&tcp_conn->hdr + tcp_conn->in.hdr_offset,
-			copylen);
-
-		dprintk("PDU gather offset %d bytes %d in.offset %d "
-			"in.copy %d\n", tcp_conn->in.hdr_offset, copylen,
-			tcp_conn->in.offset, tcp_conn->in.copy);
-
-		tcp_conn->in.offset += copylen;
-		tcp_conn->in.copy -= copylen;
-		if (copylen < hdr_remains)  {
-			tcp_conn->in_progress = IN_PROGRESS_HEADER_GATHER;
-			tcp_conn->in.hdr_offset += copylen;
-		        return -EAGAIN;
-		}
-		tcp_conn->in.hdr = &tcp_conn->hdr;
-		tcp_conn->discontiguous_hdr_cnt++;
-	        tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	return 0;
-}
-
-static int
-iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
-		unsigned int offset, size_t len)
-{
-	int rc;
-	struct iscsi_conn *conn = rd_desc->arg.data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	int processed;
-	char pad[ISCSI_PAD_LEN];
-	struct scatterlist sg;
-
-	/*
-	 * Save current SKB and its offset in the corresponding
-	 * connection context.
-	 */
-	tcp_conn->in.copy = skb->len - offset;
-	tcp_conn->in.offset = offset;
-	tcp_conn->in.skb = skb;
-	tcp_conn->in.len = tcp_conn->in.copy;
-	BUG_ON(tcp_conn->in.copy <= 0);
-	dprintk("in %d bytes\n", tcp_conn->in.copy);
-
-more:
-	tcp_conn->in.copied = 0;
-	rc = 0;
-
-	if (unlikely(conn->suspend_rx)) {
-		dprintk("conn %d Rx suspended!\n", conn->id);
-		return 0;
-	}
-
-	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER ||
-	    tcp_conn->in_progress == IN_PROGRESS_HEADER_GATHER) {
-		rc = iscsi_hdr_extract(tcp_conn);
-		if (rc) {
-		       if (rc == -EAGAIN)
-				goto nomore;
-		       else {
-				iscsi_conn_failure(conn, rc);
-				return 0;
-		       }
-		}
-
-		/*
-		 * Verify and process incoming PDU header.
-		 */
-		rc = iscsi_tcp_hdr_recv(conn);
-		if (!rc && tcp_conn->in.datalen) {
-			if (conn->datadgst_en) {
-				BUG_ON(!tcp_conn->data_rx_tfm);
-				crypto_digest_init(tcp_conn->data_rx_tfm);
-			}
-			tcp_conn->in_progress = IN_PROGRESS_DATA_RECV;
-		} else if (rc) {
-			iscsi_conn_failure(conn, rc);
-			return 0;
-		}
-	}
-
-	if (unlikely(conn->suspend_rx))
-		goto nomore;
-
-	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
-		uint32_t recv_digest;
-
-		dprintk("extra data_recv offset %d copy %d\n",
-			  tcp_conn->in.offset, tcp_conn->in.copy);
-		skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-				&recv_digest, 4);
-		tcp_conn->in.offset += 4;
-		tcp_conn->in.copy -= 4;
-		if (recv_digest != tcp_conn->in.datadgst) {
-			dprintk("iscsi_tcp: data digest error!"
-				  "0x%x != 0x%x\n", recv_digest,
-				  tcp_conn->in.datadgst);
-			iscsi_conn_failure(conn, ISCSI_ERR_DATA_DGST);
-			return 0;
-		} else {
-			dprintk("iscsi_tcp: data digest match!"
-				  "0x%x == 0x%x\n", recv_digest,
-				  tcp_conn->in.datadgst);
-			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-		}
-	}
-
-	if (tcp_conn->in_progress == IN_PROGRESS_DATA_RECV &&
-	   tcp_conn->in.copy) {
-
-		dprintk("data_recv offset %d copy %d\n",
-		       tcp_conn->in.offset, tcp_conn->in.copy);
-
-		rc = iscsi_data_recv(conn);
-		if (rc) {
-			if (rc == -EAGAIN)
-				goto again;
-			iscsi_conn_failure(conn, rc);
-			return 0;
-		}
-		tcp_conn->in.copy -= tcp_conn->in.padding;
-		tcp_conn->in.offset += tcp_conn->in.padding;
-		if (conn->datadgst_en) {
-			if (tcp_conn->in.padding) {
-				dprintk("padding -> %d\n",
-					  tcp_conn->in.padding);
-				memset(pad, 0, tcp_conn->in.padding);
-				sg_init_one(&sg, pad, tcp_conn->in.padding);
-				crypto_digest_update(tcp_conn->data_rx_tfm,
-						     &sg, 1);
-			}
-			crypto_digest_final(tcp_conn->data_rx_tfm,
-					    (u8 *) & tcp_conn->in.datadgst);
-			dprintk("rx digest 0x%x\n", tcp_conn->in.datadgst);
-			tcp_conn->in_progress = IN_PROGRESS_DDIGEST_RECV;
-		} else
-			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	dprintk("f, processed %d from out of %d padding %d\n",
-	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
-	BUG_ON(tcp_conn->in.offset - offset > len);
-
-	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
-		if (tcp_conn->in.ctask) {
-			struct iscsi_cls_session *cls_session =
-				session_to_cls(conn->session);
-			struct istgt_session *istgt_session =
-				cls_session->dd_data;
-
-			istgt_ctask_recvlist_add(tcp_conn->in.ctask);
-			tcp_conn->in.ctask = NULL;
-			schedule_work(&istgt_session->recvwork);
-		}
-
-	if (tcp_conn->in.offset - offset != len) {
-		dprintk("continue to process %d bytes\n",
-		       (int)len - (tcp_conn->in.offset - offset));
-		goto more;
-	}
-
-nomore:
-	processed = tcp_conn->in.offset - offset;
-	BUG_ON(processed == 0);
-	return processed;
-
-again:
-	processed = tcp_conn->in.offset - offset;
-	dprintk("c, processed %d from out of %d rd_desc_cnt %d\n",
-	          processed, (int)len, (int)rd_desc->count);
-	BUG_ON(processed == 0);
-	BUG_ON(processed > len);
-
-	conn->rxdata_octets += processed;
-	return processed;
-}
-
-static void
-iscsi_tcp_data_ready(struct sock *sk, int flag)
-{
-	struct iscsi_conn *conn = sk->sk_user_data;
-	read_descriptor_t rd_desc;
-
-	read_lock(&sk->sk_callback_lock);
-
-	/* use rd_desc to pass 'conn' to iscsi_tcp_data_recv */
-	rd_desc.arg.data = conn;
-	rd_desc.count = 1;
-	tcp_read_sock(sk, &rd_desc, iscsi_tcp_data_recv);
-
-	read_unlock(&sk->sk_callback_lock);
-}
-
-static void
-iscsi_tcp_state_change(struct sock *sk)
-{
-	struct iscsi_tcp_conn *tcp_conn;
-	struct iscsi_conn *conn;
-	struct iscsi_session *session;
-	void (*old_state_change)(struct sock *);
-
-	read_lock(&sk->sk_callback_lock);
-
-	conn = (struct iscsi_conn*)sk->sk_user_data;
-	session = conn->session;
-
-	if ((sk->sk_state == TCP_CLOSE_WAIT ||
-	     sk->sk_state == TCP_CLOSE) &&
-	    !atomic_read(&sk->sk_rmem_alloc)) {
-		dprintk("iscsi_tcp_state_change: TCP_CLOSE|TCP_CLOSE_WAIT\n");
-		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
-	}
-
-	tcp_conn = conn->dd_data;
-	old_state_change = tcp_conn->old_state_change;
-
-	read_unlock(&sk->sk_callback_lock);
-
-	old_state_change(sk);
-}
-
-static void
-iscsi_write_space(struct sock *sk)
-{
-	struct iscsi_conn *conn = (struct iscsi_conn*)sk->sk_user_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-
-	tcp_conn->old_write_space(sk);
-	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
-	scsi_queue_work(conn->session->host, &conn->xmitwork);
-}
-
-static void
-iscsi_conn_set_callbacks(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk = tcp_conn->sock->sk;
-
-	/* assign new callbacks */
-	write_lock_bh(&sk->sk_callback_lock);
-	sk->sk_user_data = conn;
-	tcp_conn->old_data_ready = sk->sk_data_ready;
-	tcp_conn->old_state_change = sk->sk_state_change;
-	tcp_conn->old_write_space = sk->sk_write_space;
-	sk->sk_data_ready = iscsi_tcp_data_ready;
-	sk->sk_state_change = iscsi_tcp_state_change;
-	sk->sk_write_space = iscsi_write_space;
-	write_unlock_bh(&sk->sk_callback_lock);
-}
-
-static void
-iscsi_conn_restore_callbacks(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk = tcp_conn->sock->sk;
-
-	/* restore socket callbacks, see also: iscsi_conn_set_callbacks() */
-	write_lock_bh(&sk->sk_callback_lock);
-	sk->sk_user_data    = NULL;
-	sk->sk_data_ready   = tcp_conn->old_data_ready;
-	sk->sk_state_change = tcp_conn->old_state_change;
-	sk->sk_write_space  = tcp_conn->old_write_space;
-	sk->sk_no_check	 = 0;
-	write_unlock_bh(&sk->sk_callback_lock);
-}
-
-static void
-iscsi_tcp_terminate_conn(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-
-	if (!tcp_conn->sock)
-		return;
-
-	sock_hold(tcp_conn->sock->sk);
-	iscsi_conn_restore_callbacks(conn);
-	sock_put(tcp_conn->sock->sk);
-
-	sock_release(tcp_conn->sock);
-	tcp_conn->sock = NULL;
-	conn->recv_lock = NULL;
-}
-
-static int
-iscsi_r2tpool_alloc(struct iscsi_session *session)
-{
-	int i;
-	int cmd_i;
-
-	/*
-	 * initialize per-task: R2T pool and xmit queue
-	 */
-	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
-	        struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		/*
-		 * pre-allocated x4 as much r2ts to handle race when
-		 * target acks DataOut faster than we data_xmit() queues
-		 * could replenish r2tqueue.
-		 */
-
-		/* R2T pool */
-		if (iscsi_pool_init(&tcp_ctask->r2tpool, session->max_r2t * 4,
-				    (void***)&tcp_ctask->r2ts,
-				    sizeof(struct iscsi_r2t_info))) {
-			goto r2t_alloc_fail;
-		}
-
-		/* R2T xmit queue */
-		tcp_ctask->r2tqueue = kfifo_alloc(
-		      session->max_r2t * 4 * sizeof(void*), GFP_KERNEL, NULL);
-		if (tcp_ctask->r2tqueue == ERR_PTR(-ENOMEM)) {
-			iscsi_pool_free(&tcp_ctask->r2tpool,
-					(void**)tcp_ctask->r2ts);
-			goto r2t_alloc_fail;
-		}
-
-		/*
-		 * number of
-		 * Data-Out PDU's within R2T-sequence can be quite big;
-		 * using mempool
-		 */
-		tcp_ctask->datapool = mempool_create(ISCSI_DTASK_DEFAULT_MAX,
-						     mempool_alloc_slab,
-						     mempool_free_slab,
-						     taskcache);
-		if (tcp_ctask->datapool == NULL) {
-			kfifo_free(tcp_ctask->r2tqueue);
-			iscsi_pool_free(&tcp_ctask->r2tpool,
-					(void**)tcp_ctask->r2ts);
-			goto r2t_alloc_fail;
-		}
-		INIT_LIST_HEAD(&tcp_ctask->dataqueue);
-	}
-
-	return 0;
-
-r2t_alloc_fail:
-	for (i = 0; i < cmd_i; i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		mempool_destroy(tcp_ctask->datapool);
-		kfifo_free(tcp_ctask->r2tqueue);
-		iscsi_pool_free(&tcp_ctask->r2tpool,
-				(void**)tcp_ctask->r2ts);
-	}
-	return -ENOMEM;
-}
-
-static void
-iscsi_r2tpool_free(struct iscsi_session *session)
-{
-	int i;
-
-	for (i = 0; i < session->cmds_max; i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		mempool_destroy(tcp_ctask->datapool);
-		kfifo_free(tcp_ctask->r2tqueue);
-		iscsi_pool_free(&tcp_ctask->r2tpool,
-				(void**)tcp_ctask->r2ts);
-	}
-}
-
-void istgt_session_init(struct iscsi_cls_session *cls_session)
-{
-	struct istgt_session *istgt_session =
-		(struct istgt_session *) cls_session->dd_data;
-
-	INIT_LIST_HEAD(&istgt_session->recvlist);
-	INIT_LIST_HEAD(&istgt_session->cmd_hash);
-	spin_lock_init(&istgt_session->slock);
-
-	INIT_WORK(&istgt_session->recvwork, istgt_recvworker, cls_session);
-}
-
-static struct iscsi_cls_session *
-istgt_tcp_session_create(struct iscsi_transport *iscsit,
-			 struct scsi_transport_template *scsit,
-			 uint32_t initial_cmdsn, uint32_t *hostno)
-{
-	struct Scsi_Host *shost;
-	struct iscsi_cls_session *cls_session;
-	struct iscsi_session *session;
-	uint32_t hn;
-	int err, i;
-	int cmd_task_size;
-
-	cmd_task_size = sizeof(struct iscsi_tcp_cmd_task) +
-		sizeof(struct istgt_task);
-
-	cls_session = iscsi_session_setup(iscsit, scsit,
-					  cmd_task_size,
-					  sizeof(struct iscsi_tcp_mgmt_task),
-					  initial_cmdsn, &hn);
-	if (!cls_session)
-		return NULL;
-	shost = iscsi_session_to_shost(cls_session);
-	err = scsi_tgt_alloc_queue(shost);
-	if (err)
-		goto session_free;
-	*hostno = hn;
-
-	session = class_to_transport_session(cls_session);
-	for (i = 0; i < initial_cmdsn; i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		ctask->hdr = &tcp_ctask->hdr;
-
-		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->hash);
-		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->tlist);
-	}
-
-	for (i = 0; i < session->mgmtpool_max; i++) {
-		struct iscsi_mgmt_task *mtask = session->mgmt_cmds[i];
-		struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
-
-		mtask->hdr = &tcp_mtask->hdr;
-	}
-
-	if (iscsi_r2tpool_alloc(class_to_transport_session(cls_session)))
-		goto session_free;
-
-	return cls_session;
-session_free:
-	iscsi_session_teardown(cls_session);
-	return NULL;
-}
-
-static void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
-{
-	struct iscsi_session *session = class_to_transport_session(cls_session);
-	struct iscsi_data_task *dtask, *n;
-	int cmd_i;
-
-	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		list_for_each_entry_safe(dtask, n, &tcp_ctask->dataqueue,
-					 item) {
-			list_del(&dtask->item);
-			mempool_free(dtask, tcp_ctask->datapool);
-		}
-	}
-
-	iscsi_r2tpool_free(class_to_transport_session(cls_session));
-	iscsi_session_teardown(cls_session);
-}
-
-static struct iscsi_cls_conn *
-iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
-{
-	struct iscsi_conn *conn;
-	struct iscsi_cls_conn *cls_conn;
-	struct iscsi_tcp_conn *tcp_conn;
-
-	cls_conn = iscsi_conn_setup(cls_session, conn_idx);
-	if (!cls_conn)
-		return NULL;
-	conn = cls_conn->dd_data;
-	/*
-	 * due to strange issues with iser these are not set
-	 * in iscsi_conn_setup
-	 */
-	conn->max_recv_dlength = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
-
-	tcp_conn = kzalloc(sizeof(*tcp_conn), GFP_KERNEL);
-	if (!tcp_conn)
-		goto tcp_conn_alloc_fail;
-
-	conn->dd_data = tcp_conn;
-	tcp_conn->iscsi_conn = conn;
-	tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	/* initial operational parameters */
-	tcp_conn->hdr_size = sizeof(struct iscsi_hdr);
-	tcp_conn->data_size = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
-
-	/* allocate initial PDU receive place holder */
-	if (tcp_conn->data_size <= PAGE_SIZE)
-		tcp_conn->data = kmalloc(tcp_conn->data_size, GFP_KERNEL);
-	else
-		tcp_conn->data = (void*)__get_free_pages(GFP_KERNEL,
-					get_order(tcp_conn->data_size));
-	if (!tcp_conn->data)
-		goto max_recv_dlenght_alloc_fail;
-
-	return cls_conn;
-
-max_recv_dlenght_alloc_fail:
-	kfree(tcp_conn);
-tcp_conn_alloc_fail:
-	iscsi_conn_teardown(cls_conn);
-	return NULL;
-}
-
-static void
-iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	int digest = 0;
-
-	if (conn->hdrdgst_en || conn->datadgst_en)
-		digest = 1;
-
-	iscsi_conn_teardown(cls_conn);
-
-	/* now free tcp_conn */
-	if (digest) {
-		if (tcp_conn->tx_tfm)
-			crypto_free_tfm(tcp_conn->tx_tfm);
-		if (tcp_conn->rx_tfm)
-			crypto_free_tfm(tcp_conn->rx_tfm);
-		if (tcp_conn->data_tx_tfm)
-			crypto_free_tfm(tcp_conn->data_tx_tfm);
-		if (tcp_conn->data_rx_tfm)
-			crypto_free_tfm(tcp_conn->data_rx_tfm);
-	}
-
-	/* free conn->data, size = MaxRecvDataSegmentLength */
-	if (tcp_conn->data_size <= PAGE_SIZE)
-		kfree(tcp_conn->data);
-	else
-		free_pages((unsigned long)tcp_conn->data,
-			   get_order(tcp_conn->data_size));
-	kfree(tcp_conn);
-}
-
-static int
-iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
-		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
-		    int is_leading)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk;
-	struct socket *sock;
-	int err;
-
-	/* lookup for existing socket */
-	sock = sockfd_lookup((int)transport_eph, &err);
-	if (!sock) {
-		printk(KERN_ERR "iscsi_tcp: sockfd_lookup failed %d\n", err);
-		return -EEXIST;
-	}
-
-	err = iscsi_conn_bind(cls_session, cls_conn, is_leading);
-	if (err)
-		return err;
-
-	if (conn->stop_stage != STOP_CONN_SUSPEND) {
-		/* bind iSCSI connection and socket */
-		tcp_conn->sock = sock;
-
-		/* setup Socket parameters */
-		sk = sock->sk;
-		sk->sk_reuse = 1;
-		sk->sk_sndtimeo = 15 * HZ; /* FIXME: make it configurable */
-		sk->sk_allocation = GFP_ATOMIC;
-
-		/* FIXME: disable Nagle's algorithm */
-
-		/*
-		 * Intercept TCP callbacks for sendfile like receive
-		 * processing.
-		 */
-		conn->recv_lock = &sk->sk_callback_lock;
-		iscsi_conn_set_callbacks(conn);
-		tcp_conn->sendpage = tcp_conn->sock->ops->sendpage;
-		/*
-		 * set receive state machine into initial state
-		 */
-		tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	return 0;
-}
-
-static int istgt_transfer_response(struct scsi_cmnd *scmd,
-				   void (*done)(struct scsi_cmnd *))
-{
-	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *) scmd->SCp.ptr;
-	struct iscsi_conn *conn = ctask->conn;
-	struct iscsi_cls_session *cls_session = session_to_cls(conn->session);
-	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
-
-	__kfifo_put(conn->xmitqueue, (void*)&ctask, sizeof(void*));
-	scsi_queue_work(shost, &conn->xmitwork);
-
-	return 0;
-}
-
-static int istgt_transfer_data(struct scsi_cmnd *scmd,
-				  void (*done)(struct scsi_cmnd *))
-{
-	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *) scmd->SCp.ptr;
-
-	if (scmd->sc_data_direction == DMA_TO_DEVICE) {
-		struct iscsi_tcp_conn *tcp_conn = ctask->conn->dd_data;
-		struct sock *sk = tcp_conn->sock->sk;
-
-		/* FIXME: too hacky */
-		bh_lock_sock(sk);
-
-		if (tcp_conn->in.ctask == ctask) {
-			clear_bit(ISCSI_SUSPEND_BIT, &ctask->conn->suspend_rx);
-			sk->sk_data_ready(sk, 0);
-		}
-
-		bh_unlock_sock(sk);
-	}
-	done(scmd);
-
-	return 0;
-}
-
-static int istgt_tcp_eh_abort_handler(struct scsi_cmnd *scmd)
-{
-	BUG();
-	return 0;
-}
-
-#define	DEFAULT_NR_QUEUED_CMNDS	32
-#define TGT_NAME "istgt_tcp"
-
-static struct scsi_host_template istgt_tcp_sht = {
-	.name			= TGT_NAME,
-	.module			= THIS_MODULE,
-	.can_queue		= DEFAULT_NR_QUEUED_CMNDS,
-	.sg_tablesize		= SG_ALL,
-	.max_sectors		= 65535,
-	.use_clustering		= DISABLE_CLUSTERING,
-	.transfer_response	= istgt_transfer_response,
-	.transfer_data		= istgt_transfer_data,
-	.eh_abort_handler	= istgt_tcp_eh_abort_handler,
-};
-
-static struct iscsi_transport istgt_tcp_transport = {
-	.owner			= THIS_MODULE,
-	.name			= TGT_NAME,
-	.host_template		= &istgt_tcp_sht,
-	.conndata_size		= sizeof(struct iscsi_conn),
-	.sessiondata_size	= sizeof(struct istgt_session),
-	.max_conn		= 1,
-	.max_cmd_len		= ISCSI_TCP_MAX_CMD_LEN,
-	.create_session		= istgt_tcp_session_create,
-	.destroy_session	= iscsi_tcp_session_destroy,
-	.create_conn		= iscsi_tcp_conn_create,
-	.destroy_conn		= iscsi_tcp_conn_destroy,
-	.bind_conn		= iscsi_tcp_conn_bind,
-	.start_conn		= iscsi_conn_start,
-	.terminate_conn		= iscsi_tcp_terminate_conn,
-	.xmit_cmd_task		= istgt_tcp_ctask_xmit,
-};
-
-static int __init istgt_tcp_init(void)
-{
-	printk("iSCSI Target over TCP\n");
-
-	taskcache = kmem_cache_create("istgt_taskcache",
-				      sizeof(struct iscsi_data_task), 0,
-				      SLAB_HWCACHE_ALIGN, NULL, NULL);
-	if (!taskcache)
-		return -ENOMEM;
-
-	if (!iscsi_register_transport(&istgt_tcp_transport))
-		goto free_taskcache;
-	return 0;
-free_taskcache:
-	kmem_cache_destroy(taskcache);
-	return -ENOMEM;
-}
-
-static void __exit istgt_tcp_exit(void)
-{
-	iscsi_unregister_transport(&istgt_tcp_transport);
-	kmem_cache_destroy(taskcache);
-}
-
-module_init(istgt_tcp_init);
-module_exit(istgt_tcp_exit);
-
-MODULE_DESCRIPTION("iSCSI target over TCP");
-MODULE_LICENSE("GPL");



From tomo at berlios.de  Sat Apr 29 15:54:45 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 15:54:45 +0200
Subject: [Stgt-svn] r431 - branches/use-scsi-ml/istgt/include
Message-ID: <200604291354.k3TDsjHq024561@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 15:54:19 +0200 (Sat, 29 Apr 2006)
New Revision: 431

Removed:
   branches/use-scsi-ml/istgt/include/istgt_u.h
Log:
Remove the last old file.

Deleted: branches/use-scsi-ml/istgt/include/istgt_u.h
===================================================================
--- branches/use-scsi-ml/istgt/include/istgt_u.h	2006-04-29 13:49:25 UTC (rev 430)
+++ branches/use-scsi-ml/istgt/include/istgt_u.h	2006-04-29 13:54:19 UTC (rev 431)
@@ -1,123 +0,0 @@
-#ifndef _ISTGT_U_H
-#define _ISTGT_U_H
-
-#define VERSION_STRING	"0.4.12"
-#define	THIS_NAME		"istgt"
-
-/* The maximum length of 223 bytes in the RFC. */
-#define ISCSI_NAME_LEN	256
-
-#define VENDOR_ID_LEN	8
-#define SCSI_ID_LEN	24
-
-struct session_info {
-	int tid;
-
-	uint64_t sid;
-	uint32_t exp_cmd_sn;
-	uint32_t max_cmd_sn;
-};
-
-#define DIGEST_ALL	(DIGEST_NONE | DIGEST_CRC32C)
-#define DIGEST_NONE		(1 << 0)
-#define DIGEST_CRC32C           (1 << 1)
-
-struct conn_info {
-	int tid;
-	uint64_t sid;
-
-	uint32_t cid;
-	uint32_t stat_sn;
-	uint32_t exp_stat_sn;
-	int header_digest;
-	int data_digest;
-	int fd;
-};
-
-enum {
-	key_initial_r2t,
-	key_immediate_data,
-	key_max_connections,
-	key_max_recv_data_length,
-	key_max_xmit_data_length,
-	key_max_burst_length,
-	key_first_burst_length,
-	key_default_wait_time,
-	key_default_retain_time,
-	key_max_outstanding_r2t,
-	key_data_pdu_inorder,
-	key_data_sequence_inorder,
-	key_error_recovery_level,
-	key_header_digest,
-	key_data_digest,
-	key_ofmarker,
-	key_ifmarker,
-	key_ofmarkint,
-	key_ifmarkint,
-	session_key_last,
-};
-
-enum {
-	key_queued_cmnds,
-	target_key_last,
-};
-
-enum {
-	key_session,
-	key_target,
-};
-
-struct iscsi_param_info {
-	int tid;
-	uint64_t sid;
-
-	uint32_t param_type;
-	uint32_t partial;
-
-	uint32_t session_param[session_key_last];
-	uint32_t target_param[target_key_last];
-};
-
-enum iet_event_state {
-	E_CONN_CLOSE,
-};
-
-/*
- * msg types
- */
-enum {
-	IET_ADD_SESSION,
-	IET_DEL_SESSION,
-	IET_ADD_CONN,
-	IET_DEL_CONN,
-	IET_ISCSI_PARAM_SET,
-	IET_ISCSI_PARAM_GET,
-};
-
-struct iet_msg {
-	uint32_t msg_type;
-	uint32_t result;
-
-	/* user-> kernel */
-	union {
-		struct session_info sess_info;
-		struct conn_info conn_info;
-		struct iscsi_param_info param_info;
-	} u;
-
-	/* kernel -> user */
-	union {
-		struct {
-			int tid;
-			uint64_t sid;
-			uint32_t cid;
-			uint32_t state;
-		} conn_state_change;
-	} k;
-} __attribute__ ((aligned (sizeof(uint64_t))));
-
-#define	DEFAULT_NR_QUEUED_CMNDS	32
-#define	MIN_NR_QUEUED_CMNDS	1
-#define	MAX_NR_QUEUED_CMNDS	256
-
-#endif



From tomo at berlios.de  Sat Apr 29 16:03:32 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 16:03:32 +0200
Subject: [Stgt-svn] r432 - in branches/use-scsi-ml/istgt: include kernel
Message-ID: <200604291403.k3TE3WMA005965@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 16:03:22 +0200 (Sat, 29 Apr 2006)
New Revision: 432

Added:
   branches/use-scsi-ml/istgt/include/iscsi_if.h
   branches/use-scsi-ml/istgt/include/iscsi_proto.h
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
   branches/use-scsi-ml/istgt/kernel/libiscsi.c
   branches/use-scsi-ml/istgt/kernel/libiscsi.h
   branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.c
   branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.h
Modified:
   branches/use-scsi-ml/istgt/kernel/Makefile
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
For convenience, took open-iscsi rev561 files.


Added: branches/use-scsi-ml/istgt/include/iscsi_if.h
===================================================================
--- branches/use-scsi-ml/istgt/include/iscsi_if.h	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/include/iscsi_if.h	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,311 @@
+/*
+ * iSCSI User/Kernel Shares (Defines, Constants, Protocol definitions, etc)
+ *
+ * Copyright (C) 2005 Dmitry Yusupov
+ * Copyright (C) 2005 Alex Aizman
+ * maintained by open-iscsi at googlegroups.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published
+ * by the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * See the file COPYING included with this distribution for more details.
+ */
+
+#ifndef ISCSI_IF_H
+#define ISCSI_IF_H
+
+#include <iscsi_proto.h>
+
+#define UEVENT_BASE			10
+#define KEVENT_BASE			100
+#define ISCSI_ERR_BASE			1000
+
+enum iscsi_uevent_e {
+	ISCSI_UEVENT_UNKNOWN		= 0,
+
+	/* down events */
+	ISCSI_UEVENT_CREATE_SESSION	= UEVENT_BASE + 1,
+	ISCSI_UEVENT_DESTROY_SESSION	= UEVENT_BASE + 2,
+	ISCSI_UEVENT_CREATE_CONN	= UEVENT_BASE + 3,
+	ISCSI_UEVENT_DESTROY_CONN	= UEVENT_BASE + 4,
+	ISCSI_UEVENT_BIND_CONN		= UEVENT_BASE + 5,
+	ISCSI_UEVENT_SET_PARAM		= UEVENT_BASE + 6,
+	ISCSI_UEVENT_START_CONN		= UEVENT_BASE + 7,
+	ISCSI_UEVENT_STOP_CONN		= UEVENT_BASE + 8,
+	ISCSI_UEVENT_SEND_PDU		= UEVENT_BASE + 9,
+	ISCSI_UEVENT_GET_STATS		= UEVENT_BASE + 10,
+	ISCSI_UEVENT_GET_PARAM		= UEVENT_BASE + 11,
+
+	ISCSI_UEVENT_TRANSPORT_EP_CONNECT	= UEVENT_BASE + 12,
+	ISCSI_UEVENT_TRANSPORT_EP_POLL		= UEVENT_BASE + 13,
+	ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT	= UEVENT_BASE + 14,
+
+	/* up events */
+	ISCSI_KEVENT_RECV_PDU		= KEVENT_BASE + 1,
+	ISCSI_KEVENT_CONN_ERROR		= KEVENT_BASE + 2,
+	ISCSI_KEVENT_IF_ERROR		= KEVENT_BASE + 3,
+};
+
+struct iscsi_uevent {
+	uint32_t type; /* k/u events type */
+	uint32_t iferror; /* carries interface or resource errors */
+	uint64_t transport_handle;
+
+	union {
+		/* messages u -> k */
+		struct msg_create_session {
+			uint32_t	initial_cmdsn;
+		} c_session;
+		struct msg_destroy_session {
+			uint32_t	sid;
+		} d_session;
+		struct msg_create_conn {
+			uint32_t	sid;
+			uint32_t	cid;
+		} c_conn;
+		struct msg_bind_conn {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint64_t	transport_eph;
+			uint32_t	is_leading;
+		} b_conn;
+		struct msg_destroy_conn {
+			uint32_t	sid;
+			uint32_t	cid;
+		} d_conn;
+		struct msg_send_pdu {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint32_t	hdr_size;
+			uint32_t	data_size;
+		} send_pdu;
+		struct msg_set_param {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint32_t	param; /* enum iscsi_param */
+			uint32_t	len;
+		} set_param;
+		struct msg_start_conn {
+			uint32_t	sid;
+			uint32_t	cid;
+		} start_conn;
+		struct msg_stop_conn {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint64_t	conn_handle;
+			uint32_t	flag;
+		} stop_conn;
+		struct msg_get_stats {
+			uint32_t	sid;
+			uint32_t	cid;
+		} get_stats;
+		struct msg_transport_connect {
+			uint32_t	non_blocking;
+		} ep_connect;
+		struct msg_transport_poll {
+			uint64_t	ep_handle;
+			uint32_t	timeout_ms;
+		} ep_poll;
+		struct msg_transport_disconnect {
+			uint64_t	ep_handle;
+		} ep_disconnect;
+	} u;
+	union {
+		/* messages k -> u */
+		int			retcode;
+		struct msg_create_session_ret {
+			uint32_t	sid;
+			uint32_t	host_no;
+		} c_session_ret;
+		struct msg_create_conn_ret {
+			uint32_t	sid;
+			uint32_t	cid;
+		} c_conn_ret;			
+		struct msg_recv_req {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint64_t	recv_handle;
+		} recv_req;
+		struct msg_conn_error {
+			uint32_t	sid;
+			uint32_t	cid;
+			uint32_t	error; /* enum iscsi_err */
+		} connerror;
+		struct msg_transport_connect_ret {
+			uint64_t	handle;
+		} ep_connect_ret;
+	} r;
+} __attribute__ ((aligned (sizeof(uint64_t))));
+
+/*
+ * Common error codes
+ */
+enum iscsi_err {
+	ISCSI_OK			= 0,
+
+	ISCSI_ERR_DATASN		= ISCSI_ERR_BASE + 1,
+	ISCSI_ERR_DATA_OFFSET		= ISCSI_ERR_BASE + 2,
+	ISCSI_ERR_MAX_CMDSN		= ISCSI_ERR_BASE + 3,
+	ISCSI_ERR_EXP_CMDSN		= ISCSI_ERR_BASE + 4,
+	ISCSI_ERR_BAD_OPCODE		= ISCSI_ERR_BASE + 5,
+	ISCSI_ERR_DATALEN		= ISCSI_ERR_BASE + 6,
+	ISCSI_ERR_AHSLEN		= ISCSI_ERR_BASE + 7,
+	ISCSI_ERR_PROTO			= ISCSI_ERR_BASE + 8,
+	ISCSI_ERR_LUN			= ISCSI_ERR_BASE + 9,
+	ISCSI_ERR_BAD_ITT		= ISCSI_ERR_BASE + 10,
+	ISCSI_ERR_CONN_FAILED		= ISCSI_ERR_BASE + 11,
+	ISCSI_ERR_R2TSN			= ISCSI_ERR_BASE + 12,
+	ISCSI_ERR_SESSION_FAILED	= ISCSI_ERR_BASE + 13,
+	ISCSI_ERR_HDR_DGST		= ISCSI_ERR_BASE + 14,
+	ISCSI_ERR_DATA_DGST		= ISCSI_ERR_BASE + 15,
+	ISCSI_ERR_PARAM_NOT_FOUND	= ISCSI_ERR_BASE + 16,
+	ISCSI_ERR_NO_SCSI_CMD		= ISCSI_ERR_BASE + 17,
+};
+
+/*
+ * iSCSI Parameters (RFC3720)
+ */
+enum iscsi_param {
+	/* passed in using netlink set param */
+	ISCSI_PARAM_MAX_RECV_DLENGTH,
+	ISCSI_PARAM_MAX_XMIT_DLENGTH,
+	ISCSI_PARAM_HDRDGST_EN,
+	ISCSI_PARAM_DATADGST_EN,
+	ISCSI_PARAM_INITIAL_R2T_EN,
+	ISCSI_PARAM_MAX_R2T,
+	ISCSI_PARAM_IMM_DATA_EN,
+	ISCSI_PARAM_FIRST_BURST,
+	ISCSI_PARAM_MAX_BURST,
+	ISCSI_PARAM_PDU_INORDER_EN,
+	ISCSI_PARAM_DATASEQ_INORDER_EN,
+	ISCSI_PARAM_ERL,
+	ISCSI_PARAM_IFMARKER_EN,
+	ISCSI_PARAM_OFMARKER_EN,
+	ISCSI_PARAM_EXP_STATSN,
+	ISCSI_PARAM_TARGET_NAME,
+	ISCSI_PARAM_TPGT,
+	ISCSI_PARAM_PERSISTENT_ADDRESS,
+	ISCSI_PARAM_PERSISTENT_PORT,
+	ISCSI_PARAM_SESS_RECOVERY_TMO,
+
+	/* pased in through bind conn using transport_fd */
+	ISCSI_PARAM_CONN_PORT,
+	ISCSI_PARAM_CONN_ADDRESS,
+
+	/* must always be last */
+	ISCSI_PARAM_MAX,
+};
+
+#define ISCSI_MAX_RECV_DLENGTH		(1 << ISCSI_PARAM_MAX_RECV_DLENGTH)
+#define ISCSI_MAX_XMIT_DLENGTH		(1 << ISCSI_PARAM_MAX_XMIT_DLENGTH)
+#define ISCSI_HDRDGST_EN		(1 << ISCSI_PARAM_HDRDGST_EN)
+#define ISCSI_DATADGST_EN		(1 << ISCSI_PARAM_DATADGST_EN)
+#define ISCSI_INITIAL_R2T_EN		(1 << ISCSI_PARAM_INITIAL_R2T_EN)
+#define ISCSI_MAX_R2T			(1 << ISCSI_PARAM_MAX_R2T)
+#define ISCSI_IMM_DATA_EN		(1 << ISCSI_PARAM_IMM_DATA_EN)
+#define ISCSI_FIRST_BURST		(1 << ISCSI_PARAM_FIRST_BURST)
+#define ISCSI_MAX_BURST			(1 << ISCSI_PARAM_MAX_BURST)
+#define ISCSI_PDU_INORDER_EN		(1 << ISCSI_PARAM_PDU_INORDER_EN)
+#define ISCSI_DATASEQ_INORDER_EN	(1 << ISCSI_PARAM_DATASEQ_INORDER_EN)
+#define ISCSI_ERL			(1 << ISCSI_PARAM_ERL)
+#define ISCSI_IFMARKER_EN		(1 << ISCSI_PARAM_IFMARKER_EN)
+#define ISCSI_OFMARKER_EN		(1 << ISCSI_PARAM_OFMARKER_EN)
+#define ISCSI_EXP_STATSN		(1 << ISCSI_PARAM_EXP_STATSN)
+#define ISCSI_TARGET_NAME		(1 << ISCSI_PARAM_TARGET_NAME)
+#define ISCSI_TPGT			(1 << ISCSI_PARAM_TPGT)
+#define ISCSI_PERSISTENT_ADDRESS	(1 << ISCSI_PARAM_PERSISTENT_ADDRESS)
+#define ISCSI_PERSISTENT_PORT		(1 << ISCSI_PARAM_PERSISTENT_PORT)
+#define ISCSI_SESS_RECOVERY_TMO		(1 << ISCSI_PARAM_SESS_RECOVERY_TMO)
+#define ISCSI_CONN_PORT			(1 << ISCSI_PARAM_CONN_PORT)
+#define ISCSI_CONN_ADDRESS		(1 << ISCSI_PARAM_CONN_ADDRESS)
+
+#define iscsi_ptr(_handle) ((void*)(unsigned long)_handle)
+#define iscsi_handle(_ptr) ((uint64_t)(unsigned long)_ptr)
+#define hostdata_session(_hostdata) (iscsi_ptr(*(unsigned long *)_hostdata))
+
+/**
+ * iscsi_hostdata - get LLD hostdata from scsi_host
+ * @_hostdata: pointer to scsi host's hostdata
+ **/
+#define iscsi_hostdata(_hostdata) ((void*)_hostdata + sizeof(unsigned long))
+
+/*
+ * These flags presents iSCSI Data-Path capabilities.
+ */
+#define CAP_RECOVERY_L0		0x1
+#define CAP_RECOVERY_L1		0x2
+#define CAP_RECOVERY_L2		0x4
+#define CAP_MULTI_R2T		0x8
+#define CAP_HDRDGST		0x10
+#define CAP_DATADGST		0x20
+#define CAP_MULTI_CONN		0x40
+#define CAP_TEXT_NEGO		0x80
+#define CAP_MARKERS		0x100
+
+/*
+ * These flags describes reason of stop_conn() call
+ */
+#define STOP_CONN_TERM		0x1
+#define STOP_CONN_SUSPEND	0x2
+#define STOP_CONN_RECOVER	0x3
+
+#define ISCSI_STATS_CUSTOM_MAX		32
+#define ISCSI_STATS_CUSTOM_DESC_MAX	64
+struct iscsi_stats_custom {
+	char desc[ISCSI_STATS_CUSTOM_DESC_MAX];
+	uint64_t value;
+};
+
+/*
+ * struct iscsi_stats - iSCSI Statistics (iSCSI MIB)
+ *
+ * Note: this structure contains counters collected on per-connection basis.
+ */
+struct iscsi_stats {
+	/* octets */
+	uint64_t txdata_octets;
+	uint64_t rxdata_octets;
+
+	/* xmit pdus */
+	uint32_t noptx_pdus;
+	uint32_t scsicmd_pdus;
+	uint32_t tmfcmd_pdus;
+	uint32_t login_pdus;
+	uint32_t text_pdus;
+	uint32_t dataout_pdus;
+	uint32_t logout_pdus;
+	uint32_t snack_pdus;
+
+	/* recv pdus */
+	uint32_t noprx_pdus;
+	uint32_t scsirsp_pdus;
+	uint32_t tmfrsp_pdus;
+	uint32_t textrsp_pdus;
+	uint32_t datain_pdus;
+	uint32_t logoutrsp_pdus;
+	uint32_t r2t_pdus;
+	uint32_t async_pdus;
+	uint32_t rjt_pdus;
+
+	/* errors */
+	uint32_t digest_err;
+	uint32_t timeout_err;
+
+	/*
+	 * iSCSI Custom Statistics support, i.e. Transport could
+	 * extend existing MIB statistics with its own specific statistics
+	 * up to ISCSI_STATS_CUSTOM_MAX
+	 */
+	uint32_t custom_length;
+	struct iscsi_stats_custom custom[0]
+		__attribute__ ((aligned (sizeof(uint64_t))));
+};
+
+#endif

Added: branches/use-scsi-ml/istgt/include/iscsi_proto.h
===================================================================
--- branches/use-scsi-ml/istgt/include/iscsi_proto.h	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/include/iscsi_proto.h	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,589 @@
+/*
+ * RFC 3720 (iSCSI) protocol data types
+ *
+ * Copyright (C) 2005 Dmitry Yusupov
+ * Copyright (C) 2005 Alex Aizman
+ * maintained by open-iscsi at googlegroups.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published
+ * by the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * See the file COPYING included with this distribution for more details.
+ */
+
+#ifndef ISCSI_PROTO_H
+#define ISCSI_PROTO_H
+
+#define ISCSI_VERSION_STR	"0.3"
+#define ISCSI_DATE_STR		"22-Apr-2005"
+#define ISCSI_DRAFT20_VERSION	0x00
+
+/* default iSCSI listen port for incoming connections */
+#define ISCSI_LISTEN_PORT	3260
+
+/* Padding word length */
+#define PAD_WORD_LEN		4
+
+/*
+ * useful common(control and data pathes) macro
+ */
+#define ntoh24(p) (((p)[0] << 16) | ((p)[1] << 8) | ((p)[2]))
+#define hton24(p, v) { \
+        p[0] = (((v) >> 16) & 0xFF); \
+        p[1] = (((v) >> 8) & 0xFF); \
+        p[2] = ((v) & 0xFF); \
+}
+#define zero_data(p) {p[0]=0;p[1]=0;p[2]=0;}
+
+/*
+ * iSCSI Template Message Header
+ */
+struct iscsi_hdr {
+	uint8_t		opcode;
+	uint8_t		flags;		/* Final bit */
+	uint8_t		rsvd2[2];
+	uint8_t		hlength;	/* AHSs total length */
+	uint8_t		dlength[3];	/* Data length */
+	uint8_t		lun[8];
+	__be32		itt;		/* Initiator Task Tag */
+	__be32		ttt;		/* Target Task Tag */
+	__be32		statsn;
+	__be32		exp_statsn;
+	__be32		max_statsn;
+	uint8_t		other[12];
+};
+
+/************************* RFC 3720 Begin *****************************/
+
+#define ISCSI_RESERVED_TAG		0xffffffff
+
+/* Opcode encoding bits */
+#define ISCSI_OP_RETRY			0x80
+#define ISCSI_OP_IMMEDIATE		0x40
+#define ISCSI_OPCODE_MASK		0x3F
+
+/* Initiator Opcode values */
+#define ISCSI_OP_NOOP_OUT		0x00
+#define ISCSI_OP_SCSI_CMD		0x01
+#define ISCSI_OP_SCSI_TMFUNC		0x02
+#define ISCSI_OP_LOGIN			0x03
+#define ISCSI_OP_TEXT			0x04
+#define ISCSI_OP_SCSI_DATA_OUT		0x05
+#define ISCSI_OP_LOGOUT			0x06
+#define ISCSI_OP_SNACK			0x10
+
+#define ISCSI_OP_VENDOR1_CMD		0x1c
+#define ISCSI_OP_VENDOR2_CMD		0x1d
+#define ISCSI_OP_VENDOR3_CMD		0x1e
+#define ISCSI_OP_VENDOR4_CMD		0x1f
+
+/* Target Opcode values */
+#define ISCSI_OP_NOOP_IN		0x20
+#define ISCSI_OP_SCSI_CMD_RSP		0x21
+#define ISCSI_OP_SCSI_TMFUNC_RSP	0x22
+#define ISCSI_OP_LOGIN_RSP		0x23
+#define ISCSI_OP_TEXT_RSP		0x24
+#define ISCSI_OP_SCSI_DATA_IN		0x25
+#define ISCSI_OP_LOGOUT_RSP		0x26
+#define ISCSI_OP_R2T			0x31
+#define ISCSI_OP_ASYNC_EVENT		0x32
+#define ISCSI_OP_REJECT			0x3f
+
+struct iscsi_ahs_hdr {
+	__be16 ahslength;
+	uint8_t ahstype;
+	uint8_t ahspec[5];
+};
+
+#define ISCSI_AHSTYPE_CDB		1
+#define ISCSI_AHSTYPE_RLENGTH		2
+
+/* iSCSI PDU Header */
+struct iscsi_cmd {
+	uint8_t opcode;
+	uint8_t flags;
+	__be16 rsvd2;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32 itt;	/* Initiator Task Tag */
+	__be32 data_length;
+	__be32 cmdsn;
+	__be32 exp_statsn;
+	uint8_t cdb[16];	/* SCSI Command Block */
+	/* Additional Data (Command Dependent) */
+};
+
+/* Command PDU flags */
+#define ISCSI_FLAG_CMD_FINAL		0x80
+#define ISCSI_FLAG_CMD_READ		0x40
+#define ISCSI_FLAG_CMD_WRITE		0x20
+#define ISCSI_FLAG_CMD_ATTR_MASK	0x07	/* 3 bits */
+
+/* SCSI Command Attribute values */
+#define ISCSI_ATTR_UNTAGGED		0
+#define ISCSI_ATTR_SIMPLE		1
+#define ISCSI_ATTR_ORDERED		2
+#define ISCSI_ATTR_HEAD_OF_QUEUE	3
+#define ISCSI_ATTR_ACA			4
+
+struct iscsi_rlength_ahdr {
+	__be16 ahslength;
+	uint8_t ahstype;
+	uint8_t reserved;
+	__be32 read_length;
+};
+
+/* SCSI Response Header */
+struct iscsi_cmd_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t response;
+	uint8_t cmd_status;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	rsvd1;
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	__be32	exp_datasn;
+	__be32	bi_residual_count;
+	__be32	residual_count;
+	/* Response or Sense Data (optional) */
+};
+
+/* Command Response PDU flags */
+#define ISCSI_FLAG_CMD_BIDI_OVERFLOW	0x10
+#define ISCSI_FLAG_CMD_BIDI_UNDERFLOW	0x08
+#define ISCSI_FLAG_CMD_OVERFLOW		0x04
+#define ISCSI_FLAG_CMD_UNDERFLOW	0x02
+
+/* iSCSI Status values. Valid if Rsp Selector bit is not set */
+#define ISCSI_STATUS_CMD_COMPLETED	0
+#define ISCSI_STATUS_TARGET_FAILURE	1
+#define ISCSI_STATUS_SUBSYS_FAILURE	2
+
+/* Asynchronous Event Header */
+struct iscsi_async {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[2];
+	uint8_t rsvd3;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	uint8_t rsvd4[8];
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	uint8_t async_event;
+	uint8_t async_vcode;
+	__be16	param1;
+	__be16	param2;
+	__be16	param3;
+	uint8_t rsvd5[4];
+};
+
+/* iSCSI Event Codes */
+#define ISCSI_ASYNC_MSG_SCSI_EVENT			0
+#define ISCSI_ASYNC_MSG_REQUEST_LOGOUT			1
+#define ISCSI_ASYNC_MSG_DROPPING_CONNECTION		2
+#define ISCSI_ASYNC_MSG_DROPPING_ALL_CONNECTIONS	3
+#define ISCSI_ASYNC_MSG_PARAM_NEGOTIATION		4
+#define ISCSI_ASYNC_MSG_VENDOR_SPECIFIC			255
+
+/* NOP-Out Message */
+struct iscsi_nopout {
+	uint8_t opcode;
+	uint8_t flags;
+	__be16	rsvd2;
+	uint8_t rsvd3;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	ttt;	/* Target Transfer Tag */
+	__be32	cmdsn;
+	__be32	exp_statsn;
+	uint8_t rsvd4[16];
+};
+
+/* NOP-In Message */
+struct iscsi_nopin {
+	uint8_t opcode;
+	uint8_t flags;
+	__be16	rsvd2;
+	uint8_t rsvd3;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	ttt;	/* Target Transfer Tag */
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	uint8_t rsvd4[12];
+};
+
+/* SCSI Task Management Message Header */
+struct iscsi_tm {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd1[2];
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	rtt;	/* Reference Task Tag */
+	__be32	cmdsn;
+	__be32	exp_statsn;
+	__be32	refcmdsn;
+	__be32	exp_datasn;
+	uint8_t rsvd2[8];
+};
+
+#define ISCSI_FLAG_TM_FUNC_MASK			0x7F
+
+/* Function values */
+#define ISCSI_TM_FUNC_ABORT_TASK		1
+#define ISCSI_TM_FUNC_ABORT_TASK_SET		2
+#define ISCSI_TM_FUNC_CLEAR_ACA			3
+#define ISCSI_TM_FUNC_CLEAR_TASK_SET		4
+#define ISCSI_TM_FUNC_LOGICAL_UNIT_RESET	5
+#define ISCSI_TM_FUNC_TARGET_WARM_RESET		6
+#define ISCSI_TM_FUNC_TARGET_COLD_RESET		7
+#define ISCSI_TM_FUNC_TASK_REASSIGN		8
+
+/* SCSI Task Management Response Header */
+struct iscsi_tm_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t response;	/* see Response values below */
+	uint8_t qualifier;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd2[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	rtt;	/* Reference Task Tag */
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	uint8_t rsvd3[12];
+};
+
+/* Response values */
+#define ISCSI_TMF_RSP_COMPLETE		0x00
+#define ISCSI_TMF_RSP_NO_TASK		0x01
+#define ISCSI_TMF_RSP_NO_LUN		0x02
+#define ISCSI_TMF_RSP_TASK_ALLEGIANT	0x03
+#define ISCSI_TMF_RSP_NO_FAILOVER	0x04
+#define ISCSI_TMF_RSP_NOT_SUPPORTED	0x05
+#define ISCSI_TMF_RSP_AUTH_FAILED	0x06
+#define ISCSI_TMF_RSP_REJECTED		0xff
+
+/* Ready To Transfer Header */
+struct iscsi_r2t_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[2];
+	uint8_t	hlength;
+	uint8_t	dlength[3];
+	uint8_t lun[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	ttt;	/* Target Transfer Tag */
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	__be32	r2tsn;
+	__be32	data_offset;
+	__be32	data_length;
+};
+
+/* SCSI Data Hdr */
+struct iscsi_data {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[2];
+	uint8_t rsvd3;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32	itt;
+	__be32	ttt;
+	__be32	rsvd4;
+	__be32	exp_statsn;
+	__be32	rsvd5;
+	__be32	datasn;
+	__be32	offset;
+	__be32	rsvd6;
+	/* Payload */
+};
+
+/* SCSI Data Response Hdr */
+struct iscsi_data_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2;
+	uint8_t cmd_status;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t lun[8];
+	__be32	itt;
+	__be32	ttt;
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	__be32	datasn;
+	__be32	offset;
+	__be32	residual_count;
+};
+
+/* Data Response PDU flags */
+#define ISCSI_FLAG_DATA_ACK		0x40
+#define ISCSI_FLAG_DATA_OVERFLOW	0x04
+#define ISCSI_FLAG_DATA_UNDERFLOW	0x02
+#define ISCSI_FLAG_DATA_STATUS		0x01
+
+/* Text Header */
+struct iscsi_text {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[2];
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd4[8];
+	__be32	itt;
+	__be32	ttt;
+	__be32	cmdsn;
+	__be32	exp_statsn;
+	uint8_t rsvd5[16];
+	/* Text - key=value pairs */
+};
+
+#define ISCSI_FLAG_TEXT_CONTINUE	0x40
+
+/* Text Response Header */
+struct iscsi_text_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[2];
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd4[8];
+	__be32	itt;
+	__be32	ttt;
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	uint8_t rsvd5[12];
+	/* Text Response - key:value pairs */
+};
+
+/* Login Header */
+struct iscsi_login {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t max_version;	/* Max. version supported */
+	uint8_t min_version;	/* Min. version supported */
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t isid[6];	/* Initiator Session ID */
+	__be16	tsih;	/* Target Session Handle */
+	__be32	itt;	/* Initiator Task Tag */
+	__be16	cid;
+	__be16	rsvd3;
+	__be32	cmdsn;
+	__be32	exp_statsn;
+	uint8_t rsvd5[16];
+};
+
+/* Login PDU flags */
+#define ISCSI_FLAG_LOGIN_TRANSIT		0x80
+#define ISCSI_FLAG_LOGIN_CONTINUE		0x40
+#define ISCSI_FLAG_LOGIN_CURRENT_STAGE_MASK	0x0C	/* 2 bits */
+#define ISCSI_FLAG_LOGIN_NEXT_STAGE_MASK	0x03	/* 2 bits */
+
+#define ISCSI_LOGIN_CURRENT_STAGE(flags) \
+	((flags & ISCSI_FLAG_LOGIN_CURRENT_STAGE_MASK) >> 2)
+#define ISCSI_LOGIN_NEXT_STAGE(flags) \
+	(flags & ISCSI_FLAG_LOGIN_NEXT_STAGE_MASK)
+
+/* Login Response Header */
+struct iscsi_login_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t max_version;	/* Max. version supported */
+	uint8_t active_version;	/* Active version */
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t isid[6];	/* Initiator Session ID */
+	__be16	tsih;	/* Target Session Handle */
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	rsvd3;
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	uint8_t status_class;	/* see Login RSP ststus classes below */
+	uint8_t status_detail;	/* see Login RSP Status details below */
+	uint8_t rsvd4[10];
+};
+
+/* Login stage (phase) codes for CSG, NSG */
+#define ISCSI_INITIAL_LOGIN_STAGE		-1
+#define ISCSI_SECURITY_NEGOTIATION_STAGE	0
+#define ISCSI_OP_PARMS_NEGOTIATION_STAGE	1
+#define ISCSI_FULL_FEATURE_PHASE		3
+
+/* Login Status response classes */
+#define ISCSI_STATUS_CLS_SUCCESS		0x00
+#define ISCSI_STATUS_CLS_REDIRECT		0x01
+#define ISCSI_STATUS_CLS_INITIATOR_ERR		0x02
+#define ISCSI_STATUS_CLS_TARGET_ERR		0x03
+
+/* Login Status response detail codes */
+/* Class-0 (Success) */
+#define ISCSI_LOGIN_STATUS_ACCEPT		0x00
+
+/* Class-1 (Redirection) */
+#define ISCSI_LOGIN_STATUS_TGT_MOVED_TEMP	0x01
+#define ISCSI_LOGIN_STATUS_TGT_MOVED_PERM	0x02
+
+/* Class-2 (Initiator Error) */
+#define ISCSI_LOGIN_STATUS_INIT_ERR		0x00
+#define ISCSI_LOGIN_STATUS_AUTH_FAILED		0x01
+#define ISCSI_LOGIN_STATUS_TGT_FORBIDDEN	0x02
+#define ISCSI_LOGIN_STATUS_TGT_NOT_FOUND	0x03
+#define ISCSI_LOGIN_STATUS_TGT_REMOVED		0x04
+#define ISCSI_LOGIN_STATUS_NO_VERSION		0x05
+#define ISCSI_LOGIN_STATUS_ISID_ERROR		0x06
+#define ISCSI_LOGIN_STATUS_MISSING_FIELDS	0x07
+#define ISCSI_LOGIN_STATUS_CONN_ADD_FAILED	0x08
+#define ISCSI_LOGIN_STATUS_NO_SESSION_TYPE	0x09
+#define ISCSI_LOGIN_STATUS_NO_SESSION		0x0a
+#define ISCSI_LOGIN_STATUS_INVALID_REQUEST	0x0b
+
+/* Class-3 (Target Error) */
+#define ISCSI_LOGIN_STATUS_TARGET_ERROR		0x00
+#define ISCSI_LOGIN_STATUS_SVC_UNAVAILABLE	0x01
+#define ISCSI_LOGIN_STATUS_NO_RESOURCES		0x02
+
+/* Logout Header */
+struct iscsi_logout {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd1[2];
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd2[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be16	cid;
+	uint8_t rsvd3[2];
+	__be32	cmdsn;
+	__be32	exp_statsn;
+	uint8_t rsvd4[16];
+};
+
+/* Logout PDU flags */
+#define ISCSI_FLAG_LOGOUT_REASON_MASK	0x7F
+
+/* logout reason_code values */
+
+#define ISCSI_LOGOUT_REASON_CLOSE_SESSION	0
+#define ISCSI_LOGOUT_REASON_CLOSE_CONNECTION	1
+#define ISCSI_LOGOUT_REASON_RECOVERY		2
+#define ISCSI_LOGOUT_REASON_AEN_REQUEST		3
+
+/* Logout Response Header */
+struct iscsi_logout_rsp {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t response;	/* see Logout response values below */
+	uint8_t rsvd2;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd3[8];
+	__be32	itt;	/* Initiator Task Tag */
+	__be32	rsvd4;
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	__be32	rsvd5;
+	__be16	t2wait;
+	__be16	t2retain;
+	__be32	rsvd6;
+};
+
+/* logout response status values */
+
+#define ISCSI_LOGOUT_SUCCESS			0
+#define ISCSI_LOGOUT_CID_NOT_FOUND		1
+#define ISCSI_LOGOUT_RECOVERY_UNSUPPORTED	2
+#define ISCSI_LOGOUT_CLEANUP_FAILED		3
+
+/* SNACK Header */
+struct iscsi_snack {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t rsvd2[14];
+	__be32	itt;
+	__be32	begrun;
+	__be32	runlength;
+	__be32	exp_statsn;
+	__be32	rsvd3;
+	__be32	exp_datasn;
+	uint8_t rsvd6[8];
+};
+
+/* SNACK PDU flags */
+#define ISCSI_FLAG_SNACK_TYPE_MASK	0x0F	/* 4 bits */
+
+/* Reject Message Header */
+struct iscsi_reject {
+	uint8_t opcode;
+	uint8_t flags;
+	uint8_t reason;
+	uint8_t rsvd2;
+	uint8_t hlength;
+	uint8_t dlength[3];
+	uint8_t rsvd3[8];
+	__be32  ffffffff;
+	uint8_t rsvd4[4];
+	__be32	statsn;
+	__be32	exp_cmdsn;
+	__be32	max_cmdsn;
+	__be32	datasn;
+	uint8_t rsvd5[8];
+	/* Text - Rejected hdr */
+};
+
+/* Reason for Reject */
+#define ISCSI_REASON_CMD_BEFORE_LOGIN	1
+#define ISCSI_REASON_DATA_DIGEST_ERROR	2
+#define ISCSI_REASON_DATA_SNACK_REJECT	3
+#define ISCSI_REASON_PROTOCOL_ERROR	4
+#define ISCSI_REASON_CMD_NOT_SUPPORTED	5
+#define ISCSI_REASON_IMM_CMD_REJECT		6
+#define ISCSI_REASON_TASK_IN_PROGRESS	7
+#define ISCSI_REASON_INVALID_SNACK		8
+#define ISCSI_REASON_BOOKMARK_INVALID	9
+#define ISCSI_REASON_BOOKMARK_NO_RESOURCES	10
+#define ISCSI_REASON_NEGOTIATION_RESET	11
+
+/* Max. number of Key=Value pairs in a text message */
+#define MAX_KEY_VALUE_PAIRS	8192
+
+/* maximum length for text keys/values */
+#define KEY_MAXLEN		64
+#define VALUE_MAXLEN		255
+#define TARGET_NAME_MAXLEN	VALUE_MAXLEN
+
+#define DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH	8192
+
+/************************* RFC 3720 End *****************************/
+
+#endif /* ISCSI_PROTO_H */

Modified: branches/use-scsi-ml/istgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 14:03:22 UTC (rev 432)
@@ -7,11 +7,13 @@
 #
 # Note 2! The CFLAGS definitions are now in the main makefile.
 
-EXTRA_CFLAGS += -I$(obj) -I$(KERNELSRC)/drivers/scsi/
+EXTRA_CFLAGS += -I$(obj) -I$(obj)/../include
 
 ifneq ($(KERNELRELEASE),)
 obj-m		+= iscsi_tcp_tgt.o
-#obj-m		+= libistgt.o
+obj-m		+= scsi_transport_iscsi.o
+obj-m		+= libiscsi.o
+obj-m		+= iscsi_tcp.o
 else
 
 ifeq ($(KERNELSRC),)

Added: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,2620 @@
+/*
+ * iSCSI Initiator over TCP/IP Data-Path
+ *
+ * Copyright (C) 2004 Dmitry Yusupov
+ * Copyright (C) 2004 Alex Aizman
+ * Copyright (C) 2005 - 2006 Mike Christie
+ * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
+ * maintained by open-iscsi at googlegroups.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published
+ * by the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * See the file COPYING included with this distribution for more details.
+ *
+ * Credits:
+ *	Christoph Hellwig
+ *	FUJITA Tomonori
+ *	Arne Redlich
+ *	Zhenyu Wang
+ */
+
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/inet.h>
+#include <linux/blkdev.h>
+#include <linux/crypto.h>
+#include <linux/delay.h>
+#include <linux/kfifo.h>
+#include <linux/scatterlist.h>
+#include <linux/mutex.h>
+#include <net/tcp.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi.h>
+#include "scsi_transport_iscsi.h"
+
+#include "iscsi_tcp.h"
+
+MODULE_AUTHOR("Dmitry Yusupov <dmitry_yus at yahoo.com>, "
+	      "Alex Aizman <itn780 at yahoo.com>");
+MODULE_DESCRIPTION("iSCSI/TCP data-path");
+MODULE_LICENSE("GPL");
+MODULE_VERSION("0:4.445");
+/* #define DEBUG_TCP */
+#define DEBUG_ASSERT
+
+#ifdef DEBUG_TCP
+#define debug_tcp(fmt...) printk(KERN_INFO "tcp: " fmt)
+#else
+#define debug_tcp(fmt...)
+#endif
+
+#ifndef DEBUG_ASSERT
+#ifdef BUG_ON
+#undef BUG_ON
+#endif
+#define BUG_ON(expr)
+#endif
+
+static unsigned int iscsi_max_lun = 512;
+module_param_named(max_lun, iscsi_max_lun, uint, S_IRUGO);
+
+/* global data */
+static kmem_cache_t *taskcache;
+
+static inline void
+iscsi_buf_init_virt(struct iscsi_buf *ibuf, char *vbuf, int size)
+{
+	sg_init_one(&ibuf->sg, (u8 *)vbuf, size);
+	ibuf->sent = 0;
+	ibuf->use_sendmsg = 0;
+}
+
+static inline void
+iscsi_buf_init_iov(struct iscsi_buf *ibuf, char *vbuf, int size)
+{
+	ibuf->sg.page = virt_to_page(vbuf);
+	ibuf->sg.offset = offset_in_page(vbuf);
+	ibuf->sg.length = size;
+	ibuf->sent = 0;
+	ibuf->use_sendmsg = 1;
+}
+
+static inline void
+iscsi_buf_init_sg(struct iscsi_buf *ibuf, struct scatterlist *sg)
+{
+	ibuf->sg.page = sg->page;
+	ibuf->sg.offset = sg->offset;
+	ibuf->sg.length = sg->length;
+	/*
+	 * Fastpath: sg element fits into single page
+	 */
+	if (sg->length + sg->offset <= PAGE_SIZE && !PageSlab(sg->page))
+		ibuf->use_sendmsg = 0;
+	else
+		ibuf->use_sendmsg = 1;
+	ibuf->sent = 0;
+}
+
+static inline int
+iscsi_buf_left(struct iscsi_buf *ibuf)
+{
+	int rc;
+
+	rc = ibuf->sg.length - ibuf->sent;
+	BUG_ON(rc < 0);
+	return rc;
+}
+
+static inline void
+iscsi_hdr_digest(struct iscsi_conn *conn, struct iscsi_buf *buf,
+		 u8* crc)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	crypto_digest_digest(tcp_conn->tx_tfm, &buf->sg, 1, crc);
+	buf->sg.length += sizeof(uint32_t);
+}
+
+static inline int
+iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn)
+{
+	struct sk_buff *skb = tcp_conn->in.skb;
+
+	tcp_conn->in.zero_copy_hdr = 0;
+
+	if (tcp_conn->in.copy >= tcp_conn->hdr_size &&
+	    tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER) {
+		/*
+		 * Zero-copy PDU Header: using connection context
+		 * to store header pointer.
+		 */
+		if (skb_shinfo(skb)->frag_list == NULL &&
+		    !skb_shinfo(skb)->nr_frags) {
+			tcp_conn->in.hdr = (struct iscsi_hdr *)
+				((char*)skb->data + tcp_conn->in.offset);
+			tcp_conn->in.zero_copy_hdr = 1;
+		} else {
+			/* ignoring return code since we checked
+			 * in.copy before */
+			skb_copy_bits(skb, tcp_conn->in.offset,
+				&tcp_conn->hdr, tcp_conn->hdr_size);
+			tcp_conn->in.hdr = &tcp_conn->hdr;
+		}
+		tcp_conn->in.offset += tcp_conn->hdr_size;
+		tcp_conn->in.copy -= tcp_conn->hdr_size;
+	} else {
+		int hdr_remains;
+		int copylen;
+
+		/*
+		 * PDU header scattered across SKB's,
+		 * copying it... This'll happen quite rarely.
+		 */
+
+		if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
+			tcp_conn->in.hdr_offset = 0;
+
+		hdr_remains = tcp_conn->hdr_size - tcp_conn->in.hdr_offset;
+		BUG_ON(hdr_remains <= 0);
+
+		copylen = min(tcp_conn->in.copy, hdr_remains);
+		skb_copy_bits(skb, tcp_conn->in.offset,
+			(char*)&tcp_conn->hdr + tcp_conn->in.hdr_offset,
+			copylen);
+
+		debug_tcp("PDU gather offset %d bytes %d in.offset %d "
+		       "in.copy %d\n", tcp_conn->in.hdr_offset, copylen,
+		       tcp_conn->in.offset, tcp_conn->in.copy);
+
+		tcp_conn->in.offset += copylen;
+		tcp_conn->in.copy -= copylen;
+		if (copylen < hdr_remains)  {
+			tcp_conn->in_progress = IN_PROGRESS_HEADER_GATHER;
+			tcp_conn->in.hdr_offset += copylen;
+		        return -EAGAIN;
+		}
+		tcp_conn->in.hdr = &tcp_conn->hdr;
+		tcp_conn->discontiguous_hdr_cnt++;
+	        tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	return 0;
+}
+
+/*
+ * must be called with session lock
+ */
+static void
+__iscsi_ctask_cleanup(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct scsi_cmnd *sc;
+
+	sc = ctask->sc;
+	if (unlikely(!sc))
+		return;
+
+	if (sc->sc_data_direction == DMA_TO_DEVICE) {
+		struct iscsi_data_task *dtask, *n;
+
+		/* WRITE: cleanup Data-Out's if any */
+		list_for_each_entry_safe(dtask, n, &tcp_ctask->dataqueue,
+					 item) {
+			list_del(&dtask->item);
+			mempool_free(dtask, tcp_ctask->datapool);
+		}
+	}
+	tcp_ctask->xmstate = XMSTATE_IDLE;
+	tcp_ctask->r2t = NULL;
+}
+
+/**
+ * iscsi_data_rsp - SCSI Data-In Response processing
+ * @conn: iscsi connection
+ * @ctask: scsi command task
+ **/
+static int
+iscsi_data_rsp(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	int rc;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_data_rsp *rhdr = (struct iscsi_data_rsp *)tcp_conn->in.hdr;
+	struct iscsi_session *session = conn->session;
+	int datasn = be32_to_cpu(rhdr->datasn);
+
+	rc = iscsi_check_assign_cmdsn(session, (struct iscsi_nopin*)rhdr);
+	if (rc)
+		return rc;
+	/*
+	 * setup Data-In byte counter (gets decremented..)
+	 */
+	ctask->data_count = tcp_conn->in.datalen;
+
+	if (tcp_conn->in.datalen == 0)
+		return 0;
+
+	if (ctask->datasn != datasn)
+		return ISCSI_ERR_DATASN;
+
+	ctask->datasn++;
+
+	tcp_ctask->data_offset = be32_to_cpu(rhdr->offset);
+	if (tcp_ctask->data_offset + tcp_conn->in.datalen > ctask->total_length)
+		return ISCSI_ERR_DATA_OFFSET;
+
+	if (rhdr->flags & ISCSI_FLAG_DATA_STATUS) {
+		struct scsi_cmnd *sc = ctask->sc;
+
+		conn->exp_statsn = be32_to_cpu(rhdr->statsn) + 1;
+		if (rhdr->flags & ISCSI_FLAG_DATA_UNDERFLOW) {
+			int res_count = be32_to_cpu(rhdr->residual_count);
+
+			if (res_count > 0 &&
+			    res_count <= sc->request_bufflen) {
+				sc->resid = res_count;
+				sc->result = (DID_OK << 16) | rhdr->cmd_status;
+			} else
+				sc->result = (DID_BAD_TARGET << 16) |
+					rhdr->cmd_status;
+		} else if (rhdr->flags & ISCSI_FLAG_DATA_OVERFLOW) {
+			sc->resid = be32_to_cpu(rhdr->residual_count);
+			sc->result = (DID_OK << 16) | rhdr->cmd_status;
+		} else
+			sc->result = (DID_OK << 16) | rhdr->cmd_status;
+	}
+
+	conn->datain_pdus_cnt++;
+	return 0;
+}
+
+/**
+ * iscsi_solicit_data_init - initialize first Data-Out
+ * @conn: iscsi connection
+ * @ctask: scsi command task
+ * @r2t: R2T info
+ *
+ * Notes:
+ *	Initialize first Data-Out within this R2T sequence and finds
+ *	proper data_offset within this SCSI command.
+ *
+ *	This function is called with connection lock taken.
+ **/
+static void
+iscsi_solicit_data_init(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask,
+			struct iscsi_r2t_info *r2t)
+{
+	struct iscsi_data *hdr;
+	struct iscsi_data_task *dtask;
+	struct scsi_cmnd *sc = ctask->sc;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+	dtask = mempool_alloc(tcp_ctask->datapool, GFP_ATOMIC);
+	BUG_ON(!dtask);
+	INIT_LIST_HEAD(&dtask->item);
+	hdr = &dtask->hdr;
+	memset(hdr, 0, sizeof(struct iscsi_data));
+	hdr->ttt = r2t->ttt;
+	hdr->datasn = cpu_to_be32(r2t->solicit_datasn);
+	r2t->solicit_datasn++;
+	hdr->opcode = ISCSI_OP_SCSI_DATA_OUT;
+	memcpy(hdr->lun, ctask->hdr->lun, sizeof(hdr->lun));
+	hdr->itt = ctask->hdr->itt;
+	hdr->exp_statsn = r2t->exp_statsn;
+	hdr->offset = cpu_to_be32(r2t->data_offset);
+	if (r2t->data_length > conn->max_xmit_dlength) {
+		hton24(hdr->dlength, conn->max_xmit_dlength);
+		r2t->data_count = conn->max_xmit_dlength;
+		hdr->flags = 0;
+	} else {
+		hton24(hdr->dlength, r2t->data_length);
+		r2t->data_count = r2t->data_length;
+		hdr->flags = ISCSI_FLAG_CMD_FINAL;
+	}
+	conn->dataout_pdus_cnt++;
+
+	r2t->sent = 0;
+
+	iscsi_buf_init_virt(&r2t->headbuf, (char*)hdr,
+			   sizeof(struct iscsi_hdr));
+
+	r2t->dtask = dtask;
+
+	if (sc->use_sg) {
+		int i, sg_count = 0;
+		struct scatterlist *sg = sc->request_buffer;
+
+		r2t->sg = NULL;
+		for (i = 0; i < sc->use_sg; i++, sg += 1) {
+			/* FIXME: prefetch ? */
+			if (sg_count + sg->length > r2t->data_offset) {
+				int page_offset;
+
+				/* sg page found! */
+
+				/* offset within this page */
+				page_offset = r2t->data_offset - sg_count;
+
+				/* fill in this buffer */
+				iscsi_buf_init_sg(&r2t->sendbuf, sg);
+				r2t->sendbuf.sg.offset += page_offset;
+				r2t->sendbuf.sg.length -= page_offset;
+
+				/* xmit logic will continue with next one */
+				r2t->sg = sg + 1;
+				break;
+			}
+			sg_count += sg->length;
+		}
+		BUG_ON(r2t->sg == NULL);
+	} else
+		iscsi_buf_init_iov(&tcp_ctask->sendbuf,
+			    (char*)sc->request_buffer + r2t->data_offset,
+			    r2t->data_count);
+
+	list_add(&dtask->item, &tcp_ctask->dataqueue);
+}
+
+/**
+ * iscsi_r2t_rsp - iSCSI R2T Response processing
+ * @conn: iscsi connection
+ * @ctask: scsi command task
+ **/
+static int
+iscsi_r2t_rsp(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_r2t_info *r2t;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_r2t_rsp *rhdr = (struct iscsi_r2t_rsp *)tcp_conn->in.hdr;
+	int r2tsn = be32_to_cpu(rhdr->r2tsn);
+	int rc;
+
+	if (tcp_conn->in.datalen)
+		return ISCSI_ERR_DATALEN;
+
+	if (tcp_ctask->exp_r2tsn && tcp_ctask->exp_r2tsn != r2tsn)
+		return ISCSI_ERR_R2TSN;
+
+	rc = iscsi_check_assign_cmdsn(session, (struct iscsi_nopin*)rhdr);
+	if (rc)
+		return rc;
+
+	/* FIXME: use R2TSN to detect missing R2T */
+
+	/* fill-in new R2T associated with the task */
+	spin_lock(&session->lock);
+	if (!ctask->sc || ctask->mtask ||
+	     session->state != ISCSI_STATE_LOGGED_IN) {
+		printk(KERN_INFO "iscsi_tcp: dropping R2T itt %d in "
+		       "recovery...\n", ctask->itt);
+		spin_unlock(&session->lock);
+		return 0;
+	}
+	rc = __kfifo_get(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
+	BUG_ON(!rc);
+
+	r2t->exp_statsn = rhdr->statsn;
+	r2t->data_length = be32_to_cpu(rhdr->data_length);
+	if (r2t->data_length == 0 ||
+	    r2t->data_length > session->max_burst) {
+		spin_unlock(&session->lock);
+		return ISCSI_ERR_DATALEN;
+	}
+
+	r2t->data_offset = be32_to_cpu(rhdr->data_offset);
+	if (r2t->data_offset + r2t->data_length > ctask->total_length) {
+		spin_unlock(&session->lock);
+		return ISCSI_ERR_DATALEN;
+	}
+
+	r2t->ttt = rhdr->ttt; /* no flip */
+	r2t->solicit_datasn = 0;
+
+	iscsi_solicit_data_init(conn, ctask, r2t);
+
+	tcp_ctask->exp_r2tsn = r2tsn + 1;
+	tcp_ctask->xmstate |= XMSTATE_SOL_HDR;
+	__kfifo_put(tcp_ctask->r2tqueue, (void*)&r2t, sizeof(void*));
+	__kfifo_put(conn->xmitqueue, (void*)&ctask, sizeof(void*));
+
+	scsi_queue_work(session->host, &conn->xmitwork);
+	conn->r2t_pdus_cnt++;
+	spin_unlock(&session->lock);
+
+	return 0;
+}
+
+static int
+iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
+{
+	int rc = 0, opcode, ahslen;
+	struct iscsi_hdr *hdr;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	uint32_t cdgst, rdgst = 0, itt;
+
+	hdr = tcp_conn->in.hdr;
+
+	/* verify PDU length */
+	tcp_conn->in.datalen = ntoh24(hdr->dlength);
+	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
+		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
+		       tcp_conn->in.datalen, conn->max_recv_dlength);
+		return ISCSI_ERR_DATALEN;
+	}
+	tcp_conn->data_copied = 0;
+
+	/* read AHS */
+	ahslen = hdr->hlength << 2;
+	tcp_conn->in.offset += ahslen;
+	tcp_conn->in.copy -= ahslen;
+	if (tcp_conn->in.copy < 0) {
+		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
+		       "%d bytes\n", ahslen);
+		return ISCSI_ERR_AHSLEN;
+	}
+
+	/* calculate read padding */
+	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
+	if (tcp_conn->in.padding) {
+		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
+		debug_scsi("read padding %d bytes\n", tcp_conn->in.padding);
+	}
+
+	if (conn->hdrdgst_en) {
+		struct scatterlist sg;
+
+		sg_init_one(&sg, (u8 *)hdr,
+			    sizeof(struct iscsi_hdr) + ahslen);
+		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
+		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
+				     ahslen);
+		if (cdgst != rdgst) {
+			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
+			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
+			return ISCSI_ERR_HDR_DGST;
+		}
+	}
+
+	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
+	/* verify itt (itt encoding: age+cid+itt) */
+	rc = iscsi_verify_itt(conn, hdr, &itt);
+	if (rc == ISCSI_ERR_NO_SCSI_CMD) {
+		tcp_conn->in.datalen = 0; /* force drop */
+		return 0;
+	} else if (rc)
+		return rc;
+
+	debug_tcp("opcode 0x%x offset %d copy %d ahslen %d datalen %d\n",
+		  opcode, tcp_conn->in.offset, tcp_conn->in.copy,
+		  ahslen, tcp_conn->in.datalen);
+
+	switch(opcode) {
+	case ISCSI_OP_SCSI_DATA_IN:
+		tcp_conn->in.ctask = session->cmds[itt];
+		rc = iscsi_data_rsp(conn, tcp_conn->in.ctask);
+		/* fall through */
+	case ISCSI_OP_SCSI_CMD_RSP:
+		tcp_conn->in.ctask = session->cmds[itt];
+		if (tcp_conn->in.datalen)
+			goto copy_hdr;
+
+		spin_lock(&session->lock);
+		__iscsi_ctask_cleanup(conn, tcp_conn->in.ctask);
+		rc = __iscsi_complete_pdu(conn, hdr, NULL, 0);
+		spin_unlock(&session->lock);
+		break;
+	case ISCSI_OP_R2T:
+		tcp_conn->in.ctask = session->cmds[itt];
+		if (ahslen)
+			rc = ISCSI_ERR_AHSLEN;
+		else if (tcp_conn->in.ctask->sc->sc_data_direction ==
+								DMA_TO_DEVICE)
+			rc = iscsi_r2t_rsp(conn, tcp_conn->in.ctask);
+		else
+			rc = ISCSI_ERR_PROTO;
+		break;
+	case ISCSI_OP_LOGIN_RSP:
+	case ISCSI_OP_TEXT_RSP:
+	case ISCSI_OP_LOGOUT_RSP:
+	case ISCSI_OP_NOOP_IN:
+	case ISCSI_OP_REJECT:
+	case ISCSI_OP_ASYNC_EVENT:
+		if (tcp_conn->in.datalen)
+			goto copy_hdr;
+	/* fall through */
+	case ISCSI_OP_SCSI_TMFUNC_RSP:
+		rc = iscsi_complete_pdu(conn, hdr, NULL, 0);
+		break;
+	default:
+		rc = ISCSI_ERR_BAD_OPCODE;
+		break;
+	}
+
+	return rc;
+
+copy_hdr:
+	/*
+	 * if we did zero copy for the header but we will need multiple
+	 * skbs to complete the command then we have to copy the header
+	 * for later use
+	 */
+	if (tcp_conn->in.zero_copy_hdr && tcp_conn->in.copy <
+	   (tcp_conn->in.datalen + tcp_conn->in.padding +
+	    (conn->datadgst_en ? 4 : 0))) {
+		debug_tcp("Copying header for later use. in.copy %d in.datalen"
+			  " %d\n", tcp_conn->in.copy, tcp_conn->in.datalen);
+		memcpy(&tcp_conn->hdr, tcp_conn->in.hdr,
+		       sizeof(struct iscsi_hdr));
+		tcp_conn->in.hdr = &tcp_conn->hdr;
+		tcp_conn->in.zero_copy_hdr = 0;
+	}
+	return 0;
+}
+
+/**
+ * iscsi_ctask_copy - copy skb bits to the destanation cmd task
+ * @conn: iscsi tcp connection
+ * @ctask: scsi command task
+ * @buf: buffer to copy to
+ * @buf_size: size of buffer
+ * @offset: offset within the buffer
+ *
+ * Notes:
+ *	The function calls skb_copy_bits() and updates per-connection and
+ *	per-cmd byte counters.
+ *
+ *	Read counters (in bytes):
+ *
+ *	conn->in.offset		offset within in progress SKB
+ *	conn->in.copy		left to copy from in progress SKB
+ *				including padding
+ *	conn->in.copied		copied already from in progress SKB
+ *	conn->data_copied	copied already from in progress buffer
+ *	ctask->sent		total bytes sent up to the MidLayer
+ *	ctask->data_count	left to copy from in progress Data-In
+ *	buf_left		left to copy from in progress buffer
+ **/
+static inline int
+iscsi_ctask_copy(struct iscsi_tcp_conn *tcp_conn, struct iscsi_cmd_task *ctask,
+		void *buf, int buf_size, int offset)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	int buf_left = buf_size - (tcp_conn->data_copied + offset);
+	int size = min(tcp_conn->in.copy, buf_left);
+	int rc;
+
+	size = min(size, ctask->data_count);
+
+	debug_tcp("ctask_copy %d bytes at offset %d copied %d\n",
+	       size, tcp_conn->in.offset, tcp_conn->in.copied);
+
+	BUG_ON(size <= 0);
+	BUG_ON(tcp_ctask->sent + size > ctask->total_length);
+
+	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+			   (char*)buf + (offset + tcp_conn->data_copied), size);
+	/* must fit into skb->len */
+	BUG_ON(rc);
+
+	tcp_conn->in.offset += size;
+	tcp_conn->in.copy -= size;
+	tcp_conn->in.copied += size;
+	tcp_conn->data_copied += size;
+	tcp_ctask->sent += size;
+	ctask->data_count -= size;
+
+	BUG_ON(tcp_conn->in.copy < 0);
+	BUG_ON(ctask->data_count < 0);
+
+	if (buf_size != (tcp_conn->data_copied + offset)) {
+		if (!ctask->data_count) {
+			BUG_ON(buf_size - tcp_conn->data_copied < 0);
+			/* done with this PDU */
+			return buf_size - tcp_conn->data_copied;
+		}
+		return -EAGAIN;
+	}
+
+	/* done with this buffer or with both - PDU and buffer */
+	tcp_conn->data_copied = 0;
+	return 0;
+}
+
+/**
+ * iscsi_tcp_copy - copy skb bits to the destanation buffer
+ * @conn: iscsi tcp connection
+ *
+ * Notes:
+ *	The function calls skb_copy_bits() and updates per-connection
+ *	byte counters.
+ **/
+static inline int
+iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn)
+{
+	void *buf = tcp_conn->data;
+	int buf_size = tcp_conn->in.datalen;
+	int buf_left = buf_size - tcp_conn->data_copied;
+	int size = min(tcp_conn->in.copy, buf_left);
+	int rc;
+
+	debug_tcp("tcp_copy %d bytes at offset %d copied %d\n",
+	       size, tcp_conn->in.offset, tcp_conn->data_copied);
+	BUG_ON(size <= 0);
+
+	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+			   (char*)buf + tcp_conn->data_copied, size);
+	BUG_ON(rc);
+
+	tcp_conn->in.offset += size;
+	tcp_conn->in.copy -= size;
+	tcp_conn->in.copied += size;
+	tcp_conn->data_copied += size;
+
+	if (buf_size != tcp_conn->data_copied)
+		return -EAGAIN;
+
+	return 0;
+}
+
+static inline void
+partial_sg_digest_update(struct iscsi_tcp_conn *tcp_conn,
+			 struct scatterlist *sg, int offset, int length)
+{
+	struct scatterlist temp;
+
+	memcpy(&temp, sg, sizeof(struct scatterlist));
+	temp.offset = offset;
+	temp.length = length;
+	crypto_digest_update(tcp_conn->data_rx_tfm, &temp, 1);
+}
+
+static void
+iscsi_recv_digest_update(struct iscsi_tcp_conn *tcp_conn, char* buf, int len)
+{
+	struct scatterlist tmp;
+
+	sg_init_one(&tmp, buf, len);
+	crypto_digest_update(tcp_conn->data_rx_tfm, &tmp, 1);
+}
+
+static int iscsi_scsi_data_in(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_cmd_task *ctask = tcp_conn->in.ctask;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct scsi_cmnd *sc = ctask->sc;
+	struct scatterlist *sg;
+	int i, offset, rc = 0;
+
+	BUG_ON((void*)ctask != sc->SCp.ptr);
+
+	/*
+	 * copying Data-In into the Scsi_Cmnd
+	 */
+	if (!sc->use_sg) {
+		i = ctask->data_count;
+		rc = iscsi_ctask_copy(tcp_conn, ctask, sc->request_buffer,
+				      sc->request_bufflen,
+				      tcp_ctask->data_offset);
+		if (rc == -EAGAIN)
+			return rc;
+		if (conn->datadgst_en)
+			iscsi_recv_digest_update(tcp_conn, sc->request_buffer,
+						 i);
+		rc = 0;
+		goto done;
+	}
+
+	offset = tcp_ctask->data_offset;
+	sg = sc->request_buffer;
+
+	if (tcp_ctask->data_offset)
+		for (i = 0; i < tcp_ctask->sg_count; i++)
+			offset -= sg[i].length;
+	/* we've passed through partial sg*/
+	if (offset < 0)
+		offset = 0;
+
+	for (i = tcp_ctask->sg_count; i < sc->use_sg; i++) {
+		char *dest;
+
+		dest = kmap_atomic(sg[i].page, KM_SOFTIRQ0);
+		rc = iscsi_ctask_copy(tcp_conn, ctask, dest + sg[i].offset,
+				      sg[i].length, offset);
+		kunmap_atomic(dest, KM_SOFTIRQ0);
+		if (rc == -EAGAIN)
+			/* continue with the next SKB/PDU */
+			return rc;
+		if (!rc) {
+			if (conn->datadgst_en) {
+				if (!offset)
+					crypto_digest_update(
+							tcp_conn->data_rx_tfm,
+							&sg[i], 1);
+				else
+					partial_sg_digest_update(tcp_conn,
+							&sg[i],
+							sg[i].offset + offset,
+							sg[i].length - offset);
+			}
+			offset = 0;
+			tcp_ctask->sg_count++;
+		}
+
+		if (!ctask->data_count) {
+			if (rc && conn->datadgst_en)
+				/*
+				 * data-in is complete, but buffer not...
+				 */
+				partial_sg_digest_update(tcp_conn, &sg[i],
+						sg[i].offset, sg[i].length-rc);
+			rc = 0;
+			break;
+		}
+
+		if (!tcp_conn->in.copy)
+			return -EAGAIN;
+	}
+	BUG_ON(ctask->data_count);
+
+done:
+	/* check for non-exceptional status */
+	if (tcp_conn->in.hdr->flags & ISCSI_FLAG_DATA_STATUS) {
+		debug_scsi("done [sc %lx res %d itt 0x%x]\n",
+			   (long)sc, sc->result, ctask->itt);
+		spin_lock(&conn->session->lock);
+		__iscsi_ctask_cleanup(conn, ctask);
+		__iscsi_complete_pdu(conn, tcp_conn->in.hdr, NULL, 0);
+		spin_unlock(&conn->session->lock);
+	}
+
+	return rc;
+}
+
+static int
+iscsi_data_recv(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int rc = 0, opcode;
+
+	opcode = tcp_conn->in.hdr->opcode & ISCSI_OPCODE_MASK;
+	switch (opcode) {
+	case ISCSI_OP_SCSI_DATA_IN:
+		rc = iscsi_scsi_data_in(conn);
+		break;
+	case ISCSI_OP_SCSI_CMD_RSP:
+		spin_lock(&conn->session->lock);
+		__iscsi_ctask_cleanup(conn, tcp_conn->in.ctask);
+		spin_unlock(&conn->session->lock);
+	case ISCSI_OP_TEXT_RSP:
+	case ISCSI_OP_LOGIN_RSP:
+	case ISCSI_OP_NOOP_IN:
+	case ISCSI_OP_ASYNC_EVENT:
+	case ISCSI_OP_REJECT:
+		/*
+		 * Collect data segment to the connection's data
+		 * placeholder
+		 */
+		if (iscsi_tcp_copy(tcp_conn)) {
+			rc = -EAGAIN;
+			goto exit;
+		}
+
+		rc = iscsi_complete_pdu(conn, tcp_conn->in.hdr, tcp_conn->data,
+					tcp_conn->in.datalen);
+		if (!rc && conn->datadgst_en && opcode != ISCSI_OP_LOGIN_RSP)
+			iscsi_recv_digest_update(tcp_conn, tcp_conn->data,
+			  			tcp_conn->in.datalen);
+		break;
+	default:
+		BUG_ON(1);
+	}
+exit:
+	return rc;
+}
+
+/**
+ * iscsi_tcp_data_recv - TCP receive in sendfile fashion
+ * @rd_desc: read descriptor
+ * @skb: socket buffer
+ * @offset: offset in skb
+ * @len: skb->len - offset
+ **/
+static int
+iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
+		unsigned int offset, size_t len)
+{
+	int rc;
+	struct iscsi_conn *conn = rd_desc->arg.data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int processed;
+	char pad[ISCSI_PAD_LEN];
+	struct scatterlist sg;
+
+	/*
+	 * Save current SKB and its offset in the corresponding
+	 * connection context.
+	 */
+	tcp_conn->in.copy = skb->len - offset;
+	tcp_conn->in.offset = offset;
+	tcp_conn->in.skb = skb;
+	tcp_conn->in.len = tcp_conn->in.copy;
+	BUG_ON(tcp_conn->in.copy <= 0);
+	debug_tcp("in %d bytes\n", tcp_conn->in.copy);
+
+more:
+	tcp_conn->in.copied = 0;
+	rc = 0;
+
+	if (unlikely(conn->suspend_rx)) {
+		debug_tcp("conn %d Rx suspended!\n", conn->id);
+		return 0;
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER ||
+	    tcp_conn->in_progress == IN_PROGRESS_HEADER_GATHER) {
+		rc = iscsi_hdr_extract(tcp_conn);
+		if (rc) {
+		       if (rc == -EAGAIN)
+				goto nomore;
+		       else {
+				iscsi_conn_failure(conn, rc);
+				return 0;
+		       }
+		}
+
+		/*
+		 * Verify and process incoming PDU header.
+		 */
+		rc = iscsi_tcp_hdr_recv(conn);
+		if (!rc && tcp_conn->in.datalen) {
+			if (conn->datadgst_en) {
+				BUG_ON(!tcp_conn->data_rx_tfm);
+				crypto_digest_init(tcp_conn->data_rx_tfm);
+			}
+			tcp_conn->in_progress = IN_PROGRESS_DATA_RECV;
+		} else if (rc) {
+			iscsi_conn_failure(conn, rc);
+			return 0;
+		}
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
+		uint32_t recv_digest;
+
+		debug_tcp("extra data_recv offset %d copy %d\n",
+			  tcp_conn->in.offset, tcp_conn->in.copy);
+		skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
+				&recv_digest, 4);
+		tcp_conn->in.offset += 4;
+		tcp_conn->in.copy -= 4;
+		if (recv_digest != tcp_conn->in.datadgst) {
+			debug_tcp("iscsi_tcp: data digest error!"
+				  "0x%x != 0x%x\n", recv_digest,
+				  tcp_conn->in.datadgst);
+			iscsi_conn_failure(conn, ISCSI_ERR_DATA_DGST);
+			return 0;
+		} else {
+			debug_tcp("iscsi_tcp: data digest match!"
+				  "0x%x == 0x%x\n", recv_digest,
+				  tcp_conn->in.datadgst);
+			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+		}
+	}
+
+	if (tcp_conn->in_progress == IN_PROGRESS_DATA_RECV &&
+	   tcp_conn->in.copy) {
+
+		debug_tcp("data_recv offset %d copy %d\n",
+		       tcp_conn->in.offset, tcp_conn->in.copy);
+
+		rc = iscsi_data_recv(conn);
+		if (rc) {
+			if (rc == -EAGAIN) {
+				rd_desc->count = tcp_conn->in.datalen -
+						tcp_conn->in.ctask->data_count;
+				goto again;
+			}
+			iscsi_conn_failure(conn, rc);
+			return 0;
+		}
+		tcp_conn->in.copy -= tcp_conn->in.padding;
+		tcp_conn->in.offset += tcp_conn->in.padding;
+		if (conn->datadgst_en) {
+			if (tcp_conn->in.padding) {
+				debug_tcp("padding -> %d\n",
+					  tcp_conn->in.padding);
+				memset(pad, 0, tcp_conn->in.padding);
+				sg_init_one(&sg, pad, tcp_conn->in.padding);
+				crypto_digest_update(tcp_conn->data_rx_tfm,
+						     &sg, 1);
+			}
+			crypto_digest_final(tcp_conn->data_rx_tfm,
+					    (u8 *) & tcp_conn->in.datadgst);
+			debug_tcp("rx digest 0x%x\n", tcp_conn->in.datadgst);
+			tcp_conn->in_progress = IN_PROGRESS_DDIGEST_RECV;
+		} else
+			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	debug_tcp("f, processed %d from out of %d padding %d\n",
+	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
+	BUG_ON(tcp_conn->in.offset - offset > len);
+
+	if (tcp_conn->in.offset - offset != len) {
+		debug_tcp("continue to process %d bytes\n",
+		       (int)len - (tcp_conn->in.offset - offset));
+		goto more;
+	}
+
+nomore:
+	processed = tcp_conn->in.offset - offset;
+	BUG_ON(processed == 0);
+	return processed;
+
+again:
+	processed = tcp_conn->in.offset - offset;
+	debug_tcp("c, processed %d from out of %d rd_desc_cnt %d\n",
+	          processed, (int)len, (int)rd_desc->count);
+	BUG_ON(processed == 0);
+	BUG_ON(processed > len);
+
+	conn->rxdata_octets += processed;
+	return processed;
+}
+
+static void
+iscsi_tcp_data_ready(struct sock *sk, int flag)
+{
+	struct iscsi_conn *conn = sk->sk_user_data;
+	read_descriptor_t rd_desc;
+
+	read_lock(&sk->sk_callback_lock);
+
+	/* use rd_desc to pass 'conn' to iscsi_tcp_data_recv */
+	rd_desc.arg.data = conn;
+	rd_desc.count = 0;
+	tcp_read_sock(sk, &rd_desc, iscsi_tcp_data_recv);
+
+	read_unlock(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_tcp_state_change(struct sock *sk)
+{
+	struct iscsi_tcp_conn *tcp_conn;
+	struct iscsi_conn *conn;
+	struct iscsi_session *session;
+	void (*old_state_change)(struct sock *);
+
+	read_lock(&sk->sk_callback_lock);
+
+	conn = (struct iscsi_conn*)sk->sk_user_data;
+	session = conn->session;
+
+	if ((sk->sk_state == TCP_CLOSE_WAIT ||
+	     sk->sk_state == TCP_CLOSE) &&
+	    !atomic_read(&sk->sk_rmem_alloc)) {
+		debug_tcp("iscsi_tcp_state_change: TCP_CLOSE|TCP_CLOSE_WAIT\n");
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+	}
+
+	tcp_conn = conn->dd_data;
+	old_state_change = tcp_conn->old_state_change;
+
+	read_unlock(&sk->sk_callback_lock);
+
+	old_state_change(sk);
+}
+
+/**
+ * iscsi_write_space - Called when more output buffer space is available
+ * @sk: socket space is available for
+ **/
+static void
+iscsi_write_space(struct sock *sk)
+{
+	struct iscsi_conn *conn = (struct iscsi_conn*)sk->sk_user_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	tcp_conn->old_write_space(sk);
+	debug_tcp("iscsi_write_space: cid %d\n", conn->id);
+	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	scsi_queue_work(conn->session->host, &conn->xmitwork);
+}
+
+static void
+iscsi_conn_set_callbacks(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk = tcp_conn->sock->sk;
+
+	/* assign new callbacks */
+	write_lock_bh(&sk->sk_callback_lock);
+	sk->sk_user_data = conn;
+	tcp_conn->old_data_ready = sk->sk_data_ready;
+	tcp_conn->old_state_change = sk->sk_state_change;
+	tcp_conn->old_write_space = sk->sk_write_space;
+	sk->sk_data_ready = iscsi_tcp_data_ready;
+	sk->sk_state_change = iscsi_tcp_state_change;
+	sk->sk_write_space = iscsi_write_space;
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_conn_restore_callbacks(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk = tcp_conn->sock->sk;
+
+	/* restore socket callbacks, see also: iscsi_conn_set_callbacks() */
+	write_lock_bh(&sk->sk_callback_lock);
+	sk->sk_user_data    = NULL;
+	sk->sk_data_ready   = tcp_conn->old_data_ready;
+	sk->sk_state_change = tcp_conn->old_state_change;
+	sk->sk_write_space  = tcp_conn->old_write_space;
+	sk->sk_no_check	 = 0;
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+/**
+ * iscsi_send - generic send routine
+ * @sk: kernel's socket
+ * @buf: buffer to write from
+ * @size: actual size to write
+ * @flags: socket's flags
+ */
+static inline int
+iscsi_send(struct iscsi_conn *conn, struct iscsi_buf *buf, int size, int flags)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct socket *sk = tcp_conn->sock;
+	int offset = buf->sg.offset + buf->sent;
+
+	/*
+	 * if we got use_sg=0 or are sending something we kmallocd
+	 * then we did not have to do kmap (kmap returns page_address)
+	 *
+	 * if we got use_sg > 0, but had to drop down, we do not
+	 * set clustering so this should only happen for that
+	 * slab case.
+	 */
+	if (buf->use_sendmsg)
+		return sock_no_sendpage(sk, buf->sg.page, offset, size, flags);
+	else
+		return tcp_conn->sendpage(sk, buf->sg.page, offset, size,
+					  flags);
+}
+
+/**
+ * iscsi_sendhdr - send PDU Header via tcp_sendpage()
+ * @conn: iscsi connection
+ * @buf: buffer to write from
+ * @datalen: lenght of data to be sent after the header
+ *
+ * Notes:
+ *	(Tx, Fast Path)
+ **/
+static inline int
+iscsi_sendhdr(struct iscsi_conn *conn, struct iscsi_buf *buf, int datalen)
+{
+	struct iscsi_tcp_conn *tcp_conn;
+	int flags = 0; /* MSG_DONTWAIT; */
+	int res, size;
+
+	size = buf->sg.length - buf->sent;
+	BUG_ON(buf->sent + size > buf->sg.length);
+	if (buf->sent + size != buf->sg.length || datalen)
+		flags |= MSG_MORE;
+
+	res = iscsi_send(conn, buf, size, flags);
+	debug_tcp("sendhdr %d bytes, sent %d res %d\n", size, buf->sent, res);
+	if (res >= 0) {
+		conn->txdata_octets += res;
+		buf->sent += res;
+		if (size != res)
+			return -EAGAIN;
+		return 0;
+	} else if (res == -EAGAIN) {
+		tcp_conn = conn->dd_data;
+		tcp_conn->sendpage_failures_cnt++;
+		set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	} else if (res == -EPIPE)
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+
+	return res;
+}
+
+/**
+ * iscsi_sendpage - send one page of iSCSI Data-Out.
+ * @conn: iscsi connection
+ * @buf: buffer to write from
+ * @count: remaining data
+ * @sent: number of bytes sent
+ *
+ * Notes:
+ *	(Tx, Fast Path)
+ **/
+static inline int
+iscsi_sendpage(struct iscsi_conn *conn, struct iscsi_buf *buf,
+	       int *count, int *sent)
+{
+	struct iscsi_tcp_conn *tcp_conn;
+	int flags = 0; /* MSG_DONTWAIT; */
+	int res, size;
+
+	size = buf->sg.length - buf->sent;
+	BUG_ON(buf->sent + size > buf->sg.length);
+	if (size > *count)
+		size = *count;
+	if (buf->sent + size != buf->sg.length || *count != size)
+		flags |= MSG_MORE;
+
+	res = iscsi_send(conn, buf, size, flags);
+	debug_tcp("sendpage: %d bytes, sent %d left %d sent %d res %d\n",
+		  size, buf->sent, *count, *sent, res);
+	if (res >= 0) {
+		conn->txdata_octets += res;
+		buf->sent += res;
+		*count -= res;
+		*sent += res;
+		if (size != res)
+			return -EAGAIN;
+		return 0;
+	} else if (res == -EAGAIN) {
+		tcp_conn = conn->dd_data;
+		tcp_conn->sendpage_failures_cnt++;
+		set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	} else if (res == -EPIPE)
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+
+	return res;
+}
+
+static inline void
+iscsi_data_digest_init(struct iscsi_tcp_conn *tcp_conn,
+		      struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+	BUG_ON(!tcp_conn->data_tx_tfm);
+	crypto_digest_init(tcp_conn->data_tx_tfm);
+	tcp_ctask->digest_count = 4;
+}
+
+static int
+iscsi_digest_final_send(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask,
+			struct iscsi_buf *buf, uint32_t *digest, int final)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int rc = 0;
+	int sent = 0;
+
+	if (final)
+		crypto_digest_final(tcp_conn->data_tx_tfm, (u8*)digest);
+
+	iscsi_buf_init_virt(buf, (char*)digest, 4);
+	rc = iscsi_sendpage(conn, buf, &tcp_ctask->digest_count, &sent);
+	if (rc) {
+		tcp_ctask->datadigest = *digest;
+		tcp_ctask->xmstate |= XMSTATE_DATA_DIGEST;
+	} else
+		tcp_ctask->digest_count = 4;
+	return rc;
+}
+
+/**
+ * iscsi_solicit_data_cont - initialize next Data-Out
+ * @conn: iscsi connection
+ * @ctask: scsi command task
+ * @r2t: R2T info
+ * @left: bytes left to transfer
+ *
+ * Notes:
+ *	Initialize next Data-Out within this R2T sequence and continue
+ *	to process next Scatter-Gather element(if any) of this SCSI command.
+ *
+ *	Called under connection lock.
+ **/
+static void
+iscsi_solicit_data_cont(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask,
+			struct iscsi_r2t_info *r2t, int left)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_data *hdr;
+	struct iscsi_data_task *dtask;
+	struct scsi_cmnd *sc = ctask->sc;
+	int new_offset;
+
+	dtask = mempool_alloc(tcp_ctask->datapool, GFP_ATOMIC);
+	BUG_ON(!dtask);
+	INIT_LIST_HEAD(&dtask->item);
+	hdr = &dtask->hdr;
+	memset(hdr, 0, sizeof(struct iscsi_data));
+	hdr->ttt = r2t->ttt;
+	hdr->datasn = cpu_to_be32(r2t->solicit_datasn);
+	r2t->solicit_datasn++;
+	hdr->opcode = ISCSI_OP_SCSI_DATA_OUT;
+	memcpy(hdr->lun, ctask->hdr->lun, sizeof(hdr->lun));
+	hdr->itt = ctask->hdr->itt;
+	hdr->exp_statsn = r2t->exp_statsn;
+	new_offset = r2t->data_offset + r2t->sent;
+	hdr->offset = cpu_to_be32(new_offset);
+	if (left > conn->max_xmit_dlength) {
+		hton24(hdr->dlength, conn->max_xmit_dlength);
+		r2t->data_count = conn->max_xmit_dlength;
+	} else {
+		hton24(hdr->dlength, left);
+		r2t->data_count = left;
+		hdr->flags = ISCSI_FLAG_CMD_FINAL;
+	}
+	conn->dataout_pdus_cnt++;
+
+	iscsi_buf_init_virt(&r2t->headbuf, (char*)hdr,
+			   sizeof(struct iscsi_hdr));
+
+	r2t->dtask = dtask;
+
+	if (sc->use_sg && !iscsi_buf_left(&r2t->sendbuf)) {
+		BUG_ON(tcp_ctask->bad_sg == r2t->sg);
+		iscsi_buf_init_sg(&r2t->sendbuf, r2t->sg);
+		r2t->sg += 1;
+	} else
+		iscsi_buf_init_iov(&tcp_ctask->sendbuf,
+			    (char*)sc->request_buffer + new_offset,
+			    r2t->data_count);
+
+	list_add(&dtask->item, &tcp_ctask->dataqueue);
+}
+
+static void
+iscsi_unsolicit_data_init(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_data_task *dtask;
+
+	dtask = mempool_alloc(tcp_ctask->datapool, GFP_ATOMIC);
+	BUG_ON(!dtask);
+	INIT_LIST_HEAD(&dtask->item);
+
+	iscsi_prep_unsolicit_data_pdu(ctask, &dtask->hdr,
+				      tcp_ctask->r2t_data_count);
+	iscsi_buf_init_virt(&tcp_ctask->headbuf, (char*)&dtask->hdr,
+			   sizeof(struct iscsi_hdr));
+
+	list_add(&dtask->item, &tcp_ctask->dataqueue);
+	tcp_ctask->dtask = dtask;
+}
+
+/**
+ * iscsi_tcp_cmd_init - Initialize iSCSI SCSI_READ or SCSI_WRITE commands
+ * @conn: iscsi connection
+ * @ctask: scsi command task
+ * @sc: scsi command
+ **/
+static void
+iscsi_tcp_cmd_init(struct iscsi_cmd_task *ctask)
+{
+	struct scsi_cmnd *sc = ctask->sc;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+	BUG_ON(__kfifo_len(tcp_ctask->r2tqueue));
+
+	tcp_ctask->sent = 0;
+	tcp_ctask->sg_count = 0;
+
+	if (sc->sc_data_direction == DMA_TO_DEVICE) {
+		tcp_ctask->xmstate = XMSTATE_W_HDR;
+		tcp_ctask->exp_r2tsn = 0;
+		BUG_ON(ctask->total_length == 0);
+
+		if (sc->use_sg) {
+			struct scatterlist *sg = sc->request_buffer;
+
+			iscsi_buf_init_sg(&tcp_ctask->sendbuf,
+					  &sg[tcp_ctask->sg_count++]);
+			tcp_ctask->sg = sg;
+			tcp_ctask->bad_sg = sg + sc->use_sg;
+		} else
+			iscsi_buf_init_iov(&tcp_ctask->sendbuf,
+					   sc->request_buffer,
+					   sc->request_bufflen);
+
+		if (ctask->imm_count)
+			tcp_ctask->xmstate |= XMSTATE_IMM_DATA;
+
+		tcp_ctask->pad_count = ctask->total_length & (ISCSI_PAD_LEN-1);
+		if (tcp_ctask->pad_count) {
+			tcp_ctask->pad_count = ISCSI_PAD_LEN -
+							tcp_ctask->pad_count;
+			debug_scsi("write padding %d bytes\n",
+				   tcp_ctask->pad_count);
+			tcp_ctask->xmstate |= XMSTATE_W_PAD;
+		}
+
+		if (ctask->unsol_count)
+			tcp_ctask->xmstate |= XMSTATE_UNS_HDR |
+						XMSTATE_UNS_INIT;
+		tcp_ctask->r2t_data_count = ctask->total_length -
+				    ctask->imm_count -
+				    ctask->unsol_count;
+
+		debug_scsi("cmd [itt %x total %d imm %d imm_data %d "
+			   "r2t_data %d]\n",
+			   ctask->itt, ctask->total_length, ctask->imm_count,
+			   ctask->unsol_count, tcp_ctask->r2t_data_count);
+	} else
+		tcp_ctask->xmstate = XMSTATE_R_HDR;
+
+	iscsi_buf_init_virt(&tcp_ctask->headbuf, (char*)ctask->hdr,
+			    sizeof(struct iscsi_hdr));
+}
+
+/**
+ * iscsi_tcp_mtask_xmit - xmit management(immediate) task
+ * @conn: iscsi connection
+ * @mtask: task management task
+ *
+ * Notes:
+ *	The function can return -EAGAIN in which case caller must
+ *	call it again later, or recover. '0' return code means successful
+ *	xmit.
+ *
+ *	Management xmit state machine consists of two states:
+ *		IN_PROGRESS_IMM_HEAD - PDU Header xmit in progress
+ *		IN_PROGRESS_IMM_DATA - PDU Data xmit in progress
+ **/
+static int
+iscsi_tcp_mtask_xmit(struct iscsi_conn *conn, struct iscsi_mgmt_task *mtask)
+{
+	struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
+
+	debug_scsi("mtask deq [cid %d state %x itt 0x%x]\n",
+		conn->id, tcp_mtask->xmstate, mtask->itt);
+
+	if (tcp_mtask->xmstate & XMSTATE_IMM_HDR) {
+		tcp_mtask->xmstate &= ~XMSTATE_IMM_HDR;
+		if (mtask->data_count)
+			tcp_mtask->xmstate |= XMSTATE_IMM_DATA;
+		if (conn->c_stage != ISCSI_CONN_INITIAL_STAGE &&
+		    conn->stop_stage != STOP_CONN_RECOVER &&
+		    conn->hdrdgst_en)
+			iscsi_hdr_digest(conn, &tcp_mtask->headbuf,
+					(u8*)tcp_mtask->hdrext);
+		if (iscsi_sendhdr(conn, &tcp_mtask->headbuf,
+				  mtask->data_count)) {
+			tcp_mtask->xmstate |= XMSTATE_IMM_HDR;
+			if (mtask->data_count)
+				tcp_mtask->xmstate &= ~XMSTATE_IMM_DATA;
+			return -EAGAIN;
+		}
+	}
+
+	if (tcp_mtask->xmstate & XMSTATE_IMM_DATA) {
+		BUG_ON(!mtask->data_count);
+		tcp_mtask->xmstate &= ~XMSTATE_IMM_DATA;
+		/* FIXME: implement.
+		 * Virtual buffer could be spreaded across multiple pages...
+		 */
+		do {
+			if (iscsi_sendpage(conn, &tcp_mtask->sendbuf,
+				   &mtask->data_count, &tcp_mtask->sent)) {
+				tcp_mtask->xmstate |= XMSTATE_IMM_DATA;
+				return -EAGAIN;
+			}
+		} while (mtask->data_count);
+	}
+
+	BUG_ON(tcp_mtask->xmstate != XMSTATE_IDLE);
+	if (mtask->hdr->itt == cpu_to_be32(ISCSI_RESERVED_TAG)) {
+		struct iscsi_session *session = conn->session;
+
+		spin_lock_bh(&session->lock);
+		list_del(&conn->mtask->running);
+		__kfifo_put(session->mgmtpool.queue, (void*)&conn->mtask,
+			    sizeof(void*));
+		spin_unlock_bh(&session->lock);
+	}
+	return 0;
+}
+
+static inline int
+handle_xmstate_r_hdr(struct iscsi_conn *conn,
+		     struct iscsi_tcp_cmd_task *tcp_ctask)
+{
+	tcp_ctask->xmstate &= ~XMSTATE_R_HDR;
+	if (conn->hdrdgst_en)
+		iscsi_hdr_digest(conn, &tcp_ctask->headbuf,
+				 (u8*)tcp_ctask->hdrext);
+	if (!iscsi_sendhdr(conn, &tcp_ctask->headbuf, 0)) {
+		BUG_ON(tcp_ctask->xmstate != XMSTATE_IDLE);
+		return 0; /* wait for Data-In */
+	}
+	tcp_ctask->xmstate |= XMSTATE_R_HDR;
+	return -EAGAIN;
+}
+
+static inline int
+handle_xmstate_w_hdr(struct iscsi_conn *conn,
+		     struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+	tcp_ctask->xmstate &= ~XMSTATE_W_HDR;
+	if (conn->hdrdgst_en)
+		iscsi_hdr_digest(conn, &tcp_ctask->headbuf,
+				 (u8*)tcp_ctask->hdrext);
+	if (iscsi_sendhdr(conn, &tcp_ctask->headbuf, ctask->imm_count)) {
+		tcp_ctask->xmstate |= XMSTATE_W_HDR;
+		return -EAGAIN;
+	}
+	return 0;
+}
+
+static inline int
+handle_xmstate_data_digest(struct iscsi_conn *conn,
+			   struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+	tcp_ctask->xmstate &= ~XMSTATE_DATA_DIGEST;
+	debug_tcp("resent data digest 0x%x\n", tcp_ctask->datadigest);
+	if (iscsi_digest_final_send(conn, ctask, &tcp_ctask->immbuf,
+				    &tcp_ctask->datadigest, 0)) {
+		tcp_ctask->xmstate |= XMSTATE_DATA_DIGEST;
+		debug_tcp("resent data digest 0x%x fail!\n",
+			  tcp_ctask->datadigest);
+		return -EAGAIN;
+	}
+	return 0;
+}
+
+static inline int
+handle_xmstate_imm_data(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	BUG_ON(!ctask->imm_count);
+	tcp_ctask->xmstate &= ~XMSTATE_IMM_DATA;
+
+	if (conn->datadgst_en) {
+		iscsi_data_digest_init(tcp_conn, ctask);
+		tcp_ctask->immdigest = 0;
+	}
+
+	for (;;) {
+		if (iscsi_sendpage(conn, &tcp_ctask->sendbuf, &ctask->imm_count,
+				   &tcp_ctask->sent)) {
+			tcp_ctask->xmstate |= XMSTATE_IMM_DATA;
+			if (conn->datadgst_en) {
+				crypto_digest_final(tcp_conn->data_tx_tfm,
+						(u8*)&tcp_ctask->immdigest);
+				debug_tcp("tx imm sendpage fail 0x%x\n",
+					  tcp_ctask->datadigest);
+			}
+			return -EAGAIN;
+		}
+		if (conn->datadgst_en)
+			crypto_digest_update(tcp_conn->data_tx_tfm,
+					     &tcp_ctask->sendbuf.sg, 1);
+
+		if (!ctask->imm_count)
+			break;
+		iscsi_buf_init_sg(&tcp_ctask->sendbuf,
+				  &tcp_ctask->sg[tcp_ctask->sg_count++]);
+	}
+
+	if (conn->datadgst_en && !(tcp_ctask->xmstate & XMSTATE_W_PAD)) {
+		if (iscsi_digest_final_send(conn, ctask, &tcp_ctask->immbuf,
+				            &tcp_ctask->immdigest, 1)) {
+			debug_tcp("sending imm digest 0x%x fail!\n",
+				  tcp_ctask->immdigest);
+			return -EAGAIN;
+		}
+		debug_tcp("sending imm digest 0x%x\n", tcp_ctask->immdigest);
+	}
+
+	return 0;
+}
+
+static inline int
+handle_xmstate_uns_hdr(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_data_task *dtask;
+
+	tcp_ctask->xmstate |= XMSTATE_UNS_DATA;
+	if (tcp_ctask->xmstate & XMSTATE_UNS_INIT) {
+		iscsi_unsolicit_data_init(conn, ctask);
+		BUG_ON(!tcp_ctask->dtask);
+		dtask = tcp_ctask->dtask;
+		if (conn->hdrdgst_en)
+			iscsi_hdr_digest(conn, &tcp_ctask->headbuf,
+					(u8*)dtask->hdrext);
+		tcp_ctask->xmstate &= ~XMSTATE_UNS_INIT;
+	}
+	if (iscsi_sendhdr(conn, &tcp_ctask->headbuf, ctask->data_count)) {
+		tcp_ctask->xmstate &= ~XMSTATE_UNS_DATA;
+		tcp_ctask->xmstate |= XMSTATE_UNS_HDR;
+		return -EAGAIN;
+	}
+
+	debug_scsi("uns dout [itt 0x%x dlen %d sent %d]\n",
+		   ctask->itt, ctask->unsol_count, tcp_ctask->sent);
+	return 0;
+}
+
+static inline int
+handle_xmstate_uns_data(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_data_task *dtask = tcp_ctask->dtask;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	BUG_ON(!ctask->data_count);
+	tcp_ctask->xmstate &= ~XMSTATE_UNS_DATA;
+
+	if (conn->datadgst_en) {
+		iscsi_data_digest_init(tcp_conn, ctask);
+		dtask->digest = 0;
+	}
+
+	for (;;) {
+		int start = tcp_ctask->sent;
+
+		if (iscsi_sendpage(conn, &tcp_ctask->sendbuf,
+				   &ctask->data_count, &tcp_ctask->sent)) {
+			ctask->unsol_count -= tcp_ctask->sent - start;
+			tcp_ctask->xmstate |= XMSTATE_UNS_DATA;
+			/* will continue with this ctask later.. */
+			if (conn->datadgst_en) {
+				crypto_digest_final(tcp_conn->data_tx_tfm,
+						(u8 *)&dtask->digest);
+				debug_tcp("tx uns data fail 0x%x\n",
+					  dtask->digest);
+			}
+			return -EAGAIN;
+		}
+
+		BUG_ON(tcp_ctask->sent > ctask->total_length);
+		ctask->unsol_count -= tcp_ctask->sent - start;
+
+		/*
+		 * XXX:we may run here with un-initial sendbuf.
+		 * so pass it
+		 */
+		if (conn->datadgst_en && tcp_ctask->sent - start > 0)
+			crypto_digest_update(tcp_conn->data_tx_tfm,
+					     &tcp_ctask->sendbuf.sg, 1);
+
+		if (!ctask->data_count)
+			break;
+		iscsi_buf_init_sg(&tcp_ctask->sendbuf,
+				  &tcp_ctask->sg[tcp_ctask->sg_count++]);
+	}
+	BUG_ON(ctask->unsol_count < 0);
+
+	/*
+	 * Done with the Data-Out. Next, check if we need
+	 * to send another unsolicited Data-Out.
+	 */
+	if (ctask->unsol_count) {
+		if (conn->datadgst_en) {
+			if (iscsi_digest_final_send(conn, ctask,
+						    &dtask->digestbuf,
+						    &dtask->digest, 1)) {
+				debug_tcp("send uns digest 0x%x fail\n",
+					  dtask->digest);
+				return -EAGAIN;
+			}
+			debug_tcp("sending uns digest 0x%x, more uns\n",
+				  dtask->digest);
+		}
+		tcp_ctask->xmstate |= XMSTATE_UNS_INIT;
+		return 1;
+	}
+
+	if (conn->datadgst_en && !(tcp_ctask->xmstate & XMSTATE_W_PAD)) {
+		if (iscsi_digest_final_send(conn, ctask,
+					    &dtask->digestbuf,
+					    &dtask->digest, 1)) {
+			debug_tcp("send last uns digest 0x%x fail\n",
+				   dtask->digest);
+			return -EAGAIN;
+		}
+		debug_tcp("sending uns digest 0x%x\n",dtask->digest);
+	}
+
+	return 0;
+}
+
+static inline int
+handle_xmstate_sol_data(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_r2t_info *r2t = tcp_ctask->r2t;
+	struct iscsi_data_task *dtask = r2t->dtask;
+	int left;
+
+	tcp_ctask->xmstate &= ~XMSTATE_SOL_DATA;
+	tcp_ctask->dtask = dtask;
+
+	if (conn->datadgst_en) {
+		iscsi_data_digest_init(tcp_conn, ctask);
+		dtask->digest = 0;
+	}
+solicit_again:
+	/*
+	 * send Data-Out whitnin this R2T sequence.
+	 */
+	if (!r2t->data_count)
+		goto data_out_done;
+
+	if (iscsi_sendpage(conn, &r2t->sendbuf, &r2t->data_count, &r2t->sent)) {
+		tcp_ctask->xmstate |= XMSTATE_SOL_DATA;
+		/* will continue with this ctask later.. */
+		if (conn->datadgst_en) {
+			crypto_digest_final(tcp_conn->data_tx_tfm,
+					  (u8 *)&dtask->digest);
+			debug_tcp("r2t data send fail 0x%x\n", dtask->digest);
+		}
+		return -EAGAIN;
+	}
+
+	BUG_ON(r2t->data_count < 0);
+	if (conn->datadgst_en)
+		crypto_digest_update(tcp_conn->data_tx_tfm, &r2t->sendbuf.sg,
+				     1);
+
+	if (r2t->data_count) {
+		BUG_ON(ctask->sc->use_sg == 0);
+		if (!iscsi_buf_left(&r2t->sendbuf)) {
+			BUG_ON(tcp_ctask->bad_sg == r2t->sg);
+			iscsi_buf_init_sg(&r2t->sendbuf, r2t->sg);
+			r2t->sg += 1;
+		}
+		goto solicit_again;
+	}
+
+data_out_done:
+	/*
+	 * Done with this Data-Out. Next, check if we have
+	 * to send another Data-Out for this R2T.
+	 */
+	BUG_ON(r2t->data_length - r2t->sent < 0);
+	left = r2t->data_length - r2t->sent;
+	if (left) {
+		if (conn->datadgst_en) {
+			if (iscsi_digest_final_send(conn, ctask,
+						    &dtask->digestbuf,
+						    &dtask->digest, 1)) {
+				debug_tcp("send r2t data digest 0x%x"
+					  "fail\n", dtask->digest);
+				return -EAGAIN;
+			}
+			debug_tcp("r2t data send digest 0x%x\n",
+				  dtask->digest);
+		}
+		iscsi_solicit_data_cont(conn, ctask, r2t, left);
+		tcp_ctask->xmstate |= XMSTATE_SOL_DATA;
+		tcp_ctask->xmstate &= ~XMSTATE_SOL_HDR;
+		return 1;
+	}
+
+	/*
+	 * Done with this R2T. Check if there are more
+	 * outstanding R2Ts ready to be processed.
+	 */
+	BUG_ON(tcp_ctask->r2t_data_count - r2t->data_length < 0);
+	if (conn->datadgst_en) {
+		if (iscsi_digest_final_send(conn, ctask, &dtask->digestbuf,
+					    &dtask->digest, 1)) {
+			debug_tcp("send last r2t data digest 0x%x"
+				  "fail\n", dtask->digest);
+			return -EAGAIN;
+		}
+		debug_tcp("r2t done dout digest 0x%x\n", dtask->digest);
+	}
+
+	tcp_ctask->r2t_data_count -= r2t->data_length;
+	tcp_ctask->r2t = NULL;
+	spin_lock_bh(&session->lock);
+	__kfifo_put(tcp_ctask->r2tpool.queue, (void*)&r2t, sizeof(void*));
+	spin_unlock_bh(&session->lock);
+	if (__kfifo_get(tcp_ctask->r2tqueue, (void*)&r2t, sizeof(void*))) {
+		tcp_ctask->r2t = r2t;
+		tcp_ctask->xmstate |= XMSTATE_SOL_DATA;
+		tcp_ctask->xmstate &= ~XMSTATE_SOL_HDR;
+		return 1;
+	}
+
+	return 0;
+}
+
+static inline int
+handle_xmstate_w_pad(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct iscsi_data_task *dtask = tcp_ctask->dtask;
+	int sent;
+
+	tcp_ctask->xmstate &= ~XMSTATE_W_PAD;
+	iscsi_buf_init_virt(&tcp_ctask->sendbuf, (char*)&tcp_ctask->pad,
+			    tcp_ctask->pad_count);
+	if (iscsi_sendpage(conn, &tcp_ctask->sendbuf, &tcp_ctask->pad_count,
+			   &sent)) {
+		tcp_ctask->xmstate |= XMSTATE_W_PAD;
+		return -EAGAIN;
+	}
+
+	if (conn->datadgst_en) {
+		crypto_digest_update(tcp_conn->data_tx_tfm,
+				     &tcp_ctask->sendbuf.sg, 1);
+		/* imm data? */
+		if (!dtask) {
+			if (iscsi_digest_final_send(conn, ctask,
+						    &tcp_ctask->immbuf,
+						    &tcp_ctask->immdigest, 1)) {
+				debug_tcp("send padding digest 0x%x"
+					  "fail!\n", tcp_ctask->immdigest);
+				return -EAGAIN;
+			}
+			debug_tcp("done with padding, digest 0x%x\n",
+				  tcp_ctask->datadigest);
+		} else {
+			if (iscsi_digest_final_send(conn, ctask,
+						    &dtask->digestbuf,
+						    &dtask->digest, 1)) {
+				debug_tcp("send padding digest 0x%x"
+				          "fail\n", dtask->digest);
+				return -EAGAIN;
+			}
+			debug_tcp("done with padding, digest 0x%x\n",
+				  dtask->digest);
+		}
+	}
+
+	return 0;
+}
+
+static int
+iscsi_tcp_ctask_xmit(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	int rc = 0;
+
+	debug_scsi("ctask deq [cid %d xmstate %x itt 0x%x]\n",
+		conn->id, tcp_ctask->xmstate, ctask->itt);
+
+	/*
+	 * serialize with TMF AbortTask
+	 */
+	if (ctask->mtask)
+		return rc;
+
+	if (tcp_ctask->xmstate & XMSTATE_R_HDR) {
+		rc = handle_xmstate_r_hdr(conn, tcp_ctask);
+		return rc;
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_W_HDR) {
+		rc = handle_xmstate_w_hdr(conn, ctask);
+		if (rc)
+			return rc;
+	}
+
+	/* XXX: for data digest xmit recover */
+	if (tcp_ctask->xmstate & XMSTATE_DATA_DIGEST) {
+		rc = handle_xmstate_data_digest(conn, ctask);
+		if (rc)
+			return rc;
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_IMM_DATA) {
+		rc = handle_xmstate_imm_data(conn, ctask);
+		if (rc)
+			return rc;
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_UNS_HDR) {
+		BUG_ON(!ctask->unsol_count);
+		tcp_ctask->xmstate &= ~XMSTATE_UNS_HDR;
+unsolicit_head_again:
+		rc = handle_xmstate_uns_hdr(conn, ctask);
+		if (rc)
+			return rc;
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_UNS_DATA) {
+		rc = handle_xmstate_uns_data(conn, ctask);
+		if (rc == 1)
+			goto unsolicit_head_again;
+		else if (rc)
+			return rc;
+		goto done;
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_SOL_HDR) {
+		struct iscsi_r2t_info *r2t;
+
+		tcp_ctask->xmstate &= ~XMSTATE_SOL_HDR;
+		tcp_ctask->xmstate |= XMSTATE_SOL_DATA;
+		if (!tcp_ctask->r2t)
+			__kfifo_get(tcp_ctask->r2tqueue, (void*)&tcp_ctask->r2t,
+				    sizeof(void*));
+solicit_head_again:
+		r2t = tcp_ctask->r2t;
+		if (conn->hdrdgst_en)
+			iscsi_hdr_digest(conn, &r2t->headbuf,
+					(u8*)r2t->dtask->hdrext);
+		if (iscsi_sendhdr(conn, &r2t->headbuf, r2t->data_count)) {
+			tcp_ctask->xmstate &= ~XMSTATE_SOL_DATA;
+			tcp_ctask->xmstate |= XMSTATE_SOL_HDR;
+			return -EAGAIN;
+		}
+
+		debug_scsi("sol dout [dsn %d itt 0x%x dlen %d sent %d]\n",
+			r2t->solicit_datasn - 1, ctask->itt, r2t->data_count,
+			r2t->sent);
+	}
+
+	if (tcp_ctask->xmstate & XMSTATE_SOL_DATA) {
+		rc = handle_xmstate_sol_data(conn, ctask);
+		if (rc == 1)
+			goto solicit_head_again;
+		if (rc)
+			return rc;
+	}
+
+done:
+	/*
+	 * Last thing to check is whether we need to send write
+	 * padding. Note that we check for xmstate equality, not just the bit.
+	 */
+	if (tcp_ctask->xmstate == XMSTATE_W_PAD)
+		rc = handle_xmstate_w_pad(conn, ctask);
+
+	return rc;
+}
+
+static struct iscsi_cls_conn *
+iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
+{
+	struct iscsi_conn *conn;
+	struct iscsi_cls_conn *cls_conn;
+	struct iscsi_tcp_conn *tcp_conn;
+
+	cls_conn = iscsi_conn_setup(cls_session, conn_idx);
+	if (!cls_conn)
+		return NULL;
+	conn = cls_conn->dd_data;
+	/*
+	 * due to strange issues with iser these are not set
+	 * in iscsi_conn_setup
+	 */
+	conn->max_recv_dlength = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+
+	tcp_conn = kzalloc(sizeof(*tcp_conn), GFP_KERNEL);
+	if (!tcp_conn)
+		goto tcp_conn_alloc_fail;
+
+	conn->dd_data = tcp_conn;
+	tcp_conn->iscsi_conn = conn;
+	tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	/* initial operational parameters */
+	tcp_conn->hdr_size = sizeof(struct iscsi_hdr);
+	tcp_conn->data_size = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
+
+	/* allocate initial PDU receive place holder */
+	if (tcp_conn->data_size <= PAGE_SIZE)
+		tcp_conn->data = kmalloc(tcp_conn->data_size, GFP_KERNEL);
+	else
+		tcp_conn->data = (void*)__get_free_pages(GFP_KERNEL,
+					get_order(tcp_conn->data_size));
+	if (!tcp_conn->data)
+		goto max_recv_dlenght_alloc_fail;
+
+	return cls_conn;
+
+max_recv_dlenght_alloc_fail:
+	kfree(tcp_conn);
+tcp_conn_alloc_fail:
+	iscsi_conn_teardown(cls_conn);
+	return NULL;
+}
+
+static void
+iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	int digest = 0;
+
+	if (conn->hdrdgst_en || conn->datadgst_en)
+		digest = 1;
+
+	iscsi_conn_teardown(cls_conn);
+
+	/* now free tcp_conn */
+	if (digest) {
+		if (tcp_conn->tx_tfm)
+			crypto_free_tfm(tcp_conn->tx_tfm);
+		if (tcp_conn->rx_tfm)
+			crypto_free_tfm(tcp_conn->rx_tfm);
+		if (tcp_conn->data_tx_tfm)
+			crypto_free_tfm(tcp_conn->data_tx_tfm);
+		if (tcp_conn->data_rx_tfm)
+			crypto_free_tfm(tcp_conn->data_rx_tfm);
+	}
+
+	/* free conn->data, size = MaxRecvDataSegmentLength */
+	if (tcp_conn->data_size <= PAGE_SIZE)
+		kfree(tcp_conn->data);
+	else
+		free_pages((unsigned long)tcp_conn->data,
+			   get_order(tcp_conn->data_size));
+	kfree(tcp_conn);
+}
+
+static int
+iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
+		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
+		    int is_leading)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk;
+	struct socket *sock;
+	int err;
+
+	/* lookup for existing socket */
+	sock = sockfd_lookup((int)transport_eph, &err);
+	if (!sock) {
+		printk(KERN_ERR "iscsi_tcp: sockfd_lookup failed %d\n", err);
+		return -EEXIST;
+	}
+
+	err = iscsi_conn_bind(cls_session, cls_conn, is_leading);
+	if (err)
+		return err;
+
+	if (conn->stop_stage != STOP_CONN_SUSPEND) {
+		/* bind iSCSI connection and socket */
+		tcp_conn->sock = sock;
+
+		/* setup Socket parameters */
+		sk = sock->sk;
+		sk->sk_reuse = 1;
+		sk->sk_sndtimeo = 15 * HZ; /* FIXME: make it configurable */
+		sk->sk_allocation = GFP_ATOMIC;
+
+		/* FIXME: disable Nagle's algorithm */
+
+		/*
+		 * Intercept TCP callbacks for sendfile like receive
+		 * processing.
+		 */
+		conn->recv_lock = &sk->sk_callback_lock;
+		iscsi_conn_set_callbacks(conn);
+		tcp_conn->sendpage = tcp_conn->sock->ops->sendpage;
+		/*
+		 * set receive state machine into initial state
+		 */
+		tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
+	}
+
+	return 0;
+}
+
+static void
+iscsi_tcp_cleanup_ctask(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	struct iscsi_r2t_info *r2t;
+
+	/* flush ctask's r2t queues */
+	while (__kfifo_get(tcp_ctask->r2tqueue, (void*)&r2t, sizeof(void*)))
+		__kfifo_put(tcp_ctask->r2tpool.queue, (void*)&r2t,
+			    sizeof(void*));
+
+	__iscsi_ctask_cleanup(conn, ctask);
+}
+
+static void
+iscsi_tcp_suspend_conn_rx(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk;
+
+	if (!tcp_conn->sock)
+		return;
+
+	sk = tcp_conn->sock->sk;
+	write_lock_bh(&sk->sk_callback_lock);
+	set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+static void
+iscsi_tcp_terminate_conn(struct iscsi_conn *conn)
+{
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	if (!tcp_conn->sock)
+		return;
+
+	sock_hold(tcp_conn->sock->sk);
+	iscsi_conn_restore_callbacks(conn);
+	sock_put(tcp_conn->sock->sk);
+
+	sock_release(tcp_conn->sock);
+	tcp_conn->sock = NULL;
+	conn->recv_lock = NULL;
+}
+
+/* called with host lock */
+static void 
+iscsi_tcp_mgmt_init(struct iscsi_conn *conn, struct iscsi_mgmt_task *mtask,
+		    char *data, uint32_t data_size)
+{
+	struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
+
+	iscsi_buf_init_virt(&tcp_mtask->headbuf, (char*)mtask->hdr,
+				    sizeof(struct iscsi_hdr));
+	tcp_mtask->xmstate = XMSTATE_IMM_HDR;
+
+	if (mtask->data_count)
+		iscsi_buf_init_iov(&tcp_mtask->sendbuf, (char*)mtask->data,
+				    mtask->data_count);
+}
+
+static int
+iscsi_r2tpool_alloc(struct iscsi_session *session)
+{
+	int i;
+	int cmd_i;
+
+	/*
+	 * initialize per-task: R2T pool and xmit queue
+	 */
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+	        struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		/*
+		 * pre-allocated x4 as much r2ts to handle race when
+		 * target acks DataOut faster than we data_xmit() queues
+		 * could replenish r2tqueue.
+		 */
+
+		/* R2T pool */
+		if (iscsi_pool_init(&tcp_ctask->r2tpool, session->max_r2t * 4,
+				    (void***)&tcp_ctask->r2ts,
+				    sizeof(struct iscsi_r2t_info))) {
+			goto r2t_alloc_fail;
+		}
+
+		/* R2T xmit queue */
+		tcp_ctask->r2tqueue = kfifo_alloc(
+		      session->max_r2t * 4 * sizeof(void*), GFP_KERNEL, NULL);
+		if (tcp_ctask->r2tqueue == ERR_PTR(-ENOMEM)) {
+			iscsi_pool_free(&tcp_ctask->r2tpool,
+					(void**)tcp_ctask->r2ts);
+			goto r2t_alloc_fail;
+		}
+
+		/*
+		 * number of
+		 * Data-Out PDU's within R2T-sequence can be quite big;
+		 * using mempool
+		 */
+		tcp_ctask->datapool = mempool_create(ISCSI_DTASK_DEFAULT_MAX,
+			 mempool_alloc_slab, mempool_free_slab, taskcache);
+		if (tcp_ctask->datapool == NULL) {
+			kfifo_free(tcp_ctask->r2tqueue);
+			iscsi_pool_free(&tcp_ctask->r2tpool,
+					(void**)tcp_ctask->r2ts);
+			goto r2t_alloc_fail;
+		}
+		INIT_LIST_HEAD(&tcp_ctask->dataqueue);
+	}
+
+	return 0;
+
+r2t_alloc_fail:
+	for (i = 0; i < cmd_i; i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		mempool_destroy(tcp_ctask->datapool);
+		kfifo_free(tcp_ctask->r2tqueue);
+		iscsi_pool_free(&tcp_ctask->r2tpool,
+				(void**)tcp_ctask->r2ts);
+	}
+	return -ENOMEM;
+}
+
+static void
+iscsi_r2tpool_free(struct iscsi_session *session)
+{
+	int i;
+
+	for (i = 0; i < session->cmds_max; i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		mempool_destroy(tcp_ctask->datapool);
+		kfifo_free(tcp_ctask->r2tqueue);
+		iscsi_pool_free(&tcp_ctask->r2tpool,
+				(void**)tcp_ctask->r2ts);
+	}
+}
+
+static int
+iscsi_conn_set_param(struct iscsi_cls_conn *cls_conn, enum iscsi_param param,
+		     uint32_t value)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	switch(param) {
+	case ISCSI_PARAM_MAX_RECV_DLENGTH: {
+		char *saveptr = tcp_conn->data;
+		gfp_t flags = GFP_KERNEL;
+
+		if (tcp_conn->data_size >= value) {
+			conn->max_recv_dlength = value;
+			break;
+		}
+
+		spin_lock_bh(&session->lock);
+		if (conn->stop_stage == STOP_CONN_RECOVER)
+			flags = GFP_ATOMIC;
+		spin_unlock_bh(&session->lock);
+
+		if (value <= PAGE_SIZE)
+			tcp_conn->data = kmalloc(value, flags);
+		else
+			tcp_conn->data = (void*)__get_free_pages(flags,
+							     get_order(value));
+		if (tcp_conn->data == NULL) {
+			tcp_conn->data = saveptr;
+			return -ENOMEM;
+		}
+		if (tcp_conn->data_size <= PAGE_SIZE)
+			kfree(saveptr);
+		else
+			free_pages((unsigned long)saveptr,
+				   get_order(tcp_conn->data_size));
+		conn->max_recv_dlength = value;
+		tcp_conn->data_size = value;
+		}
+		break;
+	case ISCSI_PARAM_MAX_XMIT_DLENGTH:
+		conn->max_xmit_dlength =  value;
+		break;
+	case ISCSI_PARAM_HDRDGST_EN:
+		conn->hdrdgst_en = value;
+		tcp_conn->hdr_size = sizeof(struct iscsi_hdr);
+		if (conn->hdrdgst_en) {
+			tcp_conn->hdr_size += sizeof(__u32);
+			if (!tcp_conn->tx_tfm)
+				tcp_conn->tx_tfm = crypto_alloc_tfm("crc32c",
+								    0);
+			if (!tcp_conn->tx_tfm)
+				return -ENOMEM;
+			if (!tcp_conn->rx_tfm)
+				tcp_conn->rx_tfm = crypto_alloc_tfm("crc32c",
+								    0);
+			if (!tcp_conn->rx_tfm) {
+				crypto_free_tfm(tcp_conn->tx_tfm);
+				return -ENOMEM;
+			}
+		} else {
+			if (tcp_conn->tx_tfm)
+				crypto_free_tfm(tcp_conn->tx_tfm);
+			if (tcp_conn->rx_tfm)
+				crypto_free_tfm(tcp_conn->rx_tfm);
+		}
+		break;
+	case ISCSI_PARAM_DATADGST_EN:
+		conn->datadgst_en = value;
+		if (conn->datadgst_en) {
+			if (!tcp_conn->data_tx_tfm)
+				tcp_conn->data_tx_tfm =
+				    crypto_alloc_tfm("crc32c", 0);
+			if (!tcp_conn->data_tx_tfm)
+				return -ENOMEM;
+			if (!tcp_conn->data_rx_tfm)
+				tcp_conn->data_rx_tfm =
+				    crypto_alloc_tfm("crc32c", 0);
+			if (!tcp_conn->data_rx_tfm) {
+				crypto_free_tfm(tcp_conn->data_tx_tfm);
+				return -ENOMEM;
+			}
+		} else {
+			if (tcp_conn->data_tx_tfm)
+				crypto_free_tfm(tcp_conn->data_tx_tfm);
+			if (tcp_conn->data_rx_tfm)
+				crypto_free_tfm(tcp_conn->data_rx_tfm);
+		}
+		tcp_conn->sendpage = conn->datadgst_en ?
+			sock_no_sendpage : tcp_conn->sock->ops->sendpage;
+		break;
+	case ISCSI_PARAM_INITIAL_R2T_EN:
+		session->initial_r2t_en = value;
+		break;
+	case ISCSI_PARAM_MAX_R2T:
+		if (session->max_r2t == roundup_pow_of_two(value))
+			break;
+		iscsi_r2tpool_free(session);
+		session->max_r2t = value;
+		if (session->max_r2t & (session->max_r2t - 1))
+			session->max_r2t = roundup_pow_of_two(session->max_r2t);
+		if (iscsi_r2tpool_alloc(session))
+			return -ENOMEM;
+		break;
+	case ISCSI_PARAM_IMM_DATA_EN:
+		session->imm_data_en = value;
+		break;
+	case ISCSI_PARAM_FIRST_BURST:
+		session->first_burst = value;
+		break;
+	case ISCSI_PARAM_MAX_BURST:
+		session->max_burst = value;
+		break;
+	case ISCSI_PARAM_PDU_INORDER_EN:
+		session->pdu_inorder_en = value;
+		break;
+	case ISCSI_PARAM_DATASEQ_INORDER_EN:
+		session->dataseq_inorder_en = value;
+		break;
+	case ISCSI_PARAM_ERL:
+		session->erl = value;
+		break;
+	case ISCSI_PARAM_IFMARKER_EN:
+		BUG_ON(value);
+		session->ifmarker_en = value;
+		break;
+	case ISCSI_PARAM_OFMARKER_EN:
+		BUG_ON(value);
+		session->ofmarker_en = value;
+		break;
+	case ISCSI_PARAM_EXP_STATSN:
+		conn->exp_statsn = value;
+		break;
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static int
+iscsi_session_get_param(struct iscsi_cls_session *cls_session,
+			enum iscsi_param param, uint32_t *value)
+{
+	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
+	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
+
+	switch(param) {
+	case ISCSI_PARAM_INITIAL_R2T_EN:
+		*value = session->initial_r2t_en;
+		break;
+	case ISCSI_PARAM_MAX_R2T:
+		*value = session->max_r2t;
+		break;
+	case ISCSI_PARAM_IMM_DATA_EN:
+		*value = session->imm_data_en;
+		break;
+	case ISCSI_PARAM_FIRST_BURST:
+		*value = session->first_burst;
+		break;
+	case ISCSI_PARAM_MAX_BURST:
+		*value = session->max_burst;
+		break;
+	case ISCSI_PARAM_PDU_INORDER_EN:
+		*value = session->pdu_inorder_en;
+		break;
+	case ISCSI_PARAM_DATASEQ_INORDER_EN:
+		*value = session->dataseq_inorder_en;
+		break;
+	case ISCSI_PARAM_ERL:
+		*value = session->erl;
+		break;
+	case ISCSI_PARAM_IFMARKER_EN:
+		*value = session->ifmarker_en;
+		break;
+	case ISCSI_PARAM_OFMARKER_EN:
+		*value = session->ofmarker_en;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+iscsi_conn_get_param(struct iscsi_cls_conn *cls_conn,
+		     enum iscsi_param param, uint32_t *value)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct inet_sock *inet;
+
+	switch(param) {
+	case ISCSI_PARAM_MAX_RECV_DLENGTH:
+		*value = conn->max_recv_dlength;
+		break;
+	case ISCSI_PARAM_MAX_XMIT_DLENGTH:
+		*value = conn->max_xmit_dlength;
+		break;
+	case ISCSI_PARAM_HDRDGST_EN:
+		*value = conn->hdrdgst_en;
+		break;
+	case ISCSI_PARAM_DATADGST_EN:
+		*value = conn->datadgst_en;
+		break;
+	case ISCSI_PARAM_CONN_PORT:
+		mutex_lock(&conn->xmitmutex);
+		if (!tcp_conn->sock) {
+			mutex_unlock(&conn->xmitmutex);
+			return -EINVAL;
+		}
+
+		inet = inet_sk(tcp_conn->sock->sk);
+		*value = be16_to_cpu(inet->dport); 
+		mutex_unlock(&conn->xmitmutex);
+	case ISCSI_PARAM_EXP_STATSN:
+		*value = conn->exp_statsn;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+iscsi_conn_get_str_param(struct iscsi_cls_conn *cls_conn,
+			 enum iscsi_param param, char *buf)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	struct sock *sk;
+	struct inet_sock *inet;
+	struct ipv6_pinfo *np;
+	int len = 0;
+
+	switch (param) {
+	case ISCSI_PARAM_CONN_ADDRESS:
+		mutex_lock(&conn->xmitmutex);
+		if (!tcp_conn->sock) {
+			mutex_unlock(&conn->xmitmutex);
+			return -EINVAL;
+		}
+
+		sk = tcp_conn->sock->sk;
+		if (sk->sk_family == PF_INET) {
+			inet = inet_sk(sk);
+			len = sprintf(buf, "%u.%u.%u.%u\n",
+				      NIPQUAD(inet->daddr));
+		} else {
+			np = inet6_sk(sk);
+			len = sprintf(buf,
+				"%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x\n",
+				NIP6(np->daddr));
+		}
+		mutex_unlock(&conn->xmitmutex);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return len;
+}
+
+static void
+iscsi_conn_get_stats(struct iscsi_cls_conn *cls_conn, struct iscsi_stats *stats)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+
+	stats->txdata_octets = conn->txdata_octets;
+	stats->rxdata_octets = conn->rxdata_octets;
+	stats->scsicmd_pdus = conn->scsicmd_pdus_cnt;
+	stats->dataout_pdus = conn->dataout_pdus_cnt;
+	stats->scsirsp_pdus = conn->scsirsp_pdus_cnt;
+	stats->datain_pdus = conn->datain_pdus_cnt;
+	stats->r2t_pdus = conn->r2t_pdus_cnt;
+	stats->tmfcmd_pdus = conn->tmfcmd_pdus_cnt;
+	stats->tmfrsp_pdus = conn->tmfrsp_pdus_cnt;
+	stats->custom_length = 3;
+	strcpy(stats->custom[0].desc, "tx_sendpage_failures");
+	stats->custom[0].value = tcp_conn->sendpage_failures_cnt;
+	strcpy(stats->custom[1].desc, "rx_discontiguous_hdr");
+	stats->custom[1].value = tcp_conn->discontiguous_hdr_cnt;
+	strcpy(stats->custom[2].desc, "eh_abort_cnt");
+	stats->custom[2].value = conn->eh_abort_cnt;
+}
+
+static struct iscsi_cls_session *
+iscsi_tcp_session_create(struct iscsi_transport *iscsit,
+			 struct scsi_transport_template *scsit,
+			 uint32_t initial_cmdsn, uint32_t *hostno)
+{
+	struct iscsi_cls_session *cls_session;
+	struct iscsi_session *session;
+	uint32_t hn;
+	int cmd_i;
+
+	cls_session = iscsi_session_setup(iscsit, scsit,
+					 sizeof(struct iscsi_tcp_cmd_task),
+					 sizeof(struct iscsi_tcp_mgmt_task),
+					 initial_cmdsn, &hn);
+	if (!cls_session)
+		return NULL;
+	*hostno = hn;
+
+	session = class_to_transport_session(cls_session);
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		ctask->hdr = &tcp_ctask->hdr;
+	}
+
+	for (cmd_i = 0; cmd_i < session->mgmtpool_max; cmd_i++) {
+		struct iscsi_mgmt_task *mtask = session->mgmt_cmds[cmd_i];
+		struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
+
+		mtask->hdr = &tcp_mtask->hdr;
+	}
+
+	if (iscsi_r2tpool_alloc(class_to_transport_session(cls_session)))
+		goto r2tpool_alloc_fail;
+
+	return cls_session;
+
+r2tpool_alloc_fail:
+	iscsi_session_teardown(cls_session);
+	return NULL;
+}
+
+static void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
+{
+	struct iscsi_session *session = class_to_transport_session(cls_session);
+	struct iscsi_data_task *dtask, *n;
+	int cmd_i;
+
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+
+		list_for_each_entry_safe(dtask, n, &tcp_ctask->dataqueue,
+					 item) {
+			list_del(&dtask->item);
+			mempool_free(dtask, tcp_ctask->datapool);
+		}
+	}
+
+	iscsi_r2tpool_free(class_to_transport_session(cls_session));
+	iscsi_session_teardown(cls_session);
+}
+
+static struct scsi_host_template iscsi_sht = {
+	.name			= "iSCSI Initiator over TCP/IP, v."
+				  ISCSI_VERSION_STR,
+	.queuecommand           = iscsi_queuecommand,
+	.change_queue_depth	= iscsi_change_queue_depth,
+	.can_queue		= ISCSI_XMIT_CMDS_MAX - 1,
+	.sg_tablesize		= ISCSI_SG_TABLESIZE,
+	.cmd_per_lun		= ISCSI_DEF_CMD_PER_LUN,
+	.eh_abort_handler       = iscsi_eh_abort,
+	.eh_host_reset_handler	= iscsi_eh_host_reset,
+	.use_clustering         = DISABLE_CLUSTERING,
+	.proc_name		= "iscsi_tcp",
+	.this_id		= -1,
+};
+
+static struct iscsi_transport iscsi_tcp_transport = {
+	.owner			= THIS_MODULE,
+	.name			= "tcp",
+	.caps			= CAP_RECOVERY_L0 | CAP_MULTI_R2T | CAP_HDRDGST
+				  | CAP_DATADGST,
+	.param_mask		= ISCSI_MAX_RECV_DLENGTH |
+				  ISCSI_MAX_XMIT_DLENGTH |
+				  ISCSI_HDRDGST_EN |
+				  ISCSI_DATADGST_EN |
+				  ISCSI_INITIAL_R2T_EN |
+				  ISCSI_MAX_R2T |
+				  ISCSI_IMM_DATA_EN |
+				  ISCSI_FIRST_BURST |
+				  ISCSI_MAX_BURST |
+				  ISCSI_PDU_INORDER_EN |
+				  ISCSI_DATASEQ_INORDER_EN |
+				  ISCSI_ERL |
+				  ISCSI_CONN_PORT |
+				  ISCSI_CONN_ADDRESS |
+				  ISCSI_EXP_STATSN,
+	.host_template		= &iscsi_sht,
+	.conndata_size		= sizeof(struct iscsi_conn),
+	.max_conn		= 1,
+	.max_cmd_len		= ISCSI_TCP_MAX_CMD_LEN,
+	/* session management */
+	.create_session		= iscsi_tcp_session_create,
+	.destroy_session	= iscsi_tcp_session_destroy,
+	/* connection management */
+	.create_conn		= iscsi_tcp_conn_create,
+	.bind_conn		= iscsi_tcp_conn_bind,
+	.destroy_conn		= iscsi_tcp_conn_destroy,
+	.set_param		= iscsi_conn_set_param,
+	.get_conn_param		= iscsi_conn_get_param,
+	.get_conn_str_param	= iscsi_conn_get_str_param,
+	.get_session_param	= iscsi_session_get_param,
+	.start_conn		= iscsi_conn_start,
+	.stop_conn		= iscsi_conn_stop,
+	/* these are called as part of conn recovery */
+	.suspend_conn_recv	= iscsi_tcp_suspend_conn_rx,
+	.terminate_conn		= iscsi_tcp_terminate_conn,
+	/* IO */
+	.send_pdu		= iscsi_conn_send_pdu,
+	.get_stats		= iscsi_conn_get_stats,
+	.init_cmd_task		= iscsi_tcp_cmd_init,
+	.init_mgmt_task		= iscsi_tcp_mgmt_init,
+	.xmit_cmd_task		= iscsi_tcp_ctask_xmit,
+	.xmit_mgmt_task		= iscsi_tcp_mtask_xmit,
+	.cleanup_cmd_task	= iscsi_tcp_cleanup_ctask,
+	/* recovery */
+	.session_recovery_timedout = iscsi_session_recovery_timedout,
+};
+
+static int __init
+iscsi_tcp_init(void)
+{
+	if (iscsi_max_lun < 1) {
+		printk(KERN_ERR "iscsi_tcp: Invalid max_lun value of %u\n", iscsi_max_lun);
+		return -EINVAL;
+	}
+	iscsi_tcp_transport.max_lun = iscsi_max_lun;
+
+	taskcache = kmem_cache_create("iscsi_taskcache",
+			sizeof(struct iscsi_data_task), 0,
+			SLAB_HWCACHE_ALIGN, NULL, NULL);
+	if (!taskcache)
+		return -ENOMEM;
+
+	if (!iscsi_register_transport(&iscsi_tcp_transport))
+		kmem_cache_destroy(taskcache);
+
+	return 0;
+}
+
+static void __exit
+iscsi_tcp_exit(void)
+{
+	iscsi_unregister_transport(&iscsi_tcp_transport);
+	kmem_cache_destroy(taskcache);
+}
+
+module_init(iscsi_tcp_init);
+module_exit(iscsi_tcp_exit);

Added: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,180 @@
+/*
+ * iSCSI Initiator TCP Transport
+ * Copyright (C) 2004 Dmitry Yusupov
+ * Copyright (C) 2004 Alex Aizman
+ * Copyright (C) 2005 - 2006 Mike Christie
+ * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
+ * maintained by open-iscsi at googlegroups.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published
+ * by the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * See the file COPYING included with this distribution for more details.
+ */
+
+#ifndef ISCSI_TCP_H
+#define ISCSI_TCP_H
+
+#include "libiscsi.h"
+
+/* Socket's Receive state machine */
+#define IN_PROGRESS_WAIT_HEADER		0x0
+#define IN_PROGRESS_HEADER_GATHER	0x1
+#define IN_PROGRESS_DATA_RECV		0x2
+#define IN_PROGRESS_DDIGEST_RECV	0x3
+
+/* xmit state machine */
+#define	XMSTATE_IDLE			0x0
+#define	XMSTATE_R_HDR			0x1
+#define	XMSTATE_W_HDR			0x2
+#define	XMSTATE_IMM_HDR			0x4
+#define	XMSTATE_IMM_DATA		0x8
+#define	XMSTATE_UNS_INIT		0x10
+#define	XMSTATE_UNS_HDR			0x20
+#define	XMSTATE_UNS_DATA		0x40
+#define	XMSTATE_SOL_HDR			0x80
+#define	XMSTATE_SOL_DATA		0x100
+#define	XMSTATE_W_PAD			0x200
+#define XMSTATE_DATA_DIGEST		0x400
+
+#define ISCSI_CONN_RCVBUF_MIN		262144
+#define ISCSI_CONN_SNDBUF_MIN		262144
+#define ISCSI_PAD_LEN			4
+#define ISCSI_R2T_MAX			16
+#define ISCSI_SG_TABLESIZE		SG_ALL
+#define ISCSI_TCP_MAX_CMD_LEN		16
+
+struct socket;
+
+/* Socket connection recieve helper */
+struct iscsi_tcp_recv {
+	struct iscsi_hdr	*hdr;
+	struct sk_buff		*skb;
+	int			offset;
+	int			len;
+	int			hdr_offset;
+	int			copy;
+	int			copied;
+	int			padding;
+	struct iscsi_cmd_task	*ctask;		/* current cmd in progress */
+
+	/* copied and flipped values */
+	int			datalen;
+	int			datadgst;
+	char			zero_copy_hdr;
+};
+
+struct iscsi_tcp_conn {
+	struct iscsi_conn	*iscsi_conn;
+	struct socket		*sock;
+	struct iscsi_hdr	hdr;		/* header placeholder */
+	char			hdrext[4*sizeof(__u16) +
+				    sizeof(__u32)];
+	int			data_copied;
+	char			*data;		/* data placeholder */
+	int			data_size;	/* actual recv_dlength */
+	int			stop_stage;	/* conn_stop() flag: *
+						 * stop to recover,  *
+						 * stop to terminate */
+	/* iSCSI connection-wide sequencing */
+	int			hdr_size;	/* PDU header size */
+
+	struct crypto_tfm	*rx_tfm;	/* CRC32C (Rx) */
+	struct crypto_tfm	*data_rx_tfm;	/* CRC32C (Rx) for data */
+
+	/* control data */
+	struct iscsi_tcp_recv	in;		/* TCP receive context */
+	int			in_progress;	/* connection state machine */
+
+	/* old values for socket callbacks */
+	void			(*old_data_ready)(struct sock *, int);
+	void			(*old_state_change)(struct sock *);
+	void			(*old_write_space)(struct sock *);
+
+	/* xmit */
+	struct crypto_tfm	*tx_tfm;	/* CRC32C (Tx) */
+	struct crypto_tfm	*data_tx_tfm;	/* CRC32C (Tx) for data */
+
+	/* MIB custom statistics */
+	uint32_t		sendpage_failures_cnt;
+	uint32_t		discontiguous_hdr_cnt;
+
+	ssize_t (*sendpage)(struct socket *, struct page *, int, size_t, int);
+};
+
+struct iscsi_buf {
+	struct scatterlist	sg;
+	unsigned int		sent;
+	char			use_sendmsg;
+};
+
+struct iscsi_data_task {
+	struct iscsi_data	hdr;			/* PDU */
+	char			hdrext[sizeof(__u32)];	/* Header-Digest */
+	struct list_head	item;			/* data queue item */
+	struct iscsi_buf	digestbuf;		/* digest buffer */
+	uint32_t		digest;			/* data digest */
+};
+#define ISCSI_DTASK_DEFAULT_MAX	ISCSI_SG_TABLESIZE * PAGE_SIZE / 512
+
+struct iscsi_tcp_mgmt_task {
+	struct iscsi_hdr	hdr;
+	char			hdrext[sizeof(__u32)]; /* Header-Digest */
+	int			xmstate;	/* mgmt xmit progress */
+	struct iscsi_buf	headbuf;	/* header buffer */
+	struct iscsi_buf	sendbuf;	/* in progress buffer */
+	int			sent;
+};
+
+struct iscsi_r2t_info {
+	__be32			ttt;		/* copied from R2T */
+	__be32			exp_statsn;	/* copied from R2T */
+	uint32_t		data_length;	/* copied from R2T */
+	uint32_t		data_offset;	/* copied from R2T */
+	struct iscsi_buf	headbuf;	/* Data-Out Header Buffer */
+	struct iscsi_buf	sendbuf;	/* Data-Out in progress buffer*/
+	int			sent;		/* R2T sequence progress */
+	int			data_count;	/* DATA-Out payload progress */
+	struct scatterlist	*sg;		/* per-R2T SG list */
+	int			solicit_datasn;
+	struct iscsi_data_task   *dtask;        /* which data task */
+};
+
+struct iscsi_tcp_cmd_task {
+	struct iscsi_cmd	hdr;
+	char			hdrext[4*sizeof(__u16)+	/* AHS */
+				    sizeof(__u32)];	/* HeaderDigest */
+	char			pad[ISCSI_PAD_LEN];
+	int			pad_count;		/* padded bytes */
+	struct iscsi_buf	headbuf;		/* header buf (xmit) */
+	struct iscsi_buf	sendbuf;		/* in progress buffer*/
+	int			xmstate;		/* xmit xtate machine */
+	int			sent;
+	struct scatterlist	*sg;			/* per-cmd SG list  */
+	struct scatterlist	*bad_sg;		/* assert statement */
+	int			sg_count;		/* SG's to process  */
+	uint32_t		exp_r2tsn;
+	int			r2t_data_count;		/* R2T Data-Out bytes */
+	int			data_offset;
+	struct iscsi_r2t_info	*r2t;			/* in progress R2T    */
+	struct iscsi_queue	r2tpool;
+	struct kfifo		*r2tqueue;
+	struct iscsi_r2t_info	**r2ts;
+	struct list_head	dataqueue;		/* Data-Out dataqueue */
+	mempool_t		*datapool;
+	uint32_t		datadigest;		/* for recover digest */
+	int			digest_count;
+	uint32_t		immdigest;		/* for imm data */
+	struct iscsi_buf	immbuf;			/* for imm data digest */
+	struct iscsi_data_task   *dtask;		/* data task in progress*/
+	int			digest_offset;		/* for partial buff digest */
+};
+
+#endif /* ISCSI_H */

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 14:03:22 UTC (rev 432)
@@ -39,9 +39,9 @@
 #include <scsi/scsi.h>
 #include <iscsi_tcp.h>
 #include <scsi/libiscsi.h>
-#include <scsi/scsi_transport_iscsi.h>
 #include <scsi/scsi_tgt.h>
 #include <scsi/scsi_tcq.h>
+#include "scsi_transport_iscsi.h"
 
 /* tmp - will replace with SCSI logging stuff */
 #define eprintk(fmt, args...)					\

Added: branches/use-scsi-ml/istgt/kernel/libiscsi.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/libiscsi.c	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/libiscsi.c	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,1712 @@
+/*
+ * iSCSI lib functions
+ *
+ * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
+ * Copyright (C) 2004 - 2006 Mike Christie
+ * Copyright (C) 2004 - 2005 Dmitry Yusupov
+ * Copyright (C) 2004 - 2005 Alex Aizman
+ * maintained by open-iscsi at googlegroups.com
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ */
+#include <linux/types.h>
+#include <linux/mutex.h>
+#include <linux/kfifo.h>
+#include <linux/delay.h>
+#include <net/tcp.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_eh.h>
+#include <scsi/scsi_tcq.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi.h>
+#include <scsi/iscsi_proto.h>
+#include <scsi/scsi_transport.h>
+#include "scsi_transport_iscsi.h"
+#include "libiscsi.h"
+
+struct iscsi_session *
+class_to_transport_session(struct iscsi_cls_session *cls_session)
+{
+	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
+	return iscsi_hostdata(shost->hostdata);
+}
+EXPORT_SYMBOL_GPL(class_to_transport_session);
+
+#define INVALID_SN_DELTA	0xffff
+
+int
+iscsi_check_assign_cmdsn(struct iscsi_session *session, struct iscsi_nopin *hdr)
+{
+	uint32_t max_cmdsn = be32_to_cpu(hdr->max_cmdsn);
+	uint32_t exp_cmdsn = be32_to_cpu(hdr->exp_cmdsn);
+
+	if (max_cmdsn < exp_cmdsn -1 &&
+	    max_cmdsn > exp_cmdsn - INVALID_SN_DELTA)
+		return ISCSI_ERR_MAX_CMDSN;
+	if (max_cmdsn > session->max_cmdsn ||
+	    max_cmdsn < session->max_cmdsn - INVALID_SN_DELTA)
+		session->max_cmdsn = max_cmdsn;
+	if (exp_cmdsn > session->exp_cmdsn ||
+	    exp_cmdsn < session->exp_cmdsn - INVALID_SN_DELTA)
+		session->exp_cmdsn = exp_cmdsn;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_check_assign_cmdsn);
+
+void iscsi_prep_unsolicit_data_pdu(struct iscsi_cmd_task *ctask,
+				   struct iscsi_data *hdr,
+				   int transport_data_cnt)
+{
+	struct iscsi_conn *conn = ctask->conn;
+
+	memset(hdr, 0, sizeof(struct iscsi_data));
+	hdr->ttt = cpu_to_be32(ISCSI_RESERVED_TAG);
+	hdr->datasn = cpu_to_be32(ctask->unsol_datasn);
+	ctask->unsol_datasn++;
+	hdr->opcode = ISCSI_OP_SCSI_DATA_OUT;
+	memcpy(hdr->lun, ctask->hdr->lun, sizeof(hdr->lun));
+
+	hdr->itt = ctask->hdr->itt;
+	hdr->exp_statsn = cpu_to_be32(conn->exp_statsn);
+
+	hdr->offset = cpu_to_be32(ctask->total_length -
+				  transport_data_cnt -
+				  ctask->unsol_count);
+
+	if (ctask->unsol_count > conn->max_xmit_dlength) {
+		hton24(hdr->dlength, conn->max_xmit_dlength);
+		ctask->data_count = conn->max_xmit_dlength;
+		hdr->flags = 0;
+	} else {
+		hton24(hdr->dlength, ctask->unsol_count);
+		ctask->data_count = ctask->unsol_count;
+		hdr->flags = ISCSI_FLAG_CMD_FINAL;
+	}
+}
+EXPORT_SYMBOL_GPL(iscsi_prep_unsolicit_data_pdu);
+
+/**
+ * iscsi_prep_scsi_cmd_pdu - prep iscsi scsi cmd pdu
+ * @ctask: iscsi cmd task
+ *
+ * Prep basic iSCSI PDU fields for a scsi cmd pdu. The LLD should set
+ * fields like dlength or final based on how much data it sends
+ */
+static void iscsi_prep_scsi_cmd_pdu(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_cmd *hdr = ctask->hdr;
+	struct scsi_cmnd *sc = ctask->sc;
+
+        hdr->opcode = ISCSI_OP_SCSI_CMD;
+        hdr->flags = ISCSI_ATTR_SIMPLE;
+        int_to_scsilun(sc->device->lun, (struct scsi_lun *)hdr->lun);
+        hdr->itt = ctask->itt | (conn->id << ISCSI_CID_SHIFT) |
+                         (session->age << ISCSI_AGE_SHIFT);
+        hdr->data_length = cpu_to_be32(sc->request_bufflen);
+        hdr->cmdsn = cpu_to_be32(session->cmdsn);
+        session->cmdsn++;
+        hdr->exp_statsn = cpu_to_be32(conn->exp_statsn);
+        memcpy(hdr->cdb, sc->cmnd, sc->cmd_len);
+        memset(&hdr->cdb[sc->cmd_len], 0, MAX_COMMAND_SIZE - sc->cmd_len);
+
+	if (sc->sc_data_direction == DMA_TO_DEVICE) {
+		hdr->flags |= ISCSI_FLAG_CMD_WRITE;
+		/*
+		 * Write counters:
+		 *
+		 *	imm_count	bytes to be sent right after
+		 *			SCSI PDU Header
+		 *
+		 *	unsol_count	bytes(as Data-Out) to be sent
+		 *			without	R2T ack right after
+		 *			immediate data
+		 *
+		 *	r2t_data_count	bytes to be sent via R2T ack's
+		 *
+		 *      pad_count       bytes to be sent as zero-padding
+		 */
+		ctask->imm_count = 0;
+		ctask->unsol_count = 0;
+		ctask->unsol_datasn = 0;
+
+		if (session->imm_data_en) {
+			if (ctask->total_length >= session->first_burst)
+				ctask->imm_count = min(session->first_burst,
+							conn->max_xmit_dlength);
+			else
+				ctask->imm_count = min(ctask->total_length,
+							conn->max_xmit_dlength);
+			hton24(ctask->hdr->dlength, ctask->imm_count);
+		} else
+			zero_data(ctask->hdr->dlength);
+
+		if (!session->initial_r2t_en)
+			ctask->unsol_count = min(session->first_burst,
+				ctask->total_length) - ctask->imm_count;
+		if (!ctask->unsol_count)
+			/* No unsolicit Data-Out's */
+			ctask->hdr->flags |= ISCSI_FLAG_CMD_FINAL;
+	} else {
+		ctask->datasn = 0;
+		hdr->flags |= ISCSI_FLAG_CMD_FINAL;
+		zero_data(hdr->dlength);
+
+		if (sc->sc_data_direction == DMA_FROM_DEVICE)
+			hdr->flags |= ISCSI_FLAG_CMD_READ;
+	}
+
+	conn->scsicmd_pdus_cnt++;
+}
+EXPORT_SYMBOL_GPL(iscsi_prep_scsi_cmd_pdu);
+
+/**
+ * iscsi_complete_command - return command back to scsi-ml
+ * @session: iscsi session
+ * @ctask: iscsi cmd task
+ *
+ * Must be called with session lock.
+ * This function returns the scsi command to scsi-ml and returns
+ * the cmd task to the pool of available cmd tasks.
+ */
+static void iscsi_complete_command(struct iscsi_session *session,
+				   struct iscsi_cmd_task *ctask)
+{
+	struct scsi_cmnd *sc = ctask->sc;
+
+	ctask->sc = NULL;
+	list_del_init(&ctask->running);
+	__kfifo_put(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
+	sc->scsi_done(sc);
+}
+
+/**
+ * iscsi_cmd_rsp - SCSI Command Response processing
+ * @conn: iscsi connection
+ * @hdr: iscsi header
+ * @ctask: scsi command task
+ * @data: cmd data buffer
+ * @datalen: len of buffer
+ *
+ * iscsi_cmd_rsp sets up the scsi_cmnd fields based on the PDU and
+ * then completes the command and task.
+ **/
+static int iscsi_scsi_cmd_rsp(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
+			      struct iscsi_cmd_task *ctask, char *data,
+			      int datalen)
+{
+	int rc;
+	struct iscsi_cmd_rsp *rhdr = (struct iscsi_cmd_rsp *)hdr;
+	struct iscsi_session *session = conn->session;
+	struct scsi_cmnd *sc = ctask->sc;
+
+	rc = iscsi_check_assign_cmdsn(session, (struct iscsi_nopin*)rhdr);
+	if (rc) {
+		sc->result = DID_ERROR << 16;
+		goto out;
+	}
+
+	conn->exp_statsn = be32_to_cpu(rhdr->statsn) + 1;
+
+	sc->result = (DID_OK << 16) | rhdr->cmd_status;
+
+	if (rhdr->response != ISCSI_STATUS_CMD_COMPLETED) {
+		sc->result = DID_ERROR << 16;
+		goto out;
+	}
+
+	if (rhdr->cmd_status == SAM_STAT_CHECK_CONDITION) {
+		int senselen;
+
+		if (datalen < 2) {
+invalid_datalen:
+			printk(KERN_ERR "iscsi: Got CHECK_CONDITION but invalid "
+			       "data buffer size of %d\n", datalen);
+			sc->result = DID_BAD_TARGET << 16;
+			goto out;
+		}
+
+		senselen = (data[0] << 8) | data[1];
+		if (datalen < senselen)
+			goto invalid_datalen;
+
+		memcpy(sc->sense_buffer, data + 2,
+		       min(senselen, SCSI_SENSE_BUFFERSIZE));
+		debug_scsi("copied %d bytes of sense\n",
+			   min(senselen, SCSI_SENSE_BUFFERSIZE));
+	}
+
+	if (sc->sc_data_direction == DMA_TO_DEVICE)
+		goto out;
+
+	if (rhdr->flags & ISCSI_FLAG_CMD_UNDERFLOW) {
+		int res_count = be32_to_cpu(rhdr->residual_count);
+
+		if (res_count > 0 && res_count <= sc->request_bufflen)
+			sc->resid = res_count;
+		else
+			sc->result = (DID_BAD_TARGET << 16) | rhdr->cmd_status;
+	} else if (rhdr->flags & ISCSI_FLAG_CMD_BIDI_UNDERFLOW)
+		sc->result = (DID_BAD_TARGET << 16) | rhdr->cmd_status;
+	else if (rhdr->flags & ISCSI_FLAG_CMD_OVERFLOW)
+		sc->resid = be32_to_cpu(rhdr->residual_count);
+
+out:
+	debug_scsi("done [sc %lx res %d itt 0x%x]\n",
+		   (long)sc, sc->result, ctask->itt);
+	conn->scsirsp_pdus_cnt++;
+
+	iscsi_complete_command(conn->session, ctask);
+	return rc;
+}
+
+/**
+ * __iscsi_complete_pdu - complete pdu
+ * @conn: iscsi conn
+ * @hdr: iscsi header
+ * @data: data buffer
+ * @datalen: len of data buffer
+ *
+ * Completes pdu processing by freeing any resources allocated at
+ * queuecommand or send generic. session lock must be held and verify
+ * itt must have been called.
+ */
+int __iscsi_complete_pdu(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
+			 char *data, int datalen)
+{
+	struct iscsi_session *session = conn->session;
+	int opcode = hdr->opcode & ISCSI_OPCODE_MASK, rc = 0;
+	struct iscsi_cmd_task *ctask;
+	struct iscsi_mgmt_task *mtask;
+	uint32_t itt;
+
+	if (hdr->itt != cpu_to_be32(ISCSI_RESERVED_TAG))
+		itt = hdr->itt & ISCSI_ITT_MASK;
+	else
+		itt = hdr->itt;
+
+	if (itt < session->cmds_max) {
+		ctask = session->cmds[itt];
+
+		debug_scsi("cmdrsp [op 0x%x cid %d itt 0x%x len %d]\n",
+			   opcode, conn->id, ctask->itt, datalen);
+
+		switch(opcode) {
+		case ISCSI_OP_SCSI_CMD_RSP:
+			BUG_ON((void*)ctask != ctask->sc->SCp.ptr);
+			rc = iscsi_scsi_cmd_rsp(conn, hdr, ctask, data,
+						datalen);
+			break;
+		case ISCSI_OP_SCSI_DATA_IN:
+			BUG_ON((void*)ctask != ctask->sc->SCp.ptr);
+			if (hdr->flags & ISCSI_FLAG_DATA_STATUS) {
+				conn->scsirsp_pdus_cnt++;
+				iscsi_complete_command(session, ctask);
+			}
+			break;
+		case ISCSI_OP_R2T:
+			/* LLD handles this for now */
+			break;
+		default:
+			rc = ISCSI_ERR_BAD_OPCODE;
+			break;
+		}
+	} else if (itt >= ISCSI_MGMT_ITT_OFFSET &&
+		   itt < ISCSI_MGMT_ITT_OFFSET + session->mgmtpool_max) {
+		mtask = session->mgmt_cmds[itt - ISCSI_MGMT_ITT_OFFSET];
+
+		debug_scsi("immrsp [op 0x%x cid %d itt 0x%x len %d]\n",
+			   opcode, conn->id, mtask->itt, datalen);
+
+		rc = iscsi_check_assign_cmdsn(session,
+					      (struct iscsi_nopin*)hdr);
+		if (rc)
+			goto done;
+
+		switch(opcode) {
+		case ISCSI_OP_LOGOUT_RSP:
+			conn->exp_statsn = be32_to_cpu(hdr->statsn) + 1;
+			/* fall through */
+		case ISCSI_OP_LOGIN_RSP:
+		case ISCSI_OP_TEXT_RSP:
+			/*
+			 * login related PDU's exp_statsn is handled in
+			 * userspace
+			 */
+			rc = iscsi_recv_pdu(conn->cls_conn, hdr, data, datalen);
+			list_del(&mtask->running);
+			if (conn->login_mtask != mtask)
+				__kfifo_put(session->mgmtpool.queue,
+					    (void*)&mtask, sizeof(void*));
+			break;
+		case ISCSI_OP_SCSI_TMFUNC_RSP:
+			if (datalen) {
+				rc = ISCSI_ERR_PROTO;
+				break;
+			}
+
+			conn->exp_statsn = be32_to_cpu(hdr->statsn) + 1;
+			conn->tmfrsp_pdus_cnt++;
+			if (conn->tmabort_state == TMABORT_INITIAL) {
+				conn->tmabort_state =
+					((struct iscsi_tm_rsp *)hdr)->
+					response == ISCSI_TMF_RSP_COMPLETE ?
+						TMABORT_SUCCESS:TMABORT_FAILED;
+				/* unblock eh_abort() */
+				wake_up(&conn->ehwait);
+			}
+			break;
+		case ISCSI_OP_NOOP_IN:
+			if (hdr->ttt != ISCSI_RESERVED_TAG) {
+				rc = ISCSI_ERR_PROTO;
+				break;
+			}
+			conn->exp_statsn = be32_to_cpu(hdr->statsn) + 1;
+
+			rc = iscsi_recv_pdu(conn->cls_conn, hdr, data, datalen);
+			list_del(&mtask->running);
+			if (conn->login_mtask != mtask)
+				__kfifo_put(session->mgmtpool.queue,
+					    (void*)&mtask, sizeof(void*));
+			break;
+		default:
+			rc = ISCSI_ERR_BAD_OPCODE;
+			break;
+		}
+	} else if (itt == ISCSI_RESERVED_TAG) {
+		switch(opcode) {
+		case ISCSI_OP_NOOP_IN:
+			if (!datalen) {
+				rc = iscsi_check_assign_cmdsn(session,
+						 (struct iscsi_nopin*)hdr);
+				if (!rc && hdr->ttt != ISCSI_RESERVED_TAG)
+					rc = iscsi_recv_pdu(conn->cls_conn,
+							    hdr, NULL, 0);
+			} else
+				rc = ISCSI_ERR_PROTO;
+			break;
+		case ISCSI_OP_REJECT:
+			/* we need sth like iscsi_reject_rsp()*/
+		case ISCSI_OP_ASYNC_EVENT:
+			conn->exp_statsn = be32_to_cpu(hdr->statsn) + 1;
+			/* we need sth like iscsi_async_event_rsp() */
+			rc = ISCSI_ERR_BAD_OPCODE;
+			break;
+		default:
+			rc = ISCSI_ERR_BAD_OPCODE;
+			break;
+		}
+	} else
+		rc = ISCSI_ERR_BAD_ITT;
+
+done:
+	return rc;
+}
+EXPORT_SYMBOL_GPL(__iscsi_complete_pdu);
+
+int iscsi_complete_pdu(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
+		       char *data, int datalen)
+{
+	int rc;
+
+	spin_lock(&conn->session->lock);
+	rc = __iscsi_complete_pdu(conn, hdr, data, datalen);
+	spin_unlock(&conn->session->lock);
+	return rc;
+}
+EXPORT_SYMBOL_GPL(iscsi_complete_pdu);
+
+/* verify itt (itt encoding: age+cid+itt) */
+int iscsi_verify_itt(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
+		     uint32_t *ret_itt)
+{
+	struct iscsi_session *session = conn->session;
+	struct iscsi_cmd_task *ctask;
+	uint32_t itt;
+
+	if (hdr->itt != cpu_to_be32(ISCSI_RESERVED_TAG)) {
+		if ((hdr->itt & ISCSI_AGE_MASK) !=
+		    (session->age << ISCSI_AGE_SHIFT)) {
+			printk(KERN_ERR "iscsi: received itt %x expected "
+				"session age (%x)\n", hdr->itt,
+				session->age & ISCSI_AGE_MASK);
+			return ISCSI_ERR_BAD_ITT;
+		}
+
+		if ((hdr->itt & ISCSI_CID_MASK) !=
+		    (conn->id << ISCSI_CID_SHIFT)) {
+			printk(KERN_ERR "iscsi: received itt %x, expected "
+				"CID (%x)\n", hdr->itt, conn->id);
+			return ISCSI_ERR_BAD_ITT;
+		}
+		itt = hdr->itt & ISCSI_ITT_MASK;
+	} else
+		itt = hdr->itt;
+
+	if (itt < session->cmds_max) {
+		ctask = session->cmds[itt];
+
+		if (!ctask->sc) {
+			printk(KERN_INFO "iscsi: dropping ctask with "
+			       "itt 0x%x\n", ctask->itt);
+			/* force drop */
+			return ISCSI_ERR_NO_SCSI_CMD;
+		}
+
+		if (ctask->sc->SCp.phase != session->age) {
+			printk(KERN_ERR "iscsi: ctask's session age %d, "
+				"expected %d\n", ctask->sc->SCp.phase,
+				session->age);
+			return ISCSI_ERR_SESSION_FAILED;
+		}
+	}
+
+	*ret_itt = itt;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_verify_itt);
+
+void iscsi_conn_failure(struct iscsi_conn *conn, enum iscsi_err err)
+{
+	struct iscsi_session *session = conn->session;
+	unsigned long flags;
+
+	spin_lock_irqsave(&session->lock, flags);
+	if (session->conn_cnt == 1 || session->leadconn == conn)
+		session->state = ISCSI_STATE_FAILED;
+	spin_unlock_irqrestore(&session->lock, flags);
+	set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
+	iscsi_conn_error(conn->cls_conn, err);
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_failure);
+
+/**
+ * iscsi_data_xmit - xmit any command into the scheduled connection
+ * @conn: iscsi connection
+ *
+ * Notes:
+ *	The function can return -EAGAIN in which case the caller must
+ *	re-schedule it again later or recover. '0' return code means
+ *	successful xmit.
+ **/
+static int iscsi_data_xmit(struct iscsi_conn *conn)
+{
+	struct iscsi_transport *tt;
+
+	if (unlikely(conn->suspend_tx)) {
+		debug_scsi("conn %d Tx suspended!\n", conn->id);
+		return 0;
+	}
+	tt = conn->session->tt;
+
+	/*
+	 * Transmit in the following order:
+	 *
+	 * 1) un-finished xmit (ctask or mtask)
+	 * 2) immediate control PDUs
+	 * 3) write data
+	 * 4) SCSI commands
+	 * 5) non-immediate control PDUs
+	 *
+	 * No need to lock around __kfifo_get as long as
+	 * there's one producer and one consumer.
+	 */
+
+	BUG_ON(conn->ctask && conn->mtask);
+
+	if (conn->ctask) {
+		if (tt->xmit_cmd_task(conn, conn->ctask))
+			goto again;
+		/* done with this in-progress ctask */
+		conn->ctask = NULL;
+	}
+	if (conn->mtask) {
+	        if (tt->xmit_mgmt_task(conn, conn->mtask))
+		        goto again;
+		/* done with this in-progress mtask */
+		conn->mtask = NULL;
+	}
+
+	/* process immediate first */
+        if (unlikely(__kfifo_len(conn->immqueue))) {
+	        while (__kfifo_get(conn->immqueue, (void*)&conn->mtask,
+			           sizeof(void*))) {
+			list_add_tail(&conn->mtask->running,
+				      &conn->mgmt_run_list);
+		        if (tt->xmit_mgmt_task(conn, conn->mtask))
+			        goto again;
+	        }
+		/* done with this mtask */
+		conn->mtask = NULL;
+	}
+
+	/* process command queue */
+	while (__kfifo_get(conn->xmitqueue, (void*)&conn->ctask,
+			   sizeof(void*))) {
+		/*
+		 * iscsi tcp may readd the task to the xmitqueue to send
+		 * write data
+		 */
+		if (list_empty(&conn->ctask->running))
+			list_add_tail(&conn->ctask->running, &conn->run_list);
+		if (tt->xmit_cmd_task(conn, conn->ctask))
+			goto again;
+	}
+	/* done with this ctask */
+	conn->ctask = NULL;
+
+	/* process the rest control plane PDUs, if any */
+        if (unlikely(__kfifo_len(conn->mgmtqueue))) {
+	        while (__kfifo_get(conn->mgmtqueue, (void*)&conn->mtask,
+			           sizeof(void*))) {
+			list_add_tail(&conn->mtask->running,
+				      &conn->mgmt_run_list);
+		        if (tt->xmit_mgmt_task(conn, conn->mtask))
+			        goto again;
+	        }
+		/* done with this mtask */
+		conn->mtask = NULL;
+	}
+
+	return 0;
+
+again:
+	if (unlikely(conn->suspend_tx))
+		return 0;
+
+	return -EAGAIN;
+}
+
+static void iscsi_xmitworker(void *data)
+{
+	struct iscsi_conn *conn = data;
+
+	/*
+	 * serialize Xmit worker on a per-connection basis.
+	 */
+	mutex_lock(&conn->xmitmutex);
+	if (iscsi_data_xmit(conn))
+		scsi_queue_work(conn->session->host, &conn->xmitwork);
+	mutex_unlock(&conn->xmitmutex);
+}
+
+enum {
+	FAILURE_BAD_HOST = 1,
+	FAILURE_SESSION_FAILED,
+	FAILURE_SESSION_FREED,
+	FAILURE_WINDOW_CLOSED,
+	FAILURE_SESSION_TERMINATE,
+	FAILURE_SESSION_RECOVERY_TIMEOUT,
+};
+
+int iscsi_queuecommand(struct scsi_cmnd *sc, void (*done)(struct scsi_cmnd *))
+{
+	struct Scsi_Host *host;
+	int reason = 0;
+	struct iscsi_session *session;
+	struct iscsi_conn *conn;
+	struct iscsi_cmd_task *ctask = NULL;
+
+	sc->scsi_done = done;
+	sc->result = 0;
+
+	host = sc->device->host;
+	session = iscsi_hostdata(host->hostdata);
+
+	spin_lock(&session->lock);
+
+	if (session->state != ISCSI_STATE_LOGGED_IN) {
+		if (session->recovery_failed) {
+			reason = FAILURE_SESSION_RECOVERY_TIMEOUT;
+			goto fault;
+		} else if (session->state == ISCSI_STATE_FAILED) {
+			reason = FAILURE_SESSION_FAILED;
+			goto reject;
+		} else if (session->state == ISCSI_STATE_TERMINATE) {
+			reason = FAILURE_SESSION_TERMINATE;
+			goto fault;
+		}
+		reason = FAILURE_SESSION_FREED;
+		goto fault;
+	}
+
+	/*
+	 * Check for iSCSI window and take care of CmdSN wrap-around
+	 */
+	if ((int)(session->max_cmdsn - session->cmdsn) < 0) {
+		reason = FAILURE_WINDOW_CLOSED;
+		goto reject;
+	}
+
+	conn = session->leadconn;
+
+	__kfifo_get(session->cmdpool.queue, (void*)&ctask, sizeof(void*));
+	sc->SCp.phase = session->age;
+	sc->SCp.ptr = (char *)ctask;
+
+	ctask->mtask = NULL;
+	ctask->conn = conn;
+	ctask->sc = sc;
+	INIT_LIST_HEAD(&ctask->running);
+	ctask->total_length = sc->request_bufflen;
+	iscsi_prep_scsi_cmd_pdu(ctask);
+
+	session->tt->init_cmd_task(ctask);
+
+	__kfifo_put(conn->xmitqueue, (void*)&ctask, sizeof(void*));
+	debug_scsi(
+	       "ctask enq [%s cid %d sc %lx itt 0x%x len %d cmdsn %d win %d]\n",
+		sc->sc_data_direction == DMA_TO_DEVICE ? "write" : "read",
+		conn->id, (long)sc, ctask->itt, sc->request_bufflen,
+		session->cmdsn, session->max_cmdsn - session->exp_cmdsn + 1);
+	spin_unlock(&session->lock);
+
+	scsi_queue_work(host, &conn->xmitwork);
+	return 0;
+
+reject:
+	spin_unlock(&session->lock);
+	debug_scsi("cmd 0x%x rejected (%d)\n", sc->cmnd[0], reason);
+	return SCSI_MLQUEUE_HOST_BUSY;
+
+fault:
+	spin_unlock(&session->lock);
+	printk(KERN_ERR "iscsi: cmd 0x%x is not queued (%d)\n",
+	       sc->cmnd[0], reason);
+	sc->result = (DID_NO_CONNECT << 16);
+	sc->resid = sc->request_bufflen;
+	sc->scsi_done(sc);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_queuecommand);
+
+int iscsi_change_queue_depth(struct scsi_device *sdev, int depth)
+{
+	if (depth > ISCSI_MAX_CMD_PER_LUN)
+		depth = ISCSI_MAX_CMD_PER_LUN;
+	scsi_adjust_queue_depth(sdev, scsi_get_tag_type(sdev), depth);
+	return sdev->queue_depth;
+}
+EXPORT_SYMBOL_GPL(iscsi_change_queue_depth);
+
+static int
+iscsi_conn_send_generic(struct iscsi_conn *conn, struct iscsi_hdr *hdr,
+			char *data, uint32_t data_size)
+{
+	struct iscsi_session *session = conn->session;
+	struct iscsi_nopout *nop = (struct iscsi_nopout *)hdr;
+	struct iscsi_mgmt_task *mtask;
+
+	spin_lock_bh(&session->lock);
+	if (session->state == ISCSI_STATE_TERMINATE) {
+		spin_unlock_bh(&session->lock);
+		return -EPERM;
+	}
+	if (hdr->opcode == (ISCSI_OP_LOGIN | ISCSI_OP_IMMEDIATE) ||
+	    hdr->opcode == (ISCSI_OP_TEXT | ISCSI_OP_IMMEDIATE))
+		/*
+		 * Login and Text are sent serially, in
+		 * request-followed-by-response sequence.
+		 * Same mtask can be used. Same ITT must be used.
+		 * Note that login_mtask is preallocated at conn_create().
+		 */
+		mtask = conn->login_mtask;
+	else {
+	        BUG_ON(conn->c_stage == ISCSI_CONN_INITIAL_STAGE);
+	        BUG_ON(conn->c_stage == ISCSI_CONN_STOPPED);
+
+		nop->exp_statsn = cpu_to_be32(conn->exp_statsn);
+		if (!__kfifo_get(session->mgmtpool.queue,
+				 (void*)&mtask, sizeof(void*))) {
+			spin_unlock_bh(&session->lock);
+			return -ENOSPC;
+		}
+	}
+
+	/*
+	 * pre-format CmdSN for outgoing PDU.
+	 */
+	if (hdr->itt != cpu_to_be32(ISCSI_RESERVED_TAG)) {
+		hdr->itt = mtask->itt | (conn->id << ISCSI_CID_SHIFT) |
+			   (session->age << ISCSI_AGE_SHIFT);
+		nop->cmdsn = cpu_to_be32(session->cmdsn);
+		if (conn->c_stage == ISCSI_CONN_STARTED &&
+		    !(hdr->opcode & ISCSI_OP_IMMEDIATE))
+			session->cmdsn++;
+	} else
+		/* do not advance CmdSN */
+		nop->cmdsn = cpu_to_be32(session->cmdsn);
+
+	if (data_size) {
+		memcpy(mtask->data, data, data_size);
+		mtask->data_count = data_size;
+	} else
+		mtask->data_count = 0;
+
+	INIT_LIST_HEAD(&mtask->running);
+	memcpy(mtask->hdr, hdr, sizeof(struct iscsi_hdr));
+	if (session->tt->init_mgmt_task)
+		session->tt->init_mgmt_task(conn, mtask, data, data_size);
+	spin_unlock_bh(&session->lock);
+
+	debug_scsi("mgmtpdu [op 0x%x hdr->itt 0x%x datalen %d]\n",
+		   hdr->opcode, hdr->itt, data_size);
+
+	/*
+	 * since send_pdu() could be called at least from two contexts,
+	 * we need to serialize __kfifo_put, so we don't have to take
+	 * additional lock on fast data-path
+	 */
+        if (hdr->opcode & ISCSI_OP_IMMEDIATE)
+	        __kfifo_put(conn->immqueue, (void*)&mtask, sizeof(void*));
+	else
+	        __kfifo_put(conn->mgmtqueue, (void*)&mtask, sizeof(void*));
+
+	scsi_queue_work(session->host, &conn->xmitwork);
+	return 0;
+}
+
+int iscsi_conn_send_pdu(struct iscsi_cls_conn *cls_conn, struct iscsi_hdr *hdr,
+			char *data, uint32_t data_size)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	int rc;
+
+	mutex_lock(&conn->xmitmutex);
+	rc = iscsi_conn_send_generic(conn, hdr, data, data_size);
+	mutex_unlock(&conn->xmitmutex);
+
+	return rc;
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_send_pdu);
+
+void iscsi_session_recovery_timedout(struct iscsi_cls_session *cls_session)
+{
+	struct iscsi_session *session = class_to_transport_session(cls_session);
+	struct iscsi_conn *conn = session->leadconn;
+
+	spin_lock_bh(&session->lock);
+	if (session->state != ISCSI_STATE_LOGGED_IN) {
+		session->recovery_failed = 1;
+		if (conn)
+			wake_up(&conn->ehwait);
+	}
+	spin_unlock_bh(&session->lock);
+}
+EXPORT_SYMBOL_GPL(iscsi_session_recovery_timedout);
+
+int iscsi_eh_host_reset(struct scsi_cmnd *sc)
+{
+	struct Scsi_Host *host = sc->device->host;
+	struct iscsi_session *session = iscsi_hostdata(host->hostdata);
+	struct iscsi_conn *conn = session->leadconn;
+	int fail_session = 0;
+
+	spin_lock_bh(&session->lock);
+	if (session->state == ISCSI_STATE_TERMINATE) {
+failed:
+		debug_scsi("failing host reset: session terminated "
+			   "[CID %d age %d]", conn->id, session->age);
+		spin_unlock_bh(&session->lock);
+		return FAILED;
+	}
+
+	if (sc->SCp.phase == session->age) {
+		debug_scsi("failing connection CID %d due to SCSI host reset",
+			   conn->id);
+		fail_session = 1;
+	}
+	spin_unlock_bh(&session->lock);
+
+	/*
+	 * we drop the lock here but the leadconn cannot be destoyed while
+	 * we are in the scsi eh
+	 */
+	if (fail_session) {
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+		/*
+		 * if userspace cannot respond then we must kick this off
+		 * here for it
+		 */
+		iscsi_start_session_recovery(session, conn, STOP_CONN_RECOVER);
+	}
+
+	debug_scsi("iscsi_eh_host_reset wait for relogin\n");
+	wait_event_interruptible(conn->ehwait,
+				 session->state == ISCSI_STATE_TERMINATE ||
+				 session->state == ISCSI_STATE_LOGGED_IN ||
+				 session->recovery_failed);
+	if (signal_pending(current))
+		flush_signals(current);
+
+	spin_lock_bh(&session->lock);
+	if (session->state == ISCSI_STATE_LOGGED_IN)
+		printk(KERN_INFO "iscsi: host reset succeeded\n");
+	else
+		goto failed;
+	spin_unlock_bh(&session->lock);
+
+	return SUCCESS;
+}
+EXPORT_SYMBOL_GPL(iscsi_eh_host_reset);
+
+static void iscsi_tmabort_timedout(unsigned long data)
+{
+	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *)data;
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_session *session = conn->session;
+
+	spin_lock(&session->lock);
+	if (conn->tmabort_state == TMABORT_INITIAL) {
+		conn->tmabort_state = TMABORT_TIMEDOUT;
+		debug_scsi("tmabort timedout [sc %p itt 0x%x]\n",
+			ctask->sc, ctask->itt);
+		/* unblock eh_abort() */
+		wake_up(&conn->ehwait);
+	}
+	spin_unlock(&session->lock);
+}
+
+/* must be called with the mutex lock */
+static int iscsi_exec_abort_task(struct scsi_cmnd *sc,
+				 struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_tm *hdr = &conn->tmhdr;
+	int rc;
+
+	/*
+	 * ctask timed out but session is OK requests must be serialized.
+	 */
+	memset(hdr, 0, sizeof(struct iscsi_tm));
+	hdr->opcode = ISCSI_OP_SCSI_TMFUNC | ISCSI_OP_IMMEDIATE;
+	hdr->flags = ISCSI_TM_FUNC_ABORT_TASK;
+	hdr->flags |= ISCSI_FLAG_CMD_FINAL;
+	memcpy(hdr->lun, ctask->hdr->lun, sizeof(hdr->lun));
+	hdr->rtt = ctask->hdr->itt;
+	hdr->refcmdsn = ctask->hdr->cmdsn;
+
+	rc = iscsi_conn_send_generic(conn, (struct iscsi_hdr *)hdr,
+				     NULL, 0);
+	if (rc) {
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+		debug_scsi("abort sent failure [itt 0x%x] %d", ctask->itt, rc);
+		return rc;
+	}
+
+	debug_scsi("abort sent [itt 0x%x]\n", ctask->itt);
+
+	spin_lock_bh(&session->lock);
+	ctask->mtask = (struct iscsi_mgmt_task *)
+			session->mgmt_cmds[(hdr->itt & ISCSI_ITT_MASK) -
+					ISCSI_MGMT_ITT_OFFSET];
+
+	if (conn->tmabort_state == TMABORT_INITIAL) {
+		conn->tmfcmd_pdus_cnt++;
+		conn->tmabort_timer.expires = 10*HZ + jiffies;
+		conn->tmabort_timer.function = iscsi_tmabort_timedout;
+		conn->tmabort_timer.data = (unsigned long)ctask;
+		add_timer(&conn->tmabort_timer);
+		debug_scsi("abort set timeout [itt 0x%x]", ctask->itt);
+	}
+	spin_unlock_bh(&session->lock);
+	mutex_unlock(&conn->xmitmutex);
+
+	/*
+	 * block eh thread until:
+	 *
+	 * 1) abort response
+	 * 2) abort timeout
+	 * 3) session is terminated or restarted or userspace has
+	 * given up on recovery
+	 */
+	wait_event_interruptible(conn->ehwait,
+				 sc->SCp.phase != session->age ||
+				 session->state != ISCSI_STATE_LOGGED_IN ||
+				 conn->tmabort_state != TMABORT_INITIAL ||
+				 session->recovery_failed);
+	if (signal_pending(current))
+		flush_signals(current);
+	del_timer_sync(&conn->tmabort_timer);
+
+	mutex_lock(&conn->xmitmutex);
+	return 0;
+}
+
+/*
+ * xmit mutex and session lock must be held
+ */
+#define iscsi_remove_task(tasktype)					\
+static struct iscsi_##tasktype *					\
+iscsi_remove_##tasktype(struct kfifo *fifo, uint32_t itt)		\
+{									\
+	int i, nr_tasks = __kfifo_len(fifo) / sizeof(void*);		\
+	struct iscsi_##tasktype *task;					\
+									\
+	debug_scsi("searching %d tasks\n", nr_tasks);			\
+									\
+	for (i = 0; i < nr_tasks; i++) {				\
+		__kfifo_get(fifo, (void*)&task, sizeof(void*));		\
+		debug_scsi("check task %u\n", task->itt);		\
+									\
+		if (task->itt == itt) {					\
+			debug_scsi("matched task\n");			\
+			break;						\
+		}							\
+									\
+		__kfifo_put(fifo, (void*)&task, sizeof(void*));		\
+	}								\
+	return NULL;							\
+}
+
+iscsi_remove_task(mgmt_task);
+iscsi_remove_task(cmd_task);
+
+static int iscsi_ctask_mtask_cleanup(struct iscsi_cmd_task *ctask)
+{
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_session *session = conn->session;
+
+	if (!ctask->mtask)
+		return -EINVAL;
+
+	if (!iscsi_remove_mgmt_task(conn->immqueue, ctask->mtask->itt))
+		list_del(&ctask->mtask->running);
+	__kfifo_put(session->mgmtpool.queue, (void*)&ctask->mtask,
+		    sizeof(void*));
+	ctask->mtask = NULL;
+	return 0;
+}
+
+/*
+ * session lock and xmitmutex must be held
+ */
+static void fail_command(struct iscsi_conn *conn, struct iscsi_cmd_task *ctask,
+			 int err)
+{
+	struct scsi_cmnd *sc;
+
+	conn->session->tt->cleanup_cmd_task(conn, ctask);
+	iscsi_ctask_mtask_cleanup(ctask);
+
+	sc = ctask->sc;
+	if (!sc)
+		return;
+	sc->result = err;
+	sc->resid = sc->request_bufflen;
+	iscsi_complete_command(conn->session, ctask);
+}
+
+int iscsi_eh_abort(struct scsi_cmnd *sc)
+{
+	struct iscsi_cmd_task *ctask = (struct iscsi_cmd_task *)sc->SCp.ptr;
+	struct iscsi_conn *conn = ctask->conn;
+	struct iscsi_session *session = conn->session;
+	struct iscsi_cmd_task *pending_ctask;
+	int rc;
+
+	conn->eh_abort_cnt++;
+	debug_scsi("aborting [sc %p itt 0x%x]\n", sc, ctask->itt);
+
+	mutex_lock(&conn->xmitmutex);
+	spin_lock_bh(&session->lock);
+
+	/*
+	 * If we are not logged in or we have started a new session
+	 * then let the host reset code handle this
+	 */
+	if (session->state != ISCSI_STATE_LOGGED_IN ||
+	    sc->SCp.phase != session->age)
+		goto failed;
+
+	/* ctask completed before time out */
+	if (!ctask->sc)
+		goto success;
+
+	/* what should we do here ? */
+	if (conn->ctask == ctask) {
+		printk(KERN_INFO "iscsi: sc %p itt 0x%x partially sent. Failing "
+		       "abort\n", sc, ctask->itt);
+		goto failed;
+	}
+
+	/* check for the easy pending cmd abort */
+	pending_ctask = iscsi_remove_cmd_task(conn->xmitqueue, ctask->itt);
+	if (pending_ctask) {
+		/* iscsi_tcp queues write transfers on the xmitqueue */
+		if (list_empty(&pending_ctask->running)) {
+			debug_scsi("found pending task\n");
+			goto success;
+		} else 
+			__kfifo_put(conn->xmitqueue, (void*)&pending_ctask,
+				    sizeof(void*));
+	}
+
+	conn->tmabort_state = TMABORT_INITIAL;
+
+	spin_unlock_bh(&session->lock);
+	rc = iscsi_exec_abort_task(sc, ctask);
+	spin_lock_bh(&session->lock);
+
+	iscsi_ctask_mtask_cleanup(ctask);
+	if (rc || sc->SCp.phase != session->age ||
+	    session->state != ISCSI_STATE_LOGGED_IN)
+		goto failed;
+
+	/* ctask completed before tmf abort response */
+	if (!ctask->sc) {
+		debug_scsi("sc completed while abort in progress\n");
+		goto success;
+	}
+
+	if (conn->tmabort_state != TMABORT_SUCCESS) {
+		spin_unlock_bh(&session->lock);
+		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
+		spin_lock_bh(&session->lock);
+		goto failed;
+	}
+
+success:
+	debug_scsi("abort success [sc %lx itt 0x%x]\n", (long)sc, ctask->itt);
+	spin_unlock_bh(&session->lock);
+
+	/*
+	 * clean up task if aborted. we have the xmitmutex so grab
+	 * the recv lock as a writer
+	 */
+	write_lock_bh(conn->recv_lock);
+	spin_lock(&session->lock);
+	fail_command(conn, ctask, DID_ABORT << 16);
+	spin_unlock(&session->lock);
+	write_unlock_bh(conn->recv_lock);
+
+	mutex_unlock(&conn->xmitmutex);
+	return SUCCESS;	
+
+failed:
+	spin_unlock_bh(&session->lock);
+	mutex_unlock(&conn->xmitmutex);
+
+	debug_scsi("abort failed [sc %lx itt 0x%x]\n", (long)sc, ctask->itt);
+	return FAILED;
+}
+EXPORT_SYMBOL_GPL(iscsi_eh_abort);
+
+int
+iscsi_pool_init(struct iscsi_queue *q, int max, void ***items, int item_size)
+{
+	int i;
+
+	*items = kmalloc(max * sizeof(void*), GFP_KERNEL);
+	if (*items == NULL)
+		return -ENOMEM;
+
+	q->max = max;
+	q->pool = kmalloc(max * sizeof(void*), GFP_KERNEL);
+	if (q->pool == NULL) {
+		kfree(*items);
+		return -ENOMEM;
+	}
+
+	q->queue = kfifo_init((void*)q->pool, max * sizeof(void*),
+			      GFP_KERNEL, NULL);
+	if (q->queue == ERR_PTR(-ENOMEM)) {
+		kfree(q->pool);
+		kfree(*items);
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < max; i++) {
+		q->pool[i] = kmalloc(item_size, GFP_KERNEL);
+		if (q->pool[i] == NULL) {
+			int j;
+
+			for (j = 0; j < i; j++)
+				kfree(q->pool[j]);
+
+			kfifo_free(q->queue);
+			kfree(q->pool);
+			kfree(*items);
+			return -ENOMEM;
+		}
+		memset(q->pool[i], 0, item_size);
+		(*items)[i] = q->pool[i];
+		__kfifo_put(q->queue, (void*)&q->pool[i], sizeof(void*));
+	}
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_pool_init);
+
+void iscsi_pool_free(struct iscsi_queue *q, void **items)
+{
+	int i;
+
+	for (i = 0; i < q->max; i++)
+		kfree(items[i]);
+	kfree(q->pool);
+	kfree(items);
+}
+EXPORT_SYMBOL_GPL(iscsi_pool_free);
+
+/*
+ * iSCSI Session's hostdata organization:
+ *
+ *    *------------------* <== hostdata_session(host->hostdata)
+ *    | ptr to class sess|
+ *    |------------------| <== iscsi_hostdata(host->hostdata)
+ *    | iscsi_session    |
+ *    *------------------*
+ */
+
+#define hostdata_privsize(_sz)	(sizeof(unsigned long) + _sz + \
+				 _sz % sizeof(unsigned long))
+
+#define hostdata_session(_hostdata) (iscsi_ptr(*(unsigned long *)_hostdata))
+
+/**
+ * iscsi_session_setup - create iscsi cls session and host and session
+ * @scsit: scsi transport template
+ * @iscsit: iscsi transport template
+ * @initial_cmdsn: initial CmdSN
+ * @hostno: host no allocated
+ *
+ * This can be used by software iscsi_transports that allocate
+ * a session per scsi host.
+ **/
+struct iscsi_cls_session *
+iscsi_session_setup(struct iscsi_transport *iscsit,
+		    struct scsi_transport_template *scsit,
+		    int cmd_task_size, int mgmt_task_size,
+		    uint32_t initial_cmdsn, uint32_t *hostno)
+{
+	struct Scsi_Host *shost;
+	struct iscsi_session *session;
+	struct iscsi_cls_session *cls_session;
+	int cmd_i;
+
+	shost = scsi_host_alloc(iscsit->host_template,
+				hostdata_privsize(sizeof(*session)));
+	if (!shost)
+		return NULL;
+
+	shost->max_id = 1;
+	shost->max_channel = 0;
+	shost->max_lun = iscsit->max_lun;
+	shost->max_cmd_len = iscsit->max_cmd_len;
+	shost->transportt = scsit;
+	shost->transportt->create_work_queue = 1;
+	*hostno = shost->host_no;
+
+	session = iscsi_hostdata(shost->hostdata);
+	memset(session, 0, sizeof(struct iscsi_session));
+	session->host = shost;
+	session->state = ISCSI_STATE_FREE;
+	session->mgmtpool_max = ISCSI_MGMT_CMDS_MAX;
+	session->cmds_max = ISCSI_XMIT_CMDS_MAX;
+	session->cmdsn = initial_cmdsn;
+	session->exp_cmdsn = initial_cmdsn + 1;
+	session->max_cmdsn = initial_cmdsn + 1;
+	session->max_r2t = 1;
+	session->tt = iscsit;
+
+	/* initialize SCSI PDU commands pool */
+	if (iscsi_pool_init(&session->cmdpool, session->cmds_max,
+			    (void***)&session->cmds,
+			    cmd_task_size + sizeof(struct iscsi_cmd_task)))
+		goto cmdpool_alloc_fail;
+
+	/* pre-format cmds pool with ITT */
+	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
+		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
+
+		if (cmd_task_size)
+			ctask->dd_data = &ctask[1];
+		ctask->itt = cmd_i;
+	}
+
+	spin_lock_init(&session->lock);
+	INIT_LIST_HEAD(&session->connections);
+
+	/* initialize immediate command pool */
+	if (iscsi_pool_init(&session->mgmtpool, session->mgmtpool_max,
+			   (void***)&session->mgmt_cmds,
+			   mgmt_task_size + sizeof(struct iscsi_mgmt_task)))
+		goto mgmtpool_alloc_fail;
+
+
+	/* pre-format immediate cmds pool with ITT */
+	for (cmd_i = 0; cmd_i < session->mgmtpool_max; cmd_i++) {
+		struct iscsi_mgmt_task *mtask = session->mgmt_cmds[cmd_i];
+
+		if (mgmt_task_size)
+			mtask->dd_data = &mtask[1];
+		mtask->itt = ISCSI_MGMT_ITT_OFFSET + cmd_i;
+		mtask->data = kmalloc(DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH,
+				     GFP_KERNEL);
+		if (!mtask->data) {
+			int j;
+
+			for (j = 0; j < cmd_i; j++)
+				kfree(session->mgmt_cmds[j]->data);
+			goto immdata_alloc_fail;
+		}
+	}
+
+	if (scsi_add_host(shost, NULL))
+		goto add_host_fail;
+
+	cls_session = iscsi_create_session(shost, iscsit, 0);
+	if (!cls_session)
+		goto cls_session_fail;
+	*(unsigned long*)shost->hostdata = (unsigned long)cls_session;
+
+	return cls_session;
+
+cls_session_fail:
+	scsi_remove_host(shost);
+add_host_fail:
+	for (cmd_i = 0; cmd_i < session->mgmtpool_max; cmd_i++)
+		kfree(session->mgmt_cmds[cmd_i]->data);
+immdata_alloc_fail:
+	iscsi_pool_free(&session->mgmtpool, (void**)session->mgmt_cmds);
+mgmtpool_alloc_fail:
+	iscsi_pool_free(&session->cmdpool, (void**)session->cmds);
+cmdpool_alloc_fail:
+	scsi_host_put(shost);
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(iscsi_session_setup);
+
+/**
+ * iscsi_session_teardown - destroy session, host, and cls_session
+ * shost: scsi host
+ *
+ * This can be used by software iscsi_transports that allocate
+ * a session per scsi host.
+ **/
+void iscsi_session_teardown(struct iscsi_cls_session *cls_session)
+{
+	struct Scsi_Host *shost = iscsi_session_to_shost(cls_session);
+	struct iscsi_session *session = iscsi_hostdata(shost->hostdata);
+	int cmd_i;
+
+	scsi_remove_host(shost);
+
+	for (cmd_i = 0; cmd_i < session->mgmtpool_max; cmd_i++)
+		kfree(session->mgmt_cmds[cmd_i]->data);
+
+	iscsi_pool_free(&session->mgmtpool, (void**)session->mgmt_cmds);
+	iscsi_pool_free(&session->cmdpool, (void**)session->cmds);
+
+	iscsi_destroy_session(cls_session);
+	scsi_host_put(shost);
+}
+EXPORT_SYMBOL_GPL(iscsi_session_teardown);
+
+/**
+ * iscsi_conn_setup - create iscsi_cls_conn and iscsi_conn
+ * @cls_session: iscsi_cls_session
+ * @conn_idx: cid
+ **/
+struct iscsi_cls_conn *
+iscsi_conn_setup(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
+{
+	struct iscsi_session *session = class_to_transport_session(cls_session);
+	struct iscsi_conn *conn;
+	struct iscsi_cls_conn *cls_conn;
+
+	cls_conn = iscsi_create_conn(cls_session, conn_idx);
+	if (!cls_conn)
+		return NULL;
+	conn = cls_conn->dd_data;
+	memset(conn, 0, sizeof(*conn));
+
+	conn->session = session;
+	conn->cls_conn = cls_conn;
+	conn->c_stage = ISCSI_CONN_INITIAL_STAGE;
+	conn->id = conn_idx;
+	conn->exp_statsn = 0;
+	conn->tmabort_state = TMABORT_INITIAL;
+	INIT_LIST_HEAD(&conn->run_list);
+	INIT_LIST_HEAD(&conn->mgmt_run_list);
+
+	/* initialize general xmit PDU commands queue */
+	conn->xmitqueue = kfifo_alloc(session->cmds_max * sizeof(void*),
+					GFP_KERNEL, NULL);
+	if (conn->xmitqueue == ERR_PTR(-ENOMEM))
+		goto xmitqueue_alloc_fail;
+
+	/* initialize general immediate & non-immediate PDU commands queue */
+	conn->immqueue = kfifo_alloc(session->mgmtpool_max * sizeof(void*),
+			                GFP_KERNEL, NULL);
+	if (conn->immqueue == ERR_PTR(-ENOMEM))
+		goto immqueue_alloc_fail;
+
+	conn->mgmtqueue = kfifo_alloc(session->mgmtpool_max * sizeof(void*),
+			                GFP_KERNEL, NULL);
+	if (conn->mgmtqueue == ERR_PTR(-ENOMEM))
+		goto mgmtqueue_alloc_fail;
+
+	INIT_WORK(&conn->xmitwork, iscsi_xmitworker, conn);
+
+	/* allocate login_mtask used for the login/text sequences */
+	spin_lock_bh(&session->lock);
+	if (!__kfifo_get(session->mgmtpool.queue,
+                         (void*)&conn->login_mtask,
+			 sizeof(void*))) {
+		spin_unlock_bh(&session->lock);
+		goto login_mtask_alloc_fail;
+	}
+	spin_unlock_bh(&session->lock);
+
+	init_timer(&conn->tmabort_timer);
+	mutex_init(&conn->xmitmutex);
+	init_waitqueue_head(&conn->ehwait);
+
+	return cls_conn;
+
+login_mtask_alloc_fail:
+	kfifo_free(conn->mgmtqueue);
+mgmtqueue_alloc_fail:
+	kfifo_free(conn->immqueue);
+immqueue_alloc_fail:
+	kfifo_free(conn->xmitqueue);
+xmitqueue_alloc_fail:
+	iscsi_destroy_conn(cls_conn);
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_setup);
+
+/**
+ * iscsi_conn_teardown - teardown iscsi connection
+ * cls_conn: iscsi class connection
+ *
+ * TODO: we may need to make this into a two step process
+ * like scsi-mls remove + put host
+ */
+void iscsi_conn_teardown(struct iscsi_cls_conn *cls_conn)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_session *session = conn->session;
+	unsigned long flags;
+
+	mutex_lock(&conn->xmitmutex);
+	set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	if (conn->c_stage == ISCSI_CONN_INITIAL_STAGE) {
+		if (session->tt->suspend_conn_recv)
+			session->tt->suspend_conn_recv(conn);
+
+		session->tt->terminate_conn(conn);
+	}
+
+	spin_lock_bh(&session->lock);
+	conn->c_stage = ISCSI_CONN_CLEANUP_WAIT;
+	if (session->leadconn == conn) {
+		/*
+		 * leading connection? then give up on recovery.
+		 */
+		session->state = ISCSI_STATE_TERMINATE;
+		wake_up(&conn->ehwait);
+	}
+	spin_unlock_bh(&session->lock);
+
+	mutex_unlock(&conn->xmitmutex);
+
+	/*
+	 * Block until all in-progress commands for this connection
+	 * time out or fail.
+	 */
+	for (;;) {
+		spin_lock_irqsave(session->host->host_lock, flags);
+		if (!session->host->host_busy) { /* OK for ERL == 0 */
+			spin_unlock_irqrestore(session->host->host_lock, flags);
+			break;
+		}
+		spin_unlock_irqrestore(session->host->host_lock, flags);
+		msleep_interruptible(500);
+		printk(KERN_INFO "iscsi: scsi conn_destroy(): host_busy %d host_failed %d\n",
+			session->host->host_busy, session->host->host_failed);
+		/*
+		 * force eh_abort() to unblock
+		 */
+		wake_up(&conn->ehwait);
+	}
+
+	spin_lock_bh(&session->lock);
+	__kfifo_put(session->mgmtpool.queue, (void*)&conn->login_mtask,
+		    sizeof(void*));
+	list_del(&conn->item);
+	if (list_empty(&session->connections))
+		session->leadconn = NULL;
+	if (session->leadconn && session->leadconn == conn)
+		session->leadconn = container_of(session->connections.next,
+			struct iscsi_conn, item);
+
+	if (session->leadconn == NULL)
+		/* no connections exits.. reset sequencing */
+		session->cmdsn = session->max_cmdsn = session->exp_cmdsn = 1;
+	spin_unlock_bh(&session->lock);
+
+	kfifo_free(conn->xmitqueue);
+	kfifo_free(conn->immqueue);
+	kfifo_free(conn->mgmtqueue);
+
+	iscsi_destroy_conn(cls_conn);
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_teardown);
+
+int iscsi_conn_start(struct iscsi_cls_conn *cls_conn)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_session *session = conn->session;
+
+	if (session == NULL) {
+		printk(KERN_ERR "iscsi: can't start unbound connection\n");
+		return -EPERM;
+	}
+
+	spin_lock_bh(&session->lock);
+	conn->c_stage = ISCSI_CONN_STARTED;
+	session->state = ISCSI_STATE_LOGGED_IN;
+
+	switch(conn->stop_stage) {
+	case STOP_CONN_RECOVER:
+		/*
+		 * unblock eh_abort() if it is blocked. re-try all
+		 * commands after successful recovery
+		 */
+		session->conn_cnt++;
+		conn->stop_stage = 0;
+		conn->tmabort_state = TMABORT_INITIAL;
+		session->age++;
+		session->recovery_failed = 0;
+		spin_unlock_bh(&session->lock);
+
+		iscsi_unblock_session(session_to_cls(session));
+		wake_up(&conn->ehwait);
+		return 0;
+	case STOP_CONN_TERM:
+		session->conn_cnt++;
+		conn->stop_stage = 0;
+		break;
+	case STOP_CONN_SUSPEND:
+		conn->stop_stage = 0;
+		clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
+		clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+		break;
+	default:
+		break;
+	}
+	spin_unlock_bh(&session->lock);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_start);
+
+static void
+flush_control_queues(struct iscsi_session *session, struct iscsi_conn *conn)
+{
+	struct iscsi_mgmt_task *mtask, *tmp;
+
+	/* handle pending */
+	while (__kfifo_get(conn->immqueue, (void*)&mtask, sizeof(void*)) ||
+	       __kfifo_get(conn->mgmtqueue, (void*)&mtask, sizeof(void*))) {
+		if (mtask == conn->login_mtask)
+			continue;
+		debug_scsi("flushing pending mgmt task itt 0x%x\n", mtask->itt);
+		__kfifo_put(session->mgmtpool.queue, (void*)&mtask,
+			    sizeof(void*));
+	}
+
+	/* handle running */
+	list_for_each_entry_safe(mtask, tmp, &conn->mgmt_run_list, running) {
+		debug_scsi("flushing running mgmt task itt 0x%x\n", mtask->itt);
+		list_del(&mtask->running);
+
+		if (mtask == conn->login_mtask)
+			continue;
+		__kfifo_put(session->mgmtpool.queue, (void*)&mtask,
+			   sizeof(void*));
+	}
+
+	conn->mtask = NULL;
+}
+
+/* Fail commands. Mutex and session lock held and recv side suspended */
+static void fail_all_commands(struct iscsi_conn *conn)
+{
+	struct iscsi_cmd_task *ctask, *tmp;
+
+	/* flush pending */	
+	while (__kfifo_get(conn->xmitqueue, (void*)&ctask, sizeof(void*))) {
+		debug_scsi("failing pending sc %p itt 0x%x\n", ctask->sc,
+			   ctask->itt);
+		fail_command(conn, ctask, DID_BUS_BUSY << 16);
+	}
+
+	/* fail all other running */
+	list_for_each_entry_safe(ctask, tmp, &conn->run_list, running) {
+		debug_scsi("failing in progress sc %p itt 0x%x\n",
+			   ctask->sc, ctask->itt);
+		fail_command(conn, ctask, DID_BUS_BUSY << 16);
+	}
+
+	conn->ctask = NULL;
+}
+
+void iscsi_start_session_recovery(struct iscsi_session *session,
+				  struct iscsi_conn *conn, int flag)
+{
+	int old_stop_stage;
+
+	spin_lock_bh(&session->lock);
+	if (conn->stop_stage == STOP_CONN_TERM) {
+		spin_unlock_bh(&session->lock);
+		return;
+	}
+
+	/*
+	 * When this is called for the in_login state, we only want to clean
+	 * up the login task and connection.
+	 */
+	if (conn->stop_stage != STOP_CONN_RECOVER)
+		session->conn_cnt--;
+
+	old_stop_stage = conn->stop_stage;
+	conn->stop_stage = flag;
+	spin_unlock_bh(&session->lock);
+
+	if (session->tt->suspend_conn_recv)
+		session->tt->suspend_conn_recv(conn);
+
+	mutex_lock(&conn->xmitmutex);
+	spin_lock_bh(&session->lock);
+	conn->c_stage = ISCSI_CONN_STOPPED;
+	set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+
+	if (session->conn_cnt == 0 || session->leadconn == conn)
+		session->state = ISCSI_STATE_FAILED;
+
+	spin_unlock_bh(&session->lock);
+
+	session->tt->terminate_conn(conn);
+	/*
+	 * flush queues.
+	 */
+	spin_lock_bh(&session->lock);
+	fail_all_commands(conn);
+	flush_control_queues(session, conn);
+	spin_unlock_bh(&session->lock);
+
+	/*
+	 * for connection level recovery we should not calculate
+	 * header digest. conn->hdr_size used for optimization
+	 * in hdr_extract() and will be re-negotiated at
+	 * set_param() time.
+	 */
+	if (flag == STOP_CONN_RECOVER) {
+		conn->hdrdgst_en = 0;
+		conn->datadgst_en = 0;
+
+		/*
+		 * if this is called from the eh and and from userspace
+		 * then we only need to block once.
+		 */
+		if (session->state == ISCSI_STATE_FAILED &&
+		    old_stop_stage != STOP_CONN_RECOVER)
+			iscsi_block_session(session_to_cls(session));
+	}
+	mutex_unlock(&conn->xmitmutex);
+}
+EXPORT_SYMBOL_GPL(iscsi_start_session_recovery);
+
+void iscsi_conn_stop(struct iscsi_cls_conn *cls_conn, int flag)
+{
+	struct iscsi_conn *conn = cls_conn->dd_data;
+	struct iscsi_session *session = conn->session;
+
+	switch (flag) {
+	case STOP_CONN_RECOVER:
+	case STOP_CONN_TERM:
+		iscsi_start_session_recovery(session, conn, flag);
+		break;
+	case STOP_CONN_SUSPEND:
+		if (session->tt->suspend_conn_recv)
+			session->tt->suspend_conn_recv(conn);
+
+		mutex_lock(&conn->xmitmutex);
+		spin_lock_bh(&session->lock);
+
+		conn->stop_stage = flag;
+		conn->c_stage = ISCSI_CONN_STOPPED;
+		set_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+
+		spin_unlock_bh(&session->lock);
+		mutex_unlock(&conn->xmitmutex);
+		break;
+	default:
+		printk(KERN_ERR "iscsi: invalid stop flag %d\n", flag);
+	}
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_stop);
+
+int iscsi_conn_bind(struct iscsi_cls_session *cls_session,
+		    struct iscsi_cls_conn *cls_conn, int is_leading)
+{
+	struct iscsi_session *session = class_to_transport_session(cls_session);
+	struct iscsi_conn *tmp = ERR_PTR(-EEXIST), *conn = cls_conn->dd_data;
+
+	/* lookup for existing connection */
+	spin_lock_bh(&session->lock);
+	list_for_each_entry(tmp, &session->connections, item) {
+		if (tmp == conn) {
+			if (conn->c_stage != ISCSI_CONN_STOPPED ||
+			    conn->stop_stage == STOP_CONN_TERM) {
+				printk(KERN_ERR "iscsi: can't bind "
+				       "non-stopped connection (%d:%d)\n",
+				       conn->c_stage, conn->stop_stage);
+				spin_unlock_bh(&session->lock);
+				return -EIO;
+			}
+			break;
+		}
+	}
+	if (tmp != conn) {
+		/* bind new iSCSI connection to session */
+		conn->session = session;
+		list_add(&conn->item, &session->connections);
+	}
+	spin_unlock_bh(&session->lock);
+
+	if (is_leading)
+		session->leadconn = conn;
+
+	/*
+	 * Unblock xmitworker(), Login Phase will pass through.
+	 */
+	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_rx);
+	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_bind);
+
+MODULE_AUTHOR("Mike Christie");
+MODULE_DESCRIPTION("iSCSI library functions");
+MODULE_LICENSE("GPL");

Added: branches/use-scsi-ml/istgt/kernel/libiscsi.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/libiscsi.h	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/libiscsi.h	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,286 @@
+/*
+ * iSCSI lib definitions
+ *
+ * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
+ * Copyright (C) 2004 - 2006 Mike Christie
+ * Copyright (C) 2004 - 2005 Dmitry Yusupov
+ * Copyright (C) 2004 - 2005 Alex Aizman
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ */
+#ifndef LIBISCSI_H
+#define LIBISCSI_H
+
+#include <linux/types.h>
+#include <linux/mutex.h>
+#include <scsi/iscsi_proto.h>
+#include <iscsi_if.h>
+
+struct scsi_transport_template;
+struct scsi_device;
+struct Scsi_Host;
+struct scsi_cmnd;
+struct socket;
+struct iscsi_transport;
+struct iscsi_cls_session;
+struct iscsi_cls_conn;
+struct iscsi_session;
+struct iscsi_nopin;
+
+/* #define DEBUG_SCSI */
+#ifdef DEBUG_SCSI
+#define debug_scsi(fmt...) printk(KERN_INFO "iscsi: " fmt)
+#else
+#define debug_scsi(fmt...)
+#endif
+
+#define ISCSI_XMIT_CMDS_MAX	128	/* must be power of 2 */
+#define ISCSI_MGMT_CMDS_MAX	32	/* must be power of 2 */
+#define ISCSI_CONN_MAX			1
+
+#define ISCSI_MGMT_ITT_OFFSET	0xa00
+
+#define ISCSI_DEF_CMD_PER_LUN		32
+#define ISCSI_MAX_CMD_PER_LUN		128
+
+/* Task Mgmt states */
+#define TMABORT_INITIAL			0x0
+#define TMABORT_SUCCESS			0x1
+#define TMABORT_FAILED			0x2
+#define TMABORT_TIMEDOUT		0x3
+
+/* Connection suspend "bit" */
+#define ISCSI_SUSPEND_BIT		1
+
+#define ISCSI_ITT_MASK			(0xfff)
+#define ISCSI_CID_SHIFT			12
+#define ISCSI_CID_MASK			(0xffff << ISCSI_CID_SHIFT)
+#define ISCSI_AGE_SHIFT			28
+#define ISCSI_AGE_MASK			(0xf << ISCSI_AGE_SHIFT)
+
+struct iscsi_mgmt_task {
+	/*
+	 * Becuae LLDs allocate their hdr differently, this is a pointer to
+	 * that storage. It must be setup at session creation time.
+	 */
+	struct iscsi_hdr	*hdr; 
+	char			*data;		/* mgmt payload */
+	int			data_count;	/* counts data to be sent */
+	uint32_t		itt;		/* this ITT */
+	void			*dd_data;	/* driver/transport data */
+	struct list_head	running;
+};
+
+struct iscsi_cmd_task {
+	/*
+	 * Becuae LLDs allocate their hdr differently, this is a pointer to
+	 * that storage. It must be setup at session creation time.
+	 */
+	struct iscsi_cmd	*hdr;
+	int			itt;		/* this ITT */
+	int			datasn;		/* DataSN */
+
+	uint32_t		unsol_datasn;
+	int			imm_count;	/* imm-data (bytes)   */
+	int			unsol_count;	/* unsolicited (bytes)*/
+	int			data_count;	/* remaining Data-Out */
+	struct scsi_cmnd	*sc;		/* associated SCSI cmd*/
+	int			total_length;
+	struct iscsi_conn	*conn;		/* used connection    */
+	struct iscsi_mgmt_task	*mtask;		/* tmf mtask in progr */
+
+	struct list_head	running;	/* running cmd list */
+	void			*dd_data;	/* driver/transport data */
+};
+
+struct iscsi_conn {
+	struct iscsi_cls_conn	*cls_conn;	/* ptr to class connection */
+	void			*dd_data;	/* iscsi_transport data */
+	struct iscsi_session	*session;	/* parent session */
+	/*
+	 * LLDs should set this lock. It protects the transport recv
+	 * code
+	 */
+	rwlock_t		*recv_lock;
+	/*
+	 * conn_stop() flag: stop to recover, stop to terminate
+	 */
+        int			stop_stage;
+
+	/* iSCSI connection-wide sequencing */
+	uint32_t		exp_statsn;
+
+	/* control data */
+	int			id;		/* CID */
+	struct list_head	item;		/* maintains list of conns */
+	int			c_stage;	/* connection state */
+	struct iscsi_mgmt_task	*login_mtask;	/* mtask used for login/text */
+	struct iscsi_mgmt_task	*mtask;		/* xmit mtask in progress */
+	struct iscsi_cmd_task	*ctask;		/* xmit ctask in progress */
+
+	/* xmit */
+	struct kfifo		*immqueue;	/* immediate xmit queue */
+	struct kfifo		*mgmtqueue;	/* mgmt (control) xmit queue */
+	struct list_head	mgmt_run_list;	/* list of control tasks */
+	struct kfifo		*xmitqueue;	/* data-path cmd queue */
+	struct list_head	run_list;	/* list of cmds in progress */
+	struct work_struct	xmitwork;	/* per-conn. xmit workqueue */
+	/*
+	 * serializes connection xmit, access to kfifos:
+	 * xmitqueue, immqueue, mgmtqueue
+	 */
+	struct mutex		xmitmutex;
+
+	unsigned long		suspend_tx;	/* suspend Tx */
+	unsigned long		suspend_rx;	/* suspend Rx */
+
+	/* abort */
+	wait_queue_head_t	ehwait;		/* used in eh_abort() */
+	struct iscsi_tm		tmhdr;
+	struct timer_list	tmabort_timer;
+	int			tmabort_state;	/* see TMABORT_INITIAL, etc.*/
+
+	/* negotiated params */
+	int			max_recv_dlength; /* initiator_max_recv_dsl*/
+	int			max_xmit_dlength; /* target_max_recv_dsl */
+	int			hdrdgst_en;
+	int			datadgst_en;
+
+	/* MIB-statistics */
+	uint64_t		txdata_octets;
+	uint64_t		rxdata_octets;
+	uint32_t		scsicmd_pdus_cnt;
+	uint32_t		dataout_pdus_cnt;
+	uint32_t		scsirsp_pdus_cnt;
+	uint32_t		datain_pdus_cnt;
+	uint32_t		r2t_pdus_cnt;
+	uint32_t		tmfcmd_pdus_cnt;
+	int32_t			tmfrsp_pdus_cnt;
+
+	/* custom statistics */
+	uint32_t		eh_abort_cnt;
+};
+
+struct iscsi_queue {
+	struct kfifo		*queue;		/* FIFO Queue */
+	void			**pool;		/* Pool of elements */
+	int			max;		/* Max number of elements */
+};
+
+struct iscsi_session {
+	/* iSCSI session-wide sequencing */
+	uint32_t		cmdsn;
+	uint32_t		exp_cmdsn;
+	uint32_t		max_cmdsn;
+
+	/* configuration */
+	int			initial_r2t_en;
+	int			max_r2t;
+	int			imm_data_en;
+	int			first_burst;
+	int			max_burst;
+	int			time2wait;
+	int			time2retain;
+	int			pdu_inorder_en;
+	int			dataseq_inorder_en;
+	int			erl;
+	int			ifmarker_en;
+	int			ofmarker_en;
+
+	/* control data */
+	struct iscsi_transport	*tt;
+	struct Scsi_Host	*host;
+	struct iscsi_conn	*leadconn;	/* leading connection */
+	spinlock_t		lock;		/* protects session state, *
+						 * sequence numbers,       *
+						 * session resources:      *
+						 * - cmdpool,		   *
+						 * - mgmtpool,		   *
+						 * - r2tpool		   */
+	int			state;		/* session state           */
+	int			recovery_failed;
+	struct list_head	item;
+	int			conn_cnt;
+	int			age;		/* counts session re-opens */
+
+	struct list_head	connections;	/* list of connections */
+	int			cmds_max;	/* size of cmds array */
+	struct iscsi_cmd_task	**cmds;		/* Original Cmds arr */
+	struct iscsi_queue	cmdpool;	/* PDU's pool */
+	int			mgmtpool_max;	/* size of mgmt array */
+	struct iscsi_mgmt_task	**mgmt_cmds;	/* Original mgmt arr */
+	struct iscsi_queue	mgmtpool;	/* Mgmt PDU's pool */
+};
+
+/*
+ * scsi host template
+ */
+extern int iscsi_change_queue_depth(struct scsi_device *sdev, int depth);
+extern int iscsi_eh_abort(struct scsi_cmnd *sc);
+extern int iscsi_eh_host_reset(struct scsi_cmnd *sc);
+extern int iscsi_queuecommand(struct scsi_cmnd *sc,
+			      void (*done)(struct scsi_cmnd *));
+
+/*
+ * session management
+ */
+extern struct iscsi_cls_session *
+iscsi_session_setup(struct iscsi_transport *, struct scsi_transport_template *,
+		    int, int, uint32_t, uint32_t *);
+extern void iscsi_session_teardown(struct iscsi_cls_session *);
+extern struct iscsi_session *class_to_transport_session(struct iscsi_cls_session *);
+extern void iscsi_start_session_recovery(struct iscsi_session *,
+					struct iscsi_conn *, int);
+extern void iscsi_session_recovery_timedout(struct iscsi_cls_session *);
+
+#define session_to_cls(_sess) \
+	hostdata_session(_sess->host->hostdata)
+
+/*
+ * connection management
+ */
+extern struct iscsi_cls_conn *iscsi_conn_setup(struct iscsi_cls_session *,
+					       uint32_t);
+extern void iscsi_conn_teardown(struct iscsi_cls_conn *);
+extern int iscsi_conn_start(struct iscsi_cls_conn *);
+extern void iscsi_conn_stop(struct iscsi_cls_conn *, int);
+extern int iscsi_conn_bind(struct iscsi_cls_session *, struct iscsi_cls_conn *,
+			   int);
+extern void iscsi_conn_failure(struct iscsi_conn *conn, enum iscsi_err err);
+
+/*
+ * pdu and task processing
+ */
+extern int iscsi_check_assign_cmdsn(struct iscsi_session *,
+				    struct iscsi_nopin *);
+extern void iscsi_prep_unsolicit_data_pdu(struct iscsi_cmd_task *,
+					struct iscsi_data *hdr,
+					int transport_data_cnt);
+extern int iscsi_conn_send_pdu(struct iscsi_cls_conn *, struct iscsi_hdr *,
+				char *, uint32_t);
+extern int iscsi_complete_pdu(struct iscsi_conn *, struct iscsi_hdr *,
+			      char *, int);
+extern int __iscsi_complete_pdu(struct iscsi_conn *, struct iscsi_hdr *,
+				char *, int);
+extern int iscsi_verify_itt(struct iscsi_conn *, struct iscsi_hdr *,
+			    uint32_t *);
+
+/*
+ * generic helpers
+ */
+extern void iscsi_pool_free(struct iscsi_queue *, void **);
+extern int iscsi_pool_init(struct iscsi_queue *, int, void ***, int);
+
+#endif

Added: branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.c	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.c	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,1592 @@
+/*
+ * iSCSI transport class definitions
+ *
+ * Copyright (C) IBM Corporation, 2004
+ * Copyright (C) Mike Christie, 2004 - 2005
+ * Copyright (C) Dmitry Yusupov, 2004 - 2005
+ * Copyright (C) Alex Aizman, 2004 - 2005
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ */
+#include <linux/module.h>
+#include <linux/mempool.h>
+#include <linux/mutex.h>
+#include <net/tcp.h>
+#include <scsi/scsi.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_transport.h>
+#include "scsi_transport_iscsi.h"
+#include "iscsi_if.h"
+
+#define ISCSI_SESSION_ATTRS 11
+#define ISCSI_CONN_ATTRS 11
+#define ISCSI_HOST_ATTRS 0
+
+struct iscsi_internal {
+	struct scsi_transport_template t;
+	struct iscsi_transport *iscsi_transport;
+	struct list_head list;
+	struct class_device cdev;
+
+	struct class_device_attribute *host_attrs[ISCSI_HOST_ATTRS + 1];
+	struct transport_container conn_cont;
+	struct class_device_attribute *conn_attrs[ISCSI_CONN_ATTRS + 1];
+	struct transport_container session_cont;
+	struct class_device_attribute *session_attrs[ISCSI_SESSION_ATTRS + 1];
+};
+
+static int iscsi_session_nr;	/* sysfs session id for next new session */
+
+/*
+ * list of registered transports and lock that must
+ * be held while accessing list. The iscsi_transport_lock must
+ * be acquired after the rx_queue_mutex.
+ */
+static LIST_HEAD(iscsi_transports);
+static DEFINE_SPINLOCK(iscsi_transport_lock);
+
+#define to_iscsi_internal(tmpl) \
+	container_of(tmpl, struct iscsi_internal, t)
+
+#define cdev_to_iscsi_internal(_cdev) \
+	container_of(_cdev, struct iscsi_internal, cdev)
+
+static void iscsi_transport_release(struct class_device *cdev)
+{
+	struct iscsi_internal *priv = cdev_to_iscsi_internal(cdev);
+	kfree(priv);
+}
+
+/*
+ * iscsi_transport_class represents the iscsi_transports that are
+ * registered.
+ */
+static struct class iscsi_transport_class = {
+	.name = "iscsi_transport",
+	.release = iscsi_transport_release,
+};
+
+static ssize_t
+show_transport_handle(struct class_device *cdev, char *buf)
+{
+	struct iscsi_internal *priv = cdev_to_iscsi_internal(cdev);
+	return sprintf(buf, "%llu\n", (unsigned long long)iscsi_handle(priv->iscsi_transport));
+}
+static CLASS_DEVICE_ATTR(handle, S_IRUGO, show_transport_handle, NULL);
+
+#define show_transport_attr(name, format)				\
+static ssize_t								\
+show_transport_##name(struct class_device *cdev, char *buf)		\
+{									\
+	struct iscsi_internal *priv = cdev_to_iscsi_internal(cdev);	\
+	return sprintf(buf, format"\n", priv->iscsi_transport->name);	\
+}									\
+static CLASS_DEVICE_ATTR(name, S_IRUGO, show_transport_##name, NULL);
+
+show_transport_attr(caps, "0x%x");
+show_transport_attr(max_lun, "%d");
+show_transport_attr(max_conn, "%d");
+show_transport_attr(max_cmd_len, "%d");
+
+static struct attribute *iscsi_transport_attrs[] = {
+	&class_device_attr_handle.attr,
+	&class_device_attr_caps.attr,
+	&class_device_attr_max_lun.attr,
+	&class_device_attr_max_conn.attr,
+	&class_device_attr_max_cmd_len.attr,
+	NULL,
+};
+
+static struct attribute_group iscsi_transport_group = {
+	.attrs = iscsi_transport_attrs,
+};
+
+static int iscsi_setup_host(struct transport_container *tc, struct device *dev,
+			    struct class_device *cdev)
+{
+	struct Scsi_Host *shost = dev_to_shost(dev);
+	struct iscsi_host *ihost = shost->shost_data;
+
+	memset(ihost, 0, sizeof(*ihost));
+	INIT_LIST_HEAD(&ihost->sessions);
+	mutex_init(&ihost->mutex);
+	return 0;
+}
+
+static DECLARE_TRANSPORT_CLASS(iscsi_host_class,
+			       "iscsi_host",
+			       iscsi_setup_host,
+			       NULL,
+			       NULL);
+
+static DECLARE_TRANSPORT_CLASS(iscsi_session_class,
+			       "iscsi_session",
+			       NULL,
+			       NULL,
+			       NULL);
+
+static DECLARE_TRANSPORT_CLASS(iscsi_connection_class,
+			       "iscsi_connection",
+			       NULL,
+			       NULL,
+			       NULL);
+
+static struct sock *nls;
+static int daemon_pid;
+static DEFINE_MUTEX(rx_queue_mutex);
+
+struct mempool_zone {
+	mempool_t *pool;
+	atomic_t allocated;
+	int size;
+	int hiwat;
+	struct list_head freequeue;
+	spinlock_t freelock;
+};
+
+static struct mempool_zone *z_reply;
+
+/*
+ * Z_MAX_* - actual mempool size allocated at the mempool_zone_init() time
+ * Z_HIWAT_* - zone's high watermark when if_error bit will be set to -ENOMEM
+ *             so daemon will notice OOM on NETLINK tranposrt level and will
+ *             be able to predict or change operational behavior
+ */
+#define Z_MAX_REPLY	8
+#define Z_HIWAT_REPLY	6
+#define Z_MAX_PDU	8
+#define Z_HIWAT_PDU	6
+#define Z_MAX_ERROR	16
+#define Z_HIWAT_ERROR	12
+
+static LIST_HEAD(sesslist);
+static DEFINE_SPINLOCK(sesslock);
+static LIST_HEAD(connlist);
+static DEFINE_SPINLOCK(connlock);
+
+static uint32_t iscsi_conn_get_sid(struct iscsi_cls_conn *conn)
+{
+	struct iscsi_cls_session *sess = iscsi_dev_to_session(conn->dev.parent);
+	return sess->sid;
+}
+
+/*
+ * Returns the matching session to a given sid
+ */
+static struct iscsi_cls_session *iscsi_session_lookup(uint32_t sid)
+{
+	unsigned long flags;
+	struct iscsi_cls_session *sess;
+
+	spin_lock_irqsave(&sesslock, flags);
+	list_for_each_entry(sess, &sesslist, sess_list) {
+		if (sess->sid == sid) {
+			spin_unlock_irqrestore(&sesslock, flags);
+			return sess;
+		}
+	}
+	spin_unlock_irqrestore(&sesslock, flags);
+	return NULL;
+}
+
+/*
+ * Returns the matching connection to a given sid / cid tuple
+ */
+static struct iscsi_cls_conn *iscsi_conn_lookup(uint32_t sid, uint32_t cid)
+{
+	unsigned long flags;
+	struct iscsi_cls_conn *conn;
+
+	spin_lock_irqsave(&connlock, flags);
+	list_for_each_entry(conn, &connlist, conn_list) {
+		if ((conn->cid == cid) && (iscsi_conn_get_sid(conn) == sid)) {
+			spin_unlock_irqrestore(&connlock, flags);
+			return conn;
+		}
+	}
+	spin_unlock_irqrestore(&connlock, flags);
+	return NULL;
+}
+
+/*
+ * The following functions can be used by LLDs that allocate
+ * their own scsi_hosts or by software iscsi LLDs
+ */
+static void iscsi_session_release(struct device *dev)
+{
+	struct iscsi_cls_session *session = iscsi_dev_to_session(dev);
+	struct iscsi_transport *transport = session->transport;
+	struct Scsi_Host *shost;
+
+	shost = iscsi_session_to_shost(session);
+	scsi_host_put(shost);
+	kfree(session->targetname);
+	kfree(session);
+	module_put(transport->owner);
+}
+
+static int iscsi_is_session_dev(const struct device *dev)
+{
+	return dev->release == iscsi_session_release;
+}
+
+static int iscsi_user_scan(struct Scsi_Host *shost, uint channel,
+			   uint id, uint lun)
+{
+	struct iscsi_host *ihost = shost->shost_data;
+	struct iscsi_cls_session *session;
+
+	mutex_lock(&ihost->mutex);
+	list_for_each_entry(session, &ihost->sessions, host_list) {
+		if ((channel == SCAN_WILD_CARD ||
+		     channel == session->channel) &&
+		    (id == SCAN_WILD_CARD || id == session->target_id))
+			scsi_scan_target(&session->dev, session->channel,
+					 session->target_id, lun, 1);
+	}
+	mutex_unlock(&ihost->mutex);
+
+	return 0;
+}
+
+static void session_recovery_timedout(void *data)
+{
+	struct iscsi_cls_session *session = data;
+
+	dev_printk(KERN_INFO, &session->dev, "iscsi: session recovery timed out "
+		  "after %d secs\n", session->recovery_tmo);
+
+	if (session->transport->session_recovery_timedout)
+		session->transport->session_recovery_timedout(session);
+
+	scsi_target_unblock(&session->dev);
+}
+
+void iscsi_unblock_session(struct iscsi_cls_session *session)
+{
+	if (!cancel_delayed_work(&session->recovery_work))
+		flush_scheduled_work();
+	scsi_target_unblock(&session->dev);
+}
+EXPORT_SYMBOL_GPL(iscsi_unblock_session);
+
+void iscsi_block_session(struct iscsi_cls_session *session)
+{
+	scsi_target_block(&session->dev);
+	schedule_delayed_work(&session->recovery_work,
+			     session->recovery_tmo * HZ);
+}
+EXPORT_SYMBOL_GPL(iscsi_block_session);
+
+/**
+ * iscsi_create_session - create iscsi class session
+ * @shost: scsi host
+ * @transport: iscsi transport
+ *
+ * This can be called from a LLD or iscsi_transport.
+ **/
+struct iscsi_cls_session *
+iscsi_create_session(struct Scsi_Host *shost,
+		     struct iscsi_transport *transport, int channel)
+{
+	struct iscsi_host *ihost;
+	struct iscsi_cls_session *session;
+	int err;
+
+	if (!try_module_get(transport->owner))
+		return NULL;
+
+	session = kzalloc(sizeof(*session) + transport->sessiondata_size,
+			  GFP_KERNEL);
+	if (!session)
+		goto module_put;
+	session->transport = transport;
+	session->recovery_tmo = 120;
+	INIT_WORK(&session->recovery_work, session_recovery_timedout, session);
+	INIT_LIST_HEAD(&session->host_list);
+	INIT_LIST_HEAD(&session->sess_list);
+
+	if (transport->sessiondata_size)
+		session->dd_data = &session[1];
+
+	/* this is released in the dev's release function */
+	scsi_host_get(shost);
+	ihost = shost->shost_data;
+
+	session->sid = iscsi_session_nr++;
+	session->channel = channel;
+	session->target_id = ihost->next_target_id++;
+
+	snprintf(session->dev.bus_id, BUS_ID_SIZE, "session%u",
+		 session->sid);
+	session->dev.parent = &shost->shost_gendev;
+	session->dev.release = iscsi_session_release;
+	err = device_register(&session->dev);
+	if (err) {
+		dev_printk(KERN_ERR, &session->dev, "iscsi: could not "
+			   "register session's dev\n");
+		goto free_session;
+	}
+	transport_register_device(&session->dev);
+
+	mutex_lock(&ihost->mutex);
+	list_add(&session->host_list, &ihost->sessions);
+	mutex_unlock(&ihost->mutex);
+
+	return session;
+
+free_session:
+	kfree(session);
+module_put:
+	module_put(transport->owner);
+	return NULL;
+}
+
+EXPORT_SYMBOL_GPL(iscsi_create_session);
+
+/**
+ * iscsi_destroy_session - destroy iscsi session
+ * @session: iscsi_session
+ *
+ * Can be called by a LLD or iscsi_transport. There must not be
+ * any running connections.
+ **/
+int iscsi_destroy_session(struct iscsi_cls_session *session)
+{
+	struct Scsi_Host *shost = iscsi_session_to_shost(session);
+	struct iscsi_host *ihost = shost->shost_data;
+
+	if (!cancel_delayed_work(&session->recovery_work))
+		flush_scheduled_work();
+
+	mutex_lock(&ihost->mutex);
+	list_del(&session->host_list);
+	mutex_unlock(&ihost->mutex);
+
+	transport_unregister_device(&session->dev);
+	device_unregister(&session->dev);
+	return 0;
+}
+
+EXPORT_SYMBOL_GPL(iscsi_destroy_session);
+
+static void iscsi_conn_release(struct device *dev)
+{
+	struct iscsi_cls_conn *conn = iscsi_dev_to_conn(dev);
+	struct device *parent = conn->dev.parent;
+
+	kfree(conn->persistent_address);
+	kfree(conn);
+	put_device(parent);
+}
+
+static int iscsi_is_conn_dev(const struct device *dev)
+{
+	return dev->release == iscsi_conn_release;
+}
+
+/**
+ * iscsi_create_conn - create iscsi class connection
+ * @session: iscsi cls session
+ * @cid: connection id
+ *
+ * This can be called from a LLD or iscsi_transport. The connection
+ * is child of the session so cid must be unique for all connections
+ * on the session.
+ *
+ * Since we do not support MCS, cid will normally be zero. In some cases
+ * for software iscsi we could be trying to preallocate a connection struct
+ * in which case there could be two connection structs and cid would be
+ * non-zero.
+ **/
+struct iscsi_cls_conn *
+iscsi_create_conn(struct iscsi_cls_session *session, uint32_t cid)
+{
+	struct iscsi_transport *transport = session->transport;
+	struct iscsi_cls_conn *conn;
+	int err;
+
+	conn = kzalloc(sizeof(*conn) + transport->conndata_size, GFP_KERNEL);
+	if (!conn)
+		return NULL;
+
+	if (transport->conndata_size)
+		conn->dd_data = &conn[1];
+
+	INIT_LIST_HEAD(&conn->conn_list);
+	conn->transport = transport;
+	conn->cid = cid;
+
+	/* this is released in the dev's release function */
+	if (!get_device(&session->dev))
+		goto free_conn;
+
+	snprintf(conn->dev.bus_id, BUS_ID_SIZE, "connection%d:%u",
+		 session->sid, cid);
+	conn->dev.parent = &session->dev;
+	conn->dev.release = iscsi_conn_release;
+	err = device_register(&conn->dev);
+	if (err) {
+		dev_printk(KERN_ERR, &conn->dev, "iscsi: could not register "
+			   "connection's dev\n");
+		goto release_parent_ref;
+	}
+	transport_register_device(&conn->dev);
+	return conn;
+
+release_parent_ref:
+	put_device(&session->dev);
+free_conn:
+	kfree(conn);
+	return NULL;
+}
+
+EXPORT_SYMBOL_GPL(iscsi_create_conn);
+
+/**
+ * iscsi_destroy_conn - destroy iscsi class connection
+ * @session: iscsi cls session
+ *
+ * This can be called from a LLD or iscsi_transport.
+ **/
+int iscsi_destroy_conn(struct iscsi_cls_conn *conn)
+{
+	transport_unregister_device(&conn->dev);
+	device_unregister(&conn->dev);
+	return 0;
+}
+
+EXPORT_SYMBOL_GPL(iscsi_destroy_conn);
+
+/*
+ * iscsi interface functions
+ */
+static struct iscsi_internal *
+iscsi_if_transport_lookup(struct iscsi_transport *tt)
+{
+	struct iscsi_internal *priv;
+	unsigned long flags;
+
+	spin_lock_irqsave(&iscsi_transport_lock, flags);
+	list_for_each_entry(priv, &iscsi_transports, list) {
+		if (tt == priv->iscsi_transport) {
+			spin_unlock_irqrestore(&iscsi_transport_lock, flags);
+			return priv;
+		}
+	}
+	spin_unlock_irqrestore(&iscsi_transport_lock, flags);
+	return NULL;
+}
+
+static inline struct list_head *skb_to_lh(struct sk_buff *skb)
+{
+	return (struct list_head *)&skb->cb;
+}
+
+static void*
+mempool_zone_alloc_skb(unsigned int gfp_mask, void *pool_data)
+{
+	struct mempool_zone *zone = pool_data;
+
+	return alloc_skb(zone->size, gfp_mask);
+}
+
+static void
+mempool_zone_free_skb(void *element, void *pool_data)
+{
+	kfree_skb(element);
+}
+
+static void
+mempool_zone_complete(struct mempool_zone *zone)
+{
+	unsigned long flags;
+	struct list_head *lh, *n;
+
+	spin_lock_irqsave(&zone->freelock, flags);
+	list_for_each_safe(lh, n, &zone->freequeue) {
+		struct sk_buff *skb = (struct sk_buff *)((char *)lh -
+				offsetof(struct sk_buff, cb));
+		if (!skb_shared(skb)) {
+			list_del(skb_to_lh(skb));
+			mempool_free(skb, zone->pool);
+			atomic_dec(&zone->allocated);
+		}
+	}
+	spin_unlock_irqrestore(&zone->freelock, flags);
+}
+
+static struct mempool_zone *
+mempool_zone_init(unsigned max, unsigned size, unsigned hiwat)
+{
+	struct mempool_zone *zp;
+
+	zp = kzalloc(sizeof(*zp), GFP_KERNEL);
+	if (!zp)
+		return NULL;
+
+	zp->size = size;
+	zp->hiwat = hiwat;
+	INIT_LIST_HEAD(&zp->freequeue);
+	spin_lock_init(&zp->freelock);
+	atomic_set(&zp->allocated, 0);
+
+	zp->pool = mempool_create(max, mempool_zone_alloc_skb,
+				  mempool_zone_free_skb, zp);
+	if (!zp->pool) {
+		kfree(zp);
+		return NULL;
+	}
+
+	return zp;
+}
+
+static void mempool_zone_destroy(struct mempool_zone *zp)
+{
+	mempool_destroy(zp->pool);
+	kfree(zp);
+}
+
+static struct sk_buff*
+mempool_zone_get_skb(struct mempool_zone *zone)
+{
+	struct sk_buff *skb;
+
+	skb = mempool_alloc(zone->pool, GFP_ATOMIC);
+	if (skb)
+		atomic_inc(&zone->allocated);
+	return skb;
+}
+
+static int
+iscsi_unicast_skb(struct mempool_zone *zone, struct sk_buff *skb)
+{
+	unsigned long flags;
+	int rc;
+
+	skb_get(skb);
+	rc = netlink_unicast(nls, skb, daemon_pid, MSG_DONTWAIT);
+	if (rc < 0) {
+		mempool_free(skb, zone->pool);
+		printk(KERN_ERR "iscsi: can not unicast skb (%d)\n", rc);
+		return rc;
+	}
+
+	spin_lock_irqsave(&zone->freelock, flags);
+	INIT_LIST_HEAD(skb_to_lh(skb));
+	list_add(skb_to_lh(skb), &zone->freequeue);
+	spin_unlock_irqrestore(&zone->freelock, flags);
+
+	return 0;
+}
+
+int iscsi_recv_pdu(struct iscsi_cls_conn *conn, struct iscsi_hdr *hdr,
+		   char *data, uint32_t data_size)
+{
+	struct nlmsghdr	*nlh;
+	struct sk_buff *skb;
+	struct iscsi_uevent *ev;
+	char *pdu;
+	int len = NLMSG_SPACE(sizeof(*ev) + sizeof(struct iscsi_hdr) +
+			      data_size);
+
+	mempool_zone_complete(conn->z_pdu);
+
+	skb = mempool_zone_get_skb(conn->z_pdu);
+	if (!skb) {
+		iscsi_conn_error(conn, ISCSI_ERR_CONN_FAILED);
+		dev_printk(KERN_ERR, &conn->dev, "iscsi: can not deliver "
+			   "control PDU: OOM\n");
+		return -ENOMEM;
+	}
+
+	nlh = __nlmsg_put(skb, daemon_pid, 0, 0, (len - sizeof(*nlh)), 0);
+	ev = NLMSG_DATA(nlh);
+	memset(ev, 0, sizeof(*ev));
+	ev->transport_handle = iscsi_handle(conn->transport);
+	ev->type = ISCSI_KEVENT_RECV_PDU;
+	if (atomic_read(&conn->z_pdu->allocated) >= conn->z_pdu->hiwat)
+		ev->iferror = -ENOMEM;
+	ev->r.recv_req.cid = conn->cid;
+	ev->r.recv_req.sid = iscsi_conn_get_sid(conn);
+	pdu = (char*)ev + sizeof(*ev);
+	memcpy(pdu, hdr, sizeof(struct iscsi_hdr));
+	memcpy(pdu + sizeof(struct iscsi_hdr), data, data_size);
+
+	return iscsi_unicast_skb(conn->z_pdu, skb);
+}
+EXPORT_SYMBOL_GPL(iscsi_recv_pdu);
+
+void iscsi_conn_error(struct iscsi_cls_conn *conn, enum iscsi_err error)
+{
+	struct nlmsghdr	*nlh;
+	struct sk_buff	*skb;
+	struct iscsi_uevent *ev;
+	int len = NLMSG_SPACE(sizeof(*ev));
+
+	mempool_zone_complete(conn->z_error);
+
+	skb = mempool_zone_get_skb(conn->z_error);
+	if (!skb) {
+		dev_printk(KERN_ERR, &conn->dev, "iscsi: gracefully ignored "
+			  "conn error (%d)\n", error);
+		return;
+	}
+
+	nlh = __nlmsg_put(skb, daemon_pid, 0, 0, (len - sizeof(*nlh)), 0);
+	ev = NLMSG_DATA(nlh);
+	ev->transport_handle = iscsi_handle(conn->transport);
+	ev->type = ISCSI_KEVENT_CONN_ERROR;
+	if (atomic_read(&conn->z_error->allocated) >= conn->z_error->hiwat)
+		ev->iferror = -ENOMEM;
+	ev->r.connerror.error = error;
+	ev->r.connerror.cid = conn->cid;
+	ev->r.connerror.sid = iscsi_conn_get_sid(conn);
+
+	iscsi_unicast_skb(conn->z_error, skb);
+
+	dev_printk(KERN_INFO, &conn->dev, "iscsi: detected conn error (%d)\n",
+		   error);
+}
+EXPORT_SYMBOL_GPL(iscsi_conn_error);
+
+static int
+iscsi_if_send_reply(int pid, int seq, int type, int done, int multi,
+		      void *payload, int size)
+{
+	struct sk_buff	*skb;
+	struct nlmsghdr	*nlh;
+	int len = NLMSG_SPACE(size);
+	int flags = multi ? NLM_F_MULTI : 0;
+	int t = done ? NLMSG_DONE : type;
+
+	mempool_zone_complete(z_reply);
+
+	skb = mempool_zone_get_skb(z_reply);
+	/*
+	 * FIXME:
+	 * user is supposed to react on iferror == -ENOMEM;
+	 * see iscsi_if_rx().
+	 */
+	BUG_ON(!skb);
+
+	nlh = __nlmsg_put(skb, pid, seq, t, (len - sizeof(*nlh)), 0);
+	nlh->nlmsg_flags = flags;
+	memcpy(NLMSG_DATA(nlh), payload, size);
+	return iscsi_unicast_skb(z_reply, skb);
+}
+
+static int
+iscsi_if_get_stats(struct iscsi_transport *transport, struct nlmsghdr *nlh)
+{
+	struct iscsi_uevent *ev = NLMSG_DATA(nlh);
+	struct iscsi_stats *stats;
+	struct sk_buff *skbstat;
+	struct iscsi_cls_conn *conn;
+	struct nlmsghdr	*nlhstat;
+	struct iscsi_uevent *evstat;
+	int len = NLMSG_SPACE(sizeof(*ev) +
+			      sizeof(struct iscsi_stats) +
+			      sizeof(struct iscsi_stats_custom) *
+			      ISCSI_STATS_CUSTOM_MAX);
+	int err = 0;
+
+	conn = iscsi_conn_lookup(ev->u.get_stats.sid, ev->u.get_stats.cid);
+	if (!conn)
+		return -EEXIST;
+
+	do {
+		int actual_size;
+
+		mempool_zone_complete(conn->z_pdu);
+
+		skbstat = mempool_zone_get_skb(conn->z_pdu);
+		if (!skbstat) {
+			dev_printk(KERN_ERR, &conn->dev, "iscsi: can not "
+				   "deliver stats: OOM\n");
+			return -ENOMEM;
+		}
+
+		nlhstat = __nlmsg_put(skbstat, daemon_pid, 0, 0,
+				      (len - sizeof(*nlhstat)), 0);
+		evstat = NLMSG_DATA(nlhstat);
+		memset(evstat, 0, sizeof(*evstat));
+		evstat->transport_handle = iscsi_handle(conn->transport);
+		evstat->type = nlh->nlmsg_type;
+		if (atomic_read(&conn->z_pdu->allocated) >= conn->z_pdu->hiwat)
+			evstat->iferror = -ENOMEM;
+		evstat->u.get_stats.cid =
+			ev->u.get_stats.cid;
+		evstat->u.get_stats.sid =
+			ev->u.get_stats.sid;
+		stats = (struct iscsi_stats *)
+			((char*)evstat + sizeof(*evstat));
+		memset(stats, 0, sizeof(*stats));
+
+		transport->get_stats(conn, stats);
+		actual_size = NLMSG_SPACE(sizeof(struct iscsi_uevent) +
+					  sizeof(struct iscsi_stats) +
+					  sizeof(struct iscsi_stats_custom) *
+					  stats->custom_length);
+		actual_size -= sizeof(*nlhstat);
+		actual_size = NLMSG_LENGTH(actual_size);
+		skb_trim(skbstat, NLMSG_ALIGN(actual_size));
+		nlhstat->nlmsg_len = actual_size;
+
+		err = iscsi_unicast_skb(conn->z_pdu, skbstat);
+	} while (err < 0 && err != -ECONNREFUSED);
+
+	return err;
+}
+
+static int
+iscsi_if_create_session(struct iscsi_internal *priv, struct iscsi_uevent *ev)
+{
+	struct iscsi_transport *transport = priv->iscsi_transport;
+	struct iscsi_cls_session *session;
+	unsigned long flags;
+	uint32_t hostno;
+
+	session = transport->create_session(transport, &priv->t,
+					    ev->u.c_session.initial_cmdsn,
+					    &hostno);
+	if (!session)
+		return -ENOMEM;
+
+	spin_lock_irqsave(&sesslock, flags);
+	list_add(&session->sess_list, &sesslist);
+	spin_unlock_irqrestore(&sesslock, flags);
+
+	ev->r.c_session_ret.host_no = hostno;
+	ev->r.c_session_ret.sid = session->sid;
+	return 0;
+}
+
+static int
+iscsi_if_create_conn(struct iscsi_transport *transport, struct iscsi_uevent *ev)
+{
+	struct iscsi_cls_conn *conn;
+	struct iscsi_cls_session *session;
+	unsigned long flags;
+
+	session = iscsi_session_lookup(ev->u.c_conn.sid);
+	if (!session) {
+		printk(KERN_ERR "iscsi: invalid session %d\n",
+		       ev->u.c_conn.sid);
+		return -EINVAL;
+	}
+
+	conn = transport->create_conn(session, ev->u.c_conn.cid);
+	if (!conn) {
+		printk(KERN_ERR "iscsi: couldn't create a new "
+			   "connection for session %d\n",
+			   session->sid);
+		return -ENOMEM;
+	}
+
+	conn->z_pdu = mempool_zone_init(Z_MAX_PDU,
+			NLMSG_SPACE(sizeof(struct iscsi_uevent) +
+				    sizeof(struct iscsi_hdr) +
+				    DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH),
+			Z_HIWAT_PDU);
+	if (!conn->z_pdu) {
+		dev_printk(KERN_ERR, &conn->dev, "iscsi: can not allocate "
+			   "pdu zone for new conn\n");
+		goto destroy_conn;
+	}
+
+	conn->z_error = mempool_zone_init(Z_MAX_ERROR,
+			NLMSG_SPACE(sizeof(struct iscsi_uevent)),
+			Z_HIWAT_ERROR);
+	if (!conn->z_error) {
+		dev_printk(KERN_ERR, &conn->dev, "iscsi: can not allocate "
+			   "error zone for new conn\n");
+		goto free_pdu_pool;
+	}
+
+	ev->r.c_conn_ret.sid = session->sid;
+	ev->r.c_conn_ret.cid = conn->cid;
+
+	spin_lock_irqsave(&connlock, flags);
+	list_add(&conn->conn_list, &connlist);
+	conn->active = 1;
+	spin_unlock_irqrestore(&connlock, flags);
+
+	return 0;
+
+free_pdu_pool:
+	mempool_zone_destroy(conn->z_pdu);
+destroy_conn:
+	if (transport->destroy_conn)
+		transport->destroy_conn(conn->dd_data);
+	return -ENOMEM;
+}
+
+static int
+iscsi_if_destroy_conn(struct iscsi_transport *transport, struct iscsi_uevent *ev)
+{
+	unsigned long flags;
+	struct iscsi_cls_conn *conn;
+	struct mempool_zone *z_error, *z_pdu;
+
+	conn = iscsi_conn_lookup(ev->u.d_conn.sid, ev->u.d_conn.cid);
+	if (!conn)
+		return -EINVAL;
+	spin_lock_irqsave(&connlock, flags);
+	conn->active = 0;
+	list_del(&conn->conn_list);
+	spin_unlock_irqrestore(&connlock, flags);
+
+	z_pdu = conn->z_pdu;
+	z_error = conn->z_error;
+
+	if (transport->destroy_conn)
+		transport->destroy_conn(conn);
+
+	mempool_zone_destroy(z_pdu);
+	mempool_zone_destroy(z_error);
+
+	return 0;
+}
+
+static void
+iscsi_copy_param(struct iscsi_uevent *ev, uint32_t *value, char *data)
+{
+	if (ev->u.set_param.len != sizeof(uint32_t))
+		BUG();
+	memcpy(value, data, min_t(uint32_t, sizeof(uint32_t),
+		ev->u.set_param.len));
+}
+
+static int
+iscsi_set_param(struct iscsi_transport *transport, struct iscsi_uevent *ev)
+{
+	char *data = (char*)ev + sizeof(*ev);
+	struct iscsi_cls_conn *conn;
+	struct iscsi_cls_session *session;
+	int err = 0;
+	uint32_t value = 0;
+
+	session = iscsi_session_lookup(ev->u.set_param.sid);
+	conn = iscsi_conn_lookup(ev->u.set_param.sid, ev->u.set_param.cid);
+	if (!conn || !session)
+		return -EINVAL;
+
+	switch (ev->u.set_param.param) {
+	case ISCSI_PARAM_SESS_RECOVERY_TMO:
+		iscsi_copy_param(ev, &value, data);
+		if (value != 0)
+			session->recovery_tmo = value;
+		break;
+	case ISCSI_PARAM_TARGET_NAME:
+		/* this should not change between logins */
+		if (session->targetname)
+			return 0;
+
+		session->targetname = kstrdup(data, GFP_KERNEL);
+		if (!session->targetname)
+			return -ENOMEM;
+		break;
+	case ISCSI_PARAM_TPGT:
+		iscsi_copy_param(ev, &value, data);
+		session->tpgt = value;
+		break;
+	case ISCSI_PARAM_PERSISTENT_PORT:
+		iscsi_copy_param(ev, &value, data);
+		conn->persistent_port = value;
+		break;
+	case ISCSI_PARAM_PERSISTENT_ADDRESS:
+		/*
+		 * this is the address returned in discovery so it should
+		 * not change between logins.
+		 */
+		if (conn->persistent_address)
+			return 0;
+
+		conn->persistent_address = kstrdup(data, GFP_KERNEL);
+		if (!conn->persistent_address)
+			return -ENOMEM;
+		break;
+	default:
+		iscsi_copy_param(ev, &value, data);
+		err = transport->set_param(conn, ev->u.set_param.param, value);
+	}
+
+	return err;
+}
+
+static int
+iscsi_if_transport_ep(struct iscsi_transport *transport,
+		      struct iscsi_uevent *ev, int msg_type)
+{
+	struct sockaddr *dst_addr;
+	int rc = 0;
+
+	switch (msg_type) {
+	case ISCSI_UEVENT_TRANSPORT_EP_CONNECT:
+		if (!transport->ep_connect)
+			return -EINVAL;
+
+		dst_addr = (struct sockaddr *)((char*)ev + sizeof(*ev));
+		rc = transport->ep_connect(dst_addr,
+					   ev->u.ep_connect.non_blocking,
+					   &ev->r.ep_connect_ret.handle);
+		break;
+	case ISCSI_UEVENT_TRANSPORT_EP_POLL:
+		if (!transport->ep_poll)
+			return -EINVAL;
+
+		ev->r.retcode = transport->ep_poll(ev->u.ep_poll.ep_handle,
+						   ev->u.ep_poll.timeout_ms);
+		break;
+	case ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT:
+		if (!transport->ep_disconnect)
+			return -EINVAL;
+
+		transport->ep_disconnect(ev->u.ep_disconnect.ep_handle);
+		break;
+	}
+	return rc;
+}
+
+static int
+iscsi_if_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
+{
+	int err = 0;
+	struct iscsi_uevent *ev = NLMSG_DATA(nlh);
+	struct iscsi_transport *transport = NULL;
+	struct iscsi_internal *priv;
+	struct iscsi_cls_session *session;
+	struct iscsi_cls_conn *conn;
+	unsigned long flags;
+
+	priv = iscsi_if_transport_lookup(iscsi_ptr(ev->transport_handle));
+	if (!priv)
+		return -EINVAL;
+	transport = priv->iscsi_transport;
+
+	if (!try_module_get(transport->owner))
+		return -EINVAL;
+
+	switch (nlh->nlmsg_type) {
+	case ISCSI_UEVENT_CREATE_SESSION:
+		err = iscsi_if_create_session(priv, ev);
+		break;
+	case ISCSI_UEVENT_DESTROY_SESSION:
+		session = iscsi_session_lookup(ev->u.d_session.sid);
+		if (session) {
+			spin_lock_irqsave(&sesslock, flags);
+			list_del(&session->sess_list);
+			spin_unlock_irqrestore(&sesslock, flags);
+
+			transport->destroy_session(session);
+		} else
+			err = -EINVAL;
+		break;
+	case ISCSI_UEVENT_CREATE_CONN:
+		err = iscsi_if_create_conn(transport, ev);
+		break;
+	case ISCSI_UEVENT_DESTROY_CONN:
+		err = iscsi_if_destroy_conn(transport, ev);
+		break;
+	case ISCSI_UEVENT_BIND_CONN:
+		session = iscsi_session_lookup(ev->u.b_conn.sid);
+		conn = iscsi_conn_lookup(ev->u.b_conn.sid, ev->u.b_conn.cid);
+
+		if (session && conn)
+			ev->r.retcode =	transport->bind_conn(session, conn,
+					ev->u.b_conn.transport_eph,
+					ev->u.b_conn.is_leading);
+		else
+			err = -EINVAL;
+		break;
+	case ISCSI_UEVENT_SET_PARAM:
+		err = iscsi_set_param(transport, ev);
+		break;
+	case ISCSI_UEVENT_START_CONN:
+		conn = iscsi_conn_lookup(ev->u.start_conn.sid, ev->u.start_conn.cid);
+		if (conn)
+			ev->r.retcode = transport->start_conn(conn);
+		else
+			err = -EINVAL;
+		break;
+	case ISCSI_UEVENT_STOP_CONN:
+		conn = iscsi_conn_lookup(ev->u.stop_conn.sid, ev->u.stop_conn.cid);
+		if (conn)
+			transport->stop_conn(conn, ev->u.stop_conn.flag);
+		else
+			err = -EINVAL;
+		break;
+	case ISCSI_UEVENT_SEND_PDU:
+		conn = iscsi_conn_lookup(ev->u.send_pdu.sid, ev->u.send_pdu.cid);
+		if (conn)
+			ev->r.retcode =	transport->send_pdu(conn,
+				(struct iscsi_hdr*)((char*)ev + sizeof(*ev)),
+				(char*)ev + sizeof(*ev) + ev->u.send_pdu.hdr_size,
+				ev->u.send_pdu.data_size);
+		else
+			err = -EINVAL;
+		break;
+	case ISCSI_UEVENT_GET_STATS:
+		err = iscsi_if_get_stats(transport, nlh);
+		break;
+	case ISCSI_UEVENT_TRANSPORT_EP_CONNECT:
+	case ISCSI_UEVENT_TRANSPORT_EP_POLL:
+	case ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT:
+		err = iscsi_if_transport_ep(transport, ev, nlh->nlmsg_type);
+		break;
+	default:
+		err = -EINVAL;
+		break;
+	}
+
+	module_put(transport->owner);
+	return err;
+}
+
+/*
+ * Get message from skb (based on rtnetlink_rcv_skb).  Each message is
+ * processed by iscsi_if_recv_msg.  Malformed skbs with wrong lengths or
+ * invalid creds are discarded silently.
+ */
+static void
+iscsi_if_rx(struct sock *sk, int len)
+{
+	struct sk_buff *skb;
+
+	mutex_lock(&rx_queue_mutex);
+	while ((skb = skb_dequeue(&sk->sk_receive_queue)) != NULL) {
+		if (NETLINK_CREDS(skb)->uid) {
+			skb_pull(skb, skb->len);
+			goto free_skb;
+		}
+		daemon_pid = NETLINK_CREDS(skb)->pid;
+
+		while (skb->len >= NLMSG_SPACE(0)) {
+			int err;
+			uint32_t rlen;
+			struct nlmsghdr	*nlh;
+			struct iscsi_uevent *ev;
+
+			nlh = (struct nlmsghdr *)skb->data;
+			if (nlh->nlmsg_len < sizeof(*nlh) ||
+			    skb->len < nlh->nlmsg_len) {
+				break;
+			}
+
+			ev = NLMSG_DATA(nlh);
+			rlen = NLMSG_ALIGN(nlh->nlmsg_len);
+			if (rlen > skb->len)
+				rlen = skb->len;
+
+			err = iscsi_if_recv_msg(skb, nlh);
+			if (err) {
+				ev->type = ISCSI_KEVENT_IF_ERROR;
+				ev->iferror = err;
+			}
+			do {
+				/*
+				 * special case for GET_STATS:
+				 * on success - sending reply and stats from
+				 * inside of if_recv_msg(),
+				 * on error - fall through.
+				 */
+				if (ev->type == ISCSI_UEVENT_GET_STATS && !err)
+					break;
+				err = iscsi_if_send_reply(
+					NETLINK_CREDS(skb)->pid, nlh->nlmsg_seq,
+					nlh->nlmsg_type, 0, 0, ev, sizeof(*ev));
+				if (atomic_read(&z_reply->allocated) >=
+						z_reply->hiwat)
+					ev->iferror = -ENOMEM;
+			} while (err < 0 && err != -ECONNREFUSED);
+			skb_pull(skb, rlen);
+		}
+free_skb:
+		kfree_skb(skb);
+	}
+	mutex_unlock(&rx_queue_mutex);
+}
+
+#define iscsi_cdev_to_conn(_cdev) \
+	iscsi_dev_to_conn(_cdev->dev)
+
+#define ISCSI_CLASS_ATTR(_prefix,_name,_mode,_show,_store)		\
+struct class_device_attribute class_device_attr_##_prefix##_##_name =	\
+	__ATTR(_name,_mode,_show,_store)
+
+/*
+ * iSCSI connection attrs
+ */
+#define iscsi_conn_int_attr_show(param, format)				\
+static ssize_t								\
+show_conn_int_param_##param(struct class_device *cdev, char *buf)	\
+{									\
+	uint32_t value = 0;						\
+	struct iscsi_cls_conn *conn = iscsi_cdev_to_conn(cdev);		\
+	struct iscsi_transport *t = conn->transport;			\
+									\
+	t->get_conn_param(conn, param, &value);				\
+	return snprintf(buf, 20, format"\n", value);			\
+}
+
+#define iscsi_conn_int_attr(field, param, format)			\
+	iscsi_conn_int_attr_show(param, format)				\
+static ISCSI_CLASS_ATTR(conn, field, S_IRUGO, show_conn_int_param_##param, \
+			NULL);
+
+iscsi_conn_int_attr(max_recv_dlength, ISCSI_PARAM_MAX_RECV_DLENGTH, "%u");
+iscsi_conn_int_attr(max_xmit_dlength, ISCSI_PARAM_MAX_XMIT_DLENGTH, "%u");
+iscsi_conn_int_attr(header_digest, ISCSI_PARAM_HDRDGST_EN, "%d");
+iscsi_conn_int_attr(data_digest, ISCSI_PARAM_DATADGST_EN, "%d");
+iscsi_conn_int_attr(ifmarker, ISCSI_PARAM_IFMARKER_EN, "%d");
+iscsi_conn_int_attr(ofmarker, ISCSI_PARAM_OFMARKER_EN, "%d");
+iscsi_conn_int_attr(persistent_port, ISCSI_PARAM_PERSISTENT_PORT, "%d");
+iscsi_conn_int_attr(port, ISCSI_PARAM_CONN_PORT, "%d");
+iscsi_conn_int_attr(exp_statsn, ISCSI_PARAM_EXP_STATSN, "%u");
+
+#define iscsi_conn_str_attr_show(param)					\
+static ssize_t								\
+show_conn_str_param_##param(struct class_device *cdev, char *buf)	\
+{									\
+	struct iscsi_cls_conn *conn = iscsi_cdev_to_conn(cdev);		\
+	struct iscsi_transport *t = conn->transport;			\
+	return t->get_conn_str_param(conn, param, buf);			\
+}
+
+#define iscsi_conn_str_attr(field, param)				\
+	iscsi_conn_str_attr_show(param)					\
+static ISCSI_CLASS_ATTR(conn, field, S_IRUGO, show_conn_str_param_##param, \
+			NULL);
+
+iscsi_conn_str_attr(persistent_address, ISCSI_PARAM_PERSISTENT_ADDRESS);
+iscsi_conn_str_attr(address, ISCSI_PARAM_CONN_ADDRESS);
+
+#define iscsi_cdev_to_session(_cdev) \
+	iscsi_dev_to_session(_cdev->dev)
+
+/*
+ * iSCSI session attrs
+ */
+#define iscsi_session_int_attr_show(param, format)			\
+static ssize_t								\
+show_session_int_param_##param(struct class_device *cdev, char *buf)	\
+{									\
+	uint32_t value = 0;						\
+	struct iscsi_cls_session *session = iscsi_cdev_to_session(cdev);	\
+	struct iscsi_transport *t = session->transport;			\
+									\
+	t->get_session_param(session, param, &value);			\
+	return snprintf(buf, 20, format"\n", value);			\
+}
+
+#define iscsi_session_int_attr(field, param, format)			\
+	iscsi_session_int_attr_show(param, format)			\
+static ISCSI_CLASS_ATTR(sess, field, S_IRUGO, show_session_int_param_##param, \
+			NULL);
+
+iscsi_session_int_attr(initial_r2t, ISCSI_PARAM_INITIAL_R2T_EN, "%d");
+iscsi_session_int_attr(max_outstanding_r2t, ISCSI_PARAM_MAX_R2T, "%hu");
+iscsi_session_int_attr(immediate_data, ISCSI_PARAM_IMM_DATA_EN, "%d");
+iscsi_session_int_attr(first_burst_len, ISCSI_PARAM_FIRST_BURST, "%u");
+iscsi_session_int_attr(max_burst_len, ISCSI_PARAM_MAX_BURST, "%u");
+iscsi_session_int_attr(data_pdu_in_order, ISCSI_PARAM_PDU_INORDER_EN, "%d");
+iscsi_session_int_attr(data_seq_in_order, ISCSI_PARAM_DATASEQ_INORDER_EN, "%d");
+iscsi_session_int_attr(erl, ISCSI_PARAM_ERL, "%d");
+iscsi_session_int_attr(tpgt, ISCSI_PARAM_TPGT, "%d");
+
+#define iscsi_session_str_attr_show(param)				\
+static ssize_t								\
+show_session_str_param_##param(struct class_device *cdev, char *buf)	\
+{									\
+	struct iscsi_cls_session *session = iscsi_cdev_to_session(cdev); \
+	struct iscsi_transport *t = session->transport;			\
+	return t->get_session_str_param(session, param, buf);		\
+}
+
+#define iscsi_session_str_attr(field, param)				\
+	iscsi_session_str_attr_show(param)				\
+static ISCSI_CLASS_ATTR(sess, field, S_IRUGO, show_session_str_param_##param, \
+			NULL);
+
+iscsi_session_str_attr(targetname, ISCSI_PARAM_TARGET_NAME);
+
+/*
+ * Private session and conn attrs. userspace uses several iscsi values
+ * to identify each session between reboots. Some of these values may not
+ * be present in the iscsi_transport/LLD driver becuase userspace handles
+ * login (and failback for login redirect) so for these type of drivers
+ * the class manages the attrs and values for the iscsi_transport/LLD
+ */ 
+#define iscsi_priv_session_attr_show(field, format)			\
+static ssize_t								\
+show_priv_session_##field(struct class_device *cdev, char *buf)	\
+{									\
+	struct iscsi_cls_session *session = iscsi_cdev_to_session(cdev); \
+	return sprintf(buf, format"\n", session->field);		\
+}
+
+#define iscsi_priv_session_attr(field, format)				\
+	iscsi_priv_session_attr_show(field, format)			\
+static ISCSI_CLASS_ATTR(priv_sess, field, S_IRUGO, show_priv_session_##field, \
+			NULL)
+iscsi_priv_session_attr(targetname, "%s");
+iscsi_priv_session_attr(tpgt, "%d");
+iscsi_priv_session_attr(recovery_tmo, "%d");
+
+#define iscsi_priv_conn_attr_show(field, format)			\
+static ssize_t								\
+show_priv_conn_##field(struct class_device *cdev, char *buf)		\
+{									\
+	struct iscsi_cls_conn *conn = iscsi_cdev_to_conn(cdev);		\
+	return sprintf(buf, format"\n", conn->field);			\
+}
+
+#define iscsi_priv_conn_attr(field, format)				\
+	iscsi_priv_conn_attr_show(field, format)			\
+static ISCSI_CLASS_ATTR(priv_conn, field, S_IRUGO, show_priv_conn_##field, \
+			NULL)
+iscsi_priv_conn_attr(persistent_address, "%s");
+iscsi_priv_conn_attr(persistent_port, "%d");
+
+#define SETUP_PRIV_SESSION_RD_ATTR(field)				\
+do {									\
+	priv->session_attrs[count] = &class_device_attr_priv_sess_##field; \
+	count++;							\
+} while (0)
+
+#define SETUP_SESSION_RD_ATTR(field, param_flag)			\
+do {									\
+	if (tt->param_mask & param_flag) {				\
+		priv->session_attrs[count] = &class_device_attr_sess_##field; \
+		count++;						\
+	}								\
+} while (0)
+
+#define SETUP_PRIV_CONN_RD_ATTR(field)					\
+do {									\
+	priv->conn_attrs[count] = &class_device_attr_priv_conn_##field; \
+	count++;							\
+} while (0)
+
+#define SETUP_CONN_RD_ATTR(field, param_flag)				\
+do {									\
+	if (tt->param_mask & param_flag) {				\
+		priv->conn_attrs[count] = &class_device_attr_conn_##field; \
+		count++;						\
+	}								\
+} while (0)
+
+static int iscsi_session_match(struct attribute_container *cont,
+			   struct device *dev)
+{
+	struct iscsi_cls_session *session;
+	struct Scsi_Host *shost;
+	struct iscsi_internal *priv;
+
+	if (!iscsi_is_session_dev(dev))
+		return 0;
+
+	session = iscsi_dev_to_session(dev);
+	shost = iscsi_session_to_shost(session);
+	if (!shost->transportt)
+		return 0;
+
+	priv = to_iscsi_internal(shost->transportt);
+	if (priv->session_cont.ac.class != &iscsi_session_class.class)
+		return 0;
+
+	return &priv->session_cont.ac == cont;
+}
+
+static int iscsi_conn_match(struct attribute_container *cont,
+			   struct device *dev)
+{
+	struct iscsi_cls_session *session;
+	struct iscsi_cls_conn *conn;
+	struct Scsi_Host *shost;
+	struct iscsi_internal *priv;
+
+	if (!iscsi_is_conn_dev(dev))
+		return 0;
+
+	conn = iscsi_dev_to_conn(dev);
+	session = iscsi_dev_to_session(conn->dev.parent);
+	shost = iscsi_session_to_shost(session);
+
+	if (!shost->transportt)
+		return 0;
+
+	priv = to_iscsi_internal(shost->transportt);
+	if (priv->conn_cont.ac.class != &iscsi_connection_class.class)
+		return 0;
+
+	return &priv->conn_cont.ac == cont;
+}
+
+static int iscsi_host_match(struct attribute_container *cont,
+			    struct device *dev)
+{
+	struct Scsi_Host *shost;
+	struct iscsi_internal *priv;
+
+	if (!scsi_is_host_device(dev))
+		return 0;
+
+	shost = dev_to_shost(dev);
+	if (!shost->transportt  ||
+	    shost->transportt->host_attrs.ac.class != &iscsi_host_class.class)
+		return 0;
+
+        priv = to_iscsi_internal(shost->transportt);
+        return &priv->t.host_attrs.ac == cont;
+}
+
+struct scsi_transport_template *
+iscsi_register_transport(struct iscsi_transport *tt)
+{
+	struct iscsi_internal *priv;
+	unsigned long flags;
+	int count = 0, err;
+
+	BUG_ON(!tt);
+
+	priv = iscsi_if_transport_lookup(tt);
+	if (priv)
+		return NULL;
+
+	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return NULL;
+	INIT_LIST_HEAD(&priv->list);
+	priv->iscsi_transport = tt;
+	priv->t.user_scan = iscsi_user_scan;
+
+	priv->cdev.class = &iscsi_transport_class;
+	snprintf(priv->cdev.class_id, BUS_ID_SIZE, "%s", tt->name);
+	err = class_device_register(&priv->cdev);
+	if (err)
+		goto free_priv;
+
+	err = sysfs_create_group(&priv->cdev.kobj, &iscsi_transport_group);
+	if (err)
+		goto unregister_cdev;
+
+	/* host parameters */
+	priv->t.host_attrs.ac.attrs = &priv->host_attrs[0];
+	priv->t.host_attrs.ac.class = &iscsi_host_class.class;
+	priv->t.host_attrs.ac.match = iscsi_host_match;
+	priv->t.host_size = sizeof(struct iscsi_host);
+	priv->host_attrs[0] = NULL;
+	transport_container_register(&priv->t.host_attrs);
+
+	/* connection parameters */
+	priv->conn_cont.ac.attrs = &priv->conn_attrs[0];
+	priv->conn_cont.ac.class = &iscsi_connection_class.class;
+	priv->conn_cont.ac.match = iscsi_conn_match;
+	transport_container_register(&priv->conn_cont);
+
+	SETUP_CONN_RD_ATTR(max_recv_dlength, ISCSI_MAX_RECV_DLENGTH);
+	SETUP_CONN_RD_ATTR(max_xmit_dlength, ISCSI_MAX_XMIT_DLENGTH);
+	SETUP_CONN_RD_ATTR(header_digest, ISCSI_HDRDGST_EN);
+	SETUP_CONN_RD_ATTR(data_digest, ISCSI_DATADGST_EN);
+	SETUP_CONN_RD_ATTR(ifmarker, ISCSI_IFMARKER_EN);
+	SETUP_CONN_RD_ATTR(ofmarker, ISCSI_OFMARKER_EN);
+	SETUP_CONN_RD_ATTR(address, ISCSI_CONN_ADDRESS);
+	SETUP_CONN_RD_ATTR(port, ISCSI_CONN_PORT);
+	SETUP_CONN_RD_ATTR(exp_statsn, ISCSI_EXP_STATSN);
+
+	if (tt->param_mask & ISCSI_PERSISTENT_ADDRESS)
+		SETUP_CONN_RD_ATTR(persistent_address, ISCSI_PERSISTENT_ADDRESS);
+	else
+		SETUP_PRIV_CONN_RD_ATTR(persistent_address);
+
+	if (tt->param_mask & ISCSI_PERSISTENT_PORT)
+		SETUP_CONN_RD_ATTR(persistent_port, ISCSI_PERSISTENT_PORT);
+	else
+		SETUP_PRIV_CONN_RD_ATTR(persistent_port);
+
+	BUG_ON(count > ISCSI_CONN_ATTRS);
+	priv->conn_attrs[count] = NULL;
+	count = 0;
+
+	/* session parameters */
+	priv->session_cont.ac.attrs = &priv->session_attrs[0];
+	priv->session_cont.ac.class = &iscsi_session_class.class;
+	priv->session_cont.ac.match = iscsi_session_match;
+	transport_container_register(&priv->session_cont);
+
+	SETUP_SESSION_RD_ATTR(initial_r2t, ISCSI_INITIAL_R2T_EN);
+	SETUP_SESSION_RD_ATTR(max_outstanding_r2t, ISCSI_MAX_R2T);
+	SETUP_SESSION_RD_ATTR(immediate_data, ISCSI_IMM_DATA_EN);
+	SETUP_SESSION_RD_ATTR(first_burst_len, ISCSI_FIRST_BURST);
+	SETUP_SESSION_RD_ATTR(max_burst_len, ISCSI_MAX_BURST);
+	SETUP_SESSION_RD_ATTR(data_pdu_in_order, ISCSI_PDU_INORDER_EN);
+	SETUP_SESSION_RD_ATTR(data_seq_in_order, ISCSI_DATASEQ_INORDER_EN);
+	SETUP_SESSION_RD_ATTR(erl, ISCSI_ERL);
+	SETUP_PRIV_SESSION_RD_ATTR(recovery_tmo);
+
+	if (tt->param_mask & ISCSI_TARGET_NAME)
+		SETUP_SESSION_RD_ATTR(targetname, ISCSI_TARGET_NAME);
+	else
+		SETUP_PRIV_SESSION_RD_ATTR(targetname);
+
+	if (tt->param_mask & ISCSI_TPGT)
+		SETUP_SESSION_RD_ATTR(tpgt, ISCSI_TPGT);
+	else
+		SETUP_PRIV_SESSION_RD_ATTR(tpgt);
+
+	BUG_ON(count > ISCSI_SESSION_ATTRS);
+	priv->session_attrs[count] = NULL;
+
+	spin_lock_irqsave(&iscsi_transport_lock, flags);
+	list_add(&priv->list, &iscsi_transports);
+	spin_unlock_irqrestore(&iscsi_transport_lock, flags);
+
+	printk(KERN_NOTICE "iscsi: registered transport (%s)\n", tt->name);
+	return &priv->t;
+
+unregister_cdev:
+	class_device_unregister(&priv->cdev);
+free_priv:
+	kfree(priv);
+	return NULL;
+}
+EXPORT_SYMBOL_GPL(iscsi_register_transport);
+
+int iscsi_unregister_transport(struct iscsi_transport *tt)
+{
+	struct iscsi_internal *priv;
+	unsigned long flags;
+
+	BUG_ON(!tt);
+
+	mutex_lock(&rx_queue_mutex);
+
+	priv = iscsi_if_transport_lookup(tt);
+	BUG_ON (!priv);
+
+	spin_lock_irqsave(&iscsi_transport_lock, flags);
+	list_del(&priv->list);
+	spin_unlock_irqrestore(&iscsi_transport_lock, flags);
+
+	transport_container_unregister(&priv->conn_cont);
+	transport_container_unregister(&priv->session_cont);
+	transport_container_unregister(&priv->t.host_attrs);
+
+	sysfs_remove_group(&priv->cdev.kobj, &iscsi_transport_group);
+	class_device_unregister(&priv->cdev);
+	mutex_unlock(&rx_queue_mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(iscsi_unregister_transport);
+
+static int
+iscsi_rcv_nl_event(struct notifier_block *this, unsigned long event, void *ptr)
+{
+	struct netlink_notify *n = ptr;
+
+	if (event == NETLINK_URELEASE &&
+	    n->protocol == NETLINK_ISCSI && n->pid) {
+		struct iscsi_cls_conn *conn;
+		unsigned long flags;
+
+		mempool_zone_complete(z_reply);
+		spin_lock_irqsave(&connlock, flags);
+		list_for_each_entry(conn, &connlist, conn_list) {
+			mempool_zone_complete(conn->z_error);
+			mempool_zone_complete(conn->z_pdu);
+		}
+		spin_unlock_irqrestore(&connlock, flags);
+	}
+
+	return NOTIFY_DONE;
+}
+
+static struct notifier_block iscsi_nl_notifier = {
+	.notifier_call	= iscsi_rcv_nl_event,
+};
+
+static __init int iscsi_transport_init(void)
+{
+	int err;
+
+	err = class_register(&iscsi_transport_class);
+	if (err)
+		return err;
+
+	err = transport_class_register(&iscsi_host_class);
+	if (err)
+		goto unregister_transport_class;
+
+	err = transport_class_register(&iscsi_connection_class);
+	if (err)
+		goto unregister_host_class;
+
+	err = transport_class_register(&iscsi_session_class);
+	if (err)
+		goto unregister_conn_class;
+
+	err = netlink_register_notifier(&iscsi_nl_notifier);
+	if (err)
+		goto unregister_session_class;
+
+	nls = netlink_kernel_create(NETLINK_ISCSI, 1, iscsi_if_rx,
+			THIS_MODULE);
+	if (!nls) {
+		err = -ENOBUFS;
+		goto unregister_notifier;
+	}
+
+	z_reply = mempool_zone_init(Z_MAX_REPLY,
+		NLMSG_SPACE(sizeof(struct iscsi_uevent)), Z_HIWAT_REPLY);
+	if (z_reply)
+		return 0;
+
+	sock_release(nls->sk_socket);
+unregister_notifier:
+	netlink_unregister_notifier(&iscsi_nl_notifier);
+unregister_session_class:
+	transport_class_unregister(&iscsi_session_class);
+unregister_conn_class:
+	transport_class_unregister(&iscsi_connection_class);
+unregister_host_class:
+	transport_class_unregister(&iscsi_host_class);
+unregister_transport_class:
+	class_unregister(&iscsi_transport_class);
+	return err;
+}
+
+static void __exit iscsi_transport_exit(void)
+{
+	mempool_zone_destroy(z_reply);
+	sock_release(nls->sk_socket);
+	netlink_unregister_notifier(&iscsi_nl_notifier);
+	transport_class_unregister(&iscsi_connection_class);
+	transport_class_unregister(&iscsi_session_class);
+	transport_class_unregister(&iscsi_host_class);
+	class_unregister(&iscsi_transport_class);
+}
+
+module_init(iscsi_transport_init);
+module_exit(iscsi_transport_exit);
+
+MODULE_AUTHOR("Mike Christie <michaelc at cs.wisc.edu>, "
+	      "Dmitry Yusupov <dmitry_yus at yahoo.com>, "
+	      "Alex Aizman <itn780 at yahoo.com>");
+MODULE_DESCRIPTION("iSCSI Transport Interface");
+MODULE_LICENSE("GPL");

Added: branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.h	2006-04-29 13:54:19 UTC (rev 431)
+++ branches/use-scsi-ml/istgt/kernel/scsi_transport_iscsi.h	2006-04-29 14:03:22 UTC (rev 432)
@@ -0,0 +1,222 @@
+/*
+ * iSCSI transport class definitions
+ *
+ * Copyright (C) IBM Corporation, 2004
+ * Copyright (C) Mike Christie, 2004 - 2006
+ * Copyright (C) Dmitry Yusupov, 2004 - 2005
+ * Copyright (C) Alex Aizman, 2004 - 2005
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ */
+#ifndef SCSI_TRANSPORT_ISCSI_H
+#define SCSI_TRANSPORT_ISCSI_H
+
+#include <linux/device.h>
+#include <iscsi_if.h>
+
+struct scsi_transport_template;
+struct iscsi_transport;
+struct Scsi_Host;
+struct mempool_zone;
+struct iscsi_cls_conn;
+struct iscsi_conn;
+struct iscsi_cmd_task;
+struct iscsi_mgmt_task;
+
+/**
+ * struct iscsi_transport - iSCSI Transport template
+ *
+ * @name:		transport name
+ * @caps:		iSCSI Data-Path capabilities
+ * @create_session:	create new iSCSI session object
+ * @destroy_session:	destroy existing iSCSI session object
+ * @create_conn:	create new iSCSI connection
+ * @bind_conn:		associate this connection with existing iSCSI session
+ *			and specified transport descriptor
+ * @destroy_conn:	destroy inactive iSCSI connection
+ * @set_param:		set iSCSI Data-Path operational parameter
+ * @start_conn:		set connection to be operational
+ * @stop_conn:		suspend/recover/terminate connection
+ * @send_pdu:		send iSCSI PDU, Login, Logout, NOP-Out, Reject, Text.
+ * @session_recovery_timedout: notify LLD a block during recovery timed out
+ * @suspend_conn_recv:	susepend the recv side of the connection
+ * @termincate_conn:	destroy socket connection. Called with mutex lock.
+ * @init_cmd_task:	Initialize a iscsi_cmd_task and any internal structs.
+ *			Called from queuecommand with session lock held.
+ * @init_mgmt_task:	Initialize a iscsi_mgmt_task and any internal structs.
+ *			Called from iscsi_conn_send_generic with xmitmutex.
+ * @xmit_cmd_task:	requests LLD to transfer cmd task
+ * @xmit_mgmt_task:	requests LLD to transfer mgmt task
+ * @cleanup_cmd_task:	requests LLD to fail cmd task. Called with xmitmutex
+ *			and session->lock after the connection has been
+ *			suspended and terminated during recovery. If called
+ *			from abort task then connection is not suspended
+ *			or terminated but sk_callback_lock is held
+ *
+ * Template API provided by iSCSI Transport
+ */
+struct iscsi_transport {
+	struct module *owner;
+	char *name;
+	unsigned int caps;
+	/* LLD sets this to indicate what values it can export to sysfs */
+	unsigned int param_mask;
+	struct scsi_host_template *host_template;
+	/* LLD connection data size */
+	int conndata_size;
+	/* LLD session data size */
+	int sessiondata_size;
+	int max_lun;
+	unsigned int max_conn;
+	unsigned int max_cmd_len;
+	struct iscsi_cls_session *(*create_session) (struct iscsi_transport *it,
+		struct scsi_transport_template *t, uint32_t sn, uint32_t *hn);
+	void (*destroy_session) (struct iscsi_cls_session *session);
+	struct iscsi_cls_conn *(*create_conn) (struct iscsi_cls_session *sess,
+				uint32_t cid);
+	int (*bind_conn) (struct iscsi_cls_session *session,
+			  struct iscsi_cls_conn *cls_conn,
+			  uint64_t transport_eph, int is_leading);
+	int (*start_conn) (struct iscsi_cls_conn *conn);
+	void (*stop_conn) (struct iscsi_cls_conn *conn, int flag);
+	void (*destroy_conn) (struct iscsi_cls_conn *conn);
+	int (*set_param) (struct iscsi_cls_conn *conn, enum iscsi_param param,
+			  uint32_t value);
+	int (*get_conn_param) (struct iscsi_cls_conn *conn,
+			       enum iscsi_param param, uint32_t *value);
+	int (*get_session_param) (struct iscsi_cls_session *session,
+				  enum iscsi_param param, uint32_t *value);
+	int (*get_conn_str_param) (struct iscsi_cls_conn *conn,
+				   enum iscsi_param param, char *buf);
+	int (*get_session_str_param) (struct iscsi_cls_session *session,
+				      enum iscsi_param param, char *buf);
+	int (*send_pdu) (struct iscsi_cls_conn *conn, struct iscsi_hdr *hdr,
+			 char *data, uint32_t data_size);
+	void (*get_stats) (struct iscsi_cls_conn *conn,
+			   struct iscsi_stats *stats);
+	void (*suspend_conn_recv) (struct iscsi_conn *conn);
+	void (*terminate_conn) (struct iscsi_conn *conn);
+	void (*init_cmd_task) (struct iscsi_cmd_task *ctask);
+	void (*init_mgmt_task) (struct iscsi_conn *conn,
+				struct iscsi_mgmt_task *mtask,
+				char *data, uint32_t data_size);
+	int (*xmit_cmd_task) (struct iscsi_conn *conn,
+			      struct iscsi_cmd_task *ctask);
+	void (*cleanup_cmd_task) (struct iscsi_conn *conn,
+				  struct iscsi_cmd_task *ctask);
+	int (*xmit_mgmt_task) (struct iscsi_conn *conn,
+			       struct iscsi_mgmt_task *mtask); 
+	void (*session_recovery_timedout) (struct iscsi_cls_session *session);
+	int (*ep_connect) (struct sockaddr *dst_addr, int non_blocking,
+			   uint64_t *ep_handle);
+	int (*ep_poll) (uint64_t ep_handle, int timeout_ms);
+	void (*ep_disconnect) (uint64_t ep_handle);
+};
+
+/*
+ * transport registration upcalls
+ */
+extern struct scsi_transport_template *iscsi_register_transport(struct iscsi_transport *tt);
+extern int iscsi_unregister_transport(struct iscsi_transport *tt);
+
+/*
+ * control plane upcalls
+ */
+extern void iscsi_conn_error(struct iscsi_cls_conn *conn, enum iscsi_err error);
+extern int iscsi_recv_pdu(struct iscsi_cls_conn *conn, struct iscsi_hdr *hdr,
+			  char *data, uint32_t data_size);
+
+
+/* Connection's states */
+#define ISCSI_CONN_INITIAL_STAGE	0
+#define ISCSI_CONN_STARTED		1
+#define ISCSI_CONN_STOPPED		2
+#define ISCSI_CONN_CLEANUP_WAIT		3
+
+struct iscsi_cls_conn {
+	struct list_head conn_list;	/* item in connlist */
+	void *dd_data;			/* LLD private data */
+	struct iscsi_transport *transport;
+	uint32_t cid;			/* connection id */
+
+	/* portal/group values we got during discovery */
+	char *persistent_address;
+	int persistent_port;
+	/* portal/group values we are currently using */
+	char *address;
+	int port;
+
+	int active;			/* must be accessed with the connlock */
+	struct device dev;		/* sysfs transport/container device */
+	struct mempool_zone *z_error;
+	struct mempool_zone *z_pdu;
+	struct list_head freequeue;
+};
+
+#define iscsi_dev_to_conn(_dev) \
+	container_of(_dev, struct iscsi_cls_conn, dev)
+
+/* Session's states */
+#define ISCSI_STATE_FREE		1
+#define ISCSI_STATE_LOGGED_IN		2
+#define ISCSI_STATE_FAILED		3
+#define ISCSI_STATE_TERMINATE		4
+
+struct iscsi_cls_session {
+	struct list_head sess_list;		/* item in session_list */
+	struct list_head host_list;
+	struct iscsi_transport *transport;
+
+	/* iSCSI values used as unique id by userspace. */
+	char *targetname;
+	int tpgt;
+
+	/* recovery fields */
+	int recovery_tmo;
+	struct work_struct recovery_work;
+
+	int target_id;
+	int channel;
+
+	int sid;				/* session id */
+	void *dd_data;				/* LLD private data */
+	struct device dev;	/* sysfs transport/container device */
+};
+
+#define iscsi_dev_to_session(_dev) \
+	container_of(_dev, struct iscsi_cls_session, dev)
+
+#define iscsi_session_to_shost(_session) \
+	dev_to_shost(_session->dev.parent)
+
+struct iscsi_host {
+	int next_target_id;
+	struct list_head sessions;
+	struct mutex mutex;
+};
+
+/*
+ * session and connection functions that can be used by HW iSCSI LLDs
+ */
+extern struct iscsi_cls_session *iscsi_create_session(struct Scsi_Host *shost,
+				struct iscsi_transport *t, int channel);
+extern int iscsi_destroy_session(struct iscsi_cls_session *session);
+extern struct iscsi_cls_conn *iscsi_create_conn(struct iscsi_cls_session *sess,
+					    uint32_t cid);
+extern int iscsi_destroy_conn(struct iscsi_cls_conn *conn);
+extern void iscsi_unblock_session(struct iscsi_cls_session *session);
+extern void iscsi_block_session(struct iscsi_cls_session *session);
+
+#endif



From tomo at berlios.de  Sat Apr 29 16:17:40 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 16:17:40 +0200
Subject: [Stgt-svn] r433 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291417.k3TEHeMm009507@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 16:17:38 +0200 (Sat, 29 Apr 2006)
New Revision: 433

Modified:
   branches/use-scsi-ml/istgt/kernel/Makefile
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
Log:
Makeshift to use iscsi_tcp like library.


Modified: branches/use-scsi-ml/istgt/kernel/Makefile
===================================================================
--- branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 14:03:22 UTC (rev 432)
+++ branches/use-scsi-ml/istgt/kernel/Makefile	2006-04-29 14:17:38 UTC (rev 433)
@@ -10,10 +10,10 @@
 EXTRA_CFLAGS += -I$(obj) -I$(obj)/../include
 
 ifneq ($(KERNELRELEASE),)
-obj-m		+= iscsi_tcp_tgt.o
-obj-m		+= scsi_transport_iscsi.o
-obj-m		+= libiscsi.o
-obj-m		+= iscsi_tcp.o
+obj-m			+= iscsi_tcp_tgt.o
+iscsi_tcp_tgt-objs	:= iscsi_tcp.o
+obj-m			+= scsi_transport_iscsi.o
+obj-m			+= libiscsi.o
 else
 
 ifeq ($(KERNELSRC),)

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 14:03:22 UTC (rev 432)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 14:17:38 UTC (rev 433)
@@ -2588,8 +2588,7 @@
 	.session_recovery_timedout = iscsi_session_recovery_timedout,
 };
 
-static int __init
-iscsi_tcp_init(void)
+int iscsi_tcp_init(void)
 {
 	if (iscsi_max_lun < 1) {
 		printk(KERN_ERR "iscsi_tcp: Invalid max_lun value of %u\n", iscsi_max_lun);
@@ -2609,12 +2608,8 @@
 	return 0;
 }
 
-static void __exit
-iscsi_tcp_exit(void)
+void iscsi_tcp_exit(void)
 {
 	iscsi_unregister_transport(&iscsi_tcp_transport);
 	kmem_cache_destroy(taskcache);
 }
-
-module_init(iscsi_tcp_init);
-module_exit(iscsi_tcp_exit);



From tomo at berlios.de  Sat Apr 29 17:25:55 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 17:25:55 +0200
Subject: [Stgt-svn] r434 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291525.k3TFPtq4023454@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 17:25:55 +0200 (Sat, 29 Apr 2006)
New Revision: 434

Added:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
Kill duplicated code in iscsi_tcp_tgt.c by using iscsi_tcp like library.


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 14:17:38 UTC (rev 433)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 15:25:55 UTC (rev 434)
@@ -124,7 +124,7 @@
 	buf->sg.length += sizeof(uint32_t);
 }
 
-static inline int
+inline int
 iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn)
 {
 	struct sk_buff *skb = tcp_conn->in.skb;
@@ -640,7 +640,7 @@
  *	The function calls skb_copy_bits() and updates per-connection
  *	byte counters.
  **/
-static inline int
+inline int
 iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn)
 {
 	void *buf = tcp_conn->data;
@@ -689,7 +689,7 @@
 	crypto_digest_update(tcp_conn->data_rx_tfm, &tmp, 1);
 }
 
-static int iscsi_scsi_data_in(struct iscsi_conn *conn)
+int iscsi_scsi_data_in(struct iscsi_conn *conn)
 {
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
 	struct iscsi_cmd_task *ctask = tcp_conn->in.ctask;
@@ -1894,7 +1894,7 @@
 	return rc;
 }
 
-static struct iscsi_cls_conn *
+struct iscsi_cls_conn *
 iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
 {
 	struct iscsi_conn *conn;
@@ -1940,7 +1940,7 @@
 	return NULL;
 }
 
-static void
+void
 iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn)
 {
 	struct iscsi_conn *conn = cls_conn->dd_data;
@@ -1973,7 +1973,7 @@
 	kfree(tcp_conn);
 }
 
-static int
+int
 iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
 		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
 		    int is_leading)
@@ -2052,7 +2052,7 @@
 	write_unlock_bh(&sk->sk_callback_lock);
 }
 
-static void
+void
 iscsi_tcp_terminate_conn(struct iscsi_conn *conn)
 {
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
@@ -2457,7 +2457,7 @@
 	stats->custom[2].value = conn->eh_abort_cnt;
 }
 
-static struct iscsi_cls_session *
+struct iscsi_cls_session *
 iscsi_tcp_session_create(struct iscsi_transport *iscsit,
 			 struct scsi_transport_template *scsit,
 			 uint32_t initial_cmdsn, uint32_t *hostno)
@@ -2500,7 +2500,7 @@
 	return NULL;
 }
 
-static void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
+void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
 {
 	struct iscsi_session *session = class_to_transport_session(cls_session);
 	struct iscsi_data_task *dtask, *n;

Added: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 14:17:38 UTC (rev 433)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 15:25:55 UTC (rev 434)
@@ -0,0 +1,22 @@
+/*
+ * makeshift to use iscsi_tcp.c like library
+ */
+
+extern struct iscsi_cls_conn *
+iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx);
+extern static void
+iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn);
+extern int iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
+			       struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
+			       int is_leading);
+extern void iscsi_tcp_terminate_conn(struct iscsi_conn *conn);
+
+extern struct iscsi_cls_session *
+iscsi_tcp_session_create(struct iscsi_transport *iscsit,
+			 struct scsi_transport_template *scsit,
+			 uint32_t initial_cmdsn, uint32_t *hostno);
+extern void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session);
+
+extern inline int iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn);
+extern int iscsi_scsi_data_in(struct iscsi_conn *conn);
+extern inline int iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn);

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 14:17:38 UTC (rev 433)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 15:25:55 UTC (rev 434)
@@ -42,6 +42,7 @@
 #include <scsi/scsi_tgt.h>
 #include <scsi/scsi_tcq.h>
 #include "scsi_transport_iscsi.h"
+#include "iscsi_tcp_priv.h"
 
 /* tmp - will replace with SCSI logging stuff */
 #define eprintk(fmt, args...)					\
@@ -412,158 +413,6 @@
 	return rc;
 }
 
-static inline int
-iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn)
-{
-	void *buf = tcp_conn->data;
-	int buf_size = tcp_conn->in.datalen;
-	int buf_left = buf_size - tcp_conn->data_copied;
-	int size = min(tcp_conn->in.copy, buf_left);
-	int rc;
-
-	dprintk("tcp_copy %d bytes at offset %d copied %d\n",
-		size, tcp_conn->in.offset, tcp_conn->data_copied);
-	BUG_ON(size <= 0);
-
-	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-			   (char*)buf + tcp_conn->data_copied, size);
-	BUG_ON(rc);
-
-	tcp_conn->in.offset += size;
-	tcp_conn->in.copy -= size;
-	tcp_conn->in.copied += size;
-	tcp_conn->data_copied += size;
-
-	if (buf_size != tcp_conn->data_copied)
-		return -EAGAIN;
-
-	return 0;
-}
-
-static inline void
-partial_sg_digest_update(struct iscsi_tcp_conn *tcp_conn,
-			 struct scatterlist *sg, int offset, int length)
-{
-	struct scatterlist temp;
-
-	memcpy(&temp, sg, sizeof(struct scatterlist));
-	temp.offset = offset;
-	temp.length = length;
-	crypto_digest_update(tcp_conn->data_rx_tfm, &temp, 1);
-}
-
-static inline int
-iscsi_ctask_copy(struct iscsi_tcp_conn *tcp_conn, struct iscsi_cmd_task *ctask,
-		 void *buf, int buf_size, int offset)
-{
-	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-	int buf_left = buf_size - (tcp_conn->data_copied + offset);
-	int size = min(tcp_conn->in.copy, buf_left);
-	int rc;
-
-	size = min(size, ctask->data_count);
-
-	dprintk("ctask_copy %d bytes at offset %d copied %d\n",
-		size, tcp_conn->in.offset, tcp_conn->in.copied);
-
-	BUG_ON(size <= 0);
-	BUG_ON(tcp_ctask->sent + size > ctask->total_length);
-
-	rc = skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-			   (char*)buf + (offset + tcp_conn->data_copied), size);
-	/* must fit into skb->len */
-	BUG_ON(rc);
-
-	tcp_conn->in.offset += size;
-	tcp_conn->in.copy -= size;
-	tcp_conn->in.copied += size;
-	tcp_conn->data_copied += size;
-	tcp_ctask->sent += size;
-	ctask->data_count -= size;
-
-	BUG_ON(tcp_conn->in.copy < 0);
-	BUG_ON(ctask->data_count < 0);
-
-	if (buf_size != (tcp_conn->data_copied + offset)) {
-		if (!ctask->data_count) {
-			BUG_ON(buf_size - tcp_conn->data_copied < 0);
-			/* done with this PDU */
-			return buf_size - tcp_conn->data_copied;
-		}
-		return -EAGAIN;
-	}
-
-	/* done with this buffer or with both - PDU and buffer */
-	tcp_conn->data_copied = 0;
-	return 0;
-}
-
-static int iscsi_scsi_data_in(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct iscsi_cmd_task *ctask = tcp_conn->in.ctask;
-	struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-	struct scsi_cmnd *sc = ctask->sc;
-	struct scatterlist *sg;
-	int i, offset, rc = 0;
-
-	BUG_ON((void*)ctask != sc->SCp.ptr);
-
-	offset = tcp_ctask->data_offset;
-	sg = sc->request_buffer;
-
-	if (tcp_ctask->data_offset)
-		for (i = 0; i < tcp_ctask->sg_count; i++)
-			offset -= sg[i].length;
-	/* we've passed through partial sg*/
-	if (offset < 0)
-		offset = 0;
-
-	for (i = tcp_ctask->sg_count; i < sc->use_sg; i++) {
-		char *dest;
-
-		dest = kmap_atomic(sg[i].page, KM_SOFTIRQ0);
-		rc = iscsi_ctask_copy(tcp_conn, ctask, dest + sg[i].offset,
-				      sg[i].length, offset);
-		kunmap_atomic(dest, KM_SOFTIRQ0);
-		if (rc == -EAGAIN)
-			/* continue with the next SKB/PDU */
-			return rc;
-		if (!rc) {
-			if (conn->datadgst_en) {
-				if (!offset)
-					crypto_digest_update(
-							tcp_conn->data_rx_tfm,
-							&sg[i], 1);
-				else
-					partial_sg_digest_update(tcp_conn,
-							&sg[i],
-							sg[i].offset + offset,
-							sg[i].length - offset);
-			}
-			offset = 0;
-			tcp_ctask->sg_count++;
-		}
-
-		if (!ctask->data_count) {
-			if (rc && conn->datadgst_en)
-				/*
-				 * data-in is complete, but buffer not...
-				 */
-				partial_sg_digest_update(tcp_conn, &sg[i],
-						sg[i].offset, sg[i].length-rc);
-			rc = 0;
-			break;
-		}
-
-		if (!tcp_conn->in.copy)
-			return -EAGAIN;
-	}
-	BUG_ON(ctask->data_count);
-
-	return rc;
-}
-
 static int
 iscsi_data_recv(struct iscsi_conn *conn)
 {
@@ -602,72 +451,6 @@
 	return rc;
 }
 
-static inline int
-iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn)
-{
-	struct sk_buff *skb = tcp_conn->in.skb;
-
-	tcp_conn->in.zero_copy_hdr = 0;
-
-	if (tcp_conn->in.copy >= tcp_conn->hdr_size &&
-	    tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER) {
-		/*
-		 * Zero-copy PDU Header: using connection context
-		 * to store header pointer.
-		 */
-		if (skb_shinfo(skb)->frag_list == NULL &&
-		    !skb_shinfo(skb)->nr_frags) {
-			tcp_conn->in.hdr = (struct iscsi_hdr *)
-				((char*)skb->data + tcp_conn->in.offset);
-			tcp_conn->in.zero_copy_hdr = 1;
-		} else {
-			/* ignoring return code since we checked
-			 * in.copy before */
-			skb_copy_bits(skb, tcp_conn->in.offset,
-				&tcp_conn->hdr, tcp_conn->hdr_size);
-			tcp_conn->in.hdr = &tcp_conn->hdr;
-		}
-		tcp_conn->in.offset += tcp_conn->hdr_size;
-		tcp_conn->in.copy -= tcp_conn->hdr_size;
-	} else {
-		int hdr_remains;
-		int copylen;
-
-		/*
-		 * PDU header scattered across SKB's,
-		 * copying it... This'll happen quite rarely.
-		 */
-
-		if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
-			tcp_conn->in.hdr_offset = 0;
-
-		hdr_remains = tcp_conn->hdr_size - tcp_conn->in.hdr_offset;
-		BUG_ON(hdr_remains <= 0);
-
-		copylen = min(tcp_conn->in.copy, hdr_remains);
-		skb_copy_bits(skb, tcp_conn->in.offset,
-			(char*)&tcp_conn->hdr + tcp_conn->in.hdr_offset,
-			copylen);
-
-		dprintk("PDU gather offset %d bytes %d in.offset %d "
-			"in.copy %d\n", tcp_conn->in.hdr_offset, copylen,
-			tcp_conn->in.offset, tcp_conn->in.copy);
-
-		tcp_conn->in.offset += copylen;
-		tcp_conn->in.copy -= copylen;
-		if (copylen < hdr_remains)  {
-			tcp_conn->in_progress = IN_PROGRESS_HEADER_GATHER;
-			tcp_conn->in.hdr_offset += copylen;
-		        return -EAGAIN;
-		}
-		tcp_conn->in.hdr = &tcp_conn->hdr;
-		tcp_conn->discontiguous_hdr_cnt++;
-	        tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	return 0;
-}
-
 static int
 iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
 		unsigned int offset, size_t len)
@@ -824,7 +607,7 @@
 }
 
 static void
-iscsi_tcp_data_ready(struct sock *sk, int flag)
+istgt_tcp_data_ready(struct sock *sk, int flag)
 {
 	struct iscsi_conn *conn = sk->sk_user_data;
 	read_descriptor_t rd_desc;
@@ -839,192 +622,34 @@
 	read_unlock(&sk->sk_callback_lock);
 }
 
-static void
-iscsi_tcp_state_change(struct sock *sk)
-{
-	struct iscsi_tcp_conn *tcp_conn;
-	struct iscsi_conn *conn;
-	struct iscsi_session *session;
-	void (*old_state_change)(struct sock *);
-
-	read_lock(&sk->sk_callback_lock);
-
-	conn = (struct iscsi_conn*)sk->sk_user_data;
-	session = conn->session;
-
-	if ((sk->sk_state == TCP_CLOSE_WAIT ||
-	     sk->sk_state == TCP_CLOSE) &&
-	    !atomic_read(&sk->sk_rmem_alloc)) {
-		dprintk("iscsi_tcp_state_change: TCP_CLOSE|TCP_CLOSE_WAIT\n");
-		iscsi_conn_failure(conn, ISCSI_ERR_CONN_FAILED);
-	}
-
-	tcp_conn = conn->dd_data;
-	old_state_change = tcp_conn->old_state_change;
-
-	read_unlock(&sk->sk_callback_lock);
-
-	old_state_change(sk);
-}
-
-static void
-iscsi_write_space(struct sock *sk)
-{
-	struct iscsi_conn *conn = (struct iscsi_conn*)sk->sk_user_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-
-	tcp_conn->old_write_space(sk);
-	clear_bit(ISCSI_SUSPEND_BIT, &conn->suspend_tx);
-	scsi_queue_work(conn->session->host, &conn->xmitwork);
-}
-
-static void
-iscsi_conn_set_callbacks(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk = tcp_conn->sock->sk;
-
-	/* assign new callbacks */
-	write_lock_bh(&sk->sk_callback_lock);
-	sk->sk_user_data = conn;
-	tcp_conn->old_data_ready = sk->sk_data_ready;
-	tcp_conn->old_state_change = sk->sk_state_change;
-	tcp_conn->old_write_space = sk->sk_write_space;
-	sk->sk_data_ready = iscsi_tcp_data_ready;
-	sk->sk_state_change = iscsi_tcp_state_change;
-	sk->sk_write_space = iscsi_write_space;
-	write_unlock_bh(&sk->sk_callback_lock);
-}
-
-static void
-iscsi_conn_restore_callbacks(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk = tcp_conn->sock->sk;
-
-	/* restore socket callbacks, see also: iscsi_conn_set_callbacks() */
-	write_lock_bh(&sk->sk_callback_lock);
-	sk->sk_user_data    = NULL;
-	sk->sk_data_ready   = tcp_conn->old_data_ready;
-	sk->sk_state_change = tcp_conn->old_state_change;
-	sk->sk_write_space  = tcp_conn->old_write_space;
-	sk->sk_no_check	 = 0;
-	write_unlock_bh(&sk->sk_callback_lock);
-}
-
-static void
-iscsi_tcp_terminate_conn(struct iscsi_conn *conn)
-{
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-
-	if (!tcp_conn->sock)
-		return;
-
-	sock_hold(tcp_conn->sock->sk);
-	iscsi_conn_restore_callbacks(conn);
-	sock_put(tcp_conn->sock->sk);
-
-	sock_release(tcp_conn->sock);
-	tcp_conn->sock = NULL;
-	conn->recv_lock = NULL;
-}
-
 static int
-iscsi_r2tpool_alloc(struct iscsi_session *session)
+istgt_tcp_conn_bind(struct iscsi_cls_session *cls_session,
+		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
+		    int is_leading)
 {
-	int i;
-	int cmd_i;
+	struct socket *sock;
+	int err;
 
-	/*
-	 * initialize per-task: R2T pool and xmit queue
-	 */
-	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
-	        struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		/*
-		 * pre-allocated x4 as much r2ts to handle race when
-		 * target acks DataOut faster than we data_xmit() queues
-		 * could replenish r2tqueue.
-		 */
-
-		/* R2T pool */
-		if (iscsi_pool_init(&tcp_ctask->r2tpool, session->max_r2t * 4,
-				    (void***)&tcp_ctask->r2ts,
-				    sizeof(struct iscsi_r2t_info))) {
-			goto r2t_alloc_fail;
-		}
-
-		/* R2T xmit queue */
-		tcp_ctask->r2tqueue = kfifo_alloc(
-		      session->max_r2t * 4 * sizeof(void*), GFP_KERNEL, NULL);
-		if (tcp_ctask->r2tqueue == ERR_PTR(-ENOMEM)) {
-			iscsi_pool_free(&tcp_ctask->r2tpool,
-					(void**)tcp_ctask->r2ts);
-			goto r2t_alloc_fail;
-		}
-
-		/*
-		 * number of
-		 * Data-Out PDU's within R2T-sequence can be quite big;
-		 * using mempool
-		 */
-		tcp_ctask->datapool = mempool_create(ISCSI_DTASK_DEFAULT_MAX,
-						     mempool_alloc_slab,
-						     mempool_free_slab,
-						     taskcache);
-		if (tcp_ctask->datapool == NULL) {
-			kfifo_free(tcp_ctask->r2tqueue);
-			iscsi_pool_free(&tcp_ctask->r2tpool,
-					(void**)tcp_ctask->r2ts);
-			goto r2t_alloc_fail;
-		}
-		INIT_LIST_HEAD(&tcp_ctask->dataqueue);
+	sock = sockfd_lookup((int)transport_eph, &err);
+	if (!sock) {
+		printk(KERN_ERR "iscsi_tcp: sockfd_lookup failed %d\n", err);
+		return -EEXIST;
 	}
 
-	return 0;
+	err = iscsi_tcp_conn_bind(cls_session, cls_conn, transport_eph, is_leading);
+	if (err)
+		goto out;
 
-r2t_alloc_fail:
-	for (i = 0; i < cmd_i; i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
+	write_lock_bh(&sock->sk->sk_callback_lock);
 
-		mempool_destroy(tcp_ctask->datapool);
-		kfifo_free(tcp_ctask->r2tqueue);
-		iscsi_pool_free(&tcp_ctask->r2tpool,
-				(void**)tcp_ctask->r2ts);
-	}
-	return -ENOMEM;
-}
+	sk->sk_data_ready = istgt_tcp_data_ready;
 
-static void
-iscsi_r2tpool_free(struct iscsi_session *session)
-{
-	int i;
-
-	for (i = 0; i < session->cmds_max; i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		mempool_destroy(tcp_ctask->datapool);
-		kfifo_free(tcp_ctask->r2tqueue);
-		iscsi_pool_free(&tcp_ctask->r2tpool,
-				(void**)tcp_ctask->r2ts);
-	}
+	write_unlock_bh(&sock->sk->sk_callback_lock);
+out:
+	sock_release(sock);
+	return err;
 }
 
-void istgt_session_init(struct iscsi_cls_session *cls_session)
-{
-	struct istgt_session *istgt_session =
-		(struct istgt_session *) cls_session->dd_data;
-
-	INIT_LIST_HEAD(&istgt_session->recvlist);
-	INIT_LIST_HEAD(&istgt_session->cmd_hash);
-	spin_lock_init(&istgt_session->slock);
-
-	INIT_WORK(&istgt_session->recvwork, istgt_recvworker, cls_session);
-}
-
 static struct iscsi_cls_session *
 istgt_tcp_session_create(struct iscsi_transport *iscsit,
 			 struct scsi_transport_template *scsit,
@@ -1033,45 +658,32 @@
 	struct Scsi_Host *shost;
 	struct iscsi_cls_session *cls_session;
 	struct iscsi_session *session;
-	uint32_t hn;
-	int err, i;
-	int cmd_task_size;
+	struct istgt_session *istgt_session;
+	int i, err;
 
-	cmd_task_size = sizeof(struct iscsi_tcp_cmd_task) +
-		sizeof(struct istgt_task);
-
-	cls_session = iscsi_session_setup(iscsit, scsit,
-					  cmd_task_size,
-					  sizeof(struct iscsi_tcp_mgmt_task),
-					  initial_cmdsn, &hn);
+	cls_session = iscsi_tcp_session_create(iscsit, scsit, initial_cmdsn,
+					       hostno);
 	if (!cls_session)
 		return NULL;
 	shost = iscsi_session_to_shost(cls_session);
 	err = scsi_tgt_alloc_queue(shost);
 	if (err)
 		goto session_free;
-	*hostno = hn;
 
 	session = class_to_transport_session(cls_session);
 	for (i = 0; i < initial_cmdsn; i++) {
 		struct iscsi_cmd_task *ctask = session->cmds[i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		ctask->hdr = &tcp_ctask->hdr;
-
 		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->hash);
 		INIT_LIST_HEAD(&ctask_to_ttask(ctask)->tlist);
 	}
 
-	for (i = 0; i < session->mgmtpool_max; i++) {
-		struct iscsi_mgmt_task *mtask = session->mgmt_cmds[i];
-		struct iscsi_tcp_mgmt_task *tcp_mtask = mtask->dd_data;
+	istgt_session =	(struct istgt_session *) cls_session->dd_data;
 
-		mtask->hdr = &tcp_mtask->hdr;
-	}
+	INIT_LIST_HEAD(&istgt_session->recvlist);
+	INIT_LIST_HEAD(&istgt_session->cmd_hash);
+	spin_lock_init(&istgt_session->slock);
 
-	if (iscsi_r2tpool_alloc(class_to_transport_session(cls_session)))
-		goto session_free;
+	INIT_WORK(&istgt_session->recvwork, istgt_recvworker, cls_session);
 
 	return cls_session;
 session_free:
@@ -1079,156 +691,6 @@
 	return NULL;
 }
 
-static void iscsi_tcp_session_destroy(struct iscsi_cls_session *cls_session)
-{
-	struct iscsi_session *session = class_to_transport_session(cls_session);
-	struct iscsi_data_task *dtask, *n;
-	int cmd_i;
-
-	for (cmd_i = 0; cmd_i < session->cmds_max; cmd_i++) {
-		struct iscsi_cmd_task *ctask = session->cmds[cmd_i];
-		struct iscsi_tcp_cmd_task *tcp_ctask = ctask->dd_data;
-
-		list_for_each_entry_safe(dtask, n, &tcp_ctask->dataqueue,
-					 item) {
-			list_del(&dtask->item);
-			mempool_free(dtask, tcp_ctask->datapool);
-		}
-	}
-
-	iscsi_r2tpool_free(class_to_transport_session(cls_session));
-	iscsi_session_teardown(cls_session);
-}
-
-static struct iscsi_cls_conn *
-iscsi_tcp_conn_create(struct iscsi_cls_session *cls_session, uint32_t conn_idx)
-{
-	struct iscsi_conn *conn;
-	struct iscsi_cls_conn *cls_conn;
-	struct iscsi_tcp_conn *tcp_conn;
-
-	cls_conn = iscsi_conn_setup(cls_session, conn_idx);
-	if (!cls_conn)
-		return NULL;
-	conn = cls_conn->dd_data;
-	/*
-	 * due to strange issues with iser these are not set
-	 * in iscsi_conn_setup
-	 */
-	conn->max_recv_dlength = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
-
-	tcp_conn = kzalloc(sizeof(*tcp_conn), GFP_KERNEL);
-	if (!tcp_conn)
-		goto tcp_conn_alloc_fail;
-
-	conn->dd_data = tcp_conn;
-	tcp_conn->iscsi_conn = conn;
-	tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	/* initial operational parameters */
-	tcp_conn->hdr_size = sizeof(struct iscsi_hdr);
-	tcp_conn->data_size = DEFAULT_MAX_RECV_DATA_SEGMENT_LENGTH;
-
-	/* allocate initial PDU receive place holder */
-	if (tcp_conn->data_size <= PAGE_SIZE)
-		tcp_conn->data = kmalloc(tcp_conn->data_size, GFP_KERNEL);
-	else
-		tcp_conn->data = (void*)__get_free_pages(GFP_KERNEL,
-					get_order(tcp_conn->data_size));
-	if (!tcp_conn->data)
-		goto max_recv_dlenght_alloc_fail;
-
-	return cls_conn;
-
-max_recv_dlenght_alloc_fail:
-	kfree(tcp_conn);
-tcp_conn_alloc_fail:
-	iscsi_conn_teardown(cls_conn);
-	return NULL;
-}
-
-static void
-iscsi_tcp_conn_destroy(struct iscsi_cls_conn *cls_conn)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	int digest = 0;
-
-	if (conn->hdrdgst_en || conn->datadgst_en)
-		digest = 1;
-
-	iscsi_conn_teardown(cls_conn);
-
-	/* now free tcp_conn */
-	if (digest) {
-		if (tcp_conn->tx_tfm)
-			crypto_free_tfm(tcp_conn->tx_tfm);
-		if (tcp_conn->rx_tfm)
-			crypto_free_tfm(tcp_conn->rx_tfm);
-		if (tcp_conn->data_tx_tfm)
-			crypto_free_tfm(tcp_conn->data_tx_tfm);
-		if (tcp_conn->data_rx_tfm)
-			crypto_free_tfm(tcp_conn->data_rx_tfm);
-	}
-
-	/* free conn->data, size = MaxRecvDataSegmentLength */
-	if (tcp_conn->data_size <= PAGE_SIZE)
-		kfree(tcp_conn->data);
-	else
-		free_pages((unsigned long)tcp_conn->data,
-			   get_order(tcp_conn->data_size));
-	kfree(tcp_conn);
-}
-
-static int
-iscsi_tcp_conn_bind(struct iscsi_cls_session *cls_session,
-		    struct iscsi_cls_conn *cls_conn, uint64_t transport_eph,
-		    int is_leading)
-{
-	struct iscsi_conn *conn = cls_conn->dd_data;
-	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct sock *sk;
-	struct socket *sock;
-	int err;
-
-	/* lookup for existing socket */
-	sock = sockfd_lookup((int)transport_eph, &err);
-	if (!sock) {
-		printk(KERN_ERR "iscsi_tcp: sockfd_lookup failed %d\n", err);
-		return -EEXIST;
-	}
-
-	err = iscsi_conn_bind(cls_session, cls_conn, is_leading);
-	if (err)
-		return err;
-
-	if (conn->stop_stage != STOP_CONN_SUSPEND) {
-		/* bind iSCSI connection and socket */
-		tcp_conn->sock = sock;
-
-		/* setup Socket parameters */
-		sk = sock->sk;
-		sk->sk_reuse = 1;
-		sk->sk_sndtimeo = 15 * HZ; /* FIXME: make it configurable */
-		sk->sk_allocation = GFP_ATOMIC;
-
-		/* FIXME: disable Nagle's algorithm */
-
-		/*
-		 * Intercept TCP callbacks for sendfile like receive
-		 * processing.
-		 */
-		conn->recv_lock = &sk->sk_callback_lock;
-		iscsi_conn_set_callbacks(conn);
-		tcp_conn->sendpage = tcp_conn->sock->ops->sendpage;
-		/*
-		 * set receive state machine into initial state
-		 */
-		tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	return 0;
-}
-
 static int istgt_transfer_response(struct scsi_cmnd *scmd,
 				   void (*done)(struct scsi_cmnd *))
 {
@@ -1300,7 +762,7 @@
 	.destroy_session	= iscsi_tcp_session_destroy,
 	.create_conn		= iscsi_tcp_conn_create,
 	.destroy_conn		= iscsi_tcp_conn_destroy,
-	.bind_conn		= iscsi_tcp_conn_bind,
+	.bind_conn		= istgt_tcp_conn_bind,
 	.start_conn		= iscsi_conn_start,
 	.terminate_conn		= iscsi_tcp_terminate_conn,
 	.xmit_cmd_task		= istgt_tcp_ctask_xmit,



From tomo at berlios.de  Sat Apr 29 17:31:54 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 17:31:54 +0200
Subject: [Stgt-svn] r435 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291531.k3TFVsKM023828@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 17:31:54 +0200 (Sat, 29 Apr 2006)
New Revision: 435

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
iscsi_tcp library again.

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 15:25:55 UTC (rev 434)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 15:31:54 UTC (rev 435)
@@ -20,3 +20,6 @@
 extern inline int iscsi_hdr_extract(struct iscsi_tcp_conn *tcp_conn);
 extern int iscsi_scsi_data_in(struct iscsi_conn *conn);
 extern inline int iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn);
+
+extern int iscsi_tcp_init(void);
+extern void iscsi_tcp_exit(void);

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 15:25:55 UTC (rev 434)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 15:31:54 UTC (rev 435)
@@ -65,8 +65,6 @@
 	struct list_head tlist;
 };
 
-static kmem_cache_t *taskcache;
-
 static inline struct istgt_task *ctask_to_ttask(struct iscsi_cmd_task *ctask)
 {
 	return (struct istgt_task *) ((void *) ctask->dd_data +
@@ -770,26 +768,26 @@
 
 static int __init istgt_tcp_init(void)
 {
+	int err;
 	printk("iSCSI Target over TCP\n");
 
-	taskcache = kmem_cache_create("istgt_taskcache",
-				      sizeof(struct iscsi_data_task), 0,
-				      SLAB_HWCACHE_ALIGN, NULL, NULL);
-	if (!taskcache)
-		return -ENOMEM;
+	err = iscsi_tcp_init();
+	if (err)
+		return err;
 
 	if (!iscsi_register_transport(&istgt_tcp_transport))
-		goto free_taskcache;
+		goto call_iscsi_tcp_exit;
 	return 0;
-free_taskcache:
-	kmem_cache_destroy(taskcache);
+
+call_iscsi_tcp_exit:
+	iscsi_tcp_exit();
 	return -ENOMEM;
 }
 
 static void __exit istgt_tcp_exit(void)
 {
+	iscsi_tcp_exit();
 	iscsi_unregister_transport(&istgt_tcp_transport);
-	kmem_cache_destroy(taskcache);
 }
 
 module_init(istgt_tcp_init);



From tomo at berlios.de  Sat Apr 29 18:03:15 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:03:15 +0200
Subject: [Stgt-svn] r436 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291603.k3TG3FQK026453@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:03:14 +0200 (Sat, 29 Apr 2006)
New Revision: 436

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
Log:
Split iscsi_tcp_hdr_recv().


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 15:31:54 UTC (rev 435)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:03:14 UTC (rev 436)
@@ -435,58 +435,14 @@
 	return 0;
 }
 
-static int
-iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
+static int iscsi_tcp_hdr_recv_post(struct iscsi_conn *conn)
 {
-	int rc = 0, opcode, ahslen;
-	struct iscsi_hdr *hdr;
 	struct iscsi_session *session = conn->session;
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	uint32_t cdgst, rdgst = 0, itt;
+	struct iscsi_hdr *hdr = tcp_conn->in.hdr;
+	int rc, opcode, ahslen = hdr->hlength << 2;
+	uint32_t itt;
 
-	hdr = tcp_conn->in.hdr;
-
-	/* verify PDU length */
-	tcp_conn->in.datalen = ntoh24(hdr->dlength);
-	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
-		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
-		       tcp_conn->in.datalen, conn->max_recv_dlength);
-		return ISCSI_ERR_DATALEN;
-	}
-	tcp_conn->data_copied = 0;
-
-	/* read AHS */
-	ahslen = hdr->hlength << 2;
-	tcp_conn->in.offset += ahslen;
-	tcp_conn->in.copy -= ahslen;
-	if (tcp_conn->in.copy < 0) {
-		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
-		       "%d bytes\n", ahslen);
-		return ISCSI_ERR_AHSLEN;
-	}
-
-	/* calculate read padding */
-	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
-	if (tcp_conn->in.padding) {
-		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
-		debug_scsi("read padding %d bytes\n", tcp_conn->in.padding);
-	}
-
-	if (conn->hdrdgst_en) {
-		struct scatterlist sg;
-
-		sg_init_one(&sg, (u8 *)hdr,
-			    sizeof(struct iscsi_hdr) + ahslen);
-		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
-		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
-				     ahslen);
-		if (cdgst != rdgst) {
-			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
-			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
-			return ISCSI_ERR_HDR_DGST;
-		}
-	}
-
 	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
 	/* verify itt (itt encoding: age+cid+itt) */
 	rc = iscsi_verify_itt(conn, hdr, &itt);
@@ -563,6 +519,69 @@
 	return 0;
 }
 
+int iscsi_tcp_hdr_recv_pre(struct iscsi_conn *conn)
+{
+	int ahslen;
+	struct iscsi_hdr *hdr;
+	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
+	uint32_t cdgst, rdgst = 0;
+
+	hdr = tcp_conn->in.hdr;
+
+	/* verify PDU length */
+	tcp_conn->in.datalen = ntoh24(hdr->dlength);
+	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
+		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
+		       tcp_conn->in.datalen, conn->max_recv_dlength);
+		return ISCSI_ERR_DATALEN;
+	}
+	tcp_conn->data_copied = 0;
+
+	/* read AHS */
+	ahslen = hdr->hlength << 2;
+	tcp_conn->in.offset += ahslen;
+	tcp_conn->in.copy -= ahslen;
+	if (tcp_conn->in.copy < 0) {
+		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
+		       "%d bytes\n", ahslen);
+		return ISCSI_ERR_AHSLEN;
+	}
+
+	/* calculate read padding */
+	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
+	if (tcp_conn->in.padding) {
+		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
+		debug_scsi("read padding %d bytes\n", tcp_conn->in.padding);
+	}
+
+	if (conn->hdrdgst_en) {
+		struct scatterlist sg;
+
+		sg_init_one(&sg, (u8 *)hdr,
+			    sizeof(struct iscsi_hdr) + ahslen);
+		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
+		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
+				     ahslen);
+		if (cdgst != rdgst) {
+			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
+			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
+			return ISCSI_ERR_HDR_DGST;
+		}
+	}
+
+	return 0;
+}
+
+static int iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
+{
+	int rc;
+
+	rc = iscsi_tcp_hdr_recv_pre(conn);
+	if (rc)
+		return rc;
+	return iscsi_tcp_hdr_recv_post(conn);
+}
+
 /**
  * iscsi_ctask_copy - copy skb bits to the destanation cmd task
  * @conn: iscsi tcp connection

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 15:31:54 UTC (rev 435)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 16:03:14 UTC (rev 436)
@@ -21,5 +21,7 @@
 extern int iscsi_scsi_data_in(struct iscsi_conn *conn);
 extern inline int iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn);
 
+extern int iscsi_tcp_hdr_recv_pre(struct iscsi_conn *conn);
+
 extern int iscsi_tcp_init(void);
 extern void iscsi_tcp_exit(void);



From tomo at berlios.de  Sat Apr 29 18:19:36 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:19:36 +0200
Subject: [Stgt-svn] r437 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291619.k3TGJaoF027607@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:19:35 +0200 (Sat, 29 Apr 2006)
New Revision: 437

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
Log:
Make iscsi_tcp_data_recv usable for others.


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:03:14 UTC (rev 436)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:19:35 UTC (rev 437)
@@ -853,10 +853,11 @@
  **/
 static int
 iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
-		unsigned int offset, size_t len)
+		    unsigned int offset, size_t len)
 {
 	int rc;
-	struct iscsi_conn *conn = rd_desc->arg.data;
+	struct data_ready_desc *d = rd_desc->arg.data;
+	struct iscsi_conn *conn = d->conn;
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
 	int processed;
 	char pad[ISCSI_PAD_LEN];
@@ -897,7 +898,7 @@
 		/*
 		 * Verify and process incoming PDU header.
 		 */
-		rc = iscsi_tcp_hdr_recv(conn);
+		rc = d->hdr_recv(conn);
 		if (!rc && tcp_conn->in.datalen) {
 			if (conn->datadgst_en) {
 				BUG_ON(!tcp_conn->data_rx_tfm);
@@ -939,7 +940,7 @@
 		debug_tcp("data_recv offset %d copy %d\n",
 		       tcp_conn->in.offset, tcp_conn->in.copy);
 
-		rc = iscsi_data_recv(conn);
+		rc = d->data_recv(conn);
 		if (rc) {
 			if (rc == -EAGAIN) {
 				rd_desc->count = tcp_conn->in.datalen -
@@ -999,11 +1000,16 @@
 {
 	struct iscsi_conn *conn = sk->sk_user_data;
 	read_descriptor_t rd_desc;
+	struct data_ready_desc d;
 
+	d.conn = conn;
+	d.hdr_recv = iscsi_tcp_hdr_recv;
+	d.data_recv = iscsi_data_recv;
+
 	read_lock(&sk->sk_callback_lock);
 
 	/* use rd_desc to pass 'conn' to iscsi_tcp_data_recv */
-	rd_desc.arg.data = conn;
+	rd_desc.arg.data = &d;
 	rd_desc.count = 0;
 	tcp_read_sock(sk, &rd_desc, iscsi_tcp_data_recv);
 

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 16:03:14 UTC (rev 436)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 16:19:35 UTC (rev 437)
@@ -177,4 +177,10 @@
 	int			digest_offset;		/* for partial buff digest */
 };
 
+struct data_ready_desc {
+	struct iscsi_conn *conn;
+	int (* hdr_recv)(struct iscsi_conn *conn);
+	int (* data_recv)(struct iscsi_conn *conn);
+};
+
 #endif /* ISCSI_H */



From tomo at berlios.de  Sat Apr 29 18:25:50 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:25:50 +0200
Subject: [Stgt-svn] r438 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291625.k3TGPo7r027902@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:25:50 +0200 (Sat, 29 Apr 2006)
New Revision: 438

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
Log:
Make iscsi_tcp_data_recv usable for others again.


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:19:35 UTC (rev 437)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:25:50 UTC (rev 438)
@@ -973,6 +973,8 @@
 	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
 	BUG_ON(tcp_conn->in.offset - offset > len);
 
+	d->finish(conn);
+
 	if (tcp_conn->in.offset - offset != len) {
 		debug_tcp("continue to process %d bytes\n",
 		       (int)len - (tcp_conn->in.offset - offset));

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 16:19:35 UTC (rev 437)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.h	2006-04-29 16:25:50 UTC (rev 438)
@@ -181,6 +181,7 @@
 	struct iscsi_conn *conn;
 	int (* hdr_recv)(struct iscsi_conn *conn);
 	int (* data_recv)(struct iscsi_conn *conn);
+	int (* finish)(struct iscsi_conn *conn);
 };
 
 #endif /* ISCSI_H */



From tomo at berlios.de  Sat Apr 29 18:33:31 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:33:31 +0200
Subject: [Stgt-svn] r439 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291633.k3TGXVmk031956@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:33:30 +0200 (Sat, 29 Apr 2006)
New Revision: 439

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
Log:
One more try for iscsi_tcp_data_recv


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:25:50 UTC (rev 438)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:33:30 UTC (rev 439)
@@ -851,7 +851,7 @@
  * @offset: offset in skb
  * @len: skb->len - offset
  **/
-static int
+int
 iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
 		    unsigned int offset, size_t len)
 {
@@ -973,7 +973,8 @@
 	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
 	BUG_ON(tcp_conn->in.offset - offset > len);
 
-	d->finish(conn);
+	if (d->finish)
+		d->finish(conn);
 
 	if (tcp_conn->in.offset - offset != len) {
 		debug_tcp("continue to process %d bytes\n",

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 16:25:50 UTC (rev 438)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_priv.h	2006-04-29 16:33:30 UTC (rev 439)
@@ -22,6 +22,8 @@
 extern inline int iscsi_tcp_copy(struct iscsi_tcp_conn *tcp_conn);
 
 extern int iscsi_tcp_hdr_recv_pre(struct iscsi_conn *conn);
+extern int iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
+			       unsigned int offset, size_t len);
 
 extern int iscsi_tcp_init(void);
 extern void iscsi_tcp_exit(void);



From tomo at berlios.de  Sat Apr 29 18:34:34 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:34:34 +0200
Subject: [Stgt-svn] r440 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291634.k3TGYYq1032214@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:34:32 +0200 (Sat, 29 Apr 2006)
New Revision: 440

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
iscsi_tcp_tgt.c can use iscsi_tcp_data_recv.


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:33:30 UTC (rev 439)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:34:32 UTC (rev 440)
@@ -318,61 +318,20 @@
  * the followings are taken from iscsi_tcp.
  */
 
-int iscsi_tcp_hdr_recv(struct iscsi_conn *conn)
+static int istgt_tcp_hdr_recv(struct iscsi_conn *conn)
 {
-	int rc = 0, opcode, ahslen;
+	int rc, opcode, ahslen;
 	struct iscsi_hdr *hdr;
 	struct iscsi_session *session = conn->session;
 	struct iscsi_cls_session *cls_session = session_to_cls(session);
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	struct Scsi_Host *shost;
 	uint32_t cdgst, rdgst = 0;
 	struct iscsi_cmd_task *ctask = NULL;
 
-	shost = iscsi_session_to_shost(cls_session);
-	hdr = tcp_conn->in.hdr;
+	rc = iscsi_tcp_hdr_recv_pre(conn);
+	if (rc)
+		return rc;
 
-	/* verify PDU length */
-	tcp_conn->in.datalen = ntoh24(hdr->dlength);
-	if (tcp_conn->in.datalen > conn->max_recv_dlength) {
-		printk(KERN_ERR "iscsi_tcp: datalen %d > %d\n",
-		       tcp_conn->in.datalen, conn->max_recv_dlength);
-		return ISCSI_ERR_DATALEN;
-	}
-	tcp_conn->data_copied = 0;
-
-	/* read AHS */
-	ahslen = hdr->hlength << 2;
-	tcp_conn->in.offset += ahslen;
-	tcp_conn->in.copy -= ahslen;
-	if (tcp_conn->in.copy < 0) {
-		printk(KERN_ERR "iscsi_tcp: can't handle AHS with length "
-		       "%d bytes\n", ahslen);
-		return ISCSI_ERR_AHSLEN;
-	}
-
-	/* calculate read padding */
-	tcp_conn->in.padding = tcp_conn->in.datalen & (ISCSI_PAD_LEN-1);
-	if (tcp_conn->in.padding) {
-		tcp_conn->in.padding = ISCSI_PAD_LEN - tcp_conn->in.padding;
-		dprintk("read padding %d bytes\n", tcp_conn->in.padding);
-	}
-
-	if (conn->hdrdgst_en) {
-		struct scatterlist sg;
-
-		sg_init_one(&sg, (u8 *)hdr,
-			    sizeof(struct iscsi_hdr) + ahslen);
-		crypto_digest_digest(tcp_conn->rx_tfm, &sg, 1, (u8 *)&cdgst);
-		rdgst = *(uint32_t*)((char*)hdr + sizeof(struct iscsi_hdr) +
-				     ahslen);
-		if (cdgst != rdgst) {
-			printk(KERN_ERR "iscsi_tcp: hdrdgst error "
-			       "recv 0x%x calc 0x%x\n", rdgst, cdgst);
-			return ISCSI_ERR_HDR_DGST;
-		}
-	}
-
 	opcode = hdr->opcode & ISCSI_OPCODE_MASK;
 	dprintk("opcode 0x%x offset %d copy %d ahslen %d datalen %d\n",
 		opcode, tcp_conn->in.offset, tcp_conn->in.copy,
@@ -412,7 +371,7 @@
 }
 
 static int
-iscsi_data_recv(struct iscsi_conn *conn)
+istgt_data_recv(struct iscsi_conn *conn)
 {
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
 	int rc = 0, opcode;
@@ -449,127 +408,10 @@
 	return rc;
 }
 
-static int
-iscsi_tcp_data_recv(read_descriptor_t *rd_desc, struct sk_buff *skb,
-		unsigned int offset, size_t len)
+static int stgt_pdu_recv_finish(struct iscsi_conn *conn)
 {
-	int rc;
-	struct iscsi_conn *conn = rd_desc->arg.data;
 	struct iscsi_tcp_conn *tcp_conn = conn->dd_data;
-	int processed;
-	char pad[ISCSI_PAD_LEN];
-	struct scatterlist sg;
 
-	/*
-	 * Save current SKB and its offset in the corresponding
-	 * connection context.
-	 */
-	tcp_conn->in.copy = skb->len - offset;
-	tcp_conn->in.offset = offset;
-	tcp_conn->in.skb = skb;
-	tcp_conn->in.len = tcp_conn->in.copy;
-	BUG_ON(tcp_conn->in.copy <= 0);
-	dprintk("in %d bytes\n", tcp_conn->in.copy);
-
-more:
-	tcp_conn->in.copied = 0;
-	rc = 0;
-
-	if (unlikely(conn->suspend_rx)) {
-		dprintk("conn %d Rx suspended!\n", conn->id);
-		return 0;
-	}
-
-	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER ||
-	    tcp_conn->in_progress == IN_PROGRESS_HEADER_GATHER) {
-		rc = iscsi_hdr_extract(tcp_conn);
-		if (rc) {
-		       if (rc == -EAGAIN)
-				goto nomore;
-		       else {
-				iscsi_conn_failure(conn, rc);
-				return 0;
-		       }
-		}
-
-		/*
-		 * Verify and process incoming PDU header.
-		 */
-		rc = iscsi_tcp_hdr_recv(conn);
-		if (!rc && tcp_conn->in.datalen) {
-			if (conn->datadgst_en) {
-				BUG_ON(!tcp_conn->data_rx_tfm);
-				crypto_digest_init(tcp_conn->data_rx_tfm);
-			}
-			tcp_conn->in_progress = IN_PROGRESS_DATA_RECV;
-		} else if (rc) {
-			iscsi_conn_failure(conn, rc);
-			return 0;
-		}
-	}
-
-	if (unlikely(conn->suspend_rx))
-		goto nomore;
-
-	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
-		uint32_t recv_digest;
-
-		dprintk("extra data_recv offset %d copy %d\n",
-			  tcp_conn->in.offset, tcp_conn->in.copy);
-		skb_copy_bits(tcp_conn->in.skb, tcp_conn->in.offset,
-				&recv_digest, 4);
-		tcp_conn->in.offset += 4;
-		tcp_conn->in.copy -= 4;
-		if (recv_digest != tcp_conn->in.datadgst) {
-			dprintk("iscsi_tcp: data digest error!"
-				  "0x%x != 0x%x\n", recv_digest,
-				  tcp_conn->in.datadgst);
-			iscsi_conn_failure(conn, ISCSI_ERR_DATA_DGST);
-			return 0;
-		} else {
-			dprintk("iscsi_tcp: data digest match!"
-				  "0x%x == 0x%x\n", recv_digest,
-				  tcp_conn->in.datadgst);
-			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-		}
-	}
-
-	if (tcp_conn->in_progress == IN_PROGRESS_DATA_RECV &&
-	   tcp_conn->in.copy) {
-
-		dprintk("data_recv offset %d copy %d\n",
-		       tcp_conn->in.offset, tcp_conn->in.copy);
-
-		rc = iscsi_data_recv(conn);
-		if (rc) {
-			if (rc == -EAGAIN)
-				goto again;
-			iscsi_conn_failure(conn, rc);
-			return 0;
-		}
-		tcp_conn->in.copy -= tcp_conn->in.padding;
-		tcp_conn->in.offset += tcp_conn->in.padding;
-		if (conn->datadgst_en) {
-			if (tcp_conn->in.padding) {
-				dprintk("padding -> %d\n",
-					  tcp_conn->in.padding);
-				memset(pad, 0, tcp_conn->in.padding);
-				sg_init_one(&sg, pad, tcp_conn->in.padding);
-				crypto_digest_update(tcp_conn->data_rx_tfm,
-						     &sg, 1);
-			}
-			crypto_digest_final(tcp_conn->data_rx_tfm,
-					    (u8 *) & tcp_conn->in.datadgst);
-			dprintk("rx digest 0x%x\n", tcp_conn->in.datadgst);
-			tcp_conn->in_progress = IN_PROGRESS_DDIGEST_RECV;
-		} else
-			tcp_conn->in_progress = IN_PROGRESS_WAIT_HEADER;
-	}
-
-	dprintk("f, processed %d from out of %d padding %d\n",
-	       tcp_conn->in.offset - offset, (int)len, tcp_conn->in.padding);
-	BUG_ON(tcp_conn->in.offset - offset > len);
-
 	if (tcp_conn->in_progress == IN_PROGRESS_WAIT_HEADER)
 		if (tcp_conn->in.ctask) {
 			struct iscsi_cls_session *cls_session =
@@ -582,26 +424,7 @@
 			schedule_work(&istgt_session->recvwork);
 		}
 
-	if (tcp_conn->in.offset - offset != len) {
-		dprintk("continue to process %d bytes\n",
-		       (int)len - (tcp_conn->in.offset - offset));
-		goto more;
-	}
-
-nomore:
-	processed = tcp_conn->in.offset - offset;
-	BUG_ON(processed == 0);
-	return processed;
-
-again:
-	processed = tcp_conn->in.offset - offset;
-	dprintk("c, processed %d from out of %d rd_desc_cnt %d\n",
-	          processed, (int)len, (int)rd_desc->count);
-	BUG_ON(processed == 0);
-	BUG_ON(processed > len);
-
-	conn->rxdata_octets += processed;
-	return processed;
+	return 0;
 }
 
 static void
@@ -609,11 +432,17 @@
 {
 	struct iscsi_conn *conn = sk->sk_user_data;
 	read_descriptor_t rd_desc;
+	struct data_ready_desc d;
 
+	d.conn = conn;
+	d.hdr_recv = istgt_tcp_hdr_recv;
+	d.data_recv = istgt_data_recv;
+	d.finish = istgt_pdu_recv_finish;
+
 	read_lock(&sk->sk_callback_lock);
 
 	/* use rd_desc to pass 'conn' to iscsi_tcp_data_recv */
-	rd_desc.arg.data = conn;
+	rd_desc.arg.data = &d;
 	rd_desc.count = 1;
 	tcp_read_sock(sk, &rd_desc, iscsi_tcp_data_recv);
 



From tomo at berlios.de  Sat Apr 29 18:36:57 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:36:57 +0200
Subject: [Stgt-svn] r441 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291636.k3TGav99000088@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:36:56 +0200 (Sat, 29 Apr 2006)
New Revision: 441

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
Just cleanup.

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:34:32 UTC (rev 440)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:36:56 UTC (rev 441)
@@ -1,10 +1,6 @@
 /*
  * iSCSI Target over TCP/IP
  *
- * Copyright (C) 2004 Dmitry Yusupov
- * Copyright (C) 2004 Alex Aizman
- * Copyright (C) 2005 - 2006 Mike Christie
- * Copyright (C) 2006 Red Hat, Inc.  All rights reserved.
  * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
  *
  * This program is free software; you can redistribute it and/or modify
@@ -21,18 +17,11 @@
  */
 
 /*
- * Most part is taken from iscsi_tcp. Integrating with iscsi_tcp would
- * be nice...
+ * This needs to be integrated with iscsi_tcp.
  */
-#include <linux/types.h>
 #include <linux/list.h>
 #include <linux/inet.h>
-#include <linux/blkdev.h>
-#include <linux/crypto.h>
-#include <linux/delay.h>
 #include <linux/kfifo.h>
-#include <linux/scatterlist.h>
-#include <linux/mutex.h>
 #include <net/tcp.h>
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_host.h>



From tomo at berlios.de  Sat Apr 29 18:39:29 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:39:29 +0200
Subject: [Stgt-svn] r442 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291639.k3TGdTKu000950@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:39:27 +0200 (Sat, 29 Apr 2006)
New Revision: 442

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
Log:
Clean up again.

Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:36:56 UTC (rev 441)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp_tgt.c	2006-04-29 16:39:27 UTC (rev 442)
@@ -1,7 +1,8 @@
 /*
  * iSCSI Target over TCP/IP
  *
- * Copyright (C) 2006 FUJITA Tomonori <tomof at acm.org>
+ * Copyright (C) 2004 - 2006 FUJITA Tomonori <tomof at acm.org>
+ * Copyright (C) 2005 - 2006 Mike Christie
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published
@@ -303,10 +304,6 @@
 /* 	ctask->r2t_data_count; */
 }
 
-/*
- * the followings are taken from iscsi_tcp.
- */
-
 static int istgt_tcp_hdr_recv(struct iscsi_conn *conn)
 {
 	int rc, opcode, ahslen;



From tomo at berlios.de  Sat Apr 29 18:45:09 2006
From: tomo at berlios.de (tomo at BerliOS)
Date: Sat, 29 Apr 2006 18:45:09 +0200
Subject: [Stgt-svn] r443 - branches/use-scsi-ml/istgt/kernel
Message-ID: <200604291645.k3TGj9V6003283@sheep.berlios.de>

Author: tomo
Date: 2006-04-29 18:45:06 +0200 (Sat, 29 Apr 2006)
New Revision: 443

Modified:
   branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
Log:
After iscsi_tgt_tcp receives a header, sometimes the buffer is not ready yet (e.g. unsolicited data). In such cases, iscsi_tcp_data_recv needs to stop reading data and return.


Modified: branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c
===================================================================
--- branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:39:27 UTC (rev 442)
+++ branches/use-scsi-ml/istgt/kernel/iscsi_tcp.c	2006-04-29 16:45:06 UTC (rev 443)
@@ -911,6 +911,9 @@
 		}
 	}
 
+	if (conn->suspend_rx)
+		goto nomore;
+
 	if (tcp_conn->in_progress == IN_PROGRESS_DDIGEST_RECV) {
 		uint32_t recv_digest;
 



